
# pyright: reportUnusedVariable=false, reportRedeclaration=false, reportGeneralTypeIssues=false
# pyright: reportUndefinedVariable=false, reportOptionalMemberAccess=false, reportAttributeAccessIssue=false
# type: ignore
# pylint: disable=all
# ---------------- Admin & blocking endpoints -----------------

# ...existing code...

import os, re, json, asyncio, threading, logging, pytz, time, subprocess, queue, sys, platform, traceback, uuid
from collections import defaultdict
from datetime import datetime, timedelta
from flask import Flask, render_template, jsonify, request, Response, send_from_directory
from telethon import TelegramClient

# Import expanded Ukraine addresses database
try:
    from ukraine_addresses_db import UKRAINE_ADDRESSES_DB, UKRAINE_CITIES
    print(f"INFO: Ukraine addresses database loaded: {len(UKRAINE_ADDRESSES_DB)} addresses")
except Exception as e:
    UKRAINE_ADDRESSES_DB = {}
    UKRAINE_CITIES = []
    print(f"WARNING: Ukraine addresses database not available: {e}")

# SpaCy integration for enhanced Ukrainian NLP
try:
    import spacy
    nlp = spacy.load('uk_core_news_sm')
    SPACY_AVAILABLE = True
    print("INFO: SpaCy Ukrainian model uk_core_news_sm loaded successfully")
except ImportError:
    SPACY_AVAILABLE = False
    nlp = None
    print("WARNING: SpaCy library not available - NLP analysis disabled")
except OSError:
    SPACY_AVAILABLE = False
    nlp = None
    print("WARNING: SpaCy Ukrainian model uk_core_news_sm not found - NLP analysis disabled")
    print("HINT: Install with: python -m spacy download uk_core_news_sm")
except Exception as e:
    SPACY_AVAILABLE = False
    nlp = None
    print(f"ERROR: SpaCy initialization failed: {e}")

# Nominatim geocoding integration
try:
    from nominatim_geocoder import get_coordinates_nominatim
    NOMINATIM_AVAILABLE = True
except ImportError:
    NOMINATIM_AVAILABLE = False
    def get_coordinates_nominatim(city_name, region=None):
        return None

# Gemini AI integration for message enhancement
try:
    from gemini_helper import fix_message_typos, extract_city_from_text, classify_threat_type, get_ai_stats, GEMINI_ENABLED
    print(f"INFO: Gemini AI helper loaded - {'ENABLED' if GEMINI_ENABLED else 'DISABLED (no API key)'}")
except ImportError as e:
    GEMINI_ENABLED = False
    print(f"WARNING: Gemini AI helper not available: {e}")
    def fix_message_typos(text): return text
    def extract_city_from_text(text, region=None): return None
    def classify_threat_type(text): return None
    def get_ai_stats(): return {'enabled': False}

# Groq AI integration for intelligent geocoding
GROQ_API_KEY = os.getenv('GROQ_API_KEY', '')
GROQ_ENABLED = bool(GROQ_API_KEY)

if GROQ_ENABLED:
    try:
        from groq import Groq
        groq_client = Groq(api_key=GROQ_API_KEY)
        print("INFO: Groq AI initialized successfully")
    except ImportError:
        GROQ_ENABLED = False
        groq_client = None
        print("WARNING: Groq library not installed. Run: pip install groq")
    except Exception as e:
        GROQ_ENABLED = False
        groq_client = None
        print(f"WARNING: Groq initialization failed: {e}")
else:
    groq_client = None
    print("INFO: Groq AI disabled (no API key)")

# Context-aware geocoding integration
try:
    from context_aware_geocoder import get_context_aware_geocoding
    CONTEXT_GEOCODER_AVAILABLE = True
except ImportError:
    CONTEXT_GEOCODER_AVAILABLE = False
    def get_context_aware_geocoding(text):
        return []
        return None
    nlp = None
    SPACY_AVAILABLE = False
    print("WARNING: SpaCy Ukrainian model not available. Using fallback geocoding methods.")
try:
    from telethon.errors import (
        AuthKeyDuplicatedError,
        AuthKeyUnregisteredError,
        FloodWaitError,
        SessionPasswordNeededError
    )
except ImportError:
    # Fallback dummies if some names not present in current Telethon version
    class AuthKeyDuplicatedError(Exception):
        pass
    class AuthKeyUnregisteredError(Exception):
        pass
    class FloodWaitError(Exception):
        def __init__(self, seconds=60): self.seconds = seconds
    class SessionPasswordNeededError(Exception):
        pass
from telethon.sessions import StringSession
import math

# === Kyiv Directional Enhancement Functions ===
def calculate_bearing(lat1, lon1, lat2, lon2):
    """Calculate bearing from point 1 to point 2 in degrees (0-360)"""
    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])
    
    dlon = lon2 - lon1
    y = math.sin(dlon) * math.cos(lat2)
    x = math.cos(lat1) * math.sin(lat2) - math.sin(lat1) * math.cos(lat2) * math.cos(dlon)
    
    bearing = math.atan2(y, x)
    bearing = math.degrees(bearing)
    return (bearing + 360) % 360

def get_kyiv_directional_coordinates(threat_text, original_city="київ"):
    """
    For Kyiv threats, calculate directional coordinates based on threat patterns
    Returns modified coordinates showing approach direction instead of city center
    """
    kyiv_lat, kyiv_lng = 50.4501, 30.5234
    threat_lower = threat_text.lower()
    
    # Try to extract source city/direction from course patterns
    course_patterns = [
        r'бпла.*?курс.*?на.*?київ.*?з\s+([а-яіїєё\s\-\']+?)(?:\s|$|[,\.\!])',
        r'бпла.*?курс.*?на.*?київ.*?від\s+([а-яіїєё\s\-\']+?)(?:\s|$|[,\.\!])', 
        r'([а-яіїєё\s\-\']+?).*?курс.*?на.*?київ',
        r'z\s+([а-яіїєё\s\-\']+?).*?курс.*?на.*?київ'
    ]
    
    source_city = None
    for pattern in course_patterns:
        matches = re.findall(pattern, threat_lower)
        if matches:
            potential_city = matches[0].strip()
            if potential_city and len(potential_city) > 2:
                # Clean up common noise words
                noise_words = {'бпла', 'курсом', 'курс', 'на', 'над', 'області', 'область', 'обл', 'район'}
                clean_city = ' '.join([word for word in potential_city.split() if word not in noise_words])
                if clean_city:
                    source_city = clean_city
                    break
    
    if source_city:
        # Try to find coordinates for source city (we'll need to implement a simple lookup)
        # For now, use some common approach directions
        approach_directions = {
            'чернігів': (51.4982, 31.2893, "↘ Київ"),
            'суми': (50.9077, 34.7981, "↙ Київ"), 
            'харків': (49.9935, 36.2304, "← Київ"),
            'полтава': (49.5883, 34.5514, "↖ Київ"),
            'черкаси': (49.4444, 32.0598, "↑ Київ"),
            'житомир': (50.2547, 28.6587, "→ Київ"),
            'біла церква': (49.7939, 30.1014, "↗ Київ")
        }
        
        if source_city in approach_directions:
            source_lat, source_lng, direction_label = approach_directions[source_city]
            
            # Calculate bearing from source to Kyiv
            bearing = calculate_bearing(source_lat, source_lng, kyiv_lat, kyiv_lng)
            
            # Place marker on approach path (70% of the way from source to Kyiv)
            progress = 0.7  # 70% towards Kyiv
            approach_lat = source_lat + (kyiv_lat - source_lat) * progress
            approach_lng = source_lng + (kyiv_lng - source_lng) * progress
            
            return approach_lat, approach_lng, f"{direction_label} ({int(bearing)}°)", source_city
    
    # Fallback: use directional keywords to offset from center
    direction_offsets = {
        'півдн': (-0.08, 0, "↑ Київ (Пд)"),      # south
        'півден': (-0.08, 0, "↑ Київ (Пд)"), 
        'пн': (0.08, 0, "↓ Київ (Пн)"),          # north
        'північ': (0.08, 0, "↓ Київ (Пн)"),
        'сх': (0, 0.08, "← Київ (Сх)"),          # east  
        'схід': (0, 0.08, "← Київ (Сх)"),
        'зх': (0, -0.08, "→ Київ (Зх)"),         # west
        'захід': (0, -0.08, "→ Київ (Зх)"),
        'пд-сх': (-0.06, 0.06, "↖ Київ (ПдСх)"), # southeast
        'пн-зх': (0.06, -0.06, "↘ Київ (ПнЗх)"), # northwest
    }
    
    for direction, (lat_offset, lng_offset, label) in direction_offsets.items():
        if direction in threat_lower:
            return (kyiv_lat + lat_offset, kyiv_lng + lng_offset, 
                   label, direction)
    
    # Default: return regular Kyiv coordinates
    return kyiv_lat, kyiv_lng, "Київ", None

def extract_shahed_course_info(threat_text):
    """
    Extract course information from Shahed/UAV threat messages
    Returns: (source_city, target_city, direction, bearing, course_type)
    """
    text_lower = threat_text.lower()
    
    # Common course patterns for Shahed/UAV
    course_patterns = [
        # "БпЛА курсом з [source] на [target]"
        r'бпла\s+.*?курс(?:ом)?\s+з\s+([а-яіїєё\s\-\']+?)\s+на\s+([а-яіїєё\s\-\']+?)(?:\s|$|[,\.\!])',
        # "БпЛА курсом на [target] з [source]"  
        r'бпла\s+.*?курс(?:ом)?\s+на\s+([а-яіїєё\s\-\']+?)\s+з\s+([а-яіїєё\s\-\']+?)(?:\s|$|[,\.\!])',
        # "БпЛА з [source] курсом на [target]"
        r'бпла\s+з\s+([а-яіїєё\s\-\']+?)\s+курс(?:ом)?\s+на\s+([а-яіїєё\s\-\']+?)(?:\s|$|[,\.\!])',
        # "БпЛА з [source] у напрямку [target]"
        r'бпла\s+з\s+([а-яіїєё\s\-\']+?)\s+у\s+напрямк[уи]\s+([а-яіїєё\s\-\']+?)(?:\s|$|[,\.\!])',
        # "БпЛА курсом на [target]" (target only)
        r'бпла\s+.*?курс(?:ом)?\s+на\s+([а-яіїєё\s\-\']+?)(?=\s*(?:\n|$|[,\.\!\?;]))',
        # "[count]х БпЛА курс [source]-[target]"
        r'\d*х?\s*бпла\s+курс\s+([а-яіїєё\s\-\']+?)\s*[-–—]\s*([а-яіїєё\s\-\']+?)(?:\s|$|[,\.\!])',
    ]
    
    # Try to extract course information
    for pattern_idx, pattern in enumerate(course_patterns):
        matches = re.findall(pattern, text_lower)
        if matches:
            match = matches[0]
            
            if pattern_idx == 0:  # з source на target
                source = match[0].strip()
                target = match[1].strip()
            elif pattern_idx == 1:  # на target з source  
                target = match[0].strip()
                source = match[1].strip()
            elif pattern_idx == 2:  # з source курсом на target
                source = match[0].strip()
                target = match[1].strip()
            elif pattern_idx == 3:  # з source у напрямку target
                source = match[0].strip()
                target = match[1].strip()
            elif pattern_idx == 4:  # курсом на target (no source)
                source = None
                target = match.strip() if isinstance(match, str) else match[0].strip()
            elif pattern_idx == 5:  # курс source-target
                source = match[0].strip()
                target = match[1].strip()
            
            # Clean up noise words
            noise_words = {'область', 'обл', 'район', 'р-н', 'на', 'з', 'від', 'до'}
            if source:
                source = ' '.join([word for word in source.split() if word not in noise_words]).strip()
            if target:
                target = ' '.join([word for word in target.split() if word not in noise_words]).strip()
            
            # Determine course type
            if source and target:
                course_type = "full_course"  # Full trajectory
            elif target:
                course_type = "target_only"  # Only destination
            else:
                course_type = "unknown"
                
            return {
                'source_city': source,
                'target_city': target,
                'course_direction': f"на {target}" if target else None,
                'raw_direction': None,
                'course_type': course_type
            }
    
    # Try to extract directional information
    direction_patterns = {
        'північ': 'N', 'північний': 'N', 'пн': 'N',
        'південь': 'S', 'південний': 'S', 'пд': 'S', 
        'схід': 'E', 'східний': 'E', 'сх': 'E',
        'захід': 'W', 'західний': 'W', 'зх': 'W',
        'північно-східний': 'NE', 'пн-сх': 'NE',
        'північно-західний': 'NW', 'пн-зх': 'NW', 
        'південно-східний': 'SE', 'пд-сх': 'SE',
        'південно-західний': 'SW', 'пд-зх': 'SW'
    }
    
    for direction_ukr, direction_eng in direction_patterns.items():
        if direction_ukr in text_lower:
            return {
                'source_city': None,
                'target_city': None,
                'course_direction': direction_eng,
                'raw_direction': direction_ukr,
                'course_type': "directional"
            }
    
    return None

# Basic minimal subset for Render deployment. Heavy ML parts stripped for now.
# Load secrets from a local hidden .env file (key=value) if present (for local dev),
# then fall back to environment variables (for Render / production).

def _load_local_env(path: str = '.env'):
    if not os.path.exists(path):
        return
    try:
        with open(path, encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if not line or line.startswith('#'):
                    continue
                if '=' not in line:
                    continue
                k, v = line.split('=', 1)
                k = k.strip(); v = v.strip().strip('"').strip("'")
                # don't override already exported env vars
                if k and k not in os.environ:
                    os.environ[k] = v
    except Exception as e:
        logging.warning(f"Failed to load .env file: {e}")

_load_local_env()

API_ID = int(os.getenv('TELEGRAM_API_ID', '0') or '0')
API_HASH = os.getenv('TELEGRAM_API_HASH', '')
_DEFAULT_CHANNELS = 'UkraineAlarmSignal,kpszsu,war_monitor,napramok,raketa_trevoga'
# TELEGRAM_CHANNELS env var (comma-separated) overrides; fallback includes numeric channel ID.
CHANNELS = [c.strip() for c in os.getenv('TELEGRAM_CHANNELS', _DEFAULT_CHANNELS).split(',') if c.strip()]

# Channels which failed resolution (entity not found / access denied) to avoid repeated spam
INVALID_CHANNELS = set()
GOOGLE_MAPS_KEY = os.getenv('GOOGLE_MAPS_KEY', '')
OPENCAGE_API_KEY = os.getenv('OPENCAGE_API_KEY', '')  # optional geocoding
ALWAYS_STORE_RAW = os.getenv('ALWAYS_STORE_RAW', '1') not in ('0','false','False')

logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s %(message)s')
log = logging.getLogger(__name__)

app = Flask(__name__)

# Shared rate tracking for lightweight bandwidth protection rules
request_counts = defaultdict(list)

# Presence counter configuration
VALID_PLATFORMS = {'web', 'android', 'ios'}
PRESENCE_RATE_WINDOW = 30  # seconds
PRESENCE_RATE_LIMIT = 3    # max requests per window per IP

# Scheduler removed - no longer needed for blackout schedules

# BANDWIDTH OPTIMIZATION: Rate limiting to prevent abuse
    # Rate limiting отключен: все пользователи имеют свободный доступ

# BANDWIDTH OPTIMIZATION: Enable gzip compression globally
import gzip
import io

# Add global response compression
@app.after_request
def compress_response(response):
    """Apply gzip compression to reduce bandwidth usage."""
    if (
        response.status_code == 200 and
        'gzip' in request.headers.get('Accept-Encoding', '').lower() and
        response.content_length and response.content_length > 500 and
        response.content_type.startswith(('application/json', 'text/html', 'text/css', 'application/javascript'))
    ):
        try:
            # Compress the response data
            buffer = io.BytesIO()
            with gzip.GzipFile(fileobj=buffer, mode='wb') as f:
                f.write(response.get_data())
            
            response.set_data(buffer.getvalue())
            response.headers['Content-Encoding'] = 'gzip'
            response.headers['Content-Length'] = len(response.get_data())
            response.headers['Vary'] = 'Accept-Encoding'
        except Exception:
            pass  # If compression fails, return original response
    
    # Add cache headers for static content
    if request.endpoint == 'static':
        response.headers['Cache-Control'] = 'public, max-age=86400'  # 24 hours
    
    return response

# Custom route for serving pre-compressed static files
@app.route('/static/<path:filename>')
def static_with_gzip(filename):
    """Serve static files with gzip compression support."""
    # Rate limiting removed
    # ...existing code...
    """Serve static files with gzip compression support."""
    
    # CRITICAL BANDWIDTH PROTECTION: Rate limit static files
    client_ip = request.environ.get('HTTP_X_FORWARDED_FOR', request.remote_addr)
    static_requests = request_counts.get(f"{client_ip}_static", [])
    now_time = time.time()
    
    # Clean old requests (last 60 seconds)
    static_requests = [req_time for req_time in static_requests if now_time - req_time < 60]
    
    # Allow only 5 static file requests per minute per IP
    if len(static_requests) >= 5:
        print(f"[CRITICAL BANDWIDTH] Blocking static file {filename} from {client_ip} - too many requests")
        return jsonify({'error': 'Static files rate limited - wait 1 minute'}), 429
    
    static_requests.append(now_time)
    request_counts[f"{client_ip}_static"] = static_requests
        # Rate limiting removed
    
    # SMART BANDWIDTH PROTECTION: Block only genuinely large files (>1MB)
    try:
        static_folder = os.path.join(os.path.dirname(__file__), 'static')
        file_path = os.path.join(static_folder, filename)
        
        if os.path.exists(file_path):
            file_size = os.path.getsize(file_path)
            
            # Block files larger than 1MB to save bandwidth
            if file_size > 1024 * 1024:  # 1MB limit 
                print(f"[BANDWIDTH PROTECTION] Blocking large file {filename} ({file_size//1024}KB) from {client_ip}")
                return jsonify({'error': f'Large file blocked - size {file_size//1024}KB exceeds 1MB limit'}), 503
                
            # Log access to files over 100KB for monitoring
            if file_size > 100 * 1024:
                print(f"[BANDWIDTH MONITOR] Serving large file {filename} ({file_size//1024}KB) to {client_ip}")
        else:
            print(f"[STATIC FILE] File not found: {filename}")
            return jsonify({'error': 'File not found'}), 404
            
    except Exception as e:
        print(f"[BANDWIDTH ERROR] Error checking file {filename}: {e}")
        return jsonify({'error': 'File access error'}), 500
    
    # Check if client accepts gzip and we have a gzipped version
    accepts_gzip = 'gzip' in request.headers.get('Accept-Encoding', '').lower()
    
    if accepts_gzip and filename.endswith('.js'):
        gzip_path = os.path.join(app.static_folder, filename + '.gz')
        if os.path.exists(gzip_path):
            response = send_from_directory(app.static_folder, filename + '.gz')
            response.headers['Content-Encoding'] = 'gzip'
            response.headers['Content-Type'] = 'application/javascript; charset=utf-8'
            
            # Add strong caching for JS files
            response.headers['Cache-Control'] = 'public, max-age=31536000, immutable'
            response.headers['Expires'] = (datetime.now() + timedelta(days=365)).strftime('%a, %d %b %Y %H:%M:%S GMT')
            
            return response
    
    # Fall back to regular static file serving
    response = send_from_directory(app.static_folder, filename)
    
    # CRITICAL BANDWIDTH PROTECTION: Check file size
    try:
        file_path = os.path.join(app.static_folder, filename)
        if os.path.exists(file_path):
            file_size = os.path.getsize(file_path)
            if file_size > 100 * 1024:  # 100KB limit
                print(f"[CRITICAL BANDWIDTH] Large static file {filename}: {file_size/1024:.1f}KB from {client_ip}")
    except Exception:
        pass
    
    return response

# Configure caching and compression for better performance on slow connections
app.config['SEND_FILE_MAX_AGE_DEFAULT'] = 31536000  # 1 year for static files
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16MB max file size

# Add cache headers for static files
@app.after_request
def add_cache_headers(response):
    if request.endpoint == 'static':
        # Check if this is a versioned resource (with ?v= parameter)
        if 'v=' in request.query_string.decode():
            # Cache versioned static files for 1 month (they won't change)
            response.headers['Cache-Control'] = 'public, max-age=2592000, immutable'
            response.headers['Expires'] = (datetime.now() + timedelta(days=30)).strftime('%a, %d %b %Y %H:%M:%S GMT')
        else:
            # Cache regular static files for 1 week
            response.headers['Cache-Control'] = 'public, max-age=604800, immutable'
            response.headers['Expires'] = (datetime.now() + timedelta(days=7)).strftime('%a, %d %b %Y %H:%M:%S GMT')
        
        # Add compression hints for images
        if request.path.endswith(('.png', '.jpg', '.jpeg', '.webp')):
            response.headers['Vary'] = 'Accept-Encoding'
            # Add ETag for better caching
            response.headers['ETag'] = f'"{hash(request.path + request.query_string.decode())}"'
            
    elif request.endpoint == 'index':
        # Cache main page for 5 minutes
        response.headers['Cache-Control'] = 'public, max-age=300'
        
    return response
COMMENTS = []  # retained as a small in-memory cache (recent) but now persisted to SQLite
COMMENTS_MAX = 500
ACTIVE_VISITORS = {}
ACTIVE_LOCK = threading.Lock()
ACTIVE_TTL = 70  # seconds of inactivity before a visitor is dropped
BLOCKED_FILE = 'blocked_ids.json'
STATS_FILE = 'visits_stats.json'  # persistent first-seen timestamps per visitor id
RECENT_VISITS_FILE = 'visits_recent.json'  # stores rolling today/week visitor id sets for fast counts
VISIT_STATS = None  # lazy-loaded dict: {id: first_seen_epoch}
FORCE_RELOAD_TIMESTAMP = 0  # Timestamp when force reload was triggered
FORCE_RELOAD_DURATION = 120  # Duration in seconds to keep force reload active (2 minutes)
FORCE_RELOAD_LOCK = threading.Lock()
client = None
session_str = os.getenv('TELEGRAM_SESSION')  # Telethon string session (recommended for Render)
BOT_TOKEN = os.getenv('TELEGRAM_BOT_TOKEN')  # optional bot token fallback
AUTH_SECRET = os.getenv('AUTH_SECRET')  # simple shared secret to protect /auth endpoints
FETCH_THREAD_STARTED = False
AUTH_STATUS = {'authorized': False, 'reason': 'init'}
SUBSCRIBERS = set()  # queues for SSE clients
INIT_ONCE = False  # guard to ensure background startup once
# Persistent dynamic channels file
CHANNELS_FILE = 'channels_dynamic.json'

# Global debug storage for admin panel
DEBUG_LOGS = []
MAX_DEBUG_LOGS = 100

# Cache for fallback reparse to avoid duplicate processing
FALLBACK_REPARSE_CACHE = set()  # message IDs that have been reparsed
MAX_REPARSE_CACHE_SIZE = 1000  # Limit cache size to prevent memory growth


def _normalize_platform(platform_hint: str, ua: str) -> str:
    """Map arbitrary client hints to canonical platform buckets."""
    candidate = (platform_hint or '').strip().lower()
    if candidate in VALID_PLATFORMS:
        return candidate

    ua_lower = (ua or '').lower()
    if 'android' in ua_lower:
        return 'android'
    if any(token in ua_lower for token in ('iphone', 'ipad', 'ios', 'cfnetwork')):
        return 'ios'
    return 'web'

def add_debug_log(message, category="general"):
    """Add debug message to global debug storage for admin panel."""
    global DEBUG_LOGS
    DEBUG_LOGS.append({
        'timestamp': datetime.now().isoformat(),
        'category': category,
        'message': str(message)
    })
    # Keep only recent logs
    if len(DEBUG_LOGS) > MAX_DEBUG_LOGS:
        DEBUG_LOGS = DEBUG_LOGS[-MAX_DEBUG_LOGS:]

# -------- Air alarm tracking (oblast / raion) --------
APP_ALARM_TTL_MINUTES = 65  # auto-expire if no update ~1h
ACTIVE_OBLAST_ALARMS = {}   # canonical oblast key -> {'since': epoch, 'last': epoch}
ACTIVE_RAION_ALARMS = {}    # raion base (lowercase) -> {'since': epoch, 'last': epoch}

# P-code mapping for ADM1 (області + special status cities)
OBLAST_PCODE = {
    'автономна республіка крим': 'UA01',
    'вінницька область': 'UA05',
    'волинська область': 'UA07',
    'дніпропетровська область': 'UA12',
    'донецька область': 'UA14',
    'житомирська область': 'UA18',
    'закарпатська область': 'UA21',
    'запорізька область': 'UA23',
    'івано-франківська область': 'UA26',
    'київська область': 'UA32',
    'кіровоградська область': 'UA35',
    'луганська область': 'UA44',
    'львівська область': 'UA46',
    'миколаївська область': 'UA48',
    'одеська область': 'UA51',
    'полтавська область': 'UA53',
    'рівненська область': 'UA56',
    'сумська область': 'UA59',
    'тернопільська область': 'UA61',
    'харківська область': 'UA63',
    'херсонська область': 'UA65',
    'хмельницька область': 'UA68',
    'черкаська область': 'UA71',
    'чернівецька область': 'UA73',
    'чернігівська область': 'UA74',
    'київ': 'UA80',
    'севастополь': 'UA85'
}

# ---- Alarm persistence (SQLite) ----
def init_alarms_db():
    try:
        with _visits_db_conn() as conn:
            conn.execute("""
                CREATE TABLE IF NOT EXISTS alarms (
                    id TEXT PRIMARY KEY,
                    level TEXT,
                    name TEXT,
                    since REAL,
                    last REAL
                )
            """)
            conn.execute("CREATE INDEX IF NOT EXISTS idx_alarms_level ON alarms(level)")
    except Exception as e:
        log.warning(f"alarms db init failed: {e}")

def init_alarm_events_db():
    try:
        with _visits_db_conn() as conn:
            conn.execute("""
                CREATE TABLE IF NOT EXISTS alarm_events (
                    id TEXT PRIMARY KEY,
                    level TEXT,
                    name TEXT,
                    event TEXT,
                    ts REAL
                )
            """)
            conn.execute("CREATE INDEX IF NOT EXISTS idx_alarm_events_time ON alarm_events(ts)")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_alarm_events_name ON alarm_events(name)")
    except Exception as e:
        log.warning(f"alarm_events db init failed: {e}")

def log_alarm_event(level:str, name:str, event:str, ts=None):
    ts = ts or time.time()
    try:
        with _visits_db_conn() as conn:
            conn.execute("INSERT INTO alarm_events (id,level,name,event,ts) VALUES (?,?,?,?,?)",
                         (uuid.uuid4().hex[:12], level, name, event, ts))
    except Exception as e:
        log.debug(f"log_alarm_event failed: {e}")

def _alarm_key(level:str, name:str)->str:
    return f"{level}:{name}".lower()

def persist_alarm(level:str, name:str, since:float, last:float):
    try:
        with _visits_db_conn() as conn:
            conn.execute("INSERT OR REPLACE INTO alarms (id,level,name,since,last) VALUES (?,?,?,?,?)",
                         (_alarm_key(level,name), level, name, since, last))
    except Exception as e:
        log.debug(f"persist_alarm failed: {e}")

def remove_alarm(level:str, name:str):
    try:
        with _visits_db_conn() as conn:
            conn.execute("DELETE FROM alarms WHERE id=?", (_alarm_key(level,name),))
    except Exception as e:
        log.debug(f"remove_alarm failed: {e}")

def load_active_alarms(ttl_seconds:int):
    out_obl = {}
    out_raion = {}
    cutoff = time.time() - ttl_seconds
    try:
        with _visits_db_conn() as conn:
            cur = conn.execute("SELECT level,name,since,last FROM alarms WHERE last >= ?", (cutoff,))
            for level,name,since,last in cur.fetchall():
                if level == 'oblast': out_obl[name] = {'since': since, 'last': last}
                elif level == 'raion': out_raion[name] = {'since': since, 'last': last}
    except Exception as e:
        log.debug(f"load_active_alarms failed: {e}")
    return out_obl, out_raion

def load_dynamic_channels():
    try:
        if os.path.exists(CHANNELS_FILE):
            with open(CHANNELS_FILE,'r',encoding='utf-8') as f:
                dyn = json.load(f)
            if isinstance(dyn, list):
                return [str(x).strip() for x in dyn if x]
    except Exception as e:
        log.warning(f'Failed loading {CHANNELS_FILE}: {e}')
    return []

def save_dynamic_channels(extra):
    try:
        with open(CHANNELS_FILE,'w',encoding='utf-8') as f:
            json.dump(extra, f, ensure_ascii=False, indent=2)
    except Exception as e:
        log.warning(f'Failed saving {CHANNELS_FILE}: {e}')

_dyn = load_dynamic_channels()
if _dyn:
    # Merge without duplicates
    base = [c.strip() for c in CHANNELS if c.strip()]
    for d in _dyn:
        if d not in base:
            base.append(d)
    CHANNELS = base
# ---------------- Monitoring period global config (admin editable) ----------------
CONFIG_FILE = 'config.json'
MONITOR_PERIOD_MINUTES = 30  # default; editable only via admin panel

def load_config():
    """Load persisted configuration (currently only monitor period)."""
    global MONITOR_PERIOD_MINUTES
    try:
        if os.path.exists(CONFIG_FILE):
            with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
                cfg = json.load(f)
            # Validate range 1..360 else ignore
            mp = int(cfg.get('monitor_period', MONITOR_PERIOD_MINUTES))
            if 1 <= mp <= 360:
                MONITOR_PERIOD_MINUTES = mp
    except Exception as e:
        log.warning(f'Failed loading {CONFIG_FILE}: {e}')

def save_config():
    try:
        with open(CONFIG_FILE, 'w', encoding='utf-8') as f:
            json.dump({'monitor_period': MONITOR_PERIOD_MINUTES}, f, ensure_ascii=False, indent=2)
    except Exception as e:
        log.warning(f'Failed saving {CONFIG_FILE}: {e}')

load_config()
if API_ID and API_HASH:
    if session_str:
        log.info('Initializing Telegram client with TELEGRAM_SESSION string.')
        client = TelegramClient(StringSession(session_str), API_ID, API_HASH)
    elif BOT_TOKEN:
        log.info('Initializing Telegram client with BOT token (limited access).')
        # Bot sessions auto-authorize on start
        client = TelegramClient(StringSession(), API_ID, API_HASH)
    else:
        log.info('Initializing Telegram client with local session file (may not persist on Render).')
        client = TelegramClient('anon', API_ID, API_HASH)

MESSAGES_FILE = 'messages.json'
HIDDEN_FILE = 'hidden_markers.json'
OPENCAGE_CACHE_FILE = 'opencage_cache.json'
OPENCAGE_TTL = 60 * 60 * 24 * 30  # 30 days
NEG_GEOCODE_FILE = 'negative_geocode_cache.json'
NEG_GEOCODE_TTL = 60 * 60 * 24 * 3  # 3 days for 'not found' entries
MESSAGES_RETENTION_MINUTES = int(os.getenv('MESSAGES_RETENTION_MINUTES', '1440'))  # 24 hours retention by default
MESSAGES_MAX_COUNT = int(os.getenv('MESSAGES_MAX_COUNT', '0'))  # 0 = unlimited

def _startup_diagnostics():
    """Log one-time startup diagnostics to help investigate early exit issues on hosting platforms."""
    try:
        log.info('--- Startup diagnostics begin ---')
        log.info(f'Python: {sys.version.split()[0]} Platform: {platform.platform()} PID: {os.getpid()}')
        log.info(f'Flask version: {getattr(sys.modules.get("flask"), "__version__", "?")} Telethon version: {getattr(sys.modules.get("telethon"), "__version__", "?")}')
        log.info(f'Configured channels ({len(CHANNELS)}): {CHANNELS}')
        log.info(f'API_ID set: {bool(API_ID)} HASH set: {bool(API_HASH)} SESSION len: {len(session_str) if session_str else 0}')
        log.info(f'GOOGLE_MAPS_KEY set: {bool(GOOGLE_MAPS_KEY)} OPENCAGE_API_KEY set: {bool(OPENCAGE_API_KEY)}')
        if os.path.exists(MESSAGES_FILE):
            try:
                sz = os.path.getsize(MESSAGES_FILE)
                log.info(f'{MESSAGES_FILE} exists size={sz} bytes')
            except Exception:
                pass
        else:
            log.info(f'{MESSAGES_FILE} not present yet.')
        log.info(f'Retention minutes: {MESSAGES_RETENTION_MINUTES} Max count: {MESSAGES_MAX_COUNT}')
        log.info(f'FETCH_START_DELAY={os.getenv("FETCH_START_DELAY", "0")}')
        log.info('--- Startup diagnostics end ---')
    except Exception as e:
        log.warning(f'Diagnostics error: {e}')

def _prune_messages(data):
    """Apply retention policies (time / count). Mutates and returns list."""
    if not data:
        return data
    # Time based pruning
    if MESSAGES_RETENTION_MINUTES > 0:
        cutoff = datetime.utcnow() - timedelta(minutes=MESSAGES_RETENTION_MINUTES)
        pruned = []
        for m in data:
            try:
                dt = datetime.strptime(m.get('date',''), '%Y-%m-%d %H:%M:%S')
            except Exception:
                # keep malformed to avoid data loss
                pruned.append(m)
                continue
            if dt.replace(tzinfo=None) >= cutoff:
                pruned.append(m)
        data = pruned
    # Count based pruning (keep newest by date)
    if MESSAGES_MAX_COUNT > 0 and len(data) > MESSAGES_MAX_COUNT:
        try:
            data_sorted = sorted(data, key=lambda x: x.get('date',''))
            data = data_sorted[-MESSAGES_MAX_COUNT:]
        except Exception:
            data = data[-MESSAGES_MAX_COUNT:]
    return data

def load_messages():
    if os.path.exists(MESSAGES_FILE):
        try:
            with open(MESSAGES_FILE, encoding='utf-8') as f:
                return json.load(f)
        except Exception:
            return []
    return []

def save_messages(data):
    # Apply retention before persistence
    try:
        data = _prune_messages(data)
    except Exception as e:
        log.debug(f'Retention prune error: {e}')
    print(f"DEBUG: Saving {len(data)} messages to file")
    with open(MESSAGES_FILE, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    # After each save attempt optional git auto-commit
    try:
        maybe_git_autocommit()
    except Exception as e:
        log.debug(f'git auto-commit skipped: {e}')

# ---------------- Deduplication / merge of near-duplicate geo events -----------------
# Two messages that refer to the same object coming almost back-to-back should not
# produce two separate points: instead we update the earlier one (increment count, merge text).
# Heuristics: same threat_type, within DEDUP_DIST_KM km, within DEDUP_TIME_MIN minutes.
DEDUP_TIME_MIN = int(os.getenv('DEDUP_TIME_MIN', '5'))
DEDUP_DIST_KM = float(os.getenv('DEDUP_DIST_KM', '7'))
DEDUP_SCAN_BACK = int(os.getenv('DEDUP_SCAN_BACK', '400'))  # how many recent messages to scan

def _parse_dt(s:str):
    try:
        return datetime.strptime(s, '%Y-%m-%d %H:%M:%S')
    except Exception:
        return None

def _haversine_km(lat1, lon1, lat2, lon2):
    try:
        from math import radians, sin, cos, asin, sqrt
        R = 6371.0
        dlat = radians(lat2-lat1)
        dlon = radians(lon2-lon1)
        a = sin(dlat/2)**2 + cos(radians(lat1))*cos(radians(lat2))*sin(dlon/2)**2
        c = 2*asin(sqrt(a))
        return R*c
    except Exception:
        return 999999

def maybe_merge_track(all_data:list, new_track:dict):
    """Try to merge new_track into an existing recent track.
    Returns tuple (merged: bool, track_ref: dict).
    """
    try:
        if not all_data:
            return False, new_track
        tt = (new_track.get('threat_type') or '').lower()
        if not tt:
            return False, new_track
        lat = new_track.get('lat'); lng = new_track.get('lng')
        if not isinstance(lat, (int,float)) or not isinstance(lng, (int,float)):
            return False, new_track
        new_dt = _parse_dt(new_track.get('date','')) or datetime.utcnow()
        # Scan recent slice only for performance
        scan_slice = all_data[-DEDUP_SCAN_BACK:]
        # Iterate reversed (newest first)
        for existing in reversed(scan_slice):
            if existing is new_track:  # shouldn't happen yet
                continue
            if (existing.get('threat_type') or '').lower() != tt:
                continue
            e_lat = existing.get('lat'); e_lng = existing.get('lng')
            if not isinstance(e_lat,(int,float)) or not isinstance(e_lng,(int,float)):
                continue
            dist = _haversine_km(lat,lng,e_lat,e_lng)
            if dist > DEDUP_DIST_KM:
                continue
            e_dt = _parse_dt(existing.get('date','')) or new_dt
            dt_min = abs((new_dt - e_dt).total_seconds())/60.0
            if dt_min > DEDUP_TIME_MIN:
                continue
            # Merge
            # Increment count
            existing['count'] = int(existing.get('count') or 1) + 1
            # Merge text (avoid duplication / uncontrolled growth)
            new_text = (new_track.get('text') or '').strip()
            if new_text:
                ex_text = existing.get('text') or ''
                if new_text not in ex_text:
                    combined = (ex_text + ' | ' + new_text).strip(' |') if ex_text else new_text
                    if len(combined) > 800:
                        combined = combined[:790] + '…'
                    existing['text'] = combined
            # Maintain list of merged ids
            if 'merged_ids' not in existing:
                existing['merged_ids'] = [existing.get('id')]
            nid = new_track.get('id')
            if nid and nid not in existing['merged_ids']:
                existing['merged_ids'].append(nid)
            # Update displayed date to the most recent
            if new_dt >= e_dt:
                existing['date'] = new_track.get('date') or existing.get('date')
            # Optionally capture first occurrence time
            if 'first_date' not in existing:
                existing['first_date'] = e_dt.strftime('%Y-%m-%d %H:%M:%S')
            existing['merged'] = True
            return True, existing
    except Exception as e:
        log.debug(f'dedup merge error: {e}')
    return False, new_track


def load_hidden():
    if os.path.exists(HIDDEN_FILE):
        try:
            with open(HIDDEN_FILE, encoding='utf-8') as f:
                return json.load(f)
        except Exception:
            return []
    return []

def save_hidden(data):
    with open(HIDDEN_FILE, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def load_blocked():
    if os.path.exists(BLOCKED_FILE):
        try:
            with open(BLOCKED_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception:
            return []
    return []

def save_blocked(blocked):
    try:
        with open(BLOCKED_FILE, 'w', encoding='utf-8') as f:
            json.dump(blocked, f, ensure_ascii=False, indent=2)
    except Exception as e:
        log.warning(f'Failed saving {BLOCKED_FILE}: {e}')

def _load_visit_stats():
    global VISIT_STATS
    if VISIT_STATS is not None:
        return VISIT_STATS
    if os.path.exists(STATS_FILE):
        try:
            with open(STATS_FILE,'r',encoding='utf-8') as f:
                VISIT_STATS = json.load(f)
        except Exception:
            VISIT_STATS = {}
    else:
        VISIT_STATS = {}
    return VISIT_STATS

def _save_visit_stats():
    if VISIT_STATS is None:
        return
    try:
        with open(STATS_FILE,'w',encoding='utf-8') as f:
            json.dump(VISIT_STATS, f, ensure_ascii=False, indent=2)
    except Exception as e:
        log.warning(f'Failed saving {STATS_FILE}: {e}')

def _prune_visit_stats(days:int=45):
    # remove entries older than N days to limit file growth
    if VISIT_STATS is None:
        return
    cutoff = time.time() - days*86400
    removed = 0
    for vid, ts in list(VISIT_STATS.items()):
        try:
            if float(ts) < cutoff:
                del VISIT_STATS[vid]
                removed += 1
        except Exception:
            continue
    if removed:
        _save_visit_stats()

# ---- Rolling daily / weekly visit tracking (for persistence of counts across deploys) ----
def _load_recent_visits():
    try:
        if os.path.exists(RECENT_VISITS_FILE):
            # Guard against oversized/corrupted file (e.g. concurrent writes producing concatenated JSON objects)
            try:
                raw = open(RECENT_VISITS_FILE, 'r', encoding='utf-8').read()
            except Exception as e_read:
                log.warning(f"Failed reading {RECENT_VISITS_FILE}: {e_read}")
                return {}
            # Quick heuristic: if multiple top-level JSON objects concatenated, keep first valid
            data = None
            if raw.strip():
                try:
                    data = json.loads(raw)
                except json.JSONDecodeError as je:
                    # Try to split by newlines and stitch until first valid JSON object
                    fragments = raw.splitlines()
                    buf = ''
                    for line in fragments:
                        buf += line.strip() + '\n'
                        try:
                            data = json.loads(buf)
                            log.warning(f"Recovered first valid JSON segment from {RECENT_VISITS_FILE} after decode error: {je}")
                            break
                        except Exception:
                            continue
                    if data is None:
                        log.warning(f"Unable to repair {RECENT_VISITS_FILE}: {je}")
                        return {}
                except Exception as e_generic:
                    log.warning(f"Generic JSON load failure {RECENT_VISITS_FILE}: {e_generic}")
                    return {}
            else:
                return {}
            if not isinstance(data, dict):
                log.warning(f"Unexpected structure in {RECENT_VISITS_FILE}, resetting")
                return {}
            data.setdefault('day', '')
            data.setdefault('week_start', '')
            data.setdefault('today_ids', [])
            data.setdefault('week_ids', [])
            return data
    except Exception as e:
        log.warning(f"Failed loading {RECENT_VISITS_FILE}: {e}")
    return {}

def _save_recent_visits(data:dict):
    try:
        tmp = RECENT_VISITS_FILE + '.tmp'
        # Ensure directory exists (in case path was changed to subfolder later); here file in CWD so skip
        with open(tmp, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        try:
            os.replace(tmp, RECENT_VISITS_FILE)
        except FileNotFoundError:
            # Rare race on some FS / AV scanners: fall back to simple write
            try:
                with open(RECENT_VISITS_FILE, 'w', encoding='utf-8') as f2:
                    json.dump(data, f2, ensure_ascii=False, indent=2)
            except Exception as e2:
                log.warning(f"Fallback direct save failed {RECENT_VISITS_FILE}: {e2}")
    except Exception as e:
        log.warning(f"Failed saving {RECENT_VISITS_FILE}: {e}")

def _update_recent_visits(vid:str):
    """Update rolling daily/week sets with visitor id. Uses Europe/Kyiv timezone.
    This offers stable daily/week unique counts even if the broader first-seen file is lost on redeploy."""
    if not vid:
        return
    data = _load_recent_visits() or {}
    tz = pytz.timezone('Europe/Kyiv')
    now_dt = datetime.now(tz)
    today = now_dt.strftime('%Y-%m-%d')
    # ISO week (Monday start) anchor date for 7-day rolling window (not strictly calendar week) -> we store date 6 days prior cutoff
    # We'll implement simple 7-day rolling: if stored week_start older than 7 days, reset week_ids
    stored_week_start = data.get('week_start') or today
    try:
        sw_dt = datetime.strptime(stored_week_start, '%Y-%m-%d')
        # make tz-aware in same timezone
        sw_dt = tz.localize(sw_dt)
    except Exception:
        sw_dt = now_dt
    if (now_dt - sw_dt).days >= 7:
        # reset week window
        stored_week_start = today
        data['week_ids'] = []
    # day rollover
    if data.get('day') != today:
        data['day'] = today
        data['today_ids'] = []
    # ensure lists
    if 'today_ids' not in data or not isinstance(data['today_ids'], list):
        data['today_ids'] = []
    if 'week_ids' not in data or not isinstance(data['week_ids'], list):
        data['week_ids'] = []
    if vid not in data['today_ids']:
        data['today_ids'].append(vid)
    if vid not in data['week_ids']:
        data['week_ids'].append(vid)
    data['week_start'] = stored_week_start
    _save_recent_visits(data)

def _recent_counts():
    data = _load_recent_visits()
    if not data:
        return None, None
    return len(set(data.get('today_ids', []))), len(set(data.get('week_ids', [])))

# Simplified message processor placeholder
import math
import sqlite3

_opencage_cache = None
_neg_geocode_cache = None

def _load_opencage_cache():
    global _opencage_cache
    if _opencage_cache is not None:
        return _opencage_cache
    if os.path.exists(OPENCAGE_CACHE_FILE):
        try:
            with open(OPENCAGE_CACHE_FILE, 'r', encoding='utf-8') as f:
                _opencage_cache = json.load(f)
        except Exception:
            _opencage_cache = {}
    else:
        _opencage_cache = {}
    return _opencage_cache

def _save_opencage_cache():
    if _opencage_cache is None:
        return
    try:
        with open(OPENCAGE_CACHE_FILE, 'w', encoding='utf-8') as f:
            json.dump(_opencage_cache, f, ensure_ascii=False, indent=2)
    except Exception as e:
        log.warning(f"Failed saving OpenCage cache: {e}")

def _load_neg_geocode_cache():
    global _neg_geocode_cache
    if _neg_geocode_cache is not None:
        return _neg_geocode_cache
    if os.path.exists(NEG_GEOCODE_FILE):
        try:
            with open(NEG_GEOCODE_FILE,'r',encoding='utf-8') as f:
                _neg_geocode_cache = json.load(f)
        except Exception:
            _neg_geocode_cache = {}
    else:
        _neg_geocode_cache = {}
    return _neg_geocode_cache

def _save_neg_geocode_cache():
    if _neg_geocode_cache is None:
        return
    try:
        with open(NEG_GEOCODE_FILE,'w',encoding='utf-8') as f:
            json.dump(_neg_geocode_cache,f,ensure_ascii=False,indent=2)
    except Exception as e:
        log.warning(f"Failed saving negative geocode cache: {e}")

def _msg_timestamp(msg):
    """Extract timestamp from message for sorting and filtering"""
    if not msg:
        return 0
    
    # Try different timestamp fields
    date_str = msg.get('date') or msg.get('timestamp') or msg.get('time')
    if not date_str:
        return 0
    
    try:
        # Handle different date formats
        if isinstance(date_str, (int, float)):
            return float(date_str)
        
        # Parse datetime string
        if isinstance(date_str, str):
            # Try common formats
            for fmt in ['%Y-%m-%d %H:%M:%S', '%Y-%m-%d %H:%M', '%d.%m.%Y %H:%M:%S', '%d.%m.%Y %H:%M']:
                try:
                    dt = datetime.strptime(date_str, fmt)
                    return dt.timestamp()
                except ValueError:
                    continue
            
            # Try parsing with dateutil as fallback
            try:
                from dateutil import parser
                dt = parser.parse(date_str)
                return dt.timestamp()
            except:
                pass
    except Exception:
        pass
    
    return 0

def _msg_timestamp(msg):
    """Extract timestamp from message for sorting/filtering"""
    if not msg:
        return 0
    
    # Try different timestamp fields
    date_str = msg.get('date') or msg.get('timestamp') or msg.get('ts')
    if not date_str:
        return 0
    
    try:
        # Handle different date formats
        if isinstance(date_str, (int, float)):
            return float(date_str)
        
        # Parse string dates
        if isinstance(date_str, str):
            # Try common formats
            formats = [
                '%Y-%m-%d %H:%M:%S',
                '%Y-%m-%d %H:%M',
                '%d.%m.%Y %H:%M:%S',
                '%d.%m.%Y %H:%M'
            ]
            
            for fmt in formats:
                try:
                    dt = datetime.strptime(date_str, fmt)
                    return dt.timestamp()
                except ValueError:
                    continue
                    
        return 0
    except Exception:
        return 0

def neg_geocode_check(name:str):
    if not name:
        return False
    cache = _load_neg_geocode_cache()
    key = name.strip().lower()
    entry = cache.get(key)
    if not entry:
        return False
    # expire
    if int(time.time()) - entry.get('ts',0) > NEG_GEOCODE_TTL:
        try: del cache[key]; _save_neg_geocode_cache()
        except Exception: pass
        return False
    return True

def neg_geocode_add(name:str, reason:str='not_found'):
    if not name:
        return
    cache = _load_neg_geocode_cache()
    key = name.strip().lower()
    cache[key] = {'ts': int(time.time()), 'reason': reason}
    _save_neg_geocode_cache()

UA_CITIES = [
    'київ','харків','одеса','одесса','дніпро','дніпропетровськ','львів','запоріжжя','запорожье','вінниця','миколаїв','николаев',
    'маріуполь','полтава','чернігів','чернигов','черкаси','житомир','суми','хмельницький','чернівці','рівне','івано-франківськ',
    'луцьк','тернопіль','ужгород','кропивницький','кіровоград','кременчук','краматорськ','біла церква','мелітополь','бердянськ',
    'павлоград','ніжин','шостка','короп','кролевець'
]
UA_CITY_NORMALIZE = {
    'одесса':'одеса','запорожье':'запоріжжя','дніпропетровськ':'дніпро','кировоград':'кропивницький','кіровоград':'кропивницький',
    'николаев':'миколаїв','чернигов':'чернігів',
    # Accusative / variant forms
    'липову долину':'липова долина','липову долина':'липова долина',
    'великий багачку':'велика багачка','велику багачу':'велика багачка','велику багачку':'велика багачка','велику багачка':'велика багачка',
    'улянівку':'улянівка','уляновку':'улянівка',
    # Велика Димерка падежные формы
    'велику димерку':'велика димерка','велика димерку':'велика димерка','великої димерки':'велика димерка','великій димерці':'велика димерка',
    # Велика Виска падежные формы  
    'велику виску':'велика виска','великої виски':'велика виска','великій висці':'велика виска',
    # Мала дівиця
    'малу дівицю':'мала дівиця','мала дівицю':'мала дівиця',
    # Additional safety normalizations
    'олишівку':'олишівка','згурівку':'згурівка','ставищею':'ставище','кегичівку':'кегичівка','кегичевку':'кегичівка',
    # Voznesensk variants
    'вознесенська':'вознесенськ',
    # Mykolaiv variants  
    'миколаєва':'миколаїв',
    'корабел':'корабельний район херсон',
    'корабельний':'корабельний район херсон',
    'корабельному':'корабельний район херсон',
    'корабельному херсоні':'корабельний район херсон',
    # Novoukrainka variants
    'новоукраїнку':'новоукраїнка',
    'старому салтову':'старий салтів','старому салтові':'старий салтів','карлівку':'карлівка','магдалинівку':'магдалинівка',
    'балаклію':'балаклія','білу церкву':'біла церква','баришівку':'баришівка','сквиру':'сквира','сосницю':'сосниця',
    'васильківку':'васильківка','понорницю':'понорниця','куликівку':'куликівка','терни':'терни',
    'шостку':'шостка','березну':'березна','зачепилівку':'зачепилівка','нову водолагу':'нова водолага',
    'нову':'нова водолага',  # Fallback for partial regex matches
    'убни':'лубни','олми':'холми','летичів':'летичів','летичев':'летичів','летичеве':'летичів','деражню':'деражня',
    'деражне':'деражня','деражні':'деражня','корюківку':'корюківка','борзну':'борзна','жмеринку':'жмеринка','лосинівку':'лосинівка',
    'ніжину':'ніжин','ніжина':'ніжин','межову':'межова','межової':'межова','святогірську':'святогірськ'
}

# Add accusative / genitive / variant forms for reported missing settlements
UA_CITY_NORMALIZE.update({
    'городню':'городня','городні':'городня','городне':'городня','городни':'городня',
    'кролевця':'кролевець','кролевцу':'кролевець','кролевце':'кролевець',
    'дубовʼязівку':'дубовʼязівка','дубовязівку':'дубовʼязівка','дубовязовку':'дубовʼязівка','дубовязовка':'дубовʼязівка',
    'батурина':'батурин','батурині':'батурин','батурином':'батурин'
    ,'бердичев':'бердичів','бердичева':'бердичів','бердичеве':'бердичів','бердичеву':'бердичів','бердичеві':'бердичів','бердичевом':'бердичів','бердичеву':'бердичів','бердичіву':'бердичів','бердичіва':'бердичів'
    ,'гостомеля':'гостомель','гостомелю':'гостомель','гостомелі':'гостомель','гостомель':'гостомель'
    ,'боярки':'боярка','боярку':'боярка','боярці':'боярка','боярка':'боярка'
    # Черниговская область - дополнительные формы
    ,'седнів':'седнів','седніву':'седнів','седніва':'седнів'
    ,'новгороду':'новгород','новгороді':'новгород','новгородом':'новгород'
    ,'мену':'мена','мені':'мена','меною':'мена'
    ,'макарова':'макарів','макарові':'макарів','макаров':'макарів','макарову':'макарів','макарів':'макарів'
    ,'бородянки':'бородянка','бородянку':'бородянка','бородянці':'бородянка','бородянка':'бородянка'
    ,'кілії':'кілія','кілію':'кілія','кілією':'кілія','кілія':'кілія'
    ,'ізмаїльського':'ізмаїльський','ізмаїльському':'ізмаїльський','ізмаїльський':'ізмаїльський'
    ,'броварського':'броварський','броварському':'броварський','броварський':'броварський'
    ,'обухівського':'обухівський','обухівському':'обухівський','обухівський':'обухівський'
    ,'херсонського':'херсонський','херсонському':'херсонський','херсонський':'херсонський'
    ,'вінницького':'вінницький','вінницькому':'вінницький','вінницький':'вінницький'
    ,'куцуруба':'куцуруб','воскресенку':'воскресенка','воскресенки':'воскресенка'
    # Цибулів (Черкаська обл.) падежные / вариантные формы
    ,'цибулева':'цибулів','цибулеві':'цибулів','цибулеву':'цибулів','цибулевом':'цибулів','цибулів':'цибулів'
    # New accusative / variants for UAV course parsing batch
    ,'борзну':'борзна','царичанку':'царичанка','андріївку':'андріївка','ямполь':'ямпіль','ямполя':'ямпіль','ямпіль':'ямпіль','димеру':'димер','чорнобилю':'чорнобиль'
    ,'дмитрівку':'дмитрівка','дмитрівку чернігівська':'дмитрівка','берестин':'берестин'
    ,'семенівку':'семенівка','глобине':'глобине','глобину':'глобине','глобиному':'глобине','глобина':'глобине'
    ,'кринички':'кринички','криничок':'кринички','солоне':'солоне','солоного':'солоне','солоному':'солоне'
    ,'краснопалівку':'краснопавлівка','краснопалівку':'краснопавлівка','краснопалівка':'краснопавлівка'
    ,'велику димерку':'велика димерка','великій димерці':'велика димерка','великої димерки':'велика димерка'
    ,'брусилів':'брусилів','брусилова':'брусилів','брусилові':'брусилів'
    # New cities from napramok messages September 2025
    ,'десну':'десна','кіпті':'кіпті','ічню':'ічня','цвіткове':'цвіткове'
    ,'чоповичі':'чоповичі','звягель':'звягель','сахновщину':'сахновщина'
    ,'камʼянське':'камʼянське','піщаний брід':'піщаний брід','бобринець':'бобринець'
    ,'тендрівську косу':'тендрівська коса'
    # Одеська область
    ,'вилково':'вилкове','вилкову':'вилкове'
    # Common accusative forms for major cities  
    ,'одесу':'одеса','полтаву':'полтава','сумами':'суми','суму':'суми'
})
# Apostrophe-less fallback for Sloviansk
UA_CITY_NORMALIZE['словянськ'] = "слов'янськ"

# Donetsk front city normalization (latin/ukr vowel variants)
UA_CITY_NORMALIZE['лиман'] = 'ліман'

# ---------------- Dynamic settlement name → region map (from city_ukraine.json, no coords there) ---------------
NAME_REGION_MAP = {}

def _load_name_region_map():
    global NAME_REGION_MAP
    if NAME_REGION_MAP:
        return
    path = 'city_ukraine.json'
    if not os.path.exists(path):
        return
    try:
        with open(path,'r',encoding='utf-8') as f:
            data = json.load(f)
        added = 0
        for item in data:
            if not isinstance(item, dict):
                continue
            name = str(item.get('object_name') or '').strip().lower()
            region = str(item.get('region') or '').strip().title()
            if not name or len(name) < 2:
                continue
            # Skip obviously generic words
            if name in NAME_REGION_MAP:
                continue
            NAME_REGION_MAP[name] = region
            added += 1
        log.info(f"Loaded NAME_REGION_MAP entries: {added}")
    except Exception as e:
        log.warning(f"Failed load city_ukraine.json names: {e}")

_load_name_region_map()

# Fix problematic entries in NAME_REGION_MAP that cause wrong city resolution
# Remove incomplete city names that point to wrong regions
PROBLEMATIC_ENTRIES = [
    'кривий',     # Should be 'кривий ріг' not just 'кривий' -> causes wrong region lookup
    'старий',     # Too generic, causes conflicts
    'нова',       # Too generic
    'велика',     # Too generic
    'мала',       # Too generic
    'білозерка',  # Conflicts with Херсонська область when message clearly specifies region
]

for entry in PROBLEMATIC_ENTRIES:
    NAME_REGION_MAP.pop(entry, None)

def extract_location_with_groq_ai(message_text: str):
    """Use Groq AI (Llama 3.1 70B) to intelligently extract location from Ukrainian military message.
    
    Returns dict with:
    - city: settlement name (normalized to nominative case)
    - district: district name if mentioned (or None)
    - oblast: oblast name (or None)
    - confidence: AI confidence score 0-1
    
    Examples:
    - "Дніпропетровщина: БпЛА маневрує в районі Юріївки" 
      -> {city: "Юріївка", district: None, oblast: "Дніпропетровська область", confidence: 0.95}
    - "БпЛА в Павлоградському районі курсом на Тернівку"
      -> {city: "Тернівка", district: "Павлоградський", oblast: None, confidence: 0.9}
    """
    if not GROQ_ENABLED or not message_text:
        return None
    
    try:
        prompt = f"""Ти експерт з аналізу повідомлень про повітряні тривоги в Україні.

Витягни з повідомлення:
1. Назву населеного пункту (місто/село) - ОБОВ'ЯЗКОВО в називному відмінку (Юріївка, а не Юріївки)
2. Назву району (якщо вказано явно, наприклад "Павлоградський район")
3. Назву області

КРИТИЧНО ВАЖЛИВО:
- "курсом на X", "напрямок на X", "ціль на X" - X це МІСТО (city), а НЕ район!
- "в районі X" означає "біля X", а НЕ назву району
- "Павлоградський район" - це назва району
- "курсом на Павлоград" - Павлоград це МІСТО (city="Павлоград", district=null)
- Нормалізуй назви до називного відмінку (Юріївки → Юріївка, Тернівку → Тернівка)
- "Дніпропетровщина" → "Дніпропетровська область"

Повідомлення:
{message_text}

Відповідь ТІЛЬКИ у форматі JSON (без markdown, без пояснень):
{{"city": "назва або null", "district": "назва або null", "oblast": "назва або null", "confidence": 0.95}}"""

        response = groq_client.chat.completions.create(
            model="llama-3.3-70b-versatile",  # Updated model (llama-3.1 decommissioned)
            messages=[
                {"role": "system", "content": "Ти аналізуєш повідомлення про повітряні тривоги. Відповідай ТІЛЬКИ валідним JSON."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.1,
            max_tokens=300,
            top_p=0.9
        )
        
        result_text = response.choices[0].message.content.strip()
        
        # Remove markdown code blocks if present
        if result_text.startswith('```'):
            result_text = re.sub(r'^```(?:json)?\s*', '', result_text)
            result_text = re.sub(r'\s*```$', '', result_text)
        
        result = json.loads(result_text)
        
        # Validate and normalize result
        if not isinstance(result, dict):
            return None
        
        city = result.get('city')
        district = result.get('district')
        oblast = result.get('oblast')
        confidence = result.get('confidence', 0.5)
        
        # Skip if no useful info extracted
        if not city and not oblast:
            return None
        
        # Convert null strings to None
        if city in ['null', 'None', '']:
            city = None
        if district in ['null', 'None', '']:
            district = None
        if oblast in ['null', 'None', '']:
            oblast = None
        
        print(f"DEBUG Groq AI: city='{city}', district='{district}', oblast='{oblast}', confidence={confidence}")
        
        return {
            'city': city.strip() if city else None,
            'district': district.strip() if district else None,
            'oblast': oblast.strip() if oblast else None,
            'confidence': float(confidence)
        }
        
    except json.JSONDecodeError as e:
        print(f"WARNING: Groq AI returned invalid JSON: {e}")
        print(f"Response: {result_text[:200]}")
        return None
    except Exception as e:
        print(f"WARNING: Groq AI extraction failed: {e}")
        return None

def geocode_with_context(city: str, oblast_key: str, district: str = None):
    """Geocode city using Photon API with oblast and optional district context.
    Returns (lat, lng, is_approx) or None."""
    if not city:
        return None
    
    try:
        import requests
        
        # Map oblast key to full region name for Photon
        oblast_to_region_map = {
            'дніпропетровська область': 'Дніпропетровська область',
            'харківська обл.': 'Харківська область',
            'полтавська область': 'Полтавська область',
            'сумська область': 'Сумська область',
            'чернігівська обл.': 'Чернігівська область',
            'миколаївська обл.': 'Миколаївська область',
            'одеська обл.': 'Одеська область',
            'запорізька область': 'Запорізька область',
            'херсонська обл.': 'Херсонська область',
            'київська обл.': 'Київська область',
            'донецька область': 'Донецька область',
            'луганська область': 'Луганська область',
        }
        
        region_name = oblast_to_region_map.get(oblast_key.lower(), oblast_key)
        
        photon_url = 'https://photon.komoot.io/api/'
        params = {'q': city, 'limit': 15}
        
        response = requests.get(photon_url, params=params, timeout=3)
        if response.ok:
            data = response.json()
            
            for feature in data.get('features', []):
                props = feature.get('properties', {})
                state = props.get('state', '')
                county = props.get('county', '')
                country = props.get('country', '')
                osm_key = props.get('osm_key', '')
                osm_value = props.get('osm_value', '')
                
                # Filter out POIs
                if osm_key not in ['place', 'boundary']:
                    continue
                valid_place_types = ['city', 'town', 'village', 'hamlet', 'suburb', 'neighbourhood', 'administrative', 'borough', 'quarter', 'district']
                if osm_key == 'place' and osm_value not in valid_place_types:
                    continue
                
                # Filter by Ukraine and oblast
                if (country == 'Україна' or country == 'Ukraine'):
                    if region_name in state:
                        coords_arr = feature.get('geometry', {}).get('coordinates', [])
                        if coords_arr and len(coords_arr) >= 2:
                            lat, lng = coords_arr[1], coords_arr[0]
                            
                            # If district provided, prefer district match
                            if district:
                                county_lower = county.lower()
                                district_lower = district.lower()
                                
                                if district_lower in county_lower or county_lower.startswith(district_lower):
                                    print(f"DEBUG Groq+Photon: '{city}' in {county}, {state} (district match!) -> ({lat}, {lng})")
                                    return (lat, lng, False)
                                else:
                                    continue  # Keep looking for district match
                            
                            # No district filter or found oblast match
                            print(f"DEBUG Groq+Photon: '{city}' in {state} -> ({lat}, {lng})")
                            return (lat, lng, False)
        
    except Exception as e:
        print(f"DEBUG: geocode_with_context error: {e}")
    
    return None

def extract_district_and_oblast_context(message_text: str):
    """Extract district (район) and oblast context from message.
    Returns dict with 'district', 'oblast_key', 'excluded_oblast'.
    
    Examples:
    - "БпЛА маневрує в районі Юріївки" -> Павлоградський район (from context)
    - "БпЛА в Покровському районі" -> Покровський район
    - "Дніпропетровщина: БпЛА..." -> Дніпропетровська область
    """
    if not message_text:
        return {'district': None, 'oblast_key': None, 'excluded_oblast': None}
    
    message_lower = message_text.lower()
    result = {'district': None, 'oblast_key': None, 'excluded_oblast': None}
    
    # Extract explicit district mentions
    # Pattern: "[назва] район", "в [назва] районі", "[назва]ський район"
    # BUT NOT: "в районі [село]" - this means "near [village]", not district name
    district_patterns = [
        r'([а-яїієґ]{3,}ськ(?:ий|ому|ого))\s+район',  # "павлоградський район" (min 3 chars before "ськ")
        r'([а-яїієґ]{3,})\s+район(?:і)?(?:\s|$)',      # "покровський район" (min 3 chars)
    ]
    
    # Don't extract "в районі X" as district - this means "near X"
    # Only extract explicit district names like "павлоградський район"
    
    for pattern in district_patterns:
        match = re.search(pattern, message_lower)
        if match:
            district = match.group(1).strip()
            
            # Skip common prepositions and short words
            skip_words = ['в', 'на', 'за', 'до', 'від', 'при', 'під', 'над', 'між', 'про', 'для']
            if district in skip_words or len(district) < 3:
                continue
            
            # Normalize district name
            if district.endswith('ому') or district.endswith('ого'):
                district = district[:-3] + 'ий'
            result['district'] = district
            print(f"DEBUG: Extracted district: '{district}'")
            break
    
    # Extract oblast (same logic as before)
    # Check for "з [область]" pattern - city is NOT in that oblast
    from_oblast_pattern = r'з\s+([а-яїіє]+щини|[а-яїіє]+ської\s+обл)'
    from_match = re.search(from_oblast_pattern, message_lower)
    if from_match:
        excluded = from_match.group(1).strip()
        result['excluded_oblast'] = excluded
    
    # Look for oblast mention in header or text
    oblast_patterns = [
        r'^([а-яїіє]+(?:ч)?чина|[а-яїіє]+щина|волинь):',  # "Хмельниччина:", "Вінниччина:", "Дніпропетровщина:", "Волинь:"
        r'([а-яїіє]+ська\s+обл\.?)',  # "Харківська обл."
        r'([а-яїіє]+ська\s+область)',  # "Полтавська область"
    ]
    
    for pattern in oblast_patterns:
        match = re.search(pattern, message_lower, re.MULTILINE)
        if match:
            oblast_mention = match.group(1).strip()
            
            # Normalize oblast names
            oblast_normalizations = {
                'харківщина': 'харківська обл.',
                'чернігівщина': 'чернігівська обл.',
                'полтавщина': 'полтавська область',
                'дніпропетровщина': 'дніпропетровська область',
                'сумщина': 'сумська область',
                'миколаївщина': 'миколаївська обл.',
                'одещина': 'одеська обл.',
                'запоріжжя': 'запорізька область',
                'херсонщина': 'херсонська обл.',
                'київщина': 'київська обл.',
                'черкащина': 'черкаська область',
                'вінниччина': 'вінницька область',
                'хмельниччина': 'хмельницька область',
                'тернопільщина': 'тернопільська область',
                'житомирщина': 'житомирська область',
                'волинь': 'волинська область',
                'донеччина': 'донецька область',
                'луганщина': 'луганська область',
            }
            
            if oblast_mention in oblast_normalizations:
                result['oblast_key'] = oblast_normalizations[oblast_mention]
            elif oblast_mention in OBLAST_CENTERS:
                result['oblast_key'] = oblast_mention
            
            break
    
    return result

def ensure_city_coords(name: str, region_hint: str = None):
    """Return (lat,lng,approx_bool) for settlement using Photon/Nominatim APIs.
    approx_bool True means we used oblast center fallback (low precision)."""
    if not name:
        return None
    n = name.strip().lower()
    
    # Apply UA_CITY_NORMALIZE before any lookups
    if n in UA_CITY_NORMALIZE:
        n = UA_CITY_NORMALIZE[n]
        print(f"DEBUG: Normalized '{name.lower()}' -> '{n}'")
    
    # Normalize Ukrainian city name declensions to nominative case
    # This fixes issues like "Тернівку" (accusative) -> "Тернівка" (nominative)
    # for consistent API geocoding results
    original_n = n
    if n.endswith('ку') and len(n) > 4:
        # Accusative ending: Тернівку -> Тернівка
        n = n[:-2] + 'ка'
    elif n.endswith('цю') and len(n) > 4:
        # Accusative ending: Вінницю -> Вінниця
        n = n[:-2] + 'ця'
    elif n.endswith('у') and len(n) > 3:
        # Check if it's likely accusative (not ending in consonant+у)
        if n[-2] in 'аеиоуяюєї':
            pass  # Likely nominative already (e.g., "Суму")
        else:
            # Try: Київу -> Київ, but preserve: Суму, Ромну (already nominative)
            test_form = n[:-1]
            # Only convert if it looks like a valid city name
            if test_form and test_form[-1] in 'вгджзклмнпрстфхцчшщ':
                n = test_form
    elif n.endswith('ові') and len(n) > 5:
        # Dative ending: Києву -> Київ
        n = n[:-3]
    elif n.endswith('ом') and len(n) > 4:
        # Instrumental ending: Київом -> Київ
        n = n[:-2]
    
    if n != original_n:
        print(f"DEBUG: Declension normalized '{original_n}' -> '{n}'")
    
    # PRIORITY FIX: Check for "City + Oblast" pattern (e.g., "Вилково Одещини")
    # Split on space and check if we have both a city and oblast
    words = n.split()
    region_context = None
    if len(words) >= 2:
        # Try first word as city (with normalization)
        potential_city = words[0]
        if potential_city in UA_CITY_NORMALIZE:
            potential_city = UA_CITY_NORMALIZE[potential_city]
        
        potential_oblast = ' '.join(words[1:])
        
        # Check if remaining words match an oblast
        if potential_oblast in OBLAST_CENTERS or any(potential_oblast in oblast_key for oblast_key in OBLAST_CENTERS.keys()):
            # This is "City+Oblast" pattern - extract region for API query
            n = potential_city
            region_context = potential_oblast
            print(f"DEBUG: Found 'City+Oblast' pattern: '{potential_city}' + '{potential_oblast}' -> will search API with region filter")
    
    # Check if it's a direct oblast/region name
    if n in OBLAST_CENTERS:
        lat,lng = OBLAST_CENTERS[n]; return (lat,lng,True)
    if 'SETTLEMENTS_INDEX' in globals() and n in (globals().get('SETTLEMENTS_INDEX') or {}):
        lat,lng = globals()['SETTLEMENTS_INDEX'][n]; return (lat,lng,False)
    
    # Use Photon API (supports Cyrillic, fast, finds villages)
    try:
        import requests
        
        # Get region hint from explicit parameter, extracted context, or NAME_REGION_MAP
        region_hint = region_hint or region_context or NAME_REGION_MAP.get(n)
        if isinstance(region_hint, str):
            region_hint = region_hint.lower()
        
        # Try Photon first (supports Cyrillic)
        photon_url = 'https://photon.komoot.io/api/'
        photon_params = {'q': n, 'limit': 10}
        
        photon_response = requests.get(photon_url, params=photon_params, timeout=3)
        if photon_response.ok:
            photon_data = photon_response.json()
            for feature in photon_data.get('features', []):
                props = feature.get('properties', {})
                state = props.get('state', '')
                country = props.get('country', '')
                osm_key = props.get('osm_key', '')
                osm_value = props.get('osm_value', '')
                
                # Filter out POIs and tourism - only settlements
                if osm_key not in ['place', 'boundary']:
                    continue
                valid_place_types = ['city', 'town', 'village', 'hamlet', 'suburb', 'neighbourhood', 'administrative']
                if osm_key == 'place' and osm_value not in valid_place_types:
                    continue
                
                # Filter by Ukraine
                if country in ['Україна', 'Ukraine']:
                    # If we have region hint, filter by it
                    if region_hint:
                        if region_hint in state.lower() or state.lower() in region_hint:
                            coords_arr = feature.get('geometry', {}).get('coordinates', [])
                            if coords_arr and len(coords_arr) >= 2:
                                lng, lat = coords_arr[0], coords_arr[1]
                                print(f"DEBUG Photon: Found '{n}' in {state} -> ({lat}, {lng})")
                                return (lat, lng, False)
                    else:
                        # No region hint, use first Ukraine result
                        coords_arr = feature.get('geometry', {}).get('coordinates', [])
                        if coords_arr and len(coords_arr) >= 2:
                            lng, lat = coords_arr[0], coords_arr[1]
                            print(f"DEBUG Photon: Found '{n}' in {state} -> ({lat}, {lng})")
                            return (lat, lng, False)
        
        # Fallback to Nominatim with transliteration
        def transliterate_ua_to_latin(text):
            translit_map = {
                'а': 'a', 'б': 'b', 'в': 'v', 'г': 'h', 'ґ': 'g', 'д': 'd', 'е': 'e', 'є': 'ye',
                'ж': 'zh', 'з': 'z', 'и': 'y', 'і': 'i', 'ї': 'yi', 'й': 'y', 'к': 'k', 'л': 'l',
                'м': 'm', 'н': 'n', 'о': 'o', 'п': 'p', 'р': 'r', 'с': 's', 'т': 't', 'у': 'u',
                'ф': 'f', 'х': 'kh', 'ц': 'ts', 'ч': 'ch', 'ш': 'sh', 'щ': 'shch', 'ь': '', 'ю': 'yu', 'я': 'ya',
                'А': 'A', 'Б': 'B', 'В': 'V', 'Г': 'H', 'Ґ': 'G', 'Д': 'D', 'Е': 'E', 'Є': 'Ye',
                'Ж': 'Zh', 'З': 'Z', 'И': 'Y', 'І': 'I', 'Ї': 'Yi', 'Й': 'Y', 'К': 'K', 'Л': 'L',
                'М': 'M', 'Н': 'N', 'О': 'O', 'П': 'P', 'Р': 'R', 'С': 'S', 'Т': 'T', 'У': 'U',
                'Ф': 'F', 'Х': 'Kh', 'Ц': 'Ts', 'Ч': 'Ch', 'Ш': 'Sh', 'Щ': 'Shch', 'Ь': '', 'Ю': 'Yu', 'Я': 'Ya'
            }
            return ''.join(translit_map.get(c, c) for c in text)
        
        name_latin = transliterate_ua_to_latin(n)
        nominatim_url = 'https://nominatim.openstreetmap.org/search'
        params = {'q': f'{name_latin}, Ukraine', 'format': 'json', 'limit': 5, 'addressdetails': 1}
        headers = {'User-Agent': 'NeptunAlarmMap/1.0 (https://neptun.in.ua)'}
        
        response = requests.get(nominatim_url, params=params, headers=headers, timeout=4)
        if response.ok:
            results = response.json()
            for result in results:
                if region_hint:
                    address = result.get('address', {})
                    result_state = address.get('state', '')
                    if region_hint in result_state.lower() or result_state.lower() in region_hint:
                        lat = float(result['lat'])
                        lng = float(result['lon'])
                        print(f"DEBUG Nominatim: Found '{n}' -> '{name_latin}' in {result_state} -> ({lat}, {lng})")
                        return (lat, lng, False)
                elif results:
                    # No region hint, use first result
                    first = results[0]
                    lat = float(first['lat'])
                    lng = float(first['lon'])
                    print(f"DEBUG Nominatim: Found '{n}' -> '{name_latin}' -> ({lat}, {lng})")
                    return (lat, lng, False)
                    
    except Exception as e:
        print(f"DEBUG API geocoding error in ensure_city_coords: {e}")
    # Approximate fallback: oblast center (if region hint matches an oblast name substring)
    if region_hint:
        reg_low = region_hint.lower()
        for oblast_key, (olat, olng) in OBLAST_CENTERS.items():
            if oblast_key in reg_low:
                return (olat, olng, True)
    return None

def ensure_city_coords_with_message_context(name: str, message_text: str = ""):
    """Enhanced version that tries to extract oblast from message if city not found.
    Returns (lat,lng,approx_bool) - approx_bool True means used oblast fallback."""
    
    # PRIORITY 1: Try Groq AI for intelligent context understanding
    if GROQ_ENABLED and message_text:
        try:
            ai_result = extract_location_with_groq_ai(message_text)
            if ai_result and ai_result.get('confidence', 0) > 0.7:
                ai_city = ai_result.get('city')
                ai_district = ai_result.get('district')
                ai_oblast = ai_result.get('oblast')
                
                # Use AI-extracted city name if provided and confident
                if ai_city:
                    target_city = ai_city.lower()
                    print(f"DEBUG Groq: Using AI-extracted city '{target_city}' (confidence: {ai_result['confidence']})")
                    
                    # Build context for geocoding
                    oblast_key = None
                    if ai_oblast:
                        # Normalize oblast name
                        oblast_normalizations = {
                            'дніпропетровська область': 'дніпропетровська область',
                            'харківська область': 'харківська обл.',
                            'полтавська область': 'полтавська область',
                            'сумська область': 'сумська область',
                            'чернігівська область': 'чернігівська обл.',
                            'миколаївська область': 'миколаївська обл.',
                            'одеська область': 'одеська обл.',
                            'запорізька область': 'запорізька область',
                            'херсонська область': 'херсонська обл.',
                            'київська область': 'київська обл.',
                            'донецька область': 'донецька область',
                            'луганська область': 'луганська область',
                        }
                        ai_oblast_lower = ai_oblast.lower()
                        oblast_key = oblast_normalizations.get(ai_oblast_lower, ai_oblast_lower)
                    
                    # Try geocoding with AI-provided context
                    if oblast_key:
                        # Use Photon API with oblast + optional district filtering
                        coords = geocode_with_context(target_city, oblast_key, ai_district)
                        if coords:
                            return coords
                    
                    # Fallback to basic geocoding with AI city name
                    coords = ensure_city_coords(target_city, oblast_key.lower() if isinstance(oblast_key, str) else None)
                    if coords:
                        return coords
                        
        except Exception as e:
            print(f"DEBUG: Groq AI geocoding attempt failed: {e}")
            # Continue to fallback methods
    
    # PRIORITY 2: Original declension normalization and processing
    # Normalize Ukrainian city name declensions FIRST
    original_name = name
    name_lower = name.strip().lower()
    
    # Normalize declensions to nominative case for consistent API results
    if name_lower.endswith('ку') and len(name_lower) > 4:
        name_lower = name_lower[:-2] + 'ка'
    elif name_lower.endswith('цю') and len(name_lower) > 4:
        name_lower = name_lower[:-2] + 'ця'
    elif name_lower.endswith('у') and len(name_lower) > 3:
        if name_lower[-2] not in 'аеиоуяюєї' and name_lower[-2] in 'вгджзклмнпрстфхцчшщ':
            name_lower = name_lower[:-1]
    elif name_lower.endswith('ові') and len(name_lower) > 5:
        name_lower = name_lower[:-3]
    elif name_lower.endswith('ом') and len(name_lower) > 4:
        name_lower = name_lower[:-2]
    
    if name_lower != original_name.lower():
        print(f"DEBUG: Declension '{original_name}' -> '{name_lower}'")
        name = name_lower  # Update name for further processing
    
    # PRIORITY: Try SpaCy first if available
    if SPACY_AVAILABLE and message_text:
        try:
            spacy_results = spacy_enhanced_geocoding(message_text)
            
            # Look for the specific city we're searching for
            name_lower = name.lower()
            for result in spacy_results:
                if (result['normalized'] == name_lower or 
                    result['name'].lower() == name_lower):
                    if result['coords']:
                        lat, lng = result['coords']
                        print(f"DEBUG SpaCy: Found {name} via SpaCy -> ({lat}, {lng})")
                        return (lat, lng, False)  # Not approximate since SpaCy found exact match
            
        except Exception as e:
            print(f"DEBUG SpaCy fallback error: {e}")
            # Continue to regex-based processing
    
    # FALLBACK: Original regex-based processing
    
    # SMART CONTEXT EXTRACTION: Extract district and oblast from message
    context = extract_district_and_oblast_context(message_text)
    district_hint = context.get('district')
    detected_oblast_key = context.get('oblast_key')
    excluded_oblast = context.get('excluded_oblast')
    
    # Legacy oblast detection (kept for backward compatibility)
    # Initialize detected_oblast_key at function scope
    detected_oblast_key = None
    from_region_hint = None  # Additional region hint from "з [область]" pattern
    
    # First, if we have message text, try to extract oblast info and build specific city keys
    if message_text:
        message_lower = message_text.lower()
        
        # Check for "з [область]" pattern - use as ADDITIONAL region hint (not exclusion)
        # Example: "БпЛА на Юріївку з Харківщини" - Yuriivka is likely IN Kharkiv region
        from_oblast_pattern = r'з\s+([а-яїіє]+щини|[а-яїіє]+ської\s+обл)'
        from_match = re.search(from_oblast_pattern, message_lower)
        if from_match:
            from_region = from_match.group(1).strip()
            # Normalize to oblast name
            if from_region.endswith('щини'):
                from_region = from_region[:-1]  # миколаївщини -> миколаївщин
            if from_region.endswith('н'):
                from_region = from_region[:-1] + 'на'  # миколаївщин -> миколаївщина
            
            # Map to oblast key
            from_region_map = {
                'миколаївщина': 'миколаївська',
                'одещина': 'одеська', 
                'херсонщина': 'херсонська',
                'дніпропетровщина': 'дніпропетровська',
                'харківщина': 'харківська',
                'сумщина': 'сумська',
                'чернігівщина': 'чернігівська',
                'полтавщина': 'полтавська',
            }
            from_region_hint = from_region_map.get(from_region)
            if from_region_hint:
                print(f"DEBUG: Found 'з {from_region}' pattern - using {from_region_hint} oblast as region hint for '{name}'")
        
        # ENHANCED: Find the closest oblast to the specific city name
        city_pos = message_lower.find(name.lower())
        if city_pos != -1:
            # Look for oblast in close proximity to the city (within 100 characters before/after)
            start_pos = max(0, city_pos - 100)
            end_pos = min(len(message_lower), city_pos + len(name) + 100)
            context = message_lower[start_pos:end_pos]
            
            # PRIORITY: Check for oblast at the START of the line with colon (e.g., "Дніпропетровщина: БпЛА...")
            # This is most reliable indicator in multi-region messages
            line_start_oblast = re.match(r'^([а-яїіє]+щина|[а-яїіє]+ська\s+обл(?:\.|асть)?):?\s+', context.lstrip())
            if line_start_oblast:
                match = line_start_oblast.group(1).strip().lower()
                add_debug_log(f"OBLAST CONTEXT: Found line-start oblast '{match}' for city '{name}'", "oblast_line_start")
            else:
                # Enhanced regional context detection - try parenthetical oblast first
                oblast_patterns = [
                    # Parenthetical oblast: "(Oblast обл.)" - most specific
                    r'\(([^)]+)\s+обл\.\)',
                    r'\(([^)]+)\s+область\)',
                    # Oblast adjective forms: "харківська обл."
                    r'\b([а-яїіє]+ська)\s+обл(?:\.|асть)?\b',
                    r'\b([а-яїіє]+цька)\s+обл(?:\.|асть)?\b', 
                    # Regional names: "харківщина", "полтавщина", etc.
                    r'\b([а-яїіє]+щина)\b',
                    r'\b([а-яїіє]+щині)\b',
                    r'\b([а-яїіє]+щину)\b',
                    # Additional patterns for regional context
                    r'\bна\s+([а-яїіє]+щині)\b',  # "на Сумщині"
                    r'\bу\s+([а-яїіє]+щині)\b',   # "у Сумщині"
                    r'\bв\s+([а-яїіє]+щині)\b',   # "в Сумщині"
                ]
                
                match = None
                for pattern in oblast_patterns:
                    matches = re.findall(pattern, context)  # Search in context, not full message
                    if matches:
                        match = matches[0].strip().lower()
                        break
            
            if match:
                # Normalize regional names to nominative case AND adjective form
                if match.endswith('щині'):
                    match = match[:-2] + 'на'  # сумщині -> сумщина
                elif match.endswith('щину'):
                    match = match[:-2] + 'на'  # сумщину -> сумщина
                
                # Convert regional names to adjective forms for city lookup
                regional_to_adjective = {
                    'сумщина': 'сумська',
                    'харківщина': 'харківська',
                    'чернігівщина': 'чернігівська',
                    'полтавщина': 'полтавська',
                    'дніпропетровщина': 'дніпропетровська',
                    'херсонщина': 'херсонська',
                    'миколаївщина': 'миколаївська',
                    'одещина': 'одеська',
                    'київщина': 'київська',
                    'житомирщина': 'житомирська',
                    'рівненщина': 'рівненська',
                }
                
                if match in regional_to_adjective:
                    match = regional_to_adjective[match]
                
                # Priority: use from_region_hint if present (from "з [область]" pattern)
                if from_region_hint:
                    print(f"DEBUG: Prioritizing 'з [область]' hint: {from_region_hint} for city '{name}'")
                    match = from_region_hint
                
                if match:  # Only process if we have a valid match
                    # Create possible city+oblast combinations to search
                    city_variants = [
                        f"{name.lower()}({match})",  # миколаївка(сумська)
                        f"{name.lower()} ({match})",  # миколаївка (сумська)
                        f"{name.lower()} {match}",
                        f"{name.lower()} {match} обл.",
                        f"{name.lower()} {match} область",
                    ]
                    
                    print(f"DEBUG: Checking variants for {name} with oblast {match}: trying API with region filter")
                    
                    # Store oblast key for potential fallback
                    oblast_normalizations = {
                        'харківська': 'харківська обл.',
                        'чернігівська': 'чернігівська обл.',
                        'полтавська': 'полтавська область',
                        'дніпропетровська': 'дніпропетровська область',
                        'сумська': 'сумська область',
                        'миколаївська': 'миколаївська обл.',
                        'одеська': 'одеська обл.',
                        'запорізька': 'запорізька область',
                        'херсонська': 'херсонська обл.',
                        'київська': 'київська обл.',
                        'черкаська': 'черкаська область',
                        'вінницька': 'вінницька область',
                        'харківщина': 'харківська обл.',
                        'чернігівщина': 'чернігівська обл.',
                        'полтавщина': 'полтавська область',
                        'дніпропетровщина': 'дніпропетровська область',
                        'сумщина': 'сумська область',
                        'миколаївщина': 'миколаївська обл.',
                        'одещина': 'одеська обл.',
                        'запоріжжя': 'запорізька область',
                        'херсонщина': 'херсонська обл.',
                        'київщина': 'київська обл.',
                        'черкащина': 'черкаська область',
                        'вінниччина': 'вінницька область',
                    }
                    
                    if match in oblast_normalizations:
                        detected_oblast_key = oblast_normalizations[match]
                    elif match in OBLAST_CENTERS:
                        detected_oblast_key = match
    
    # CRITICAL: Try Photon API with region filtering for multi-regional cities
    # This handles cases like "Ольшанське" which exists in multiple oblasts
    if detected_oblast_key and message_text:
        try:
            import requests
            
            # Map oblast key to region name for API filtering
            oblast_to_region_map = {
                'харківська обл.': 'Харківська область',
                'чернігівська обл.': 'Чернігівська область',
                'полтавська область': 'Полтавська область',
                'дніпропетровська область': 'Дніпропетровська область',
                'сумська область': 'Сумська область',
                'миколаївська обл.': 'Миколаївська область',
                'одеська обл.': 'Одеська область',
                'запорізька область': 'Запорізька область',
                'херсонська обл.': 'Херсонська область',
                'київська обл.': 'Київська область',
                'черкаська область': 'Черкаська область',
                'вінницька область': 'Вінницька область',
                'хмельницька область': 'Хмельницька область',
                'житомирська область': 'Житомирська область',
                'рівненська область': 'Рівненська область',
                'волинська область': 'Волинська область',
                'львівська область': 'Львівська область',
                'тернопільська область': 'Тернопільська область',
                'івано-франківська область': 'Івано-Франківська область',
                'закарпатська область': 'Закарпатська область',
                'чернівецька область': 'Чернівецька область',
            }
            
            region_name = oblast_to_region_map.get(detected_oblast_key)
            
            # Try Photon API first (fastest and most reliable for Ukrainian cities)
            photon_url = 'https://photon.komoot.io/api/'
            params = {
                'q': name,
                'limit': 10  # Get multiple results to filter by region
            }
            
            response = requests.get(photon_url, params=params, timeout=3)
            if response.ok:
                data = response.json()
                best_match = None
                district_match = None
                
                for feature in data.get('features', []):
                    props = feature.get('properties', {})
                    state = props.get('state', '')
                    county = props.get('county', '')  # district/район
                    country = props.get('country', '')
                    osm_key = props.get('osm_key', '')
                    osm_value = props.get('osm_value', '')
                    
                    # Filter out POIs - only settlements
                    if osm_key not in ['place', 'boundary']:
                        continue
                    valid_place_types = ['city', 'town', 'village', 'hamlet', 'suburb', 'neighbourhood', 'administrative']
                    if osm_key == 'place' and osm_value not in valid_place_types:
                        continue
                    
                    # Filter by Ukraine and detected region
                    if (country == 'Україна' or country == 'Ukraine'):
                        # Check if state matches detected oblast
                        if region_name and region_name in state:
                            coords_arr = feature.get('geometry', {}).get('coordinates', [])
                            if coords_arr and len(coords_arr) >= 2:
                                lat, lng = coords_arr[1], coords_arr[0]
                                
                                # PRIORITY: If district hint exists, check if it matches
                                if district_hint:
                                    county_lower = county.lower()
                                    district_lower = district_hint.lower()
                                    
                                    # Normalize both for comparison
                                    # "Павлоградський район" should match "павлоградський"
                                    if district_lower in county_lower or county_lower.startswith(district_lower):
                                        print(f"DEBUG: Photon API found '{name}' in {county}, {state} (district match!) -> ({lat}, {lng})")
                                        return (lat, lng, False)
                                    else:
                                        # Store as potential match but keep looking for district match
                                        if not district_match:
                                            district_match = (lat, lng)
                                        continue
                                
                                # No district hint or no match yet - use this result
                                if not best_match:
                                    best_match = (lat, lng)
                                    print(f"DEBUG: Photon API found '{name}' in {state} -> ({lat}, {lng})")
                
                # Return best match (district match preferred, then first oblast match)
                if district_match:
                    return (district_match[0], district_match[1], False)
                if best_match:
                    return (best_match[0], best_match[1], False)
            
            # Fallback to Nominatim API if Photon didn't find the city
            # NOTE: Nominatim doesn't support Cyrillic in query, need transliteration
            if region_name:
                # Transliterate to Latin for Nominatim (it rejects Cyrillic with HTTP 400)
                def transliterate_ua_to_latin(text):
                    """Ukrainian to Latin transliteration for Nominatim API"""
                    translit_map = {
                        'а': 'a', 'б': 'b', 'в': 'v', 'г': 'h', 'ґ': 'g', 'д': 'd', 'е': 'e', 'є': 'ye',
                        'ж': 'zh', 'з': 'z', 'и': 'y', 'і': 'i', 'ї': 'yi', 'й': 'y', 'к': 'k', 'л': 'l',
                        'м': 'm', 'н': 'n', 'о': 'o', 'п': 'p', 'р': 'r', 'с': 's', 'т': 't', 'у': 'u',
                        'ф': 'f', 'х': 'kh', 'ц': 'ts', 'ч': 'ch', 'ш': 'sh', 'щ': 'shch', 'ь': '', 'ю': 'yu', 'я': 'ya',
                        'А': 'A', 'Б': 'B', 'В': 'V', 'Г': 'H', 'Ґ': 'G', 'Д': 'D', 'Е': 'E', 'Є': 'Ye',
                        'Ж': 'Zh', 'З': 'Z', 'И': 'Y', 'І': 'I', 'Ї': 'Yi', 'Й': 'Y', 'К': 'K', 'Л': 'L',
                        'М': 'M', 'Н': 'N', 'О': 'O', 'П': 'P', 'Р': 'R', 'С': 'S', 'Т': 'T', 'У': 'U',
                        'Ф': 'F', 'Х': 'Kh', 'Ц': 'Ts', 'Ч': 'Ch', 'Ш': 'Sh', 'Щ': 'Shch', 'Ь': '', 'Ю': 'Yu', 'Я': 'Ya'
                    }
                    return ''.join(translit_map.get(c, c) for c in text)
                
                name_latin = transliterate_ua_to_latin(name)
                
                nominatim_url = 'https://nominatim.openstreetmap.org/search'
                params = {
                    'q': f'{name_latin}, Ukraine',
                    'format': 'json',
                    'limit': 5,
                    'addressdetails': 1
                }
                headers = {
                    'User-Agent': 'NeptunAlarmMap/1.0 (https://neptun-alarm.onrender.com)'
                }
                
                response = requests.get(nominatim_url, params=params, headers=headers, timeout=4)
                if response.ok:
                    results = response.json()
                    for result in results:
                        # Verify it's in the correct oblast
                        address = result.get('address', {})
                        result_state = address.get('state', '')
                        
                        if region_name in result_state or result_state in region_name:
                            lat = float(result['lat'])
                            lng = float(result['lon'])
                            display_name = result.get('display_name', '')
                            print(f"DEBUG: Nominatim API found '{name}' -> '{name_latin}' in {result_state} -> ({lat}, {lng})")
                            return (lat, lng, False)
        except Exception as e:
            print(f"DEBUG: Multi-regional API lookup error: {e}")
    
    # Second try: standard city lookup via API (without oblast context but with excluded_oblast filter)
    try:
        import requests
        
        # Try Photon API (supports Cyrillic)
        photon_url = 'https://photon.komoot.io/api/'
        photon_params = {'q': name, 'limit': 10}
        
        photon_response = requests.get(photon_url, params=photon_params, timeout=3)
        if photon_response.ok:
            photon_data = photon_response.json()
            
            # Military context priority: if message contains UAV/shahed keywords,
            # prioritize oblasts closer to frontline (Dnipropetrovska, Donetska, Zaporizka, Khersonska)
            military_keywords = ['бпла', 'шахед', 'shahed', 'дрон', 'курс', 'напрямок']
            is_military_context = any(kw in message_text.lower() for kw in military_keywords) if message_text else False
            frontline_oblasts = ['дніпропетровська', 'донецька', 'запорізька', 'херсонська', 'миколаївська', 'харківська', 'луганська']
            
            # Collect all results
            ukraine_results = []
            for feature in photon_data.get('features', []):
                props = feature.get('properties', {})
                state = props.get('state', '')
                country = props.get('country', '')
                osm_key = props.get('osm_key', '')
                osm_value = props.get('osm_value', '')
                
                # CRITICAL: Filter out POIs and tourism objects - only accept actual settlements
                # This fixes issue where "Тернівка" matched tourism POI "Красивый вид на Терновку" in Crimea
                if osm_key not in ['place', 'boundary']:
                    continue  # Skip tourism, amenity, etc.
                
                # Only accept settlement types
                valid_place_types = ['city', 'town', 'village', 'hamlet', 'suburb', 'neighbourhood', 'administrative']
                if osm_key == 'place' and osm_value not in valid_place_types:
                    continue
                
                if country in ['Україна', 'Ukraine']:
                    # If we have excluded_oblast, skip results from that oblast
                    if excluded_oblast and excluded_oblast in state.lower():
                        print(f"DEBUG: Skipping Photon result in excluded oblast: {state}")
                        continue
                    
                    coords_arr = feature.get('geometry', {}).get('coordinates', [])
                    if coords_arr and len(coords_arr) >= 2:
                        lng, lat = coords_arr[0], coords_arr[1]
                        
                        # Check if this is a frontline oblast
                        is_frontline = any(oblast in state.lower() for oblast in frontline_oblasts)
                        
                        ukraine_results.append({
                            'lat': lat,
                            'lng': lng,
                            'state': state,
                            'is_frontline': is_frontline
                        })
            
            # Select best result based on context
            if ukraine_results:
                # If military context, prioritize frontline oblasts
                if is_military_context:
                    frontline_results = [r for r in ukraine_results if r['is_frontline']]
                    if frontline_results:
                        best = frontline_results[0]
                        print(f"DEBUG Photon (military priority): Found '{name}' in {best['state']} -> ({best['lat']}, {best['lng']})")
                        return (best['lat'], best['lng'], False)
                
                # Otherwise use first result
                best = ukraine_results[0]
                print(f"DEBUG Photon: Found '{name}' in {best['state']} (excluded={excluded_oblast}) -> ({best['lat']}, {best['lng']})")
                return (best['lat'], best['lng'], False)
    except Exception as e:
        print(f"DEBUG: Photon fallback error: {e}")
    
    # Try ensure_city_coords as final fallback
    result = ensure_city_coords(name, detected_oblast_key.lower() if isinstance(detected_oblast_key, str) else None)
    if result:
        return result
    
    # AI FALLBACK: Try to extract city using AI if standard lookup failed
    if GEMINI_ENABLED and message_text:
        try:
            # Extract oblast from message if available
            region_match = re.search(r'([а-яїіє]+щині|[а-яїіє]+щина|[а-яїіє]+ська обл)', message_text.lower())
            region_hint = region_match.group(1) if region_match else None
            
            ai_result = extract_city_from_text(message_text, region_hint)
            if ai_result:
                city_name, confidence = ai_result
                add_debug_log(f"AI: Extracted city '{city_name}' from message (confidence: {confidence:.2f})", "ai_city_extract")
                
                # Try to geocode the AI-extracted city via API (no fallback)
                ai_coords = ensure_city_coords(city_name, region_hint.lower() if isinstance(region_hint, str) else None)
                if ai_coords:
                    add_debug_log(f"AI: Successfully geocoded AI-extracted city '{city_name}' via API -> {ai_coords[:2]}", "ai_geocode_success")
                    return ai_coords
        except Exception as e:
            add_debug_log(f"AI: Error extracting city: {e}", "ai_error")
    
    # Third try: if we have oblast key, return oblast center as fallback
    if message_text and detected_oblast_key and detected_oblast_key in OBLAST_CENTERS:
        lat, lng = OBLAST_CENTERS[detected_oblast_key]
        print(f"DEBUG: Using oblast center fallback for {name}: {detected_oblast_key} -> ({lat}, {lng})")
        return (lat, lng, True)  # True indicates this is an oblast fallback
    
    return None

def normalize_ukrainian_toponym(lemmatized_name: str, original_text: str, grammatical_case: str = None) -> str:
    """
    Universal normalization for Ukrainian place names using linguistic patterns
    
    Args:
        lemmatized_name: SpaCy lemmatized form
        original_text: Original text from message
        grammatical_case: Grammatical case detected by SpaCy (Nom, Gen, Acc, etc.)
        
    Returns:
        Properly normalized toponym
    """
    
    # Rule 1: Special exceptions that need manual handling
    special_exceptions = {
        'чкаловський': 'чкаловське',    # "Чкаловське" wrongly lemmatized as adjective
        'чкаловського': 'чкаловське',   # Genitive case of Чкаловське
        'чкаловському': 'чкаловське',   # Locative case of Чкаловське
        'чкаловськом': 'чкаловське',    # Instrumental case of Чкаловське
        'олексадрія': 'олександрія',    # Common typo/variant
    }
    
    if lemmatized_name in special_exceptions:
        fixed = special_exceptions[lemmatized_name]
        print(f"DEBUG normalize_toponym: Special exception '{lemmatized_name}' → '{fixed}'")
        return fixed
    
    # Rule 2: Adjective endings → City names (most common SpaCy error)
    adjective_to_city_patterns = [
        (r'(.+)ський$', r'\1ськ'),      # покровський → покровськ
        (r'(.+)цький$', r'\1цьк'),      # краматорський → краматорськ  
        (r'(.+)рський$', r'\1рськ'),    # examples like "петрівський" → "петрівськ"
        (r'(.+)нський$', r'\1нськ'),    # examples like "український" → "українськ"
        (r'(.+)льський$', r'\1льськ'),  # examples like "кривський" → "кривськ"
    ]
    
    for pattern, replacement in adjective_to_city_patterns:
        import re
        if re.match(pattern, lemmatized_name):
            normalized = re.sub(pattern, replacement, lemmatized_name)
            print(f"DEBUG normalize_toponym: Adjective pattern '{lemmatized_name}' → '{normalized}'")
            return normalized
    
    # Rule 3: Handle specific case forms that need different normalization
    case_specific_fixes = {
        # Genitive forms that should be nominative
        'зарічний': 'зарічне',          # "Зарічного" (Gen) → "зарічне" (Nom)
        
        # Instrumental case normalization
        'новоукраїнськом': 'новоукраїнськ',  # "над Новоукраїнськом" (Ins) → base form
        'краматорськом': 'краматорськ',      # "над Краматорськом" (Ins) → base form
        'покровськом': 'покровськ',          # "над Покровськом" (Ins) → base form
    }
    
    if lemmatized_name in case_specific_fixes:
        fixed = case_specific_fixes[lemmatized_name]
        print(f"DEBUG normalize_toponym: Case fix '{lemmatized_name}' → '{fixed}'")
        return fixed
    
    # Rule 4: Handle endings that indicate feminine places
    feminine_place_patterns = [
        (r'(.+)івка$', r'\1івка'),      # Keep as is: миколаївка, гусарівка
        (r'(.+)енка$', r'\1енка'),      # Keep as is: савинка (but handle special cases)
    ]
    
    # Special feminine cases that need fixing
    feminine_special_cases = {
        'савинка': 'савинці',  # This is actually "Савинці" wrongly lemmatized
    }
    
    if lemmatized_name in feminine_special_cases:
        fixed = feminine_special_cases[lemmatized_name]
        print(f"DEBUG normalize_toponym: Feminine fix '{lemmatized_name}' → '{fixed}'")
        return fixed
    
    # Rule 5: Use original text pattern if lemmatization looks wrong
    original_lower = original_text.lower()
    
    # If original ends with typical city suffixes but lemma doesn't, prefer original pattern
    city_ending_patterns = [r'(.+)ськ$', r'(.+)цьк$', r'(.+)ів$', r'(.+)ине$', r'(.+)не$']
    lemma_is_adjective = any(lemmatized_name.endswith(ending) for ending in ['ський', 'цький', 'рський', 'нський'])
    
    import re
    for pattern in city_ending_patterns:
        if re.match(pattern, original_lower) and lemma_is_adjective:
            print(f"DEBUG normalize_toponym: Using original pattern '{original_lower}' over lemma '{lemmatized_name}'")
            return original_lower
    
    # Rule 6: Default - return the lemmatized form if no patterns match
    return lemmatized_name


def determine_regional_context(entity, doc, detected_regions, message_text):
    """
    Determine the correct regional context for a geographical entity
    based on its position in the text relative to regional headers
    
    Args:
        entity: SpaCy entity or PseudoEntity
        doc: SpaCy Doc object
        detected_regions: List of detected region names
        message_text: Original message text
        
    Returns:
        str: Most appropriate region name or None
    """
    if not detected_regions:
        return None
    
    if len(detected_regions) == 1:
        return detected_regions[0]
    
    # For multiple regions, find the closest preceding region header
    entity_start_char = entity.start_char if hasattr(entity, 'start_char') else 0
    
    # If entity doesn't have char positions, estimate from token positions
    if not hasattr(entity, 'start_char'):
        try:
            # Find token in doc by text matching
            for token in doc:
                if token.text == entity.text and token.i >= entity.start:
                    entity_start_char = token.idx
                    break
        except:
            entity_start_char = 0
    
    # Find all region positions in text
    region_positions = []
    message_lower = message_text.lower()
    
    region_patterns = {
        'сумщина': ['сумщин'],
        'чернігівщина': ['чернігівщин'],
        'харківщина': ['харківщин'],
        'полтавщина': ['полтавщин'],
        'херсонщина': ['херсонщин'],
        'миколаївщина': ['миколаївщин'],
        'дніпропетровщина': ['дніпропетровщин'],
        'київщина': ['київщин'],
        'донеччина': ['донеччин'],
        'луганщина': ['луганщин'],
        'одесщина': ['одесщин', 'одещин'],
        'запорізька': ['запорізьк'],
        'львівщина': ['львівщин'],
        'волинщина': ['волинщин', 'волинь'],
        'житомирщина': ['житомирщин'],
        'черкащина': ['черкащин'],
        'вінниччина': ['вінниччин', 'вінничин'],
    }
    
    for region_name in detected_regions:
        patterns = region_patterns.get(region_name, [region_name])
        for pattern in patterns:
            pos = message_lower.find(pattern)
            if pos != -1:
                region_positions.append((pos, region_name))
                break
    
    # Sort by position
    region_positions.sort(key=lambda x: x[0])
    
    # Find the closest preceding region
    closest_region = None
    closest_distance = float('inf')
    
    for pos, region_name in region_positions:
        if pos <= entity_start_char:
            distance = entity_start_char - pos
            if distance < closest_distance:
                closest_distance = distance
                closest_region = region_name
    
    # If no preceding region found, use the first one
    result = closest_region if closest_region else detected_regions[0]
    
    print(f"DEBUG Regional context: Entity '{entity.text}' at char {entity_start_char} -> region '{result}'")
    print(f"DEBUG Region positions: {region_positions}")
    
    return result


def spacy_enhanced_geocoding(message_text: str, existing_city_coords: dict = None, 
                           existing_normalizer: dict = None) -> list:
    """
    Enhanced city extraction using SpaCy NLP for Ukrainian text with proper entity recognition
    
    Args:
        message_text: Original message text
        existing_city_coords: deprecated parameter (now uses API instead of local dict)
        existing_normalizer: UA_CITY_NORMALIZE dict (defaults to global UA_CITY_NORMALIZE)
        
    Returns:
        List of dicts with city information:
        {
            'name': str,           # Original city name from message
            'normalized': str,     # Normalized city name for lookup
            'coords': tuple,       # (lat, lng) coordinates if found
            'region': str,         # Detected region if any
            'confidence': float,   # Confidence score 0.0-1.0
            'source': str,         # Detection method used
            'case': str           # Grammatical case if detected
        }
    """
    if not SPACY_AVAILABLE:
        return []
    
    # existing_city_coords is deprecated - we use API now
    if existing_normalizer is None:
        existing_normalizer = UA_CITY_NORMALIZE
        
    results = []
    
    try:
        doc = nlp(message_text)
        
        # Extract regions first for context
        detected_regions = []
        region_patterns = {
            'сумщина': ['сумщин', 'сумська область', 'сумська обл'],
            'чернігівщина': ['чернігівщин', 'чернігівська область', 'чернігівська обл'],
            'харківщина': ['харківщин', 'харківська область', 'харківська обл'],
            'полтавщина': ['полтавщин', 'полтавська область', 'полтавська обл'],
            'херсонщина': ['херсонщин', 'херсонська область', 'херсонська обл'],
            'миколаївщина': ['миколаївщин', 'миколаївська область', 'миколаївська обл'],
            'дніпропетровщина': ['дніпропетровщин', 'дніпропетровська область', 'дніпропетровська обл'],
            'київщина': ['київщин', 'київська область', 'київська обл'],
            'донеччина': ['донеччин', 'донецька область', 'донецька обл'],
            'луганщина': ['луганщин', 'луганська область', 'луганська обл'],
            'одесщина': ['одесщин', 'одеська область', 'одеська обл', 'одещин', 'одещина'],
            'запорізька': ['запорізьк', 'запорізька область', 'запорізька обл'],
            'львівщина': ['львівщин', 'львівська область', 'львівська обл'],
            'волинщина': ['волинщин', 'волинська область', 'волинська обл', 'волинь'],
            'житомирщина': ['житомирщин', 'житомирська область', 'житомирська обл'],
            'черкащина': ['черкащин', 'черкаська область', 'черкаська обл'],
            'вінниччина': ['вінниччин', 'вінницька область', 'вінницька обл', 'вінничин'],
        }
        
        message_lower = message_text.lower()
        for region_name, patterns in region_patterns.items():
            if any(pattern in message_lower for pattern in patterns):
                detected_regions.append(region_name)
        
        print(f"DEBUG SpaCy NLP: Processing text: '{message_text}'")
        print(f"DEBUG SpaCy NLP: Detected regions: {detected_regions}")
        
        # Process named entities from SpaCy NER - this is the proper NLP approach
        geographical_entities = []
        for ent in doc.ents:
            if ent.label_ in ['LOC', 'GPE']:  # Location, Geopolitical entity
                print(f"DEBUG SpaCy NLP: Found entity '{ent.text}' with label '{ent.label_}' confidence: {ent._.score if hasattr(ent, '_') and hasattr(ent._, 'score') else 'N/A'}")
                geographical_entities.append(ent)
        
        # Also look for proper nouns that might be geographical names
        for token in doc:
            if (token.pos_ == 'PROPN' and 
                not any(ent.start <= token.i < ent.end for ent in geographical_entities) and
                len(token.text) > 2):  # Skip short tokens
                print(f"DEBUG SpaCy NLP: Found additional PROPN candidate: '{token.text}'")
                # Create a pseudo-entity for processing
                class PseudoEntity:
                    def __init__(self, token):
                        self.text = token.text
                        self.start = token.i
                        self.end = token.i + 1  # Add missing end attribute
                        self.label_ = 'PROPN_CANDIDATE'
                geographical_entities.append(PseudoEntity(token))
        
        for ent in geographical_entities:
            entity_text = ent.text.lower()
            
            # Skip if this is a region (already processed)
            is_region = False
            for region_name, patterns in region_patterns.items():
                if any(pattern in entity_text for pattern in patterns):
                    is_region = True
                    break
            
            if not is_region:
                # Get morphological info
                if hasattr(ent, 'start'):
                    token = doc[ent.start]
                else:
                    # For pseudo-entities, find the token
                    token = next((t for t in doc if t.text.lower() == entity_text), None)
                    if not token:
                        continue
                
                case_info = None
                if hasattr(token, 'morph') and token.morph:
                    morph_dict = token.morph.to_dict()
                    case_info = morph_dict.get('Case', None)
                
                # Normalize city name using lemma - this is proper NLP morphological analysis
                normalized_name = token.lemma_.lower() if token.lemma_ and token.lemma_ != '-PRON-' else entity_text
                
                # For multi-word geographical entities, handle them specially
                if len(ent.text.split()) > 1:
                    # For multi-word entities, use custom normalization
                    entity_lower = ent.text.lower()
                    multi_word_fixes = {
                        'кривому рогу': 'кривий ріг',
                        'кривий ріг': 'кривий ріг',
                        'кривого рогу': 'кривий ріг',
                        'новий буг': 'новий буг',
                        'білий камінь': 'білий камінь',
                        'покровськ': 'покровськ',  # formerly красноармейск
                    }
                    for pattern, canonical in multi_word_fixes.items():
                        if pattern in entity_lower:
                            normalized_name = canonical
                            break
                    else:
                        # If no special case, try to reconstruct from lemmas
                        words = []
                        for i in range(ent.start, ent.end):
                            word_token = doc[i]
                            word_lemma = word_token.lemma_.lower() if word_token.lemma_ and word_token.lemma_ != '-PRON-' else word_token.text.lower()
                            words.append(word_lemma)
                        normalized_name = ' '.join(words)
                
                print(f"DEBUG SpaCy NLP: Entity '{ent.text}' -> normalized: '{normalized_name}', case: {case_info}")
                
                # Apply intelligent normalization for Ukrainian place names
                normalized_name = normalize_ukrainian_toponym(normalized_name, ent.text, case_info)
                
                # Apply existing normalization rules
                if normalized_name in existing_normalizer:
                    normalized_name = existing_normalizer[normalized_name]
                
                # Determine the most appropriate regional context for this entity
                region_context = determine_regional_context(ent, doc, detected_regions, message_text)
                
                # Look up coordinates using enhanced lookup with Nominatim fallback
                coords = get_coordinates_enhanced(normalized_name, region_context, message_text)
                
                # Determine confidence based on source
                confidence = 0.9 if ent.label_ in ['LOC', 'GPE'] else 0.7  # Higher for NER entities
                source = 'spacy_ner' if ent.label_ in ['LOC', 'GPE'] else 'spacy_propn'
                
                result = {
                    'name': ent.text,
                    'normalized': normalized_name,
                    'coords': coords,
                    'region': region_context,
                    'confidence': confidence,
                    'source': source,
                    'case': case_info
                }
                results.append(result)
                print(f"DEBUG SpaCy NLP: Added result: {result}")
        
        # Additional pattern-based extraction for missed entities (as fallback)
        preposition_patterns = ['на', 'повз', 'через', 'у напрямку', 'в напрямку']
        
        for i, token in enumerate(doc):
            # Simple prepositions
            if token.text.lower() in preposition_patterns[:3]:  # на, повз, через
                city_info = _extract_city_after_preposition_spacy(doc, i, detected_regions, 
                                                                existing_city_coords, existing_normalizer)
                if city_info:
                    results.append(city_info)
            
            # Direction patterns
            elif (token.text.lower() == 'у' and i + 1 < len(doc) and 
                  doc[i + 1].text.lower() == 'напрямку'):
                city_info = _extract_city_after_preposition_spacy(doc, i + 1, detected_regions,
                                                                existing_city_coords, existing_normalizer)
                if city_info:
                    results.append(city_info)
        
        # Remove duplicates while preserving order
        unique_results = []
        seen_cities = set()
        for result in results:
            city_key = result['normalized']
            if city_key not in seen_cities:
                seen_cities.add(city_key)
                unique_results.append(result)
        
        print(f"DEBUG SpaCy NLP: Final results: {unique_results}")
        return unique_results
        
    except Exception as e:
        print(f"SpaCy processing error: {e}")
        return []

def _find_coordinates_multiple_formats(city_name: str, detected_regions: list, existing_city_coords: dict) -> tuple:
    """
    Try to find coordinates using API with regional filtering
    Returns coordinates tuple (lat, lng) or None
    
    Note: existing_city_coords parameter is deprecated but kept for backward compatibility
    """
    try:
        import requests
        
        # Build region context from detected_regions
        region_context = None
        if detected_regions:
            # Convert region names to adjective forms
            region_adj_map = {
                'сумщина': 'сумська',
                'чернігівщина': 'чернігівська', 
                'харківщина': 'харківська',
                'полтавщина': 'полтавська',
                'дніпропетровщина': 'дніпропетровська',
                'херсонщина': 'херсонська',
                'миколаївщина': 'миколаївська',
                'київщина': 'київська',
                'донеччина': 'донецька',
                'луганщина': 'луганська'
            }
            
            for region in detected_regions:
                region_adj = region_adj_map.get(region, region)
                region_context = region_adj + ' область'
                break
        
        # Try Photon API (supports Cyrillic)
        photon_url = 'https://photon.komoot.io/api/'
        photon_params = {'q': city_name, 'limit': 10}
        
        photon_response = requests.get(photon_url, params=photon_params, timeout=3)
        if photon_response.ok:
            photon_data = photon_response.json()
            for feature in photon_data.get('features', []):
                props = feature.get('properties', {})
                state = props.get('state', '')
                country = props.get('country', '')
                osm_key = props.get('osm_key', '')
                osm_value = props.get('osm_value', '')
                
                # Filter out POIs - only settlements
                if osm_key not in ['place', 'boundary']:
                    continue
                valid_place_types = ['city', 'town', 'village', 'hamlet', 'suburb', 'neighbourhood', 'administrative']
                if osm_key == 'place' and osm_value not in valid_place_types:
                    continue
                
                if country in ['Україна', 'Ukraine']:
                    # Filter by region if available
                    if region_context and region_context in state:
                        coords_arr = feature.get('geometry', {}).get('coordinates', [])
                        if coords_arr and len(coords_arr) >= 2:
                            lng, lat = coords_arr[0], coords_arr[1]
                            print(f"DEBUG SpaCy Photon: Found '{city_name}' in {state} -> ({lat}, {lng})")
                            return (lat, lng)
                    elif not region_context:
                        # No region filter, use first Ukraine result
                        coords_arr = feature.get('geometry', {}).get('coordinates', [])
                        if coords_arr and len(coords_arr) >= 2:
                            lng, lat = coords_arr[0], coords_arr[1]
                            print(f"DEBUG SpaCy Photon: Found '{city_name}' in {state} -> ({lat}, {lng})")
                            return (lat, lng)
    
    except Exception as e:
        print(f"DEBUG SpaCy API lookup error: {e}")
    
    print(f"DEBUG SpaCy coord lookup: No coordinates found via API for '{city_name}'")
    return None

def get_coordinates_enhanced(city_name: str, region: str = None, context: str = "") -> tuple:
    """
    Enhanced coordinate lookup with Nominatim API fallback
    
    Args:
        city_name: Name of the settlement
        region: Optional region specification
        context: Context for military priority (e.g., "БпЛА курсом на")
        
    Returns:
        Tuple of (latitude, longitude) or None if not found
    """
    
    # First try local database with regional context prioritization
    context_lower = context.lower()
    
    # Handle Зарічне disambiguation based on context
    if city_name == 'зарічне':
        if any(keyword in context_lower for keyword in ['дніпропетровщина', 'дніпро', 'покровський', 'бпла']):
            # For Dnipropetrovska oblast contexts
            coords = DNIPRO_CITY_COORDS.get('зарічне дніпропетровська')
            if coords:
                print(f"DEBUG Enhanced coord lookup: Found '{city_name}' using Dnipropetrovska context -> {coords}")
                return coords
        elif any(keyword in context_lower for keyword in ['рівненщина', 'рівне']):
            # For Rivne oblast contexts  
            coords = (51.2167, 26.0833)
            print(f"DEBUG Enhanced coord lookup: Found '{city_name}' using Rivne context -> {coords}")
            return coords
    
    # Handle regional prefixes in context
    regional_indicators = {
        'дніпропетровщина': 'дніпропетровська',
        'киівщина': 'київська', 
        'харківщина': 'харківська',
        'житомирщина': 'житомирська',
        'чернігівщина': 'чернігівська',
        'сумщина': 'сумська'
    }
    
    detected_region = None
    for indicator, region_name in regional_indicators.items():
        if indicator in context_lower:
            detected_region = region_name
            break
    
    # If region detected from context but not passed as parameter, use detected
    if detected_region and not region:
        region = detected_region
        print(f"DEBUG Enhanced coord lookup: Detected region '{region}' from context for '{city_name}'")
    
    # Handle specific directional contexts (e.g., "північніше Чернігова")
    if 'чернігов' in context_lower and any(direction in context_lower for direction in ['північн', 'півн', 'північ']):
        if city_name == 'любеч':
            # Любеч північніше Чернігова
            coords = (51.4961, 30.2675)  # Правильні координати Любеча
            print(f"DEBUG Enhanced coord lookup: Found '{city_name}' using directional context north of Chernigiv -> {coords}")
            return coords
    
    # PRIORITIZE NOMINATIM API when region is specified
    if region and NOMINATIM_AVAILABLE:
        # Normalize region name for Nominatim API
        normalized_region = region.lower()
        
        # Convert regional nicknames to standard oblast names
        region_mappings = {
            'миколаївщина': 'миколаївська область',
            'херсонщина': 'херсонська область', 
            'харківщина': 'харківська область',
            'донеччина': 'донецька область',
            'луганщина': 'луганська область',
            'запоріжжя': 'запорізька область',
            'дніпропетровщина': 'дніпропетровська область',
            'полтавщина': 'полтавська область',
            'сумщина': 'сумська область',
            'чернігівщина': 'чернігівська область',
            'київщина': 'київська область',
            'житомирщина': 'житомирська область',
            'вінниччина': 'вінницька область',
            'черкащина': 'черкаська область',
            'кіровоградщина': 'кіровоградська область',
            'тернопільщина': 'тернопільська область',
            'хмельниччина': 'хмельницька область',
            'рівненщина': 'рівненська область',
            'волинщина': 'волинська область',
            'львівщина': 'львівська область',
            'закарпаття': 'закарпатська область',
            'івано-франківщина': 'івано-франківська область',
            'буковина': 'чернівецька область',
            'одещина': 'одеська область',
            'одесщина': 'одеська область',
        }
        
        # Apply mapping if available
        nominatim_region = region_mappings.get(normalized_region, region)
        
        print(f"DEBUG Enhanced coord lookup: Trying Nominatim API first for '{city_name}' in {nominatim_region} (from {region})")
        coords = get_coordinates_nominatim(city_name, nominatim_region)
        if coords:
            print(f"DEBUG Enhanced coord lookup: Nominatim found '{city_name}' in {nominatim_region} -> {coords}")
            # Cache the result in local database for future use
            cache_key = f"{city_name} {region}"
            CITY_COORDS[cache_key] = coords
            return coords
        else:
            print(f"DEBUG Enhanced coord lookup: Nominatim could not find '{city_name}' in {nominatim_region}")
    
    # API-only geocoding - NO local database fallback
    coords = ensure_city_coords(city_name, region.lower() if isinstance(region, str) else None)
    if coords:
        print(f"DEBUG Enhanced coord lookup: API found '{city_name}' -> {coords}")
        return coords
    
    # API-only geocoding - NO local database fallback
    coords = ensure_city_coords(city_name, region.lower() if isinstance(region, str) else None)
    if coords:
        print(f"DEBUG Enhanced coord lookup: API found '{city_name}' -> {coords}")
        return coords
    
    # Fallback to Nominatim API for precise geocoding
    if NOMINATIM_AVAILABLE:
        print(f"DEBUG Enhanced coord lookup: Trying Nominatim API for '{city_name}'" + (f" in {region}" if region else ""))
        coords = get_coordinates_nominatim(city_name, region)
        if coords:
            print(f"DEBUG Enhanced coord lookup: Nominatim found '{city_name}' -> {coords}")
            # Cache the result in local database for future use
            cache_key = f"{city_name}" + (f" {region}" if region else "")
            CITY_COORDS[cache_key] = coords
            return coords
        else:
            print(f"DEBUG Enhanced coord lookup: Nominatim could not find '{city_name}'")
    
    print(f"DEBUG Enhanced coord lookup: No coordinates found for '{city_name}' anywhere")
    return None

def get_coordinates_context_aware(text: str) -> tuple:
    """
    Context-aware coordinate lookup using intelligent text analysis
    
    Args:
        text: Full message text for context analysis
        
    Returns:
        Tuple of (latitude, longitude, target_city_name) or None if not found
    """
    
    if not CONTEXT_GEOCODER_AVAILABLE:
        print("DEBUG Context geocoder: Not available")
        return None
    
    print(f"DEBUG Context geocoder: Analyzing text: '{text}'")
    
    # Get prioritized geocoding candidates
    candidates = get_context_aware_geocoding(text)
    
    if not candidates:
        print("DEBUG Context geocoder: No candidates found")
        return None
    
    print(f"DEBUG Context geocoder: Found {len(candidates)} candidates: {candidates}")
    
    # Try each candidate in order of confidence
    for city_name, region, confidence in candidates:
        # Skip obviously invalid candidates
        if len(city_name) < 2 or city_name in ['-', 'над', 'на', 'у', 'в', 'до', 'під', 'біля', 'а', 'курсом']:
            continue
            
        print(f"DEBUG Context geocoder: Trying candidate '{city_name}' (region: {region}, confidence: {confidence})")
        
        # Use enhanced coordinate lookup
        coords = get_coordinates_enhanced(city_name, region=region, context=text)
        
        if coords:
            print(f"DEBUG Context geocoder: SUCCESS - Found '{city_name}' -> {coords}")
            return coords[0], coords[1], city_name
    
    print("DEBUG Context geocoder: No valid coordinates found for any candidate")
    return None

def _extract_city_after_preposition_spacy(doc, prep_index: int, detected_regions: list,
                                        existing_city_coords: dict, existing_normalizer: dict) -> dict:
    """Extract city name after preposition using SpaCy tokens"""
    if prep_index + 1 >= len(doc):
        return None
    
    # Collect potential city tokens (proper nouns, nouns, adjectives)
    city_tokens = []
    start_idx = prep_index + 1
    
    for i in range(start_idx, min(start_idx + 3, len(doc))):  # Max 3 words
        token = doc[i]
        if token.pos_ in ['PROPN', 'NOUN', 'ADJ'] or token.text == '-':
            city_tokens.append(token)
        else:
            break
    
    if not city_tokens:
        return None
    
    # Build city name
    city_name = ' '.join(token.text for token in city_tokens)
    
    # Get morphological info from the main token (usually the first one)
    main_token = city_tokens[0]
    case_info = None
    if hasattr(main_token, 'morph') and main_token.morph:
        morph_dict = main_token.morph.to_dict()
        case_info = morph_dict.get('Case', None)
    
    # Normalize using lemma
    normalized_name = main_token.lemma_ if main_token.lemma_ != city_name.lower() else city_name.lower()
    
    # Apply intelligent normalization for Ukrainian place names
    normalized_name = normalize_ukrainian_toponym(normalized_name, city_name, case_info)
    
    # Apply existing normalization rules
    if normalized_name in existing_normalizer:
        normalized_name = existing_normalizer[normalized_name]
    
    # Look up coordinates using enhanced lookup with Nominatim fallback  
    region_context = detected_regions[0] if detected_regions else None
    coords = get_coordinates_enhanced(normalized_name, region_context, ' '.join(token.text for token in doc))
    
    return {
        'name': city_name,
        'normalized': normalized_name,
        'coords': coords,
        'region': detected_regions[0] if detected_regions else None,
        'confidence': 0.7,  # Medium confidence for pattern-based
        'source': 'spacy_pattern',
        'case': case_info
    }

# DEPRECATED: CITY_COORDS dictionary is no longer used for primary geocoding
# The system now uses Photon/Nominatim APIs for real-time geocoding
# This dictionary is kept only for backward compatibility and as fallback
# See ensure_city_coords() and ensure_city_coords_with_message_context() for current API-based implementation
CITY_COORDS = {
        # Core cities
        'київ': (50.4501, 30.5234), 'харків': (49.9935, 36.2304), 'одеса': (46.4825, 30.7233), 'дніпро': (48.4647, 35.0462),
        'львів': (49.8397, 24.0297), 'запоріжжя': (47.8388, 35.1396), 'вінниця': (49.2331, 28.4682), 'миколаїв': (46.9750, 31.9946),
        'маріуполь': (47.0971, 37.5434), 'полтава': (49.5883, 34.5514), 'чернігів': (51.4982, 31.2893), 'черкаси': (49.4444, 32.0598),
        'житомир': (50.2547, 28.6587), 'суми': (50.9077, 34.7981), 'хмельницький': (49.4229, 26.9871), 'чернівці': (48.2921, 25.9358),
    
    # Житомирська область - усі основні міста
    'овруч': (51.3244, 28.8006), 'коростень': (50.9550, 28.6336), 'новоград-волинський': (50.5833, 27.6167), 
    'бердичів': (49.8978, 28.6011), 'звягель': (50.5833, 27.6167), 'малин': (50.7726, 29.2360), 
    'радомишль': (50.4972, 29.2292), 'черняхів': (50.4583, 28.8500), 'баранівка': (50.3000, 27.6667),
    'попільня': (49.9333, 28.4167), 'ємільчине': (50.8667, 28.8500), 'олевськ': (51.2167, 27.6667),
    'лугини': (50.9333, 27.2667), 'чудnів': (50.0500, 28.1167), 'андрушівка': (50.0833, 29.8000),
    'романів': (50.1500, 28.2667), 'ружин': (49.6333, 28.6000), 'володарськ-волинський': (50.5500, 28.3833),
    'коростишів': (50.3167, 29.0333), 'народичі': (51.0583, 29.1167), 'іванківець': (50.1333, 29.3333),
    'любар': (49.9167, 27.7333), 'високе': (51.1000, 28.1000), 'чорнобиль': (51.2768, 30.2219),
    'поліське': (51.1833, 29.5000),
    
    # Форми відмінків для Овруча
    'овручі': (51.3244, 28.8006), 'овручу': (51.3244, 28.8006), 'овручем': (51.3244, 28.8006),
    'овручем': (51.3244, 28.8006), 'овруча': (51.3244, 28.8006),
    
    # Інші форми для міст Житомирської області
    'малині': (50.7726, 29.2360), 'малину': (50.7726, 29.2360), 'малином': (50.7726, 29.2360),
    'коростені': (50.9550, 28.6336), 'коростену': (50.9550, 28.6336), 'коростенем': (50.9550, 28.6336),
    'бердичеві': (49.8978, 28.6011), 'бердичеву': (49.8978, 28.6011), 'бердичевом': (49.8978, 28.6011),
    'новограді-волинському': (50.5833, 27.6167), 'новоград-волинському': (50.5833, 27.6167),
    
    # Бершадь - райцентр Вінницької області
    'бершадь': (48.3667, 29.5167),
    'бершаді': (48.3667, 29.5167),
    'бершадю': (48.3667, 29.5167),
    'бершадью': (48.3667, 29.5167),
    'бершадей': (48.3667, 29.5167),
    
    # Added per user report (обстріл alert should map): Костянтинівка (Donetsk Obl.)
    'костянтинівка': (48.5277, 37.7050),
    # Mezhova (Дніпропетровська обл.) to avoid fallback to Dnipro
    'межова': (48.2583, 36.7363),
    # Sviatohirsk (Святогірськ) Donetsk Oblast
    'святогірськ': (49.0339, 37.5663),
    # Antonivka (Kherson urban-type settlement, user report for UAV threat)
    'антонівка': (46.6925, 32.7186),
    # Alexandria (Kirovohrad Oblast) - avoid confusion with other cities named Alexandria
    'олександрія': (48.8033, 33.1147),
    # Vilshany (Kirovohrad Oblast) - separate from Vilshanka in other regions  
    'вільшани': (48.4667, 32.2667),
    'вільшанам': (48.4667, 32.2667),
    'вільшанах': (48.4667, 32.2667),
    # Baturyn (Chernihiv Obl.) for directional course reports
    'батурин': (51.3450, 32.8761),
        'рівне': (50.6199, 26.2516), 'івано-франківськ': (48.9226, 24.7111), 'луцьк': (50.7472, 25.3254), 'тернопіль': (49.5535, 25.5948),
        'ужгород': (48.6208, 22.2879), 'кропивницький': (48.5079, 32.2623), 'кременчук': (49.0670, 33.4204), 'краматорськ': (48.7389, 37.5848),
        'мелітополь': (46.8489, 35.3650), 'бердянськ': (46.7553, 36.7885), 'павлоград': (48.5350, 35.8700), 'нікополь': (47.5667, 34.4061),
        'марганець': (47.6433, 34.6289), 'херсон': (46.6350, 32.6169),
        'корабельний район херсон': (46.6578, 32.5099),
        'білозерка': (46.64, 32.88),  # Херсонська область
        'чорнобаївка': (46.6964, 32.5469),  # Херсонська область
    
    # Недостающие города из UAV сообщений (сентябрь 2025)
    'зарічне': (51.2167, 26.0833),      # Рівненська область (default - first in alphabetical order)
    'зарічне(дніпропетровська)': (48.15, 35.2),  # Зарічне, Дніпропетровська область
    'зарічне (дніпропетровська)': (48.15, 35.2),  # With space
    'зарічне(рівненська)': (51.2167, 26.0833),  # Explicit Рівненська
    'зарічне (рівненська)': (51.2167, 26.0833),  # With space
    'сенкевичівка': (51.5667, 25.8333), # Волинська область
    'голоби': (50.7833, 25.2167),       # Волинська область
    
    # Дополнительные города из UAV сообщений (сентябрь 2025)
    'корнин': (50.9167, 29.1167),       # Житомирська область, Малинський район
    'корнину': (50.9167, 29.1167),
    'корнином': (50.9167, 29.1167),
    'корнина': (50.9167, 29.1167),
    'устинівка': (50.7481, 29.0028),    # Житомирська область, Малинський район
    'устинівці': (50.7481, 29.0028),
    'устинівку': (50.7481, 29.0028),
    'устинівкою': (50.7481, 29.0028),
    'добротвір': (50.2053, 24.4239),    # Львівська область, енергетичний центр
    'добротворі': (50.2053, 24.4239),
    'добротвору': (50.2053, 24.4239),
    'добротвором': (50.2053, 24.4239),
    'добротвора': (50.2053, 24.4239),
    'слов\'янськ': (48.8417, 37.5983), 'дружківка': (48.6203, 37.5263),
    # Fallback key without apostrophe (some sources strip it)
    'словянськ': (48.8417, 37.5983),
    'білопілля': (51.1500, 34.3014),
        # Extended regional towns & settlements
        'гадяч': (50.3713, 34.0109), 'чорнухи': (50.2833, 33.0000), 'великі сорочинці': (50.0167, 33.9833), 'семенівка': (50.6633, 32.3933),
        'лубни': (50.0186, 32.9931), 'шишаки': (49.8992, 34.0072), 'широке': (47.6833, 34.5667), 'зеленодольськ': (47.5667, 33.5333),
        'бабанка': (48.9833, 30.4167), 'новий буг': (47.6833, 32.5167), 'березнегувате': (47.3167, 32.8500), 'новоархангельськ': (48.6667, 30.8000),
        'липняжка': (48.6167, 30.8667), 'голованівськ': (48.3772, 30.5322), 'бишів': (50.3167, 29.9833), 'обухів': (50.1072, 30.6211),
        'гребінки': (50.2500, 30.2500), 'біла церква': (49.7950, 30.1310), 'сквира': (49.7333, 29.6667), 'чорнобиль': (51.2768, 30.2219),
        'пулини': (50.4333, 28.4333), 'головине': (50.3833, 28.6667), 'радомишль': (50.4972, 29.2292), 'коростень': (50.9500, 28.6333),
        'погребище': (49.4833, 29.2667), 'теплик': (48.6667, 29.6667), 'оратів': (48.9333, 29.5167), 'дашів': (48.9000, 29.4333),
        'шаргород': (48.7333, 28.0833), 'бірки': (49.7517, 36.1025), 'златопіль': (49.9800, 35.5300), 'балаклія': (49.4627, 36.8586),
        'берестин': (50.2000, 35.0000), 'старий салтів': (50.0847, 36.7424), 'борки': (49.9380, 36.1260), 'кролевець': (51.5481, 33.3847),
    'глобине': (49.3833, 33.2667), 'кринички': (47.2333, 34.3500), 'солоне': (48.1436, 35.9933), 'брусилів': (50.2800, 29.5300),
    'терни': (50.9070, 34.0130), 'понорниця': (51.8033, 32.5333), 'куликівка': (51.3520, 31.6480),
    # Additional settlements from multi-region UAV course messages (September 2025)
    'путивль': (51.3361, 33.8692), 'бахмач': (51.1808, 32.8203), 'носівка': (50.9444, 32.0167), 'козелець': (50.9167, 31.1833),
    'страхолісся': (50.5167, 30.8833), 'білокоровичі': (51.1667, 27.75),
    'краснопавлівка': (50.0167, 35.95), 'божедрівка': (48.4167, 35.0167), 'пʼятихатки': (48.5667, 33.6833),
    'петрове': (48.7333, 32.8), 'брилівка': (46.8167, 32.7833),
    # Additional missing cities from napramok messages (September 2025)
    'десна': (51.0333, 31.1667), 'кіпті': (51.2833, 31.2167), 'ічня': (50.3833, 34.8833), 'цвіткове': (49.7167, 32.2167),
    'чоповичі': (50.8333, 28.7333), 'звягель': (50.5833, 27.6667), 'камʼянське': (48.5167, 34.6167),
    'піщаний брід': (48.1167, 32.0833), 'бобринець': (48.0333, 32.1833), 'тендрівська коса': (46.1833, 31.5333),
        'новгород-сіверський': (51.9874, 33.2620), 'сосниця': (51.5236, 32.4953), 'олишівка': (51.0725, 31.3525), 'березна': (51.5756, 31.7431),
        'зачепилівка': (49.1717, 35.2742), 'близнюки': (48.8520, 36.5440), 'нова водолага': (49.7270, 35.8570), 'сахновщина': (49.1544, 35.1460),
        'губиниха': (48.7437, 35.2960), 'перещепине': (48.6260, 35.3580), 'карлівка': (49.4586, 35.1272), 'магдалинівка': (48.8836, 34.8669),
        'савинці': (49.4365, 37.2981), 'шевченкове': (49.6996, 37.1770), 'обухівка': (48.6035, 34.8530), 'курилівка': (48.6715, 34.8740),
        'петриківка': (48.7330, 34.6300), 'підгородне': (48.5747, 35.1482), 'самар': (48.6500, 35.4200), 'верхньодніпровськ': (48.6535, 34.3372),
        'горішні плавні': (49.0123, 33.6450), "кам'янське": (48.5110, 34.6021), 'камянське': (48.5110, 34.6021), 'липова долина': (50.5700, 33.7900),
        'тростянець': (50.4833, 34.9667), 'лебедин': (50.5872, 34.4912), 'улянівка': (50.8530, 34.3170), 'уляновка': (50.8530, 34.3170),
        'богодухів': (50.1646, 35.5279), 'холми': (51.6272, 32.5531), 'блистова': (51.6833, 32.6333), 'ніжин': (51.0480, 31.8860),
        'мена': (51.5211, 32.2147), 'десна': (51.0833, 30.9333), 'євминка': (51.3167, 31.7167), 'м.-коцюбинське': (51.5833, 31.1167),
        'лосинівка': (51.1333, 31.7167), 'ічня': (51.0722, 32.3931), 'борзна': (51.2542, 32.4192), 'прилуки': (50.5931, 32.3878),
        'линовиця': (50.7833, 32.4167), 'валки': (49.8427, 35.6150), 'кегичівка': (49.5440, 35.7760), 'велика багачка': (50.1946, 33.7894),
        'велику багачку': (50.1946, 33.7894), 'велику багачу': (50.1946, 33.7894), 'липову долину': (50.5700, 33.7900), 'затока': (46.0660, 30.4680),
        'янське': (48.4567, 36.3342), 'чугуїв': (49.8376, 36.6881), 'ворожба': (51.8031, 34.4972), 'краснопілля': (50.4422, 35.3081),
        'бориспіль': (50.3527, 30.9550), 'жашків': (49.2431, 30.1122), 'есмань': (51.8833, 34.2833), 'мерефа': (49.8181, 36.0572),
        'глухів': (51.6781, 33.9169), 'недригайлів': (50.8281, 33.8781), 'вороніж': (51.8081, 33.3722), 'ромни': (50.7497, 33.4746),
    'ямпіль': (51.2247, 34.3224), 'ямпіль сумська': (51.2247, 34.3224), 'ямполь сумська': (51.2247, 34.3224),
    'хутір-михайлівський': (51.8000, 33.5000),
        'узин': (49.8216, 30.4567), 'гончарівське': (51.6272, 31.3192), 'голованівськ': (48.3772, 30.5322), 'новоукраїнка': (48.3122, 31.5272),
        'тульчин': (48.6783, 28.8486), 'бровари': (50.5110, 30.7909), 'канів': (49.7517, 31.4717), 'миронівка': (49.6631, 31.0100),
        'борова': (49.3742, 36.4892), 'буринь': (51.2000, 33.8500), 'конотоп': (51.2417, 33.2022), 'кролевец': (51.5486, 33.3856), 'остер': (50.9481, 30.8831),
        'плавні': (49.0123, 33.6450), 'голованівський район': (48.3772, 30.5322), 'новоукраїнський район': (48.3122, 31.5272),
        'безлюдівка': (49.8872, 36.2731), 'рогань': (49.9342, 36.4942), 'савинці(харківщина)': (49.6272, 36.9781),
        'слатине': (49.7500, 36.1500),  # Слатине, Дергачівський р-н, Харківська обл.
        'гути': (50.0167, 36.3833),  # Гути, Харьковская область
        # Temporary missing cities (should be in external data sources)
        'гусарівка': (49.1000, 37.1500),  # Гусарівка, Харківська область - TEMP: SpaCy не находит автоматически
        'протопопівка': (49.7000, 37.0000),  # Протопопівка, Харківська область - TEMP: SpaCy не находит автоматически
        'українка': (50.1447, 30.7381), 'царичанка': (48.9767, 34.3772), 'ріпки': (51.8122, 31.0817), 'михайло-коцюбинське': (51.5833, 31.1167),
    'андріївка': (49.9380, 36.9510),
        'макошине': (51.6275, 32.2731), 'парафіївка': (50.9833, 32.2833), 'дубовʼязівка': (51.1833, 33.7833), 'боромля': (50.7500, 34.9833),
    # Newly added (missing in earlier dictionary lookups reported by user)
    'городня': (51.8892, 31.6011),
        'жукин': (50.7800, 30.6820), 'велика димерка': (50.8140, 30.8080), 'велику димерку': (50.8140, 30.8080), 'вишгород': (50.5840, 30.4890),
    'димер': (50.8390, 30.3050),
        'ржищів': (49.9719, 31.0500), 'вишеньки': (50.2987, 30.6445), 'жуляни': (50.4017, 30.4519), 'троєщина': (50.5130, 30.6030),
        'троєщину': (50.5130, 30.6030), 'конча-заспа': (50.2650, 30.5760), 'любар': (50.0500, 27.7500), 'старий остропіль': (49.6503, 27.2291),
        'петрівці': (50.4167, 30.5833),
        'згурівка': (50.4950, 31.7780), 'мала дівиця': (50.8240, 32.4700), 'яготин': (50.2360, 31.7700), 'ставище': (49.3958, 30.1875),
        'березань': (50.3085, 31.4576), 'бортничі': (50.3915, 30.6695), 'старокостянтинів': (49.7574, 27.2039), 'адампіль': (49.6500, 27.3000),
        # Additional single-city early parser support
        'покровське': (48.1180, 36.2470), 'петропавлівка': (48.5000, 36.4500), 'шахтарське': (47.9500, 36.0500),
        # 'миколаївка': Удалено - неоднозначное название, используется контекстный поиск
        'низи': (50.7435, 34.9860), 'барвінкове': (48.9000, 37.0167), 'пісочин': (49.9500, 36.1330), 'берестове': (49.3500, 37.0000),
    'кобеляки': (49.1500, 34.2000), 'бердичів': (49.8942, 28.5986),
    'куцуруб': (46.7906, 31.9222), 'воскресенка': (50.4850, 30.6090),
    # Newly added Kyiv & Odesa region settlements / raion centers for alerts
    'гостомель': (50.5853, 30.2617), 'боярка': (50.3301, 30.5201), 'макарів': (50.4645, 29.8114),
    'бородянка': (50.6447, 29.9202), 'кілія': (45.4553, 29.2640),
    # Cherkasy region settlement (directional course report: "БпЛА курсом на Цибулів")
    'цибулів': (49.0733, 29.8472),
    # Raion centers (approx: use main settlement or administrative center)
    'ізмаїльський район': (45.3516, 28.8365), # near Izmail
    'броварський район': (50.5110, 30.7909),
    'обухівський район': (50.1072, 30.6211),
    'херсонський район': (46.6350, 32.6169),
    'вінницький район': (49.2331, 28.4682)
    ,# --- Newly added (Sept 2 multi-line UAV message) ---
    'нечаяне': (46.8840, 32.0310), 'нечаянеу': (46.8840, 32.0310), 'нечаяному': (46.8840, 32.0310),
    'чечельник': (48.2156, 29.3708), 'чечельнику': (48.2156, 29.3708),
    'залісся': (51.0836, 30.1914), 'заліссям': (51.0836, 30.1914),
    'красятичі': (51.0410, 29.6000), 'красятичів': (51.0410, 29.6000),
    'іршанськ': (50.7833, 28.9000), 'іршанську': (50.7833, 28.9000),
    'хорошів': (50.7167, 28.6167), 'хорошеві': (50.7167, 28.6167), 'хорошеву': (50.7167, 28.6167),
    'народичі': (51.2000, 29.0833), 'народичів': (51.2000, 29.0833),
    'нові білокоровичі': (51.1333, 27.7667), 'нові білокоровичів': (51.1333, 27.7667),
    'городниця': (51.3270, 27.3460), 'городницю': (51.3270, 27.3460),
    'березне': (50.9833, 26.7500), 'березному': (50.9833, 26.7500),
    'божедарівка': (48.3014, 34.5522), 'божедарівку': (48.3014, 34.5522), 'божедарівці': (48.3014, 34.5522),
    'пʼятихатки': (48.5667, 33.6833), "п'ятихатки": (48.5667, 33.6833), 'пятихатки': (48.5667, 33.6833),
    'жовті води': (48.3500, 33.5000), 'жовтих вод': (48.3500, 33.5000),
    'згурівку': (50.4950, 31.7780), 'згурівці': (50.4950, 31.7780),
    'козятин': (49.7167, 28.8333), 'козятина': (49.7167, 28.8333),
    'теплик': (48.6650, 29.7480), 'теплика': (48.6650, 29.7480),
    'новий буг': (47.6833, 32.5167), 'нового буга': (47.6833, 32.5167),
    'семенівку': (50.6633, 32.3933), 'лубни': (50.0186, 32.9931),
    'згурівка (київщина)': (50.4950, 31.7780),
    'гребінку': (50.2500, 30.2500), 'згурівко': (50.4950, 31.7780),
    # Гребінка (Полтавська область) - правильні координати
    'гребінка': (50.1058, 32.4464), 'гребінці': (50.1058, 32.4464), 'гребінку полтавська': (50.1058, 32.4464),
    'хотінь': (51.0550, 34.0000), 'хотіні': (51.0550, 34.0000),
    # Додаткові міста з нових повідомлень
    'хмільник': (49.5500, 27.9667), 'хмільнику': (49.5500, 27.9667), 'хмільника': (49.5500, 27.9667),
    'балта': (47.9667, 29.6167), 'балту': (47.9667, 29.6167), 'балті': (47.9667, 29.6167),
    'голованівськ': (48.7667, 31.4833), 'голованівську': (48.7667, 31.4833), 'голованівська': (48.7667, 31.4833),
    'помічна': (48.4333, 32.5333), 'помічну': (48.4333, 32.5333), 'помічній': (48.4333, 32.5333),
    'звенигородка': (49.0803, 30.9617), 'звенигородку': (49.0803, 30.9617), 'звенигородці': (49.0803, 30.9617),
    'буки': (49.1167, 30.8833), 'букам': (49.1167, 30.8833), 'буках': (49.1167, 30.8833),
    'дубовʼязівка': (50.7833, 34.3667), 'дубовʼязівку': (50.7833, 34.3667), "дуб'язівка": (50.7833, 34.3667), "дубов'язівка": (50.7833, 34.3667),
    'парафіївка': (51.4833, 31.1167), 'парафіївку': (51.4833, 31.1167), 'парафіївці': (51.4833, 31.1167),
    'нова борова': (50.7167, 27.9167), 'нову борову': (50.7167, 27.9167), 'новій боровій': (50.7167, 27.9167),
    'чоповичі': (50.4333, 28.1167), 'чоповичів': (50.4333, 28.1167), 'чоповичах': (50.4333, 28.1167),
    'ємільчине': (50.8667, 27.8667), 'ємільчину': (50.8667, 27.8667), 'ємільчиному': (50.8667, 27.8667),
    'стара синява': (49.6333, 27.6167), 'стару синяву': (49.6333, 27.6167), 'старій синяві': (49.6333, 27.6167),
    'шепетівка': (50.1833, 27.0667), 'шепетівку': (50.1833, 27.0667), 'шепетівці': (50.1833, 27.0667),
    'сарни': (51.3333, 26.6000), 'сарнах': (51.3333, 26.6000), 'сарнів': (51.3333, 26.6000),
    'степань': (50.5167, 25.9167), 'степані': (50.5167, 25.9167), 'степаня': (50.5167, 25.9167),
    'любешів': (51.9000, 25.3333), 'любешеві': (51.9000, 25.3333), 'любешову': (51.9000, 25.3333),
    'маневичі': (51.3000, 25.5167), 'маневичів': (51.3000, 25.5167), 'маневичах': (51.3000, 25.5167),
    'колки': (51.9333, 24.7167), 'колках': (51.9333, 24.7167), 'колкам': (51.9333, 24.7167),
    'рожище': (51.6333, 24.2333), 'рожищу': (51.6333, 24.2333), 'рожищі': (51.6333, 24.2333),
    'рокині': (50.9833, 24.5167), 'рокинях': (50.9833, 24.5167), 'рокинів': (50.9833, 24.5167),
    'володимир': (50.8500, 24.3167), 'володимиру': (50.8500, 24.3167), 'володимирі': (50.8500, 24.3167),
    # Додаткові міста з нових повідомлень 2
    'жовква': (49.9333, 23.9667), 'жовкву': (49.9333, 23.9667), 'жовкві': (49.9333, 23.9667),
    'криве озеро': (47.9500, 30.3500), 'кривому озеру': (47.9500, 30.3500), 'кривого озера': (47.9500, 30.3500),
    'могилів-подільський': (48.4833, 27.8000), 'могилева-подільського': (48.4833, 27.8000),
    'ямпіль вінницька': (48.1333, 28.2833), 'ямполь вінницька': (48.1333, 28.2833),
    'ямполю': (48.1333, 28.2833), 'ямполі': (48.1333, 28.2833),
    'дзигівка': (49.2167, 28.1500), 'дзигівку': (49.2167, 28.1500), 'дзигівці': (49.2167, 28.1500),
    # березівка - removed duplicate, use Odesa region coordinates (47.2050, 30.9080) in Odesa section
    # 'миколаївка': Удалено - неоднозначное название, используется контекстный поиск
    'вільногірськ': (47.9333, 34.0167), 'вільногірську': (47.9333, 34.0167), 'вільногірська': (47.9333, 34.0167),
    'велика виска': (49.2333, 32.1833), 'великої виски': (49.2333, 32.1833), 'великій висці': (49.2333, 32.1833),
    'велику виску': (49.2333, 32.1833),  # accusative form
    'доброслав': (46.6000, 30.0500), 'доброславу': (46.6000, 30.0500), 'доброславі': (46.6000, 30.0500),
    'тишківка': (48.7667, 32.6833), 'тишківку': (48.7667, 32.6833), 'тишківці': (48.7667, 32.6833),
    'салькове': (48.6167, 32.4500), 'салькову': (48.6167, 32.4500), 'сальковому': (48.6167, 32.4500),
    'благовіщенське': (48.4167, 32.8833), 'благовіщенську': (48.4167, 32.8833), 'благовіщенського': (48.4167, 32.8833),
    'оржиця': (50.0667, 32.3833), 'оржицю': (50.0667, 32.3833), 'оржиці': (50.0667, 32.3833),
    'тальне': (49.1833, 30.6833), 'тальному': (49.1833, 30.6833), 'тального': (49.1833, 30.6833),
    'бобровиця': (51.0833, 32.1167), 'бобровицю': (51.0833, 32.1167), 'бобровиці': (51.0833, 32.1167),
    'холми': (51.6833, 32.4000), 'холмам': (51.6833, 32.4000), 'холмах': (51.6833, 32.4000),
    'сосниця': (51.9500, 32.4667), 'сосницю': (51.9500, 32.4667), 'сосниці': (51.9500, 32.4667),
    'вишгород': (50.5833, 30.4833), 'вишгороду': (50.5833, 30.4833), 'вишгороді': (50.5833, 30.4833),
    'малин': (50.7667, 29.2333), 'маліну': (50.7667, 29.2333), 'маліні': (50.7667, 29.2333),
    'бучмани': (50.2833, 28.3333), 'бучманам': (50.2833, 28.3333), 'бучманах': (50.2833, 28.3333),
    'червоне': (50.4167, 28.9167), 'червоному': (50.4167, 28.9167), 'червоного': (50.4167, 28.9167),
    'понінка': (49.6167, 27.4500), 'понінку': (49.6167, 27.4500), 'понінці': (49.6167, 27.4500),
    'теофіполь': (49.8833, 27.6500), 'теофіполю': (49.8833, 27.6500), 'теофіполі': (49.8833, 27.6500),
    'гоща': (50.6167, 26.4167), 'гощу': (50.6167, 26.4167), 'гощі': (50.6167, 26.4167),
    'клевань': (50.7667, 25.9833), 'клевані': (50.7667, 25.9833), 'клеваню': (50.7667, 25.9833),
    'володимирець': (51.4333, 25.9167), 'володимирцю': (51.4333, 25.9167), 'володимирці': (51.4333, 25.9167),
    'локачі': (51.1167, 24.2667), 'локачам': (51.1167, 24.2667), 'локачах': (51.1167, 24.2667),
    'іваничі': (51.2333, 24.3167), 'іваничам': (51.2333, 24.3167), 'іваничах': (51.2333, 24.3167),
    'турійськ': (51.0833, 24.7000), 'турійську': (51.0833, 24.7000), 'турійська': (51.0833, 24.7000),
    # Додаткові міста з великих повідомлень
    'великі мости': (48.9167, 25.3333), 'великих мостів': (48.9167, 25.3333), 'великих мостах': (48.9167, 25.3333),
    'снігурівка': (46.7500, 32.8167), 'снігурівку': (46.7500, 32.8167), 'снігурівці': (46.7500, 32.8167),
    'баранівка': (50.3000, 27.6667), 'баранівку': (50.3000, 27.6667), 'баранівці': (50.3000, 27.6667),
    'новоград-волинський': (50.5833, 27.6167), 'новограда-волинського': (50.5833, 27.6167),
    'красилів': (49.6500, 27.1667), 'красилову': (49.6500, 27.1667), 'красилові': (49.6500, 27.1667),
    'шепетівка': (50.1833, 27.0667), 'шепетівку': (50.1833, 27.0667), 'шепетівці': (50.1833, 27.0667),
    'славута': (50.3000, 26.8667), 'славуту': (50.3000, 26.8667), 'славуті': (50.3000, 26.8667),
    'нетішин': (50.3333, 26.6333), 'нетішину': (50.3333, 26.6333), 'нетішині': (50.3333, 26.6333),
    'острог': (50.3333, 26.5167), 'острогу': (50.3333, 26.5167), 'острозі': (50.3333, 26.5167),
    'дубно': (50.4167, 25.7667), 'дубну': (50.4167, 25.7667), 'дубні': (50.4167, 25.7667),
    'вараш': (51.3500, 25.8500), 'вараші': (51.3500, 25.8500), 'варашу': (51.3500, 25.8500),
    'костопіль': (50.8833, 26.4500), 'костополю': (50.8833, 26.4500), 'костополі': (50.8833, 26.4500),
    'сарни': (51.3333, 26.6000), 'сарнам': (51.3333, 26.6000), 'сарнах': (51.3333, 26.6000),
    'рокитне': (50.9333, 26.1667), 'рокитному': (50.9333, 26.1667), 'рокитного': (50.9333, 26.1667),
    'дубровиця': (51.5667, 26.5667), 'дубровицю': (51.5667, 26.5667), 'дубровиці': (51.5667, 26.5667),
    'березне': (51.4500, 26.7167), 'березному': (51.4500, 26.7167), 'березного': (51.4500, 26.7167),
    'шостку': (51.8667, 33.4833), 'конотопу': (51.2417, 33.2022), 'недригайлів': (50.8281, 33.8781),
    'липову долину': (50.5700, 33.7900), 'носівку': (50.9444, 32.0167), 'бахмач': (51.1808, 32.8203), 'бахмача': (51.1808, 32.8203)
    ,'пісківка': (50.6767, 29.5283), 'пісківку': (50.6767, 29.5283), 'пісківці': (50.6767, 29.5283)
    ,'зіньків': (49.2019, 34.3744), 'зінькові': (49.2019, 34.3744), 'зіньківу': (49.2019, 34.3744), 'зінькова': (49.2019, 34.3744)
}

# Donetsk Oblast cities (повний перелік міст області). Added per user request to ensure precise mapping.
# Sources: OpenStreetMap / GeoNames (approx to 4 decimal places). Using setdefault to avoid overriding existing entries.
DONETSK_CITY_COORDS = {
    'донецьк': (48.0028, 37.8053),
    'макіївка': (48.0478, 37.9258),
    'горлівка': (48.3336, 38.0925),
    'маріуполь': (47.0971, 37.5434),  # already present
    'краматорськ': (48.7389, 37.5848),  # already present
    'слов\'янськ': (48.8417, 37.5983),  # already present
    'дружківка': (48.6203, 37.5263),  # already present
    'костянтинівка': (48.5277, 37.7050),  # already present
    'бахмут': (48.5937, 38.0000),
    'авдіївка': (48.1417, 37.7425),
    'покровськ': (48.2833, 37.1833),
    'мирноград': (48.3000, 37.2667),
    'торецьк': (48.3976, 37.8687),
    'добропілля': (48.4697, 37.0851),
    'селидове': (48.1500, 37.3000),
    'новогродівка': (48.2065, 37.3467),
    'волноваха': (47.6000, 37.5000),
    'вугледар': (47.7811, 37.2358),
    'ліман': (48.9890, 37.8020),
    'святогірськ': (49.0339, 37.5663),  # already present
    'сіверськ': (48.8667, 38.1000),
    'соледар': (48.5356, 38.0875),
    'часів яр': (48.5969, 37.8350),
    'шахтарськ': (48.0500, 38.4500),
    'єнакієве': (48.2333, 38.2000),
    'амвросіївка': (47.7956, 38.4772),
    'дебальцеве': (48.3400, 38.4000),
    'докучаєвськ': (47.7489, 37.6789),
    'іловайськ': (47.9233, 38.1950),
    'жданівка': (48.1500, 38.2667),
    'зугрес': (48.0167, 38.2667),
    'харцизьк': (48.0400, 38.1500),
    'вуглегірськ': (48.3167, 38.2167),
    'ясинувата': (48.1167, 37.8333),
    'сніжне': (48.0333, 38.7667),
    'кальміуське': (47.6528, 38.0664),
    'моспине': (47.8583, 38.0000),
    'українськ': (48.0333, 37.9000),
    'родинське': (48.3500, 37.2000),
    'залізне': (48.3539, 37.8483),
    # Historical / alt names not added to avoid noise; add normalization separately if needed.
}

for _dn_name, _dn_coords in DONETSK_CITY_COORDS.items():
    CITY_COORDS.setdefault(_dn_name, _dn_coords)

# Kharkiv Oblast cities and key settlements (міста + важливі селища) per user request.
# Many already present; using setdefault to avoid override. Includes normalized variants.
KHARKIV_CITY_COORDS = {
    'ізюм': (49.2103, 37.2483),
    'куп\'янськ': (49.7106, 37.6156),
    'купянськ': (49.7106, 37.6156),  # variant without apostrophe
    'юріївка': (50.131641, 37.394371),  # Kupiansk district, near Russian border
    'юріївка харків': (50.131641, 37.394371),
    'юріївка харківська': (50.131641, 37.394371),
    'лозова': (48.8897, 36.3175),
    'липці': (50.3061, 36.7597),  # село біля кордону з Росією
    'первомайський': (49.3914, 36.2147),
    'вовчанськ': (50.3000, 36.9500),
    'люботин': (49.9486, 35.9292),
    'дергачі': (50.1061, 36.1217),
    'зміїв': (49.6897, 36.3472),
    'красноград': (49.3740, 35.4405),
    'печеніги': (49.8667, 36.9667),
    'золочів(харківщина)': (50.2744, 36.3592),
    'золочів': (50.2744, 36.3592),  # may conflict with Львівська обл.; disambiguation via region context
    'великий бурлук': (50.0514, 37.3903),
    # 'південне': Removed from Kharkiv section - this is Odesa region (46.6226, 31.1013)
    'покотилівка': (49.9345, 36.0603),
    'манченки': (49.9840, 35.9680),
    'малинівка': (49.6550, 36.7060),
    'коломак': (49.8422, 35.2761),
    'козача лопань': (49.8872, 36.4167),  # СМТ в Дергачівському районі
    'чкаловське': (49.7155296, 36.9322501),  # Правильне Чкаловське в Харківській області
    'першотравневий': (49.3914, 36.2147),  # с. Першотравневе, Харківська область (same as Первомайський)
    'створ населеного пункту балки?': (49.4627, 36.8586),  # placeholder example – remove/replace if noise
}

for _kh_name, _kh_coords in KHARKIV_CITY_COORDS.items():
    CITY_COORDS.setdefault(_kh_name, _kh_coords)

# Chernihiv Oblast cities / key settlements (міста та важливі селища)
# Many base ones already in CITY_COORDS (чернігів, ніжин, прилуки, новгород-сіверський, коростень (інша обл.), корюківка maybe missing).
CHERNIHIV_CITY_COORDS = {
    'ніжин': (51.0480, 31.8860),  # already present
    'прилуки': (50.5931, 32.3878),  # already present
    'новгород-сіверський': (51.9874, 33.2620),  # already present
    'корюківка': (51.7725, 32.2494),
    'козелець': (51.5625, 31.2058),  # Added
    'носівка': (51.0325, 31.5522),   # Added
    'куликівка': (51.3667, 32.2000),  # Added
    'мена': (51.5211, 32.2147),      # Fixed typo
    'ічня': (51.0722, 32.3931),      # Added
    'борзна': (51.2542, 32.4192),  # already present
    'батиївка?': (51.4982, 31.2893),  # placeholder if appears; else remove
    'менa': (51.5211, 32.2147),  # variant with latin a? (typo guard)
    'м ена': (51.5211, 32.2147),  # spacing anomaly fallback
    'семенівка(чернігівщина)': (52.1833, 32.5833),  # north settlement (if referenced)
    'семенівка чернігівська': (52.1833, 32.5833),
    'семенівка': (52.1833, 32.5833),  # might conflict with Poltava one; context disambiguation may be needed
    'сновськ': (51.8200, 31.9500),
    'короп': (51.5667, 32.9667),
    'іхня': (51.0722, 32.3931),  # misspelling variant of ічня
    'ичня': (51.0722, 32.3931),  # alt transliteration
    'глухів?': (51.6781, 33.9169),  # actually Sumy oblast; placeholder if mis-tag appears
    'сосниця': (51.5236, 32.4953),  # already present
    'конотоп?': (51.2417, 33.2022),  # Sumy oblast - guard only
    'остер': (50.9481, 30.8831),  # already present
    'ніжину': (51.0480, 31.8860),  # accusative
    'борзні': (51.2542, 32.4192),
    'коропі': (51.5667, 32.9667),
    'корюківці': (51.7725, 32.2494),
    'корюківку': (51.7725, 32.2494),
    'сновську': (51.8200, 31.9500),
    'семенівці': (52.1833, 32.5833),
    'семенівку': (52.1833, 32.5833),
    # Дополнительные города и формы
    'седнів': (51.5211, 32.1897),
    'новгород': (51.9874, 33.2620),  # новгород-сіверський
    'новгород-сіверський': (51.9874, 33.2620),
}

for _ch_name, _ch_coords in CHERNIHIV_CITY_COORDS.items():
    CITY_COORDS.setdefault(_ch_name, _ch_coords)

# Dnipropetrovsk (Дніпропетровська) Oblast cities & key settlements.
DNIPRO_CITY_COORDS = {
    'кривий ріг': (47.9105, 33.3918),  # already implied in stems
    'жіовті води': (48.3456, 33.5022),  # typo guard for жовті води
    'жовті води': (48.3456, 33.5022),
    'кам\'янське': (48.5110, 34.6021),  # already present as variant
    'камянське': (48.5110, 34.6021),  # present
    'нікополь': (47.5667, 34.4061),  # present
    'марганець': (47.6433, 34.6289),  # present
    'покров': (47.6542, 34.1167),
    # 'тернівка' - REMOVED: Now handled via Photon/Nominatim API with military context priority
    'першотравенськ': (48.3460, 36.4030),
    'вільногірськ': (48.4850, 34.0300),
    'жовті': (48.3456, 33.5022),  # truncated mention mapping
    'новомосковськ': (48.6333, 35.2167),
    'зарічне': (48.15, 35.2),  # Зарічне, Покровський район, Дніпропетровська область
    'зарічне дніпропетровська': (48.15, 35.2),  # Спеціально для військового контексту  
    'зарічне покровський': (48.15, 35.2),  # Альтернативний ключ
    'синельникове': (48.3167, 35.5167),
    'петропавлівка': (48.5000, 36.4500),  # present
    'покровське(дніпропетровщина)': (48.1180, 36.2470),
    'покровське дніпропетровська': (48.1180, 36.2470),
    'покровське дніпропетровщини': (48.1180, 36.2470),
    'покровське': (48.1180, 36.2470),  # present
    'богданівка(дніпро)': (48.4647, 35.0462),  # fallback to oblast center if ambiguous
    'васильківка': (48.3550, 36.1240),
    'варварівка': (48.7440, 34.7000),
    'верхівцеве': (48.4769, 34.3458),
    'верхньодніпровськ': (48.6535, 34.3372),  # present
    'губиниха': (48.7437, 35.2960),  # present
    'домоткань': (48.6680, 34.2160),
    'жеребетівка': (48.2500, 36.7000),
    'зайцеве(дніпропетровщина)': (48.4647, 35.0462),  # generic fallback center
    'зелений гай': (48.4200, 35.1200),
    'зеленодольськ': (47.5667, 33.5333),  # present
    'карнаухівка': (48.4870, 34.5480),
    'карпівка': (47.5930, 33.5960),
    'маломихайлівка': (48.2300, 36.4500),
    'меліоративне': (48.6340, 35.1750),
    'магідалинівка': (48.8836, 34.8669),  # typo guard for магдалинівка
    'магдалинівка': (48.8836, 34.8669),  # present
    'межова': (48.2583, 36.7363),  # present
    'миколаївка(дніпро)': (48.4647, 35.0462),
    'новомиколаївка(дніпро)': (48.4647, 35.0462),
    'обухівка': (48.6035, 34.8530),  # present
    'орлівщина': (48.6110, 34.9550),
    'павлоград': (48.5350, 35.8700),  # present
    'перещепине': (48.6260, 35.3580),  # present
    'петриківка': (48.7330, 34.6300),  # present
    'підгородне': (48.5747, 35.1482),  # present
    'покровське (смт)': (48.1180, 36.2470),
    'самар': (48.6500, 35.4200),  # present
    'сурсько-литовське': (48.3720, 34.8130),
    'тернівські хутори': (48.6600, 34.9400),
    'томаківка': (47.8130, 34.7450),
    'царичанка': (48.9767, 34.3772),  # present
    'чумакове': (48.3400, 35.2800),
    'шевченківське(дніпро)': (48.4647, 35.0462),
    'юр’ївка': (48.7250, 36.0130),
    'юр'"'"'ївка': (48.7250, 36.0130),  # attempt to guard variant – may adjust quoting
    'юрївка': (48.7250, 36.0130),
    'юр’ївку': (48.7250, 36.0130),
    'юр'"'"'ївку': (48.7250, 36.0130),
}

for _dp_name, _dp_coords in DNIPRO_CITY_COORDS.items():
    CITY_COORDS.setdefault(_dp_name, _dp_coords)

# Sumy (Сумська) Oblast cities & key settlements.
SUMY_CITY_COORDS = {
    'суми': (50.9077, 34.7981),  # already present
    'шостка': (51.8733, 33.4800),
    'кременчук?': (49.0670, 33.4204),  # ignore (other oblast) placeholder if mis-ref
    'охтирка': (50.3116, 34.8988),
    'р омни': (50.7497, 33.4746),  # space anomaly guard
    'ромни': (50.7497, 33.4746),  # present
    'к о тростянець': (50.4833, 34.9667),  # anomaly
    'тростянець': (50.4833, 34.9667),  # present
    'глухів': (51.6781, 33.9169),  # present
    'конотоп': (51.2417, 33.2022),  # present
    'ліпова долина': (50.5700, 33.7900),  # typo
    'липова долина': (50.5700, 33.7900),  # present
    'буринь': (51.2000, 33.8500),  # present
    'путівль': (51.3375, 33.8700),
    'середина-буда': (52.1900, 33.9300),
    'лебедин': (50.5872, 34.4912),  # present
    'недригайлів': (50.8281, 33.8781),  # present
    'в сууликівка?': (50.9077, 34.7981),  # fallback noise
    'білопілля': (51.1500, 34.3014),  # present
    'краснопілля': (50.4422, 35.3081),  # present
    'сумської області центр': (50.9077, 34.7981),
    'велика писарівка': (50.4250, 35.4650),
    'велика писарівка смт': (50.4250, 35.4650),
    'велика писарівку': (50.4250, 35.4650),
    'бранцівка?': (50.9077, 34.7981),
    'дружба(сумщина)': (51.5230, 34.5770),
    'дружба': (51.5230, 34.5770),
    'зорине?': (50.9077, 34.7981),
    'кир ик івка?': (51.2000, 33.8500),
    'к и рик івка': (51.2000, 33.8500),
    'кирзаківка?': (51.2000, 33.8500),
    'кир ик івку': (51.2000, 33.8500),
    'кир иківка': (51.2000, 33.8500),
    'кир иківку': (51.2000, 33.8500),
    'кир ик івці': (51.2000, 33.8500),
    'кир ик івці?': (51.2000, 33.8500),
    'кир иківці': (51.2000, 33.8500),
    'кир иківці?': (51.2000, 33.8500),
    'кир ичівка?': (51.2000, 33.8500),
    'к ирик івка': (51.2000, 33.8500),
    'смородине': (50.9660, 34.5500),
    'смородино': (50.9660, 34.5500),
    'смородиному': (50.9660, 34.5500),
    'смородиного': (50.9660, 34.5500),
    'ясенок?': (51.5230, 34.5770),
    'ясенок': (51.5230, 34.5770),
    'ясенку': (51.5230, 34.5770),
    'ясенку?': (51.5230, 34.5770),
    'ясенка': (51.5230, 34.5770),
    'ясенка?': (51.5230, 34.5770),
    'ясенці': (51.5230, 34.5770),
    'ясенці?': (51.5230, 34.5770),
    'ясенців': (51.5230, 34.5770),
    'ясенців?': (51.5230, 34.5770),
    'миколаївка(сумська)': (51.5667, 34.1333),  # Миколаївка, районний центр Сумської області
    'миколаївка (сумська)': (51.5667, 34.1333),  # з пробілом
    'миколаївку(сумська)': (51.5667, 34.1333),  # винительный падеж
    'миколаївку (сумська)': (51.5667, 34.1333),  # винительный падеж з пробілом
}

for _sm_name, _sm_coords in SUMY_CITY_COORDS.items():
    CITY_COORDS.setdefault(_sm_name, _sm_coords)

# Zaporizhzhia (Запорізька) Oblast cities & key settlements.
ZAPORIZHZHIA_CITY_COORDS = {
    'запоріжжя': (47.8388, 35.1396),  # already present
    'бердянськ': (46.7553, 36.7885),  # present
    'мелітополь': (46.8489, 35.3650),  # present
    'енергодар': (47.4980, 34.6580),
    'токмак': (47.2550, 35.7120),
    'пологи': (47.4768, 36.2543),
    'вільнянськ': (47.9450, 35.4350),
    'оріхів': (47.5672, 35.7814),
    'гуляйполе': (47.6611, 36.2567),
    'приморськ': (46.7310, 36.3440),
    'дазовськ': (47.8388, 35.1396),  # typo guard (азовськ?) fallback
    'азовськ?': (47.8388, 35.1396),
    'васильівка': (47.4393, 35.2745),
    'дорожнянка': (47.5540, 36.0950),
    'роботине': (47.3780, 35.9300),
    'роботиному': (47.3780, 35.9300),
    'роботиного': (47.3780, 35.9300),
    'работине': (47.3780, 35.9300),  # transliteration variant
    'чернігівка(запоріжжя)': (47.0870, 36.2320),
    'чернігівка': (47.0870, 36.2320),
    'михайлівка(запоріжжя)': (47.2730, 35.2200),
    'михайлівка': (47.2730, 35.2200),  # may conflict (other oblast) – context disambiguation
    'костянтинівка(запоріжжя)': (47.2460, 35.3220),  # small settlement, not Donetsk one
    'степногірськ': (47.5660, 35.2850),
    'камянка-дніпровська': (47.4980, 34.4000),
    'кам\'янка-дніпровська': (47.4980, 34.4000),
    'кирпотине?': (47.3780, 35.9300),  # noise variant to robotyne
    'малокатеринівка': (47.7040, 35.2710),
    'комишуваха(запорізька)': (47.5760, 35.5090),
    'комишуваха': (47.5760, 35.5090),  # duplicate name in other oblasts
    'комишувасі': (47.5760, 35.5090),
    'комишуваху': (47.5760, 35.5090),
    'чергове?': (47.8388, 35.1396),
    'н ове?': (47.8388, 35.1396),
    'нововасилівка': (47.3290, 35.5130),
    'малинівка(зап)': (47.6260, 35.8700),
    'малинівка запорізька': (47.6260, 35.8700),
    'малинівка': (47.6260, 35.8700),  # may conflict with Kharkiv one
    'веселе(запоріжжя)': (47.1700, 35.1750),
    'веселе': (47.1700, 35.1750),  # generic name multiple oblasts
    'балабине': (47.7520, 35.1660),
    'кушугум': (47.7630, 35.2200),
    'тернувате': (47.8520, 35.5560),
    'чайкине?': (47.8388, 35.1396),
}

for _zp_name, _zp_coords in ZAPORIZHZHIA_CITY_COORDS.items():
    CITY_COORDS.setdefault(_zp_name, _zp_coords)

# Poltava (Полтавська) Oblast cities & key settlements.
POLTAVA_CITY_COORDS = {
    'полтава': (49.5883, 34.5514),  # already present
    'кременчук': (49.0670, 33.4204),  # present
    'горішні плавні': (49.0123, 33.6450),  # present
    'лубни': (50.0186, 32.9931),  # present
    'миргород': (49.9688, 33.6083),
    'гадяч': (50.3713, 34.0109),  # present
    'карлівка': (49.4586, 35.1272),  # present
    'решетилівка': (49.5630, 34.0720),
    'пирятин': (50.2444, 32.5144),
    'хорол': (49.7850, 33.2200),
    'чутове': (49.7070, 35.0960),
    'глобине': (49.3958, 33.2664),
    'голтвa?': (49.5883, 34.5514),  # noise
    'нові санжари': (49.3280, 34.3170),
    'великі сорочинці': (50.0167, 33.9833),  # present
    'дикистань?': (49.9688, 33.6083),  # noise dykanka variant
    'дика нка': (49.8214, 34.5769),
    'ди канка': (49.8214, 34.5769),
    'ди канку': (49.8214, 34.5769),
    'ди канці': (49.8214, 34.5769),
    'ди к анці': (49.8214, 34.5769),
    'ди к анку': (49.8214, 34.5769),
    'ди к анка': (49.8214, 34.5769),
    'ди канки': (49.8214, 34.5769),
    'ди к анки': (49.8214, 34.5769),
    'ди к анкою': (49.8214, 34.5769),
    'ди к анкою?': (49.8214, 34.5769),
    'ди к анкою.': (49.8214, 34.5769),
    'ди к анкою,': (49.8214, 34.5769),
    'ди канкою': (49.8214, 34.5769),
    'ди канкою,': (49.8214, 34.5769),
    'ди канкою.': (49.8214, 34.5769),
    'ди к анці?': (49.8214, 34.5769),
    'ди канці?': (49.8214, 34.5769),
    'ди к анок?': (49.8214, 34.5769),
    'ди к анок': (49.8214, 34.5769),
    'ди канок?': (49.8214, 34.5769),
    'ди канок': (49.8214, 34.5769),
    'ди к анці,': (49.8214, 34.5769),
    'ди канці,': (49.8214, 34.5769),
    'ди канок.': (49.8214, 34.5769),
    'ди к анок.': (49.8214, 34.5769),
    'ди канок,': (49.8214, 34.5769),
    'ди к анок,': (49.8214, 34.5769),
    'ди ка нка': (49.8214, 34.5769),
    'ди ка нку': (49.8214, 34.5769),
    'ди ка нці': (49.8214, 34.5769),
    'ди ка нкою': (49.8214, 34.5769),
    'дика нці': (49.8214, 34.5769),
    'дика нкою': (49.8214, 34.5769),
    'ди к анці.': (49.8214, 34.5769),
    'ди канці.': (49.8214, 34.5769),
    'ди ка нці.': (49.8214, 34.5769),
    'дика нці.': (49.8214, 34.5769),
    'ди ка нкою.': (49.8214, 34.5769),
    'дика нкою.': (49.8214, 34.5769),
    'ди ка нкою,': (49.8214, 34.5769),
    'дика нкою,': (49.8214, 34.5769),
    'диканька': (49.8214, 34.5769),
    'диканьку': (49.8214, 34.5769),
    'диканьці': (49.8214, 34.5769),
    'диканькою': (49.8214, 34.5769),
    'дика нка?': (49.8214, 34.5769),
    'дика нка.': (49.8214, 34.5769),
    'дика нка,': (49.8214, 34.5769),
    'диканці': (49.8214, 34.5769),
    'дика нці?': (49.8214, 34.5769),
    'дика нок': (49.8214, 34.5769),
    'дика нок?': (49.8214, 34.5769),
    'дика нок.': (49.8214, 34.5769),
    'дика нок,': (49.8214, 34.5769),
    'дика нці': (49.8214, 34.5769),
    'дика нкою': (49.8214, 34.5769),
    'ди ка нок': (49.8214, 34.5769),
    'ди ка нок?': (49.8214, 34.5769),
    'ди ка нок.': (49.8214, 34.5769),
    'ди ка нок,': (49.8214, 34.5769),
    'заводське': (50.0750, 33.4000),
    'машівка': (49.4410, 34.8680),
    'семенівка (полтавська)': (50.6633, 32.3933),
    'семенівка полтавська': (50.6633, 32.3933),
    'семенівка': (50.6633, 32.3933),  # conflict with others
    'кобеляки': (49.1500, 34.2000),  # present
    'чорнухи': (50.2833, 33.0000),  # present
    'шишаки': (49.8992, 34.0072),  # present
    'диканька?': (49.8214, 34.5769),
    'диканьці?': (49.8214, 34.5769),
    'диканці': (49.8214, 34.5769),
    'диканку': (49.8214, 34.5769),
    'диканкою': (49.8214, 34.5769),
    'диканкою,': (49.8214, 34.5769),
    'диканкою.': (49.8214, 34.5769),
    'дик анка': (49.8214, 34.5769),
    'дик анці': (49.8214, 34.5769),
    'дик анкою': (49.8214, 34.5769),
    'дик анок': (49.8214, 34.5769),
    'дик анок?': (49.8214, 34.5769),
    'дик анок.': (49.8214, 34.5769),
    'дик анок,': (49.8214, 34.5769),
    
    # ========== CITY+OBLAST SPECIFIC COORDINATES ==========
    # These entries resolve ambiguous city names by including oblast context
    
    # Срібне (different cities in different oblasts)
    'срібне чернігівська': (51.1300, 31.9400),  # Срібне, Чернігівська область  
    'срібне чернігівська обл.': (51.1300, 31.9400),
    'срібне (чернігівська обл.)': (51.1300, 31.9400),
    'срібне чернігівщина': (51.1300, 31.9400),
    'срібне чернігівщині': (51.1300, 31.9400),
    'срібне': (51.1300, 31.9400),  # Default to Chernihiv oblast variant
    
    # Златопіль (fixing incorrect coordinates - was pointing to Donetsk)
    'златопіль харківська': (49.9800, 35.5300),  # Златопіль, Харківська область (correct)
    'златопіль харківська обл.': (49.9800, 35.5300),
    'златопіль (харківська обл.)': (49.9800, 35.5300),
    'златопіль харківщина': (49.9800, 35.5300),
    'златопіль харківщині': (49.9800, 35.5300),
    # Keep old incorrect entry as fallback for other messages, but correct default
    'златопіль': (49.9800, 35.5300),  # Override with correct Kharkiv oblast coordinates
    
    # Чернігівська область - додаткові міста
    'любеч': (51.4961, 30.2675),  # Любеч, Чернігівська область
    'любеч чернігівська': (51.4961, 30.2675),
    'любеч чернігівська обл.': (51.4961, 30.2675),
    'любеч (чернігівська обл.)': (51.4961, 30.2675),
}

for _pl_name, _pl_coords in POLTAVA_CITY_COORDS.items():
    CITY_COORDS.setdefault(_pl_name, _pl_coords)

# Mykolaiv (Миколаївська) Oblast cities & key settlements.
MYKOLAIV_CITY_COORDS = {
    'миколаїв': (46.9750, 31.9946),  # already present
    'первомайськ': (48.0449, 30.8500),  # not to confuse with Первомайський (Kharkiv)
    'вознесенськ': (47.5679, 31.3336),
    'южноукраїнськ': (47.8178, 31.1800),
    'новий буг': (47.6833, 32.5167),  # present
    'нового буга': (47.6833, 32.5167),
    'нового бугу': (47.6833, 32.5167),
    'новому бугу': (47.6833, 32.5167),
    'радушне': (47.9333, 32.5167),
    'радушному': (47.9333, 32.5167),
    'радушним': (47.9333, 32.5167),
    'нова одеса': (47.3100, 31.7830),
    'нову одесу': (47.3100, 31.7830),
    'новій одесі': (47.3100, 31.7830),
    'очаків': (46.6167, 31.5500),
    'очаков': (46.6167, 31.5500),  # russian variant
    'снігурівка': (47.0750, 32.8050),
    'снігурівку': (47.0750, 32.8050),
    'снігурівці': (47.0750, 32.8050),
    'казанка': (47.8460, 32.8460),
    'арбатська стрілка?': (46.9750, 31.9946),  # noise guard
    'доманівка': (47.6290, 30.9920),
    'врадіївка': (47.8820, 30.5910),
    'криве озеро': (47.9500, 30.3500),
    'єланець': (47.8667, 31.8667), 'єланця': (47.8667, 31.8667), 'єланцю': (47.8667, 31.8667), 'єланці': (47.8667, 31.8667),
    'баштанка': (47.4086, 32.4389), 'баштанки': (47.4086, 32.4389), 'баштанку': (47.4086, 32.4389), 'баштанці': (47.4086, 32.4389),
    'березнегувате': (47.3167, 32.8500),  # present
    'березнегуватому': (47.3167, 32.8500),
    'аркасове?': (46.9750, 31.9946),
    'кашперо-миколаївка': (47.3620, 31.8790),
    'парутине': (46.7530, 31.0160),
    'парутиному': (46.7530, 31.0160),
    'парутиного': (46.7530, 31.0160),
    'парутині': (46.7530, 31.0160),
    'коблеве': (46.6670, 31.2170),
    'коблево': (46.6670, 31.2170),
    'коблевому': (46.6670, 31.2170),
    'коблевого': (46.6670, 31.2170),
    'коблеві': (46.6670, 31.2170),
    'галіцинове': (46.9710, 31.9400),
    'галицинове': (46.9710, 31.9400),
    'галіциновому': (46.9710, 31.9400),
    'галіциново': (46.9710, 31.9400),
    'лиман (миколаїв)': (46.5410, 31.3270),
    'кутузівка?': (46.9750, 31.9946),
    'олександрівка(мик)': (46.7160, 31.8660),
    'олександрівка миколаївська': (46.7160, 31.8660),
    'олександрівка': (46.7160, 31.8660),  # multiple oblasts
    'старий буг?': (47.6833, 32.5167),
    # Додаткові населені пункти Миколаївської області
    'братське': (47.5333, 32.1667), 'братську': (47.5333, 32.1667), 'братського': (47.5333, 32.1667),
    'возсіятське': (46.8167, 32.0833), 'возсіятську': (46.8167, 32.0833), 'возсіятського': (46.8167, 32.0833),
    'березівка(миколаївська)': (47.5167, 31.4500), 'березівку(миколаївська)': (47.5167, 31.4500), 'березівці(миколаївська)': (47.5167, 31.4500),
    'дорошівка': (47.5000, 32.0500), 'дорошівки': (47.5000, 32.0500), 'дорошівку': (47.5000, 32.0500),
    'шевченкове(миколаївська)': (47.45, 31.35), 'шевченкову(миколаївська)': (47.45, 31.35),  # Шевченкове, Вознесенський район
}

for _my_name, _my_coords in MYKOLAIV_CITY_COORDS.items():
    CITY_COORDS.setdefault(_my_name, _my_coords)

# Odesa (Одеська) Oblast cities & key settlements.
ODESA_CITY_COORDS = {
    'одеса': (46.4825, 30.7233),  # already present
    'одесса': (46.4825, 30.7233),  # russian variant
    'чорноморськ': (46.3019, 30.6548),
    'южне': (46.6226, 31.1013),
    'південне': (46.6226, 31.1013),  # Ukrainian name for Южне (Odesa region)
    'білгород-дністровський': (46.1900, 30.3400),
    'білгород-дністровськ': (46.1900, 30.3400),
    'білгород-дністровську': (46.1900, 30.3400),
    'белгород-днестровский': (46.1900, 30.3400),
    'подільськ': (47.7425, 29.5322),
    'подольськ': (47.7425, 29.5322),
    'балта': (47.9381, 29.6125),
    'балті': (47.9381, 29.6125),
    'балту': (47.9381, 29.6125),
    'балтою': (47.9381, 29.6125),
    'артемівськ(одеса)?': (46.4825, 30.7233),  # noise
    'роздільна': (46.8450, 30.0780),
    'роздільній': (46.8450, 30.0780),
    'роздільну': (46.8450, 30.0780),
    'килія': (45.4550, 29.2680),
    'ізмаїл': (45.3511, 28.8367),
    'ізмаїлі': (45.3511, 28.8367),
    'ізмаїл у': (45.3511, 28.8367),
    'ізмаїлу': (45.3511, 28.8367),
    'вилкове': (45.4031, 29.5986),
    'вилковому': (45.4031, 29.5986),
    # Чаплине (Дніпропетровська область)
    'чаплине': (47.3811, 34.5619),
    'чаплином': (47.3811, 34.5619),
    'чаплиному': (47.3811, 34.5619),
    'рений': (45.4560, 28.2830),
    'рені': (45.4560, 28.2830),
    'рено?': (45.4560, 28.2830),
    'татарбунари': (45.8417, 29.6128),
    'сарни(одеса)?': (46.4825, 30.7233),  # noise
    'болград': (45.6772, 28.6147),
    'болграді': (45.6772, 28.6147),
    'болградом': (45.6772, 28.6147),
    'арциз': (45.9919, 29.4181),
    'арцизі': (45.9919, 29.4181),
    'арцизом': (45.9919, 29.4181),
    'таврія(одеса)?': (46.4825, 30.7233),  # noise
    'любашівка': (47.8540, 30.2550),
    'любашівці': (47.8540, 30.2550),
    'ананьїв': (47.7244, 29.9686),
    'ананьєв': (47.7244, 29.9686),
    'ананьєві': (47.7244, 29.9686),
    'ананьєву': (47.7244, 29.9686),
    'березівка(одеська)': (47.2050, 30.9080),
    'березівці(одеська)': (47.2050, 30.9080),
    'березівку(одеська)': (47.2050, 30.9080),
    'березівка': (47.2050, 30.9080),
    'березівці': (47.2050, 30.9080),
    'березівку': (47.2050, 30.9080),
    'буялик': (46.7167, 30.4167),
    'буялику': (46.7167, 30.4167),
    'буялика': (46.7167, 30.4167),
    'зато ка?': (46.0660, 30.4680),  # noise for затока
    'затока': (46.0660, 30.4680),  # present
    'кароліно-бугаз': (46.1530, 30.5200),
    'кароліно-бугазі': (46.1530, 30.5200),
    'кароліно-бугазу': (46.1530, 30.5200),
    'кароліно-бугазом': (46.1530, 30.5200),
    'градізськ(одеса)?': (46.4825, 30.7233),  # noise
    'таїрове': (46.3990, 30.6940),
    'таїровому': (46.3990, 30.6940),
    'сергіївка': (46.0006, 29.9578),
    'сергіївці': (46.0006, 29.9578),
    'сергіївку': (46.0006, 29.9578),
    'сергіївкою': (46.0006, 29.9578),
    'тузли': (45.8650, 30.0975),
    'тузл': (45.8650, 30.0975),
    'тузлах': (45.8650, 30.0975),
    'тузлами': (45.8650, 30.0975),
    'таїрово': (46.3990, 30.6940),
    'лиман(одеса)': (46.3530, 30.6500),
    'лиман одеса': (46.3530, 30.6500),
    'лиман (одеса)': (46.3530, 30.6500),
}

for _od_name, _od_coords in ODESA_CITY_COORDS.items():
    CITY_COORDS.setdefault(_od_name, _od_coords)

# Kyiv (Київська) Oblast cities & key settlements (excluding Kyiv already present).
KYIV_OBLAST_CITY_COORDS = {
    'біла церква': (49.7950, 30.1310),  # present
    'бровари': (50.5110, 30.7909),  # present
    'бориспіль': (50.3527, 30.9550),  # present
    'гнідин': (50.3722, 30.8639),  # село біля Борисполя
    'ірпінь': (50.5218, 30.2506),
    'ірпеня': (50.5218, 30.2506),
    'буча': (50.5436, 30.2120),
    'бучу': (50.5436, 30.2120),
    'бучі': (50.5436, 30.2120),
    'васильків': (50.1846, 30.3133),
    'василькові': (50.1846, 30.3133),
    'василькові?': (50.1846, 30.3133),
    'фастів': (50.0780, 29.9170),
    'фастові': (50.0780, 29.9170),
    'фастову': (50.0780, 29.9170),
    'обухів': (50.1072, 30.6211),  # present
    'обухові': (50.1072, 30.6211),
    'обухову': (50.1072, 30.6211),
    'обуховом': (50.1072, 30.6211),
    'славутич': (51.5226, 30.7203),
    'славутичі': (51.5226, 30.7203),
    'славутичу': (51.5226, 30.7203),
    'славутичем': (51.5226, 30.7203),
    'березань': (50.3085, 31.4576),  # present
    'березані': (50.3085, 31.4576),
    'березаньська?': (50.3085, 31.4576),
    'сквира': (49.7333, 29.6667),  # present
    'сквирі': (49.7333, 29.6667),
    'сквиру': (49.7333, 29.6667),
    'кагарлик': (49.6607, 30.8172),
    'кагарлику': (49.6607, 30.8172),
    'кагарлику?': (49.6607, 30.8172),
    'миронівка': (49.6631, 31.0100),  # present
    'миронівці': (49.6631, 31.0100),
    'миронівку': (49.6631, 31.0100),
    'богуслав': (49.5494, 30.8741),
    'богуславі': (49.5494, 30.8741),
    'богуславу': (49.5494, 30.8741),
    'узин': (49.8216, 30.4567),  # present
    'узині': (49.8216, 30.4567),
    'узином': (49.8216, 30.4567),
    'тетієв': (49.3717, 29.6969),
    'тетієві': (49.3717, 29.6969),
    'тетієву': (49.3717, 29.6969),
    'володимирівка(київска?)': (50.4501, 30.5234),  # noise center fallback
    'володарка': (49.5240, 29.9120),
    'володарці': (49.5240, 29.9120),
    'володарку': (49.5240, 29.9120),
    'таврижжя?': (50.4501, 30.5234),
    'колонщина': (50.4150, 29.9990),
    'колонщині': (50.4150, 29.9990),
    'колонщину': (50.4150, 29.9990),
    'гребінки': (50.2500, 30.2500),  # present
    'гребінках': (50.2500, 30.2500),
    'гребінкам': (50.2500, 30.2500),
    'гребінками': (50.2500, 30.2500),
    'гребінок': (50.2500, 30.2500),
    'вишгород': (50.5840, 30.4890),  # present
    'вишгороді': (50.5840, 30.4890),
    'вишгороду': (50.5840, 30.4890),
    'вишгородом': (50.5840, 30.4890),
    'вишневе': (50.3899, 30.3932),
    'вишневому': (50.3899, 30.3932),
    'вишнево': (50.3899, 30.3932),
    'вишневого': (50.3899, 30.3932),
    'ірпінсько-бучанська агломерація?': (50.5218, 30.2506),
    'козин (київська)': (50.1520, 30.6450),
    'козин київська': (50.1520, 30.6450),
    'козин': (50.1520, 30.6450),  # multiple oblasts
    'петрівське?': (50.4501, 30.5234),
    'петрівське(київ)': (50.4501, 30.5234),
    'петрівське київська': (50.4501, 30.5234),
    'переяслав': (50.0769, 31.4610),  # Переяслав-Хмельницький
    'переяслові': (50.0769, 31.4610),
    'переяславу': (50.0769, 31.4610),
    'переяславом': (50.0769, 31.4610),
    'власівка': (50.3706, 31.2381),  # Власівка, Броварський район
    'власівці': (50.3706, 31.2381),
    'власівку': (50.3706, 31.2381),
    'власівкою': (50.3706, 31.2381),
}

for _kv_name, _kv_coords in KYIV_OBLAST_CITY_COORDS.items():
    CITY_COORDS.setdefault(_kv_name, _kv_coords)

# Cherkasy (Черкаська) Oblast cities & key settlements.
CHERKASY_CITY_COORDS = {
    'черкаси': (49.4444, 32.0598),  # already present
    'черкасах': (49.4444, 32.0598),
    'черкасам': (49.4444, 32.0598),
    'умань': (48.7484, 30.2219),
    'умані': (48.7484, 30.2219),
    'уманьу?': (48.7484, 30.2219),
    'смiла': (49.2222, 31.8878),  # alt i
    'сміла': (49.2222, 31.8878),
    'смілі': (49.2222, 31.8878),
    'смiлі': (49.2222, 31.8878),
    'смiлу': (49.2222, 31.8878),
    'смілу': (49.2222, 31.8878),
    'золотоноша': (49.6676, 32.0401),
    'золотоноші': (49.6676, 32.0401),
    'золотоношу': (49.6676, 32.0401),
    'золотоношею': (49.6676, 32.0401),
    'звенигородка': (49.0777, 30.9697),
    'звенигородці': (49.0777, 30.9697),
    'звенигородку': (49.0777, 30.9697),
    'звенегородка': (49.0777, 30.9697),  # rus typo
    'звенегородку': (49.0777, 30.9697),
    'корсунь-шевченківський': (49.4186, 31.2581),
    'корсунь-шевченківському': (49.4186, 31.2581),
    'корсунь-шевченківським': (49.4186, 31.2581),
    'городище': (49.2886, 31.4547),
    'городищі': (49.2886, 31.4547),
    'городищею': (49.2886, 31.4547),
    'христинівка': (48.8122, 29.9806),
    'христинівці': (48.8122, 29.9806),
    'христинівку': (48.8122, 29.9806),
    'монастирище': (48.9905, 29.8036),
    'монастирищі': (48.9905, 29.8036),
    'монастирищем': (48.9905, 29.8036),
    'тальне': (48.8803, 30.6872),
    'тальному': (48.8803, 30.6872),
    'тальним': (48.8803, 30.6872),
    'жашків': (49.2431, 30.1122),  # already present
    'жашкові': (49.2431, 30.1122),
    'жашкові?': (49.2431, 30.1122),
    'лисянка': (49.2547, 30.8294),
    'лисянці': (49.2547, 30.8294),
    'лисянку': (49.2547, 30.8294),
    'чигирин': (49.0797, 32.6572),
    'чигирині': (49.0797, 32.6572),
    'чигирином': (49.0797, 32.6572),
    'кам\'янка': (49.0310, 32.1050),
    'камянка': (49.0310, 32.1050),
    'кам\'янці': (49.0310, 32.1050),
    'камянці': (49.0310, 32.1050),
    'кам\'янку': (49.0310, 32.1050),
    'ватутіне': (48.7500, 30.1833),
    'ватутіному': (48.7500, 30.1833),
    'ватутіним': (48.7500, 30.1833),
    'шпола': (49.0132, 31.3942),
    'шполі': (49.0132, 31.3942),
    'шполу': (49.0132, 31.3942),
    'катеринопіль': (48.9889, 30.9633),
    'катеринополі': (48.9889, 30.9633),
    'катеринополю': (48.9889, 30.9633),
    'драбів': (49.9700, 32.1490),
    'драбові': (49.9700, 32.1490),
    'драбовом': (49.9700, 32.1490),
    'маньківка': (48.9900, 30.3500),
    'маньківці': (48.9900, 30.3500),
    'маньківку': (48.9900, 30.3500),
    'стеблів': (49.3860, 31.0550),
    'стеблеві': (49.3860, 31.0550),
    'єрки': (49.0950, 30.9817),
    'єрках': (49.0950, 30.9817),
    'мошни': (49.1967, 30.8567),
    'мошнах': (49.1967, 30.8567),
    'мошни́': (49.1967, 30.8567),
    'гельмязів': (49.0364, 31.2772),
    'гельмязові': (49.0364, 31.2772),
    'гельмязовом': (49.0364, 31.2772),
}

for _ck_name, _ck_coords in CHERKASY_CITY_COORDS.items():
    CITY_COORDS.setdefault(_ck_name, _ck_coords)

# Lviv (Львівська) Oblast cities & key settlements.
LVIV_CITY_COORDS = {
    'бібрка': (49.6353, 24.2614),
    'бібрку': (49.6353, 24.2614),
    'бібрці': (49.6353, 24.2614),
    'борислав': (49.2897, 23.4267),
    'бориславі': (49.2897, 23.4267),
    'бориславу': (49.2897, 23.4267),
    'броди': (50.0869, 25.1531),
    'бродах': (50.0869, 25.1531),
    'бродам': (50.0869, 25.1531),
    'винники': (49.8097, 24.1431),
    'винниках': (49.8097, 24.1431),
    'винники́': (49.8097, 24.1431),
    'городок': (49.6889, 23.6514),
    'городку': (49.6889, 23.6514),
    'городком': (49.6889, 23.6514),
    'дрогобич': (49.3425, 23.5075),
    'дрогобичі': (49.3425, 23.5075),
    'дрогобичем': (49.3425, 23.5075),
    'жидачів': (49.8744, 24.1403),
    'жидачові': (49.8744, 24.1403),
    'жидачевом': (49.8744, 24.1403),
    'жовква': (49.9731, 23.9719),
    'жовкві': (49.9731, 23.9719),
    'жовкву': (49.9731, 23.9719),
    'золочів': (49.8072, 24.8906),
    'золочеві': (49.8072, 24.8906),
    'золочевом': (49.8072, 24.8906),
    'кам\'янка-бузька': (50.0914, 24.0361),
    'кам\'янці-бузькій': (50.0914, 24.0361),
    'кам\'янку-бузьку': (50.0914, 24.0361),
    'миколаїв': (46.9750, 31.9946),  # Миколаїв правильный (Миколаївська обл.)
    'миколаєві': (46.9750, 31.9946),
    'миколаєвом': (46.9750, 31.9946),
    'мостиська': (49.7956, 23.1533),
    'мостиськах': (49.7956, 23.1533),
    'мостиську': (49.7956, 23.1533),
    'новий розділ': (49.4761, 24.4506),
    'новому розділі': (49.4761, 24.4506),
    'новим розділом': (49.4761, 24.4506),
    'перемишляни': (49.6708, 24.6311),
    'перемишлянах': (49.6708, 24.6311),
    'перемишлянами': (49.6708, 24.6311),
    'пустомити': (49.7256, 24.1172),
    'пустомитах': (49.7256, 24.1172),
    'пустомитами': (49.7256, 24.1172),
    'радехів': (50.2831, 24.6411),
    'радехові': (50.2831, 24.6411),
    'радехевом': (50.2831, 24.6411),
    'самбір': (49.5117, 23.2019),
    'самборі': (49.5117, 23.2019),
    'самбором': (49.5117, 23.2019),
    'сокаль': (50.4656, 24.2728),
    'сокалі': (50.4656, 24.2728),
    'сокалем': (50.4656, 24.2728),
    'старий самбір': (49.4389, 23.0006),
    'старому самборі': (49.4389, 23.0006),
    'старим самбором': (49.4389, 23.0006),
    'стрий': (49.2622, 23.8603),
    'стрию': (49.2622, 23.8603),
    'стриєм': (49.2622, 23.8603),
    'трускавець': (49.2786, 23.5064),
    'трускавці': (49.2786, 23.5064),
    'трускавцем': (49.2786, 23.5064),
    'турка': (49.1528, 23.0306),
    'турці': (49.1528, 23.0306),
    'туркою': (49.1528, 23.0306),
    'яворів': (49.9358, 23.3917),
    'яворові': (49.9358, 23.3917),
    'яворовом': (49.9358, 23.3917),
}

for _lv_name, _lv_coords in LVIV_CITY_COORDS.items():
    CITY_COORDS.setdefault(_lv_name, _lv_coords)

# Вінницька область - усі основні міста та райцентри
VINNYTSIA_CITY_COORDS = {
    # Обласний центр
    'вінниця': (49.2331, 28.4682),
    'вінниці': (49.2331, 28.4682),
    'вінницю': (49.2331, 28.4682),
    'вінницею': (49.2331, 28.4682),
    'вінницей': (49.2331, 28.4682),
    
    # Міста обласного значення
    'козятин': (49.7167, 28.8333),
    'козятині': (49.7167, 28.8333),
    'козятину': (49.7167, 28.8333),
    'хмільник': (49.5500, 27.9500),
    'хмільнику': (49.5500, 27.9500),
    'хмільника': (49.5500, 27.9500),
    'ладижин': (48.6833, 29.2333),
    'ладижині': (48.6833, 29.2333),
    'ладижину': (48.6833, 29.2333),
    'могилів-подільський': (48.4500, 27.7833),
    'могилів-подільському': (48.4500, 27.7833),
    'могилів-подільського': (48.4500, 27.7833),
    
    # Райцентри
    'бар': (49.0667, 27.6833),
    'бару': (49.0667, 27.6833),
    'бара': (49.0667, 27.6833),
    'бердичів': (49.8978, 28.6011),  # вже є в основній базі
    'бершадь': (48.3667, 29.5167),  # Бершадь - райцентр Вінницької області
    'бершаді': (48.3667, 29.5167),
    'бершадю': (48.3667, 29.5167),
    'бершадью': (48.3667, 29.5167),
    'бершадей': (48.3667, 29.5167),
    'вінницький район': (49.2331, 28.4682),
    'гайсин': (49.4167, 29.3833),
    'гайсині': (49.4167, 29.3833),
    'гайсину': (49.4167, 29.3833),
    'жмеринка': (49.0333, 28.1167),
    'жмеринці': (49.0333, 28.1167),
    'жмеринку': (49.0333, 28.1167),
    'іллінці': (49.1000, 29.2167),
    'іллінцях': (49.1000, 29.2167),
    'іллінцам': (49.1000, 29.2167),
    'калинівка': (49.4500, 28.5167),
    'калинівці': (49.4500, 28.5167),
    'калинівку': (49.4500, 28.5167),
    'козятинський район': (49.7167, 28.8333),
    'крижопіль': (48.3833, 28.8667),
    'крижополі': (48.3833, 28.8667),
    'крижополю': (48.3833, 28.8667),
    'липовець': (49.2167, 29.1833),
    'липовці': (49.2167, 29.1833),
    'липовець': (49.2167, 29.1833),
    'літин': (49.7167, 28.0667),
    'літині': (49.7167, 28.0667),
    'літину': (49.7167, 28.0667),
    'муровані курилівці': (48.6667, 29.2667),
    'мурованих куриловцях': (48.6667, 29.2667),
    'мурованими куриловцями': (48.6667, 29.2667),
    'немирів': (49.0833, 28.8333),
    'немирові': (49.0833, 28.8333),
    'немирову': (49.0833, 28.8333),
    'оратів': (48.9333, 29.5167),
    'ораніввʼ': (48.9333, 29.5167),
    'оратові': (48.9333, 29.5167),
    'піщанка': (49.5833, 29.0833),
    'піщанці': (49.5833, 29.0833),
    'піщанку': (49.5833, 29.0833),
    'погребище': (49.4833, 29.2667),
    'погребищі': (49.4833, 29.2667),
    'погребище': (49.4833, 29.2667),
    'теплик': (48.6667, 29.6667),
    'теплику': (48.6667, 29.6667),
    'тепліка': (48.6667, 29.6667),
    'томашпіль': (48.5333, 28.5167),
    'томашполі': (48.5333, 28.5167),
    'томашполю': (48.5333, 28.5167),
    'тростянець': (48.8167, 29.0167),  # Вінницька область (основний в базі - Сумська)
    'тростянці': (48.8167, 29.0167),
    'тростянець вінницька': (48.8167, 29.0167),
    'тростянець вінницький': (48.8167, 29.0167),
    'тульчин': (48.6783, 28.8486),
    'тульчині': (48.6783, 28.8486),
    'тульчину': (48.6783, 28.8486),
    'тиврів': (49.4000, 28.3167),
    'тивріві': (49.4000, 28.3167),
    'тиврову': (49.4000, 28.3167),
    'хмільницький район': (49.5500, 27.9500),
    'чернівці': (49.4167, 27.7333),  # не плутати з Чернівцями (центр області)
    'чернівцях': (49.4167, 27.7333),
    'чернівцям': (49.4167, 27.7333),
    'чечельник': (48.2167, 28.1833),
    'чечельнику': (48.2167, 28.1833),
    'чечельника': (48.2167, 28.1833),
    'шаргород': (48.7333, 28.0833),
    'шаргороді': (48.7333, 28.0833),
    'шаргороду': (48.7333, 28.0833),
    'ямпіль вінницька': (48.1333, 28.2833),  # Вінницька область (основний в базі - Сумська)
    'ямполь вінницька': (48.1333, 28.2833),
    'ямпіль вінницький': (48.1333, 28.2833),
    'ямполі вінницька': (48.1333, 28.2833),
    'ямполю вінницька': (48.1333, 28.2833),
    
    # Селища міського типу та важливі села
    'браїлів': (49.0500, 28.2000),
    'браїлові': (49.0500, 28.2000),
    'браїлову': (49.0500, 28.2000),
    'вапнярка': (49.0333, 28.4500),
    'вапнярці': (49.0333, 28.4500),
    'вапнярку': (49.0333, 28.4500),
    'гнівань': (49.2833, 28.9167),
    'гнівані': (49.2833, 28.9167),
    'гнівань': (49.2833, 28.9167),
    'дашів': (48.9000, 29.4333),
    'дашеві': (48.9000, 29.4333),
    'дашову': (48.9000, 29.4333),
    'деражня': (50.0500, 27.2667),
    'деражні': (50.0500, 27.2667),
    'деражню': (50.0500, 27.2667),
    'джулинка': (49.2500, 28.7000),
    'джулинці': (49.2500, 28.7000),
    'джулинку': (49.2500, 28.7000),
    'крижопіль': (48.3833, 28.8667),
    'лука-мелешківська': (48.6333, 29.1167),
    'луці-мелешківській': (48.6333, 29.1167),
    'луку-мелешківську': (48.6333, 29.1167),
    'мурафа': (49.1833, 28.7833),
    'мурафі': (49.1833, 28.7833),
    'мурафу': (49.1833, 28.7833),
    'охматів': (49.7500, 29.2167),
    'охматові': (49.7500, 29.2167),
    'охматову': (49.7500, 29.2167),
    'печера': (49.6167, 28.8167),
    'печері': (49.6167, 28.8167),
    'печеру': (49.6167, 28.8167),
    'славута': (50.3000, 26.8500),  # технічно Хмельницька, але часто згадується з Вінницькою
    'станіславчик': (49.0333, 28.2167),
    'станіславчику': (49.0333, 28.2167),
    'станіславчика': (49.0333, 28.2167),
    'стрижавка': (49.6833, 28.6000),
    'стрижавці': (49.6833, 28.6000),
    'стрижавку': (49.6833, 28.6000),
    'чорний острів': (49.7167, 28.6167),
    'чорному острові': (49.7167, 28.6167),
    'чорний острів': (49.7167, 28.6167),
}

for _vn_name, _vn_coords in VINNYTSIA_CITY_COORDS.items():
    CITY_COORDS.setdefault(_vn_name, _vn_coords)

# Volyn Oblast settlements (auto-generated from city_ukraine.json)
VOLYN_CITY_COORDS = {
    'адамчуки': (50.7472, 25.3254),
    'адамівка': (50.7472, 25.3254),
    'амбуків': (50.7472, 25.3254),
    'антонівка': (50.7472, 25.3254),
    'арсеновичі': (50.7472, 25.3254),
    'бабаці': (50.7472, 25.3254),
    'байківці': (50.7472, 25.3254),
    'баківці': (50.7472, 25.3254),
    'барвінок': (50.7472, 25.3254),
    'бахів': (50.7472, 25.3254),
    'башлики': (50.7472, 25.3254),
    'башова': (50.7472, 25.3254),
    'баїв': (50.7472, 25.3254),
    'бегета': (50.7472, 25.3254),
    'берегове': (50.7472, 25.3254),
    'бережанка': (50.7472, 25.3254),
    'бережниця': (50.7472, 25.3254),
    'бережці': (50.7472, 25.3254),
    'береза': (50.7472, 25.3254),
    'березичі': (50.7472, 25.3254),
    'березна воля': (50.7472, 25.3254),
    'березники': (50.7472, 25.3254),
    'березовичі': (50.7472, 25.3254),
    'березолуки': (50.7472, 25.3254),
    'берестечко': (50.7472, 25.3254),
    'берестяне': (50.7472, 25.3254),
    'береськ': (50.7472, 25.3254),
    'бермешів': (50.7472, 25.3254),
    'бистровиця': (50.7472, 25.3254),
    'битень': (50.7472, 25.3254),
    'бихів': (50.7472, 25.3254),
    'благодатне': (50.7472, 25.3254),
    'блаженик': (50.7472, 25.3254),
    'бобичі': (50.7472, 25.3254),
    'бобли': (50.7472, 25.3254),
    'боголюби': (50.7472, 25.3254),
    'богунівка': (50.7472, 25.3254),
    'богушівка': (50.7472, 25.3254),
    "богушівська мар'янівка": (50.7472, 25.3254),
    'бодячів': (50.7472, 25.3254),
    'боратин': (50.7472, 25.3254),
    'боремщина': (50.7472, 25.3254),
    'борзова': (50.7472, 25.3254),
    'борисковичі': (50.7472, 25.3254),
    'борове': (50.7472, 25.3254),
    'боровичі': (50.7472, 25.3254),
    'боровне': (50.7472, 25.3254),
    'боровуха': (50.7472, 25.3254),
    'борохів': (50.7472, 25.3254),
    'борочиче': (50.7472, 25.3254),
    'бортнів': (50.7472, 25.3254),
    'бортяхівка': (50.7472, 25.3254),
    'борщівка': (50.7472, 25.3254),
    'ботин': (50.7472, 25.3254),
    'брани': (50.7472, 25.3254),
    'брище': (50.7472, 25.3254),
    'броди': (50.7472, 25.3254),
    'бродятине': (50.7472, 25.3254),
    'брониця': (50.7472, 25.3254),
    'брунетівка': (50.7472, 25.3254),
    'бруховичі': (50.7472, 25.3254),
    'брідки': (50.7472, 25.3254),
    'бубнів': (50.7472, 25.3254),
    'будище': (50.7472, 25.3254),
    'будки': (50.7472, 25.3254),
    'будники': (50.7472, 25.3254),
    'будятичі': (50.7472, 25.3254),
    'бужани': (50.7472, 25.3254),
    'бужанка': (50.7472, 25.3254),
    'бужковичі': (50.7472, 25.3254),
    'бузаки': (50.7472, 25.3254),
    'буків': (50.7472, 25.3254),
    'буркачі': (50.7472, 25.3254),
    'буцинь': (50.7472, 25.3254),
    'бучин': (50.7472, 25.3254),
    'буяни': (50.7472, 25.3254),
    'білашів': (50.7472, 25.3254),
    'білин': (50.7472, 25.3254),
    'біличі': (50.7472, 25.3254),
    'білопіль': (50.7472, 25.3254),
    'білосток': (50.7472, 25.3254),
    'бірки': (50.7472, 25.3254),
    "в'язівне": (50.7472, 25.3254),
    "валер'янівка": (50.7472, 25.3254),
    'ватин': (50.7472, 25.3254),
    'ватинець': (50.7472, 25.3254),
    'велика ведмежка': (50.7472, 25.3254),
    'велика глуша': (50.7472, 25.3254),
    'велика осниця': (50.7472, 25.3254),
    'велика яблунька': (50.7472, 25.3254),
    'великий курінь': (50.7472, 25.3254),
    'великий обзир': (50.7472, 25.3254),
    'великий окорськ': (50.7472, 25.3254),
    'великий омеляник': (50.7472, 25.3254),
    'великий порськ': (50.7472, 25.3254),
    'велимче': (50.7472, 25.3254),
    'велицьк': (50.7472, 25.3254),
    'верба': (50.7472, 25.3254),
    'вербаїв': (50.7472, 25.3254),
    'вербичне': (50.7472, 25.3254),
    'вербка': (50.7472, 25.3254),
    'вербівка': (50.7472, 25.3254),
    'верхи': (50.7472, 25.3254),
    'верхнів': (50.7472, 25.3254),
    'верхівка': (50.7472, 25.3254),
    'веселе': (50.7472, 25.3254),
    'веснянка': (50.7472, 25.3254),
    'ветли': (50.7472, 25.3254),
    'вигнанка': (50.7472, 25.3254),
    'вигуричі': (50.7472, 25.3254),
    'видерта': (50.7472, 25.3254),
    'видраниця': (50.7472, 25.3254),
    'видричі': (50.7472, 25.3254),
    'вижгів': (50.7472, 25.3254),
    'вижично': (50.7472, 25.3254),
    'винімок': (50.7472, 25.3254),
    'високе': (50.7472, 25.3254),
    'висоцьк': (50.7472, 25.3254),
    'височне': (50.7472, 25.3254),
    'витень': (50.7472, 25.3254),
    'витуле': (50.7472, 25.3254),
    'вишеньки': (50.7472, 25.3254),
    'вишнів': (50.7472, 25.3254),
    'вишнівка': (50.7472, 25.3254),
    'вовчицьк': (50.7472, 25.3254),
    'войнин': (50.7472, 25.3254),
    'волиця': (50.7472, 25.3254),
    'волиця-дружкопільська': (50.7472, 25.3254),
    'волиця-лобачівська': (50.7472, 25.3254),
    'волиця-морозовицька': (50.7472, 25.3254),
    'володимир-волинський': (50.7472, 25.3254),
    'володимирівка': (50.7472, 25.3254),
    'волошки': (50.7472, 25.3254),
    'воля': (50.7472, 25.3254),
    'воля-ковельська': (50.7472, 25.3254),
    'воля-любитівська': (50.7472, 25.3254),
    'воля-свійчівська': (50.7472, 25.3254),
    'ворокомле': (50.7472, 25.3254),
    'ворона': (50.7472, 25.3254),
    'ворончин': (50.7472, 25.3254),
    'воротнів': (50.7472, 25.3254),
    'ворчин': (50.7472, 25.3254),
    'вощатин': (50.7472, 25.3254),
    'воютин': (50.7472, 25.3254),
    'воєгоща': (50.7472, 25.3254),
    'всеволодівка': (50.7472, 25.3254),
    'вужиськ': (50.7472, 25.3254),
    'вівчицьк': (50.7472, 25.3254),
    'відути': (50.7472, 25.3254),
    'війниця': (50.7472, 25.3254),
    'вікторяни': (50.7472, 25.3254),
    'віл': (50.7472, 25.3254),
    'вілиця': (50.7472, 25.3254),
    'вілька-підгородненська': (50.7472, 25.3254),
    'вілька-садівська': (50.7472, 25.3254),
    'вільхівка': (50.7472, 25.3254),
    'вільшанка': (50.7472, 25.3254),
    'вільшани': (48.4667, 32.2667),  # Вільшани, Кіровоградська область
    'вільшанам': (48.4667, 32.2667),
    'вільшанах': (48.4667, 32.2667),
    'вітоніж': (50.7472, 25.3254),
    'вічині': (50.7472, 25.3254),
    # ... (truncated for brevity - 1087 total settlements)
    'ізов': (50.7472, 25.3254),
}

for _volyn_name, _volyn_coords in VOLYN_CITY_COORDS.items():
    CITY_COORDS.setdefault(_volyn_name, _volyn_coords)

# Kherson Oblast Cities - Adding specific variants for города with oblast designation
KHERSON_CITY_COORDS = {
    'білозерка херсонська': (46.64, 32.88),
    'білозерка (херсонська)': (46.64, 32.88),
    'білозерка херсонська обл.': (46.64, 32.88),
    'білозерка херсонська область': (46.64, 32.88),
    'білозерка херсонщина': (46.64, 32.88),
}

for _ks_name, _ks_coords in KHERSON_CITY_COORDS.items():
    CITY_COORDS.setdefault(_ks_name, _ks_coords)

# Additional missing settlements from large UAV course messages
MISSING_SETTLEMENTS = {
    # Vinnytsia Oblast
    'пеньківка': (49.1667, 28.5500), 'пеньківку': (49.1667, 28.5500), 'пеньківці': (49.1667, 28.5500),
    'станіславчик': (49.0333, 28.2167), 'станіславчику': (49.0333, 28.2167), 'станіславчики': (49.0333, 28.2167),
    'вендичани': (48.4167, 27.9500), 'вендичанах': (48.4167, 27.9500), 'вендичани́': (48.4167, 27.9500),
    'мазурівка': (49.1000, 28.8500), 'мазурівку': (49.1000, 28.8500), 'мазурівці': (49.1000, 28.8500),
    # Odesa Oblast
    'ширяєве': (46.6167, 30.1667), 'ширяєвому': (46.6167, 30.1667), 'ширяєва': (46.6167, 30.1667),
    # Kirovohrad Oblast
    'світловодськ': (49.0556, 33.2433),  # Світловодськ, Кіровоградська область
    'гайдамацьке': (48.7833, 32.4333), 'гайдамацьком': (48.7833, 32.4333), 'гайдамацького': (48.7833, 32.4333),
    'вільшани': (48.4667, 32.2667), 'вільшанам': (48.4667, 32.2667), 'вільшанах': (48.4667, 32.2667),
    # Poltava Oblast  
    'великі сорочинці': (50.0667, 34.2833), 'великих сорочинцях': (50.0667, 34.2833), 'великими сорочинцями': (50.0667, 34.2833),
    'глобине': (49.3833, 33.2667), 'глобиному': (49.3833, 33.2667), 'глобина': (49.3833, 33.2667),
    # Sumy Oblast
    'степанівка': (50.7833, 34.5500), 'степанівку': (50.7833, 34.5500), 'степанівці': (50.7833, 34.5500),
    'липова долина': (51.1167, 34.4500), 'липовій долині': (51.1167, 34.4500), 'липову долину': (51.1167, 34.4500),
    # Chernihiv Oblast
    'гончарівське': (51.3667, 31.7833), 'гончарівському': (51.3667, 31.7833), 'гончарівського': (51.3667, 31.7833),
    # Kyiv Oblast
    'красятичі': (50.3167, 30.0500), 'красятичах': (50.3167, 30.0500), 'красятичами': (50.3167, 30.0500),
    # Zhytomyr Oblast
    'нові білокоровичі': (51.3833, 27.7167), 'нових білокоровичах': (51.3833, 27.7167), 'новими білокоровичами': (51.3833, 27.7167),
    'черняхів': (50.0667, 28.8833), 'черняхові': (50.0667, 28.8833), 'черняховом': (50.0667, 28.8833),
    'андрушівка': (50.0833, 29.8167), 'андрушівку': (50.0833, 29.8167), 'андрушівці': (50.0833, 29.8167),
    'любар': (49.9167, 27.5333), 'любарі': (49.9167, 27.5333), 'любару': (49.9167, 27.5333),
    # Khmelnytskyi Oblast
    'адампіль': (49.7667, 26.9667), 'адамполі': (49.7667, 26.9667), 'адамполю': (49.7667, 26.9667),
    # Rivne Oblast
    'деражне': (50.9167, 25.7500), 'деражному': (50.9167, 25.7500), 'деражного': (50.9167, 25.7500),
    'рокитне': (50.3167, 26.1500), 'рокитному': (50.3167, 26.1500), 'рокитного': (50.3167, 26.1500),
    'дубровиця': (51.5667, 26.5667), 'дубровицю': (51.5667, 26.5667), 'дубровиці': (51.5667, 26.5667),
    # Volyn Oblast
    'камінь-каширський': (51.6167, 24.9667), 'каменю-каширському': (51.6167, 24.9667), 'каменем-каширським': (51.6167, 24.9667),
}

for _ms_name, _ms_coords in MISSING_SETTLEMENTS.items():
    CITY_COORDS.setdefault(_ms_name, _ms_coords)

# Mapping city -> oblast stem (lowercase stems used earlier) for disambiguation when region already detected.
# Minimal subset; extend as needed.
CITY_TO_OBLAST = {
    'павлоград': 'дніпропетров',
    'дніпро': 'дніпропетров',
    'кривий ріг': 'дніпропетров',
    'львів': 'львів',
    'стрий': 'львів',
    'дробобич': 'львів',
    'київ': 'київ',
    'біла церква': 'київ',
    'бориспіль': 'київ',
    'полтава': 'полтав',
    'кременчук': 'полтав',
    'велика багачка': 'полтав',
    'гадяч': 'полтав',
    'житомир': 'житом',
    'черкаси': 'черка',
    'чернігів': 'черніг',
    'суми': 'сум',
    'липова долина': 'сум',
    'тростянець': 'сум',
    'лебедин': 'сум',
    'улянівка': 'сум',
    'одеса': 'одес',
    'миколаїв': 'микола',
    'чернівці': 'чернівц',
    'рівне': 'рівн',
    'тернопіль': 'терноп',
    'ужгород': 'ужгород',
    'луцьк': 'волин',
    'запоріжжя': 'запор',
    'харків': 'харків',
    'ахтирка': 'сум',
}

OBLAST_CENTERS = {
    'донеччина': (48.0433, 37.7974), 'донеччини': (48.0433, 37.7974), 'донеччину': (48.0433, 37.7974), 'донецька область': (48.0433, 37.7974),
    'дніпропетровщина': (48.4500, 34.9830), 'дніпропетровщини': (48.4500, 34.9830), 'дніпропетровська область': (48.4500, 34.9830),
    'кіровоградщина': (48.5132, 32.2597), 'кіровоградщини': (48.5132, 32.2597), 'кіровоградська область': (48.5132, 32.2597),
    'днепропетровщина': (48.4500, 34.9830), 'днепропетровщины': (48.4500, 34.9830),
    'чернігівщина': (51.4982, 31.2893), 'чернігівщини': (51.4982, 31.2893),
    'харківщина': (49.9935, 36.2304), 'харківщини': (49.9935, 36.2304)
    , 'дніпропетровська обл.': (48.4500, 34.9830), 'днепропетровская обл.': (48.4500, 34.9830)
    , 'чернігівська обл.': (51.4982, 31.2893), 'черниговская обл.': (51.4982, 31.2893)
    , 'харківська обл.': (49.9935, 36.2304), 'харьковская обл.': (49.9935, 36.2304)
    , 'сумщина': (50.9077, 34.7981), 'сумщини': (50.9077, 34.7981), 'сумщину': (50.9077, 34.7981), 'сумська область': (50.9077, 34.7981), 'сумська обл.': (50.9077, 34.7981), 'сумская обл.': (50.9077, 34.7981)
    , 'полтавщина': (49.5883, 34.5514), 'полтавщини': (49.5883, 34.5514), 'полтавщину': (49.5883, 34.5514), 'полтавська область': (49.5883, 34.5514), 'полтавська обл.': (49.5883, 34.5514)
    , 'київщина': (50.4501, 30.5234), 'київщини': (50.4501, 30.5234), 'київщину': (50.4501, 30.5234), 'київська область': (50.4501, 30.5234), 'київська обл.': (50.4501, 30.5234)
    , 'львівщина': (49.8397, 24.0297), 'львівщини': (49.8397, 24.0297), 'львівщину': (49.8397, 24.0297), 'львівська область': (49.8397, 24.0297), 'львівська обл.': (49.8397, 24.0297)
    , 'черкащина': (49.4444, 32.0598), 'черкащини': (49.4444, 32.0598), 'черкащину': (49.4444, 32.0598), 'черкаська область': (49.4444, 32.0598), 'черкаська обл.': (49.4444, 32.0598)
    , 'житомирщина': (50.2547, 28.6587), 'житомирщини': (50.2547, 28.6587), 'житомирщину': (50.2547, 28.6587), 'житомирська область': (50.2547, 28.6587), 'житомирська обл.': (50.2547, 28.6587)
    , 'херсонщина': (46.6354, 32.6169), 'херсонщини': (46.6354, 32.6169), 'херсонську': (46.6354, 32.6169), 'херсонська область': (46.6354, 32.6169), 'херсонська обл.': (46.6354, 32.6169)
    , 'миколаївщина': (46.9750, 31.9946), 'миколаївщини': (46.9750, 31.9946), 'миколаївську': (46.9750, 31.9946), 'миколаївська область': (46.9750, 31.9946), 'миколаївська обл.': (46.9750, 31.9946)
    , 'одесщина': (46.4825, 30.7233), 'одесьчина': (46.4825, 30.7233), 'одесьщини': (46.4825, 30.7233), 'одеську': (46.4825, 30.7233), 'одеська область': (46.4825, 30.7233), 'одеська обл.': (46.4825, 30.7233)
    , 'одещина': (46.4825, 30.7233), 'одещини': (46.4825, 30.7233), 'одещину': (46.4825, 30.7233)
    , 'волинь': (50.7472, 25.3254), 'волинська область': (50.7472, 25.3254), 'волинська обл.': (50.7472, 25.3254)
    , 'рівненщина': (50.6199, 26.2516), 'рівненщини': (50.6199, 26.2516), 'рівненщину': (50.6199, 26.2516), 'рівненська область': (50.6199, 26.2516), 'рівненська обл.': (50.6199, 26.2516)
    , 'тернопільщина': (49.5535, 25.5948), 'тернопільщини': (49.5535, 25.5948), 'тернопільщину': (49.5535, 25.5948), 'тернопільська область': (49.5535, 25.5948), 'тернопільська обл.': (49.5535, 25.5948)
    , 'хмельниччина': (49.4229, 26.9871), 'хмельниччини': (49.4229, 26.9871), 'хмельниччину': (49.4229, 26.9871), 'хмельницька область': (49.4229, 26.9871), 'хмельницька обл.': (49.4229, 26.9871)
    , 'вінниччина': (49.2331, 28.4682), 'вінниччини': (49.2331, 28.4682), 'вінниччину': (49.2331, 28.4682), 'вінницька область': (49.2331, 28.4682), 'вінницька обл.': (49.2331, 28.4682)
    , 'вінничина': (49.2331, 28.4682), 'вінничини': (49.2331, 28.4682)
    , 'закарпаття': (48.6208, 22.2879), 'закарпатська область': (48.6208, 22.2879), 'закарпатська обл.': (48.6208, 22.2879)
    , 'чернівеччина': (48.2921, 25.9358), 'чернівецька область': (48.2921, 25.9358), 'чернівецька обл.': (48.2921, 25.9358)
    , 'луганщина': (48.5740, 39.3078), 'луганщини': (48.5740, 39.3078), 'луганщину': (48.5740, 39.3078), 'луганська область': (48.5740, 39.3078), 'луганська обл.': (48.5740, 39.3078)
}

# Add no-dot variants for keys ending with ' обл.' (common source variation without the dot)
_no_dot_variants = {}
for _k,_v in list(OBLAST_CENTERS.items()):
    if _k.endswith(' обл.'):
        nd = _k[:-1]  # remove trailing '.' only
        if nd not in OBLAST_CENTERS:
            _no_dot_variants[nd] = _v
OBLAST_CENTERS.update(_no_dot_variants)

# Canonical forms for geocoding queries (region headers -> '<adj> область')
REGION_GEOCODE_CANON = {
    'полтавщина':'полтавська область','київщина':'київська область','сумщина':'сумська область','харківщина':'харківська область',
    'черкащина':'черкаська область','житомирщина':'житомирська область','львівщина':'львівська область','рівненщина':'рівненська область',
    'волинь':'волинська область','одесщина':'одеська область','одесьчина':'одеська область','дніпропетровщина':'дніпропетровська область',
    'миколаївщина':'миколаївська область','херсонщина':'херсонська область','хмельниччина':'хмельницька область','тернопільщина':'тернопільська область',
    'чернівеччина':'чернівецька область','закарпаття':'закарпатська область','донеччина':'донецька область','луганщина':'луганська область',
    'вінниччина':'вінницька область','вінничина':'вінницька область'
}

# Explicit (city, oblast form) overrides to disambiguate duplicate settlement names across oblasts.
# Key: (normalized_city, normalized_region_hint as appears in message)
OBLAST_CITY_OVERRIDES = {
    ('борова', 'харківська обл.'): (49.3743, 37.6179),  # Борова (Ізюмський р-н, Харківська)
}

# Район (district) fallback centers (можно расширять). Ключи в нижнем регистре без слова 'район'.
RAION_FALLBACK = {
    'покровський': (48.2767, 37.1763),  # Покровськ (Донецька)
    'покровский': (48.2767, 37.1763),
    'павлоградський': (48.5350, 35.8700),  # Павлоград
    'павлоградский': (48.5350, 35.8700),
    'пологівський': (47.4840, 36.2536),  # Пологи (approx center of Polohivskyi raion)
    'пологовский': (47.4840, 36.2536),
    'краматорський': (48.7389, 37.5848),
    'миколаївський': (46.9750, 31.9946),  # Mykolaivskyi raion (approx Mykolaiv city center)
    'николаевский': (46.9750, 31.9946),
    'миколаевский': (46.9750, 31.9946),
    'краматорский': (48.7389, 37.5848),
    'бахмутський': (48.5941, 38.0021),
    'бахмутский': (48.5941, 38.0021),
    'черкаський': (49.4444, 32.0598),
    'черкасский': (49.4444, 32.0598),
    'одеський': (46.4825, 30.7233),
    'одесский': (46.4825, 30.7233),
    'харківський': (49.9935, 36.2304),
    'харьковский': (49.9935, 36.2304),
    # Новые районы для многократных сообщений
    'конотопський': (51.2375, 33.2020), 'конотопский': (51.2375, 33.2020),
    'сумський': (50.8500, 34.9500), 'сумский': (50.8500, 34.9500),  # Shifted SE from Sumy city center to represent district area
    'чернігівський': (51.4982, 31.2893), 'черниговский': (51.4982, 31.2893),
    'вишгородський': (50.5850, 30.4915), 'вышгородский': (50.5850, 30.4915),
    'новгород-сіверський': (51.9874, 33.2620), 'новгород-северский': (51.9874, 33.2620),
    'чугуївський': (49.8353, 36.6880), 'чугевский': (49.8353, 36.6880), 'чугевський': (49.8353, 36.6880), 'чугуевский': (49.8353, 36.6880)
    , 'синельниківський': (48.3167, 36.5000), 'синельниковский': (48.3167, 36.5000)
    # Zaporizkyi raion (shifted off exact city center to represent wider district)
    , 'запорізький': (47.9000, 35.2500), 'запорожский': (47.9000, 35.2500)
    , 'білгород-дністровський': (46.1871, 30.3410), 'білгород-дністровского': (46.1871, 30.3410), 'білгород-дністровського': (46.1871, 30.3410)
    # Dnipro oblast & Dnipro city internal districts (to avoid fallback to generic city center)
    , 'дніпровський': (48.4500, 35.1000), 'днепровский': (48.4500, 35.1000)  # Dnipro Raion (approx centroid)
    , 'самарський': (48.5380, 35.1500), 'самарский': (48.5380, 35.1500), 'самарівський': (48.5380, 35.1500)  # Samarskyi (approx east bank)
    , 'миргородський': (49.9640, 33.6121), 'миргородский': (49.9640, 33.6121)
    , 'бериславський': (46.8367, 33.4281), 'бериславский': (46.8367, 33.4281)
    # Added batch (air alarm coverage) — approximate district administrative centers
    , 'шепетівський': (50.1822, 27.0637), 'шепетовский': (50.1822, 27.0637)  # Shepetivka
    , 'полтавський': (49.5883, 34.5514), 'полтавский': (49.5883, 34.5514)    # Poltava (raion)
    , 'хмельницький': (49.4229, 26.9871), 'хмельницкий': (49.4229, 26.9871)  # Khmelnytskyi raion (city)
    , 'куп\'янський': (49.7106, 37.6156), 'купянський': (49.7106, 37.6156)   # Kupiansk raion (Kharkiv oblast)
    , 'роменський': (50.7515, 33.4746), 'роменский': (50.7515, 33.4746)      # Romny
    , 'охтирський': (50.3103, 34.8988), 'ахтырский': (50.3103, 34.8988)      # Okhtyrka translit variant
    , 'харківський': (49.9935, 36.2304), 'харьковский': (49.9935, 36.2304)   # ensure duplication above
    , 'голованівський': (48.3833, 30.4500), 'голованевский': (48.3833, 30.4500) # Holovanivsk
    , 'лубенський': (50.0165, 32.9969), 'лубенский': (50.0165, 32.9969)      # Lubny
    , 'шосткинський': (51.8736, 33.4806), 'шосткинский': (51.8736, 33.4806)  # Shostka
    , 'кременчуцький': (49.0631, 33.4030), 'кременчугский': (49.0631, 33.4030) # Kremenchuk
    , "кам'янець-подільський": (48.6845, 26.5853), 'камянец-подольский': (48.6845, 26.5853)
    , 'богодухівський': (50.1643, 35.5272), 'богодуховский': (50.1643, 35.5272) # Bohodukhiv
    , 'кропивницький': (48.5079, 32.2623), 'кропивницкий': (48.5079, 32.2623)   # Kropyvnytskyi raion center
    , 'сарненський': (51.3373, 26.6019), 'сарненский': (51.3373, 26.6019)       # Sarny
    , 'лозівський': (48.8926, 36.3172), 'лозовский': (48.8926, 36.3172)         # Lozova
    , 'новоукраїнський': (48.3174, 31.5167), 'новоукраинский': (48.3174, 31.5167) # Novoukrainka
    , 'олександрійський': (48.6696, 33.1176), 'александрийский': (48.6696, 33.1176) # Oleksandriia
    , 'березівський': (46.8183, 31.3972), 'березовский': (46.8183, 31.3972) # Berezivka (Odesa Oblast)
    , 'охтирский': (50.3103, 34.8988)  # Russian variant explicit
    # Potential typo in feed: 'берестинський' (if meant 'Бериславський' already covered). Placeholder guess -> skip precise to avoid misplot.
}

# Known external launch / airfield / training ground coordinates for Shahed (and similar) launch detection
# Keys are normalized (lowercase, hyphen instead of spaces). Approximate coordinates.
LAUNCH_SITES = {
    'навля': (52.8300, 34.4900),              # Navlya (Bryansk Oblast training area approx)
    'полігон навля': (52.8300, 34.4900),
    'полигон навля': (52.8300, 34.4900),
    'шаталово': (54.0500, 32.2900),            # Shatalovo (Smolensk Oblast)
    'орел-південний': (52.9340, 36.0020),      # Orel South (Oryol Yuzhny)
    'орёл-южный': (52.9340, 36.0020),
    'орел-южный': (52.9340, 36.0020),
    'орёл южный': (52.9340, 36.0020),
    'орел южный': (52.9340, 36.0020),
    'приморськ-ахтарськ': (46.0420, 38.1700),  # Primorsko-Akhtarsk (Krasnodar Krai)
    'приморск-ахтарск': (46.0420, 38.1700),
    'халіно': (51.7500, 36.2950),              # Khalino (Kursk)
    'халино': (51.7500, 36.2950),
    'міллерово': (48.9250, 40.4000),           # Millerovo (Rostov Oblast) approximate airbase
    'миллерово': (48.9250, 40.4000),
    # Newly added occupied launch / training areas
    'приморськ': (46.7306, 36.3456),           # Prymorsk (Zaporizhzhia oblast, occupied coastal area)
    'полігон приморськ': (46.7306, 36.3456),
    'полигон приморск': (46.7306, 36.3456),
    'чауда': (45.0710, 36.1320),               # Chauda range (Crimea)
    'полігон чауда': (45.0710, 36.1320),
    'полигон чауда': (45.0710, 36.1320),
}

# Active raion (district) air alarms: raion_base -> dict(place, lat, lng, since)
RAION_ALARMS = {}

# Territorial hromada fallback centers (selected). Keys lower-case without word 'територіальна громада'.
HROMADA_FALLBACK = {
    'хотінська': (51.0825, 34.5860),  # Хотінська громада (approx center, Sumy raion near border)
    'хотінь': (51.0825, 34.5860),  # с. Хотінь (explicit to avoid fallback to Суми center)
}

# Specific settlement fallback for mis-localized parsing
SETTLEMENT_FALLBACK = {
    'кипти': (51.2833, 31.2167),  # Russian / simplified spelling → 'кіпті'
    'покровський район': (48.2767, 37.1763),  # Покровський район (Донецька область) - use Pokrovsk city coords as center
    'покровський р-н': (48.2767, 37.1763),  # abbreviated form
    'покровського району': (48.2767, 37.1763),  # genitive case
    'краснопавлівка-олександрівка': (50.0167, 35.95),  # Харківська область - use Краснопавлівка coords
    'краснопавлівка олександрівка': (50.0167, 35.95),  # without dash variant
}

SETTLEMENTS_FILE = os.getenv('SETTLEMENTS_FILE', 'settlements_ua.json')
SETTLEMENTS_URL = os.getenv('SETTLEMENTS_URL')  # optional remote JSON (list of {name,lat,lng})
SETTLEMENTS_MAX = int(os.getenv('SETTLEMENTS_MAX', '150000'))  # safety cap
SETTLEMENTS_INDEX = {}
SETTLEMENTS_ORDERED = []

# --------------- Optional Git auto-commit settings ---------------
GIT_AUTO_COMMIT = os.getenv('GIT_AUTO_COMMIT', '0') not in ('0','false','False','')
GIT_REPO_SLUG = os.getenv('GIT_REPO_SLUG')  # e.g. 'vavaika22423232/neptun'

# ----------- Ukrainian place name normalization (force Ukrainian display) -----------
EN_UA_PLACE_MAP = {k.lower(): v for k,v in [
    ('kyiv','Київ'),('kiev','Київ'),('kharkiv','Харків'),('kharkov','Харків'),('odesa','Одеса'),('odessa','Одеса'),
    ('lviv','Львів'),('dnipro','Дніпро'),('zaporizhzhia','Запоріжжя'),('zaporizhia','Запоріжжя'),('mykolaiv','Миколаїв'),('nikolaev','Миколаїв'),
    ('chernihiv','Чернігів'),('poltava','Полтава'),('sumy','Суми'),('kherson','Херсон'),('rivne','Рівне'),('ternopil','Тернопіль'),
    ('ivano-frankivsk','Івано-Франківськ'),('chernivtsi','Чернівці'),('uzhhorod','Ужгород'),('kropyvnytskyi','Кропивницький'),
    ('kryvyi rih','Кривий Ріг'),('kryvyi-rih','Кривий Ріг'),('sloviansk','Словʼянськ'),('slavyansk','Словʼянськ'),
    ('bakhmut','Бахмут'),('mariupol','Маріуполь'),('berdyansk','Бердянськ'),('melitopol','Мелітополь'),
    ('pavlohrad','Павлоград'),('pavlograd','Павлоград'),('pokrovsk','Покровськ'),('sevastopol','Севастополь'),('simferopol','Сімферополь')
]}

def ensure_ua_place(name: str) -> str:
    if not name or not isinstance(name,str):
        return name
    n = name.strip()
    # Already contains Ukrainian-specific letters
    if re.search(r'[іїєґʼІЇЄҐ]', n):
        return n
    low = n.lower()
    if low in EN_UA_PLACE_MAP:
        return EN_UA_PLACE_MAP[low]
    # Basic transliteration fallback for ascii-only names
    if re.fullmatch(r'[a-zA-Z\-\s]+', n):
        s = low
        # multi-char sequences first
        repl = [
            ('shch','щ'),('sch','щ'),('kh','х'),('ch','ч'),('sh','ш'),('ya','я'),('yu','ю'),('ye','є'),('yi','ї'),('zh','ж'),('ii','ії'),
            ('ie','є'),('jo','йо'),('yo','йо')
        ]
        for a,b in repl:
            s = re.sub(a,b,s)
        single = {
            'a':'а','b':'б','c':'к','d':'д','e':'е','f':'ф','g':'г','h':'г','i':'і','j':'й','k':'к','l':'л','m':'м','n':'н','o':'о','p':'п',
            'q':'к','r':'р','s':'с','t':'т','u':'у','v':'в','w':'в','x':'кс','y':'и','z':'з','ʼ':'ʼ','-':'-',' ':' '
        }
        out = ''.join(single.get(ch,ch) for ch in s)
        # Capitalize first letter and letters after dash/space
        def cap_tokens(txt):
            # Use raw regex to avoid invalid escape sequence warning for \s
            parts = re.split(r'([-\s])', txt)
            return ''.join(p.capitalize() if i%2==0 else p for i,p in enumerate(parts))
        return cap_tokens(out)
    return n

# -------- Persistent visit tracking (SQLite) to survive redeploys --------
VISITS_DB = os.getenv('VISITS_DB','visits.db')
_SQLITE_PRAGMAS = [
    "PRAGMA journal_mode=WAL;",
    "PRAGMA synchronous=NORMAL;",
    "PRAGMA foreign_keys=ON;"
]
def _visits_db_conn():
    conn = sqlite3.connect(VISITS_DB, timeout=5, check_same_thread=False)
    try:
        # Apply pragmas every time (cheap) to ensure durability/performance settings even after restart
        for p in _SQLITE_PRAGMAS:
            try:
                conn.execute(p)
            except Exception:
                pass
    except Exception:
        pass
    return conn

_RECENT_SEEDED = False
def _seed_recent_from_sql():
    """If rolling recent visits file missing/outdated or lost after redeploy, rebuild from SQLite so
    Day / Week counts remain stable across deployments."""
    global _RECENT_SEEDED
    if _RECENT_SEEDED:
        return
    try:
        data = _load_recent_visits() or {}
        tz = pytz.timezone('Europe/Kyiv')
        now_dt = datetime.now(tz)
        today_str = now_dt.strftime('%Y-%m-%d')
        week_cut = now_dt - timedelta(days=7)
        today_start = tz.localize(datetime.strptime(today_str, '%Y-%m-%d')).timestamp()
        week_start_ts = week_cut.timestamp()
        with _visits_db_conn() as conn:
            cur_day = conn.execute("SELECT id FROM visits WHERE last_seen >= ?", (today_start,))
            day_ids = [r[0] for r in cur_day.fetchall()]
            cur_week = conn.execute("SELECT id FROM visits WHERE last_seen >= ?", (week_start_ts,))
            week_ids = [r[0] for r in cur_week.fetchall()]
        need_seed = False
        # Conditions to trigger seeding: empty/missing file, day mismatch, or counts smaller than SQL (lost state)
        if not data:
            need_seed = True
        else:
            if data.get('day') != today_str:
                need_seed = True
            elif len(set(data.get('today_ids', []))) < len(day_ids):
                need_seed = True
            elif len(set(data.get('week_ids', []))) < len(week_ids):
                need_seed = True
        if need_seed:
            data = {
                'day': today_str,
                'today_ids': list(dict.fromkeys(day_ids)),  # preserve order unique
                'week_ids': list(dict.fromkeys(week_ids)),
                'week_start': week_cut.strftime('%Y-%m-%d')  # informational; rolling window logic tolerates
            }
            _save_recent_visits(data)
            log.info(f"recent visits seeded from SQL: day={len(day_ids)} week={len(week_ids)}")
        _RECENT_SEEDED = True
    except Exception as e:
        log.warning(f"recent visits seeding failed: {e}")

def init_visits_db():
    try:
        with _visits_db_conn() as conn:
            conn.execute("CREATE TABLE IF NOT EXISTS visits (id TEXT PRIMARY KEY, ip TEXT, first_seen REAL, last_seen REAL)")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_visits_first ON visits(first_seen)")
            # Helpful for fast lookups of currently active users by recent activity window
            conn.execute("CREATE INDEX IF NOT EXISTS idx_visits_last ON visits(last_seen)")
            # Add ip column if missing (for existing databases)
            try:
                conn.execute("ALTER TABLE visits ADD COLUMN ip TEXT")
            except:
                pass  # Column already exists
    except Exception as e:
        log.warning(f"visits db init failed: {e}")

# --------------- Persistent comments (SQLite) ---------------
def init_comments_db():
    """Create comments table if missing. Uses same SQLite DB as visits for simplicity."""
    try:
        with _visits_db_conn() as conn:
            conn.execute("""
                CREATE TABLE IF NOT EXISTS comments (
                    id TEXT PRIMARY KEY,
                    text TEXT,
                    ts   TEXT,
                    epoch REAL
                )
            """)
            # Enhanced reactions table
            conn.execute("""
                CREATE TABLE IF NOT EXISTS comment_reactions (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    comment_id TEXT NOT NULL,
                    emoji TEXT NOT NULL,
                    user_ip TEXT NOT NULL,
                    timestamp REAL NOT NULL,
                    UNIQUE(comment_id, emoji, user_ip)
                )
            """)
            # Migration: ensure reply_to column exists
            cur = conn.execute("PRAGMA table_info(comments)")
            cols = [r[1] for r in cur.fetchall()]
            if 'reply_to' not in cols:
                try:
                    conn.execute("ALTER TABLE comments ADD COLUMN reply_to TEXT")
                    log.info('comments table migrated: added reply_to column')
                except Exception as me:
                    log.warning(f'failed adding reply_to column: {me}')
            # Create indexes (individually wrapped)
            for idx_sql in [
                "CREATE INDEX IF NOT EXISTS idx_comments_epoch ON comments(epoch)",
                "CREATE INDEX IF NOT EXISTS idx_comments_reply ON comments(reply_to)",
                "CREATE INDEX IF NOT EXISTS idx_reactions_comment ON comment_reactions(comment_id)",
                "CREATE INDEX IF NOT EXISTS idx_reactions_user ON comment_reactions(user_ip)"
            ]:
                try:
                    conn.execute(idx_sql)
                except Exception as ie:
                    log.debug(f'index create skipped: {ie}')
    except Exception as e:
        log.warning(f"comments db init failed: {e}")

# --------------- Redirect pages tracking ---------------
def init_redirect_tracking_db():
    """Create redirect_visits table for tracking redirect page visits"""
    try:
        with _visits_db_conn() as conn:
            conn.execute("""
                CREATE TABLE IF NOT EXISTS redirect_visits (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    page_name TEXT NOT NULL,
                    user_ip TEXT,
                    user_agent TEXT,
                    timestamp REAL NOT NULL
                )
            """)
            conn.execute("CREATE INDEX IF NOT EXISTS idx_redirect_page ON redirect_visits(page_name)")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_redirect_timestamp ON redirect_visits(timestamp)")
            log.info("Redirect tracking database initialized")
    except Exception as e:
        log.warning(f"redirect tracking db init failed: {e}")

def track_redirect_visit(page_name, user_ip=None, user_agent=None):
    """Track a visit to a redirect page"""
    try:
        with _visits_db_conn() as conn:
            conn.execute("""
                INSERT INTO redirect_visits (page_name, user_ip, user_agent, timestamp)
                VALUES (?, ?, ?, ?)
            """, (page_name, user_ip, user_agent, time.time()))
    except Exception as e:
        log.warning(f"Failed to track redirect visit: {e}")

def get_redirect_stats():
    """Get statistics for all redirect pages"""
    try:
        with _visits_db_conn() as conn:
            # Get total visits per page
            cur = conn.execute("""
                SELECT page_name, COUNT(*) as total_visits,
                       COUNT(DISTINCT user_ip) as unique_visitors,
                       MAX(timestamp) as last_visit
                FROM redirect_visits
                GROUP BY page_name
                ORDER BY total_visits DESC
            """)
            stats = {}
            for row in cur.fetchall():
                page_name, total, unique, last = row
                stats[page_name] = {
                    'total_visits': total,
                    'unique_visitors': unique,
                    'last_visit': datetime.fromtimestamp(last, tz=pytz.UTC).isoformat() if last else None
                }
            return stats
    except Exception as e:
        log.warning(f"Failed to get redirect stats: {e}")
        return {}

def save_comment_record(item:dict):
    try:
        with _visits_db_conn() as conn:
            conn.execute("INSERT OR REPLACE INTO comments (id,text,ts,epoch,reply_to) VALUES (?,?,?,?,?)",
                         (item.get('id'), item.get('text'), item.get('ts'), item.get('epoch'), item.get('reply_to')))
    except Exception as e:
        log.warning(f"save_comment_record failed: {e}")

def load_recent_comments(limit:int=80)->list[dict]:
    rows = []
    try:
        with _visits_db_conn() as conn:
            try:
                cur = conn.execute("SELECT id,text,ts,reply_to FROM comments ORDER BY epoch DESC LIMIT ?", (limit,))
                fetched = cur.fetchall()
            except Exception as sel_err:
                # Fallback legacy schema (no reply_to); try to migrate then retry
                log.warning(f'comments select fallback (legacy schema): {sel_err}')
                try:
                    conn.execute("ALTER TABLE comments ADD COLUMN reply_to TEXT")
                    cur = conn.execute("SELECT id,text,ts,reply_to FROM comments ORDER BY epoch DESC LIMIT ?", (limit,))
                    fetched = cur.fetchall()
                except Exception as mig_err:
                    log.warning(f'comments migration select failed: {mig_err}')
                    # Last resort: select without reply_to
                    try:
                        cur = conn.execute("SELECT id,text,ts FROM comments ORDER BY epoch DESC LIMIT ?", (limit,))
                        fetched = [(*r, None) for r in cur.fetchall()]
                    except Exception:
                        fetched = []
            for rid, text, ts, reply_to in fetched:
                d={'id': rid, 'text': text, 'ts': ts}
                if reply_to: d['reply_to']=reply_to
                
                # Load reactions for this comment
                try:
                    reactions = load_comment_reactions(rid, conn)
                    if reactions:
                        d['reactions'] = reactions
                except Exception:
                    pass  # Non-critical, skip reactions if failed
                
                rows.append(d)
    except Exception as e:
        log.warning(f"load_recent_comments failed: {e}")
    return list(reversed(rows))  # reverse so oldest of the slice first

def load_comment_reactions(comment_id: str, conn=None) -> dict:
    """Load reaction counts for a specific comment."""
    try:
        if conn:
            cur = conn.execute("""
                SELECT emoji, COUNT(*) as count 
                FROM comment_reactions 
                WHERE comment_id = ? 
                GROUP BY emoji
            """, (comment_id,))
            
            reactions = {}
            for emoji, count in cur.fetchall():
                reactions[emoji] = count
            return reactions
        else:
            with _visits_db_conn() as use_conn:
                cur = use_conn.execute("""
                    SELECT emoji, COUNT(*) as count 
                    FROM comment_reactions 
                    WHERE comment_id = ? 
                    GROUP BY emoji
                """, (comment_id,))
                
                reactions = {}
                for emoji, count in cur.fetchall():
                    reactions[emoji] = count
                return reactions
    except Exception as e:
        log.debug(f"load_comment_reactions failed: {e}")
        return {}

def toggle_comment_reaction(comment_id: str, emoji: str, user_ip: str) -> dict:
    """Toggle a reaction on a comment. Returns updated reaction counts."""
    try:
        with _visits_db_conn() as conn:
            # Check if reaction already exists
            cur = conn.execute("""
                SELECT id FROM comment_reactions 
                WHERE comment_id = ? AND emoji = ? AND user_ip = ?
            """, (comment_id, emoji, user_ip))
            
            existing = cur.fetchone()
            
            if existing:
                # Remove existing reaction
                conn.execute("DELETE FROM comment_reactions WHERE id = ?", (existing[0],))
                action = 'removed'
            else:
                # Add new reaction
                conn.execute("""
                    INSERT INTO comment_reactions (comment_id, emoji, user_ip, timestamp)
                    VALUES (?, ?, ?, ?)
                """, (comment_id, emoji, user_ip, time.time()))
                action = 'added'
            
            conn.commit()
            
            # Return updated counts
            reactions = load_comment_reactions(comment_id, conn)
            return {'action': action, 'reactions': reactions}
            
    except Exception as e:
        log.warning(f"toggle_comment_reaction failed: {e}")
        return {'action': 'error', 'reactions': {}}

def load_comment_reactions(comment_id: str, conn=None) -> dict:
    """Load reaction counts for a specific comment."""
    try:
        use_conn = conn
        if not use_conn:
            use_conn = _visits_db_conn()
            
        with use_conn as c:
            cur = c.execute("""
                SELECT emoji, COUNT(*) as count 
                FROM comment_reactions 
                WHERE comment_id = ? 
                GROUP BY emoji
            """, (comment_id,))
            
            reactions = {}
            for emoji, count in cur.fetchall():
                reactions[emoji] = count
            return reactions
    except Exception as e:
        log.debug(f"load_comment_reactions failed: {e}")
        return {}

def toggle_comment_reaction(comment_id: str, emoji: str, user_ip: str) -> dict:
    """Toggle a reaction on a comment. Returns updated reaction counts."""
    try:
        with _visits_db_conn() as conn:
            # Check if reaction already exists
            cur = conn.execute("""
                SELECT id FROM comment_reactions 
                WHERE comment_id = ? AND emoji = ? AND user_ip = ?
            """, (comment_id, emoji, user_ip))
            
            existing = cur.fetchone()
            
            if existing:
                # Remove existing reaction
                conn.execute("DELETE FROM comment_reactions WHERE id = ?", (existing[0],))
                action = 'removed'
            else:
                # Add new reaction
                conn.execute("""
                    INSERT INTO comment_reactions (comment_id, emoji, user_ip, timestamp)
                    VALUES (?, ?, ?, ?)
                """, (comment_id, emoji, user_ip, time.time()))
                action = 'added'
            
            conn.commit()
            
            # Return updated counts
            reactions = load_comment_reactions(comment_id, conn)
            return {'action': action, 'reactions': reactions}
            
    except Exception as e:
        log.warning(f"toggle_comment_reaction failed: {e}")
        return {'action': 'error', 'reactions': {}}

def record_visit_sql(id_:str, now_ts:float, ip_addr:str=None):
    if not id_:
        return
    try:
        with _visits_db_conn() as conn:
            # Use upsert pattern to avoid race between SELECT and INSERT under concurrent requests
            conn.execute("INSERT OR IGNORE INTO visits (id,ip,first_seen,last_seen) VALUES (?,?,?,?)", (id_, ip_addr, now_ts, now_ts))
            conn.execute("UPDATE visits SET last_seen=?, ip=? WHERE id=?", (now_ts, ip_addr, id_))
    except Exception as e:
        log.warning(f"record_visit_sql failed: {e}")

def sql_unique_counts():
    try:
        with _visits_db_conn() as conn:
            tz = pytz.timezone('Europe/Kyiv')
            now_dt = datetime.now(tz)
            today_start = tz.localize(datetime.strptime(now_dt.strftime('%Y-%m-%d'), '%Y-%m-%d'))
            week_start = now_dt - timedelta(days=7)
            today_ts = today_start.timestamp()
            week_ts = week_start.timestamp()
            cur1 = conn.execute("SELECT COUNT(*) FROM visits WHERE last_seen >= ?", (today_ts,))
            day = cur1.fetchone()[0]
            cur2 = conn.execute("SELECT COUNT(*) FROM visits WHERE last_seen >= ?", (week_ts,))
            week = cur2.fetchone()[0]
            return day, week
    except Exception as e:
        log.warning(f"sql_unique_counts failed: {e}")
    return None, None

def _active_sessions_from_db(ttl:int)->list[dict]:
    """Return list of active sessions (id, first_seen, last_seen) from persistent DB within ttl seconds."""
    cutoff = time.time() - ttl
    out = []
    try:
        with _visits_db_conn() as conn:
            cur = conn.execute("SELECT id, first_seen, last_seen FROM visits WHERE last_seen >= ?", (cutoff,))
            for row in cur.fetchall():
                try:
                    out.append({'id': row[0], 'first': float(row[1] or 0), 'last': float(row[2] or 0)})
                except Exception:
                    continue
    except Exception as e:
        log.warning(f"active sessions db query failed: {e}")
    return out

# Initialize DB at import
init_visits_db()
init_comments_db()
init_redirect_tracking_db()
init_alarms_db()
init_alarm_events_db()
# Restore persisted active alarms
try:
    _obl,_r = load_active_alarms(APP_ALARM_TTL_MINUTES*60)
    if _obl: ACTIVE_OBLAST_ALARMS.update(_obl)
    if _r: ACTIVE_RAION_ALARMS.update(_r)
except Exception as _e_rec:
    log.debug(f'alarm restore failed: {_e_rec}')
# Preload recent comments into in-memory cache so first GET can serve quickly without hitting DB again
try:
    COMMENTS = load_recent_comments(limit=COMMENTS_MAX)
except Exception as _e:
    log.debug(f'preload comments failed: {_e}')
GIT_SYNC_TOKEN = os.getenv('GIT_SYNC_TOKEN')  # GitHub PAT (classic or fine-grained) with repo write
GIT_COMMIT_INTERVAL = int(os.getenv('GIT_COMMIT_INTERVAL', '180'))  # seconds between commits
_last_git_commit = 0

# Delay before first Telegram connect (helps избежать пересечения старого и нового инстанса при деплое)
FETCH_START_DELAY = int(os.getenv('FETCH_START_DELAY', '0'))  # seconds

def maybe_git_autocommit():
    """If enabled, commit & push updated messages.json back to GitHub.
    Requirements:
      - Set GIT_AUTO_COMMIT=1
      - Provide GIT_REPO_SLUG (owner/repo)
      - Provide GIT_SYNC_TOKEN (PAT with repo write)
    The container build must include git (Render base images do).
    Commits throttled by GIT_COMMIT_INTERVAL seconds.
    """
    global _last_git_commit
    if not GIT_AUTO_COMMIT or not GIT_REPO_SLUG or not GIT_SYNC_TOKEN:
        return
    now = time.time()
    if now - _last_git_commit < GIT_COMMIT_INTERVAL:
        return
    if not os.path.isdir('.git'):
        raise RuntimeError('Not a git repo')
    # Configure user (once)
    def run(cmd):
        return subprocess.run(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
    run('git config user.email "bot@local"')
    run('git config user.name "Auto Sync Bot"')
    # Set remote URL embedding token (avoid logging token!)
    safe_remote = f'https://x-access-token:{GIT_SYNC_TOKEN}@github.com/{GIT_REPO_SLUG}.git'
    # Do not print safe_remote (contains secret)
    # Update origin only if needed
    remotes = run('git remote -v').stdout
    if 'origin' not in remotes or GIT_REPO_SLUG not in remotes:
        run('git remote remove origin')
        run(f'git remote add origin "{safe_remote}"')
    # Stage & commit if there is a change
    run(f'git add {MESSAGES_FILE}')
    status = run('git status --porcelain').stdout
    if MESSAGES_FILE not in status:
        return  # no actual diff
    commit_msg = f'Update {MESSAGES_FILE} (auto)'  # no secrets
    run(f'git commit -m "{commit_msg}"')
    push_res = run('git push origin HEAD:main')
    if push_res.returncode == 0:
        _last_git_commit = now
    else:
        # If push fails (e.g., diverged), attempt pull+rebase then push
        run('git fetch origin')
        run('git rebase origin/main || git rebase --abort')
        push_res2 = run('git push origin HEAD:main')
        if push_res2.returncode == 0:
            _last_git_commit = now
        # else: give up silently to avoid spamming logs

def _download_settlements():
    if not SETTLEMENTS_URL or os.path.exists(SETTLEMENTS_FILE):
        return False
    try:
        import requests
        r = requests.get(SETTLEMENTS_URL, timeout=30)
        if r.status_code == 200:
            with open(SETTLEMENTS_FILE, 'wb') as f:
                f.write(r.content)
            log.info(f'Downloaded settlements file from {SETTLEMENTS_URL}')
            return True
        else:
            log.warning(f'Failed to download settlements ({r.status_code}) from {SETTLEMENTS_URL}')
    except Exception as e:
        log.warning(f'Error downloading settlements: {e}')
    return False

def _load_settlements():
    global SETTLEMENTS_INDEX, SETTLEMENTS_ORDERED
    if not os.path.exists(SETTLEMENTS_FILE):
        _download_settlements()
    if not os.path.exists(SETTLEMENTS_FILE):
        log.info('No settlements file present; only basic CITY_COORDS will be used.')
        return
    try:
        with open(SETTLEMENTS_FILE, 'r', encoding='utf-8') as f:
            data = json.load(f)
        count = 0
        for item in data:
            if count >= SETTLEMENTS_MAX:
                break
            try:
                name = item.get('name') or item.get('n')
                if not name:
                    continue
                lat_raw = item.get('lat')
                lng_raw = item.get('lng') or item.get('lon')
                if lat_raw is None or lng_raw is None:
                    continue
                lat = float(lat_raw)
                lng = float(lng_raw)
                key = name.strip().lower()
                if key and key not in SETTLEMENTS_INDEX:
                    SETTLEMENTS_INDEX[key] = (lat, lng)
                    count += 1
            except Exception:
                continue
        SETTLEMENTS_ORDERED = sorted(SETTLEMENTS_INDEX.keys(), key=len, reverse=True)[:SETTLEMENTS_MAX]
        log.info(f'Loaded settlements: {len(SETTLEMENTS_INDEX)} (cap {SETTLEMENTS_MAX})')
    except Exception as e:
        log.warning(f'Failed to load settlements file {SETTLEMENTS_FILE}: {e}')

_load_settlements()

# ---- External comprehensive cities/settlements file merge (user-provided) ----
# You supplied an external file with full coordinates of Ukrainian cities / settlements.
# Set EXT_CITIES_FILE env var (default 'city_ukraine.json') and place the file in the app working directory.
# Accepted JSON shapes:
#   1) List[ { name|city|settlement: str, lat|latitude: float, lng|lon|long|longitude: float } ]
#   2) List[ [ name, lat, lon ] ]
#   3) Dict[str, { lat: x, lng: y }] or Dict[str, [lat, lon]]
# Fields may also appear in Ukrainian/Russian ("назва","широта","довгота","долгота").
EXT_CITIES_FILE = os.getenv('EXT_CITIES_FILE', 'city_ukraine.json')

def _load_external_cities():
    global CITY_COORDS, SETTLEMENTS_INDEX, SETTLEMENTS_ORDERED
    path = EXT_CITIES_FILE
    if not path or not os.path.exists(path):
        return
    try:
        with open(path, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except Exception as e:
        log.warning(f"Failed reading {path}: {e}")
        return
    added = 0
    def add_entry(name_raw, lat_raw, lon_raw):
        nonlocal added
        try:
            if name_raw is None: return
            name = str(name_raw).strip().lower()
            if not name or len(name) < 2: return
            lat = float(lat_raw); lon = float(lon_raw)
            # Basic sanity bounds for Ukraine region (approx) to skip corrupt rows
            if not (43.0 <= lat <= 53.5 and 21.0 <= lon <= 41.5):
                return
            if name not in CITY_COORDS:
                CITY_COORDS[name] = (lat, lon)
            if name not in SETTLEMENTS_INDEX:
                SETTLEMENTS_INDEX[name] = (lat, lon)
                added += 1
        except Exception:
            return
    if isinstance(data, dict):
        # Expect mapping name -> {lat,lng} or name -> [lat,lon]
        for k,v in data.items():
            if isinstance(v, dict):
                lat = v.get('lat') or v.get('latitude') or v.get('широта')
                lon = v.get('lng') or v.get('lon') or v.get('long') or v.get('longitude') or v.get('довгота') or v.get('долгота')
                add_entry(k, lat, lon)
            elif isinstance(v, (list, tuple)) and len(v) >= 2:
                add_entry(k, v[0], v[1])
    elif isinstance(data, list):
        for item in data:
            if isinstance(item, dict):
                name = item.get('name') or item.get('city') or item.get('settlement') or item.get('населенный пункт') or item.get('населений пункт') or item.get('назва')
                lat = item.get('lat') or item.get('latitude') or item.get('широта')
                lon = item.get('lng') or item.get('lon') or item.get('long') or item.get('longitude') or item.get('довгота') or item.get('долгота')
                add_entry(name, lat, lon)
            elif isinstance(item, (list, tuple)) and len(item) >= 3:
                add_entry(item[0], item[1], item[2])
    # Rebuild ordered list (largest names first to prefer longer multi-word matches)
    if added:
        try:
            SETTLEMENTS_ORDERED = sorted(SETTLEMENTS_INDEX.keys(), key=len, reverse=True)[:SETTLEMENTS_MAX]
        except Exception:
            pass
        log.info(f"Merged external cities file {path}: +{added} settlements (total {len(SETTLEMENTS_INDEX)})")
    else:
        log.info(f"External cities file {path} parsed; no new settlements added (maybe already present)")

_load_external_cities()

def geocode_opencage(place: str):
    if not OPENCAGE_API_KEY:
        return None
    
    # Skip if known negative
    if neg_geocode_check(place):
        return None
    
    # Block general directional terms that don't represent specific places
    place_lower = place.lower().strip()
    directional_terms = [
        'напрямок', 'напрям', 'направлении', 'направление',
        'північно-східний', 'північно-західний', 'південно-східний', 'південно-західний',
        'північний', 'південний', 'східний', 'західний',
        'nord', 'south', 'east', 'west', 'northeast', 'northwest', 'southeast', 'southwest'
    ]
    
    if any(term in place_lower for term in directional_terms):
        # Add to negative cache to avoid repeated attempts
        neg_geocode_add(place, 'directional')
        return None
    
    cache = _load_opencage_cache()
    key = place.strip().lower()
    now = int(datetime.utcnow().timestamp())
    if key in cache:
        entry = cache[key]
        if now - entry.get('ts', 0) < OPENCAGE_TTL:
            return tuple(entry['coords']) if entry['coords'] else None
    import requests
    try:
        resp = requests.get('https://api.opencagedata.com/geocode/v1/json', params={
            'q': place,
            'key': OPENCAGE_API_KEY,
            'language': 'uk',
            'limit': 1,
            'countrycode': 'ua'
        }, timeout=6)
        if resp.status_code == 200:
            data = resp.json()
            if data.get('results'):
                g = data['results'][0]['geometry']
                coords = (g['lat'], g['lng'])
                cache[key] = {'ts': now, 'coords': coords}
                _save_opencage_cache()
                return coords
        # negative (no results or non-200)
        cache[key] = {'ts': now, 'coords': None}
        _save_opencage_cache(); neg_geocode_add(place,'nocode')
        return None
    except Exception as e:
        log.warning(f"OpenCage error for '{place}': {e}")
        cache[key] = {'ts': now, 'coords': None}
        _save_opencage_cache(); neg_geocode_add(place,'error')
        return None

def calculate_projected_path(source_lat, source_lng, target_lat, target_lng, speed_kmh=50):
    """
    Calculate projected path from source to target with intermediate points
    
    Args:
        source_lat, source_lng: Current/source coordinates
        target_lat, target_lng: Target coordinates  
        speed_kmh: Estimated speed in km/h (default: 50 km/h for UAVs)
    
    Returns:
        dict with path_points, estimated_arrival, total_distance
    """
    try:
        # Calculate distance using Haversine formula
        R = 6371  # Earth's radius in km
        
        lat1_rad = math.radians(source_lat)
        lon1_rad = math.radians(source_lng)
        lat2_rad = math.radians(target_lat)
        lon2_rad = math.radians(target_lng)
        
        dlat = lat2_rad - lat1_rad
        dlon = lon2_rad - lon1_rad
        
        a = math.sin(dlat/2)**2 + math.cos(lat1_rad) * math.cos(lat2_rad) * math.sin(dlon/2)**2
        c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))
        distance_km = R * c
        
        # Calculate estimated travel time
        travel_time_hours = distance_km / speed_kmh
        travel_time_minutes = travel_time_hours * 60
        
        # Generate intermediate points along the path (every ~10km or 10 points max)
        num_points = min(10, max(2, int(distance_km / 10)))
        path_points = []
        
        for i in range(num_points + 1):
            fraction = i / num_points
            
            # Linear interpolation for simple path
            lat = source_lat + (target_lat - source_lat) * fraction
            lng = source_lng + (target_lng - source_lng) * fraction
            
            # Calculate ETA for this point
            point_travel_time = travel_time_minutes * fraction
            
            path_points.append({
                'lat': lat,
                'lng': lng,
                'eta_minutes': point_travel_time,
                'fraction': fraction
            })
        
        return {
            'path_points': path_points,
            'total_distance_km': distance_km,
            'estimated_arrival_minutes': travel_time_minutes,
            'speed_kmh': speed_kmh
        }
        
    except Exception as e:
        print(f"ERROR calculating projected path: {e}")
        return None

def create_eta_circles(center_lat, center_lng, time_minutes, speed_kmh=50):
    """
    Create ETA circles showing possible positions after given time
    
    Args:
        center_lat, center_lng: Center coordinates
        time_minutes: Time in minutes
        speed_kmh: Speed in km/h
        
    Returns:
        List of circle definitions for different confidence levels
    """
    try:
        # Calculate distance that can be covered in given time
        max_distance_km = (speed_kmh * time_minutes) / 60
        
        # Create circles with different confidence levels
        circles = []
        
        # 90% confidence circle (slightly smaller radius)
        circles.append({
            'center_lat': center_lat,
            'center_lng': center_lng,
            'radius_km': max_distance_km * 0.9,
            'confidence': 90,
            'color': '#ff4444',
            'opacity': 0.3,
            'stroke_color': '#cc0000',
            'stroke_width': 2
        })
        
        # 50% confidence circle (even smaller)
        circles.append({
            'center_lat': center_lat,
            'center_lng': center_lng,
            'radius_km': max_distance_km * 0.6,
            'confidence': 50,
            'color': '#ffaa00',
            'opacity': 0.4,
            'stroke_color': '#ff8800',
            'stroke_width': 2
        })
        
        return circles
        
    except Exception as e:
        print(f"ERROR creating ETA circles: {e}")
        return []

def _create_directional_trajectory_markers(text, mid, date_str, channel):
    """
    Create trajectory markers for directional movement messages
    Instead of showing destination marker, show projected path and ETA circles
    """
    import re
    from datetime import datetime, timedelta
    
    try:
        text_lower = text.lower()
        
        # Extract target city from directional patterns
        target_city = None
        source_direction = None
        
        # Patterns to extract target city
        target_patterns = [
            r'у напрямку\s+([а-яіїєґ\'\-\s]+?)(?:\s|$|з)',
            r'в напрямку\s+([а-яіїєґ\'\-\s]+?)(?:\s|$|з)',
            r'курс на\s+([а-яіїєґ\'\-\s]+?)(?:\s|$|з)',
            r'прямує до\s+([а-яіїєґ\'\-\s]+?)(?:\s|$|з)'
        ]
        
        for pattern in target_patterns:
            match = re.search(pattern, text_lower)
            if match:
                target_city = match.group(1).strip()
                break
        
        # Extract source direction
        direction_patterns = [
            r'з\s+(північного?-?сходу?)',
            r'з\s+(південного?-?заходу?)', 
            r'з\s+(північного?-?заходу?)',
            r'з\s+(південного?-?сходу?)',
            r'з\s+(півночі)',
            r'з\s+(півдня)',
            r'з\s+(заходу)',
            r'з\s+(сходу)'
        ]
        
        for pattern in direction_patterns:
            match = re.search(pattern, text_lower)
            if match:
                source_direction = match.group(1)
                break
        
        if not target_city:
            return []
        
        # Normalize target city name and get coordinates
        target_city_normalized = target_city.lower().strip()
        
        # Try to find coordinates for target city
        target_coords = None
        
        # Check in CITY_COORDS
        if target_city_normalized in CITY_COORDS:
            target_coords = CITY_COORDS[target_city_normalized]
        else:
            # Try common variations and declensions
            common_variations = {
                'дніпро': 'дніпро',
                'киев': 'київ', 
                'київа': 'київ',
                'харков': 'харків',
                'харкова': 'харків',
                'одесса': 'одеса',
                'одеси': 'одеса'
            }
            
            for variant, canonical in common_variations.items():
                if variant in target_city_normalized or target_city_normalized in variant:
                    if canonical in CITY_COORDS:
                        target_coords = CITY_COORDS[canonical]
                        break
            
            # If still not found, try removing common endings (declensions)
            if not target_coords:
                endings_to_try = ['а', 'у', 'ом', 'і', 'ів', 'ами']
                for ending in endings_to_try:
                    if target_city_normalized.endswith(ending) and len(target_city_normalized) > len(ending) + 2:
                        base_form = target_city_normalized[:-len(ending)]
                        # Special case for київ + а = києва -> київ  
                        if base_form + ending == 'києва':
                            base_form = 'київ'
                        if base_form in CITY_COORDS:
                            target_coords = CITY_COORDS[base_form]
                            break
        
        if not target_coords:
            # Fallback - return empty if we can't find target coordinates
            return []
        
        target_lat, target_lng = target_coords
        
        # Estimate source coordinates based on direction
        source_lat, source_lng = _estimate_source_coordinates(target_lat, target_lng, source_direction)
        
        # Create projected path
        projected_path = calculate_projected_path(source_lat, source_lng, target_lat, target_lng)
        
        if not projected_path:
            return []
        
        # Create trajectory markers
        markers = []
        
        # Add path markers (intermediate points)
        for i, point in enumerate(projected_path['path_points'][1:-1], 1):  # Skip first and last
            if i % 2 == 0:  # Only show every other point to avoid clutter
                continue
                
            markers.append({
                'id': f"{mid}_path_{i}",
                'place': f"Траєкторія ({int(point['eta_minutes'])}хв)",
                'lat': point['lat'],
                'lng': point['lng'],
                'threat_type': 'trajectory',
                'text': f"Проміжна точка маршруту до {target_city.title()}",
                'date': date_str,
                'channel': channel,
                'marker_icon': 'trajectory.png',
                'source_match': 'projected_path',
                'eta_minutes': point['eta_minutes'],
                'marker_type': 'trajectory_point',
                'opacity': 0.7
            })
        
        # Add ETA circles around target
        eta_circles = create_eta_circles(target_lat, target_lng, projected_path['estimated_arrival_minutes'])
        
        # Create main target marker with trajectory info
        markers.append({
            'id': f"{mid}_target",
            'place': f"{target_city.title()} (ціль)",
            'lat': target_lat,
            'lng': target_lng,
            'threat_type': 'trajectory_target',
            'text': f"Ціль: {target_city.title()} (ETA: {int(projected_path['estimated_arrival_minutes'])}хв)",
            'date': date_str,
            'channel': channel,
            'marker_icon': 'target.png',
            'source_match': 'trajectory_target',
            'eta_minutes': projected_path['estimated_arrival_minutes'],
            'distance_km': projected_path['total_distance_km'],
            'marker_type': 'trajectory_target',
            'eta_circles': eta_circles,
            'projected_path': projected_path['path_points']
        })
        
        return markers
        
    except Exception as e:
        print(f"ERROR creating directional trajectory markers: {e}")
        return []

def _estimate_source_coordinates(target_lat, target_lng, direction):
    """Estimate source coordinates based on target and direction"""
    
    # Default distance for estimation (50km)
    distance_km = 50
    
    # Direction offsets (approximate)
    direction_offsets = {
        'північного-сходу': (-0.45, 0.45),
        'південного-заходу': (0.45, -0.45),
        'північного-заходу': (-0.45, -0.45), 
        'південного-сходу': (0.45, 0.45),
        'півночі': (-0.45, 0),
        'півдня': (0.45, 0),
        'заходу': (0, -0.45),
        'сходу': (0, 0.45)
    }
    
    # Get offset or default to east
    lat_offset, lng_offset = direction_offsets.get(direction, (0, 0.45))
    
    # Apply offset (rough approximation: 1 degree ≈ 111km)
    source_lat = target_lat + lat_offset
    source_lng = target_lng + lng_offset
    
    return source_lat, source_lng

def process_message(text, mid, date_str, channel, _disable_multiline=False):  # type: ignore
    import re
    
    # Helper function to clean text from subscription prompts
    def clean_text(text_to_clean):
        if not text_to_clean:
            return text_to_clean
        import re as re_import
        cleaned = []
        for ln in text_to_clean.splitlines():
            ln2 = ln.strip()
            if not ln2:
                continue
            # Remove invisible/unicode spaces and normalize
            ln2 = re_import.sub(r'[\u200B-\u200D\uFEFF\u3164\u2060\u00A0\u1680\u180E\u2000-\u200F\u202A-\u202E\u2028\u2029\u205F\u3000]+', ' ', ln2)
            ln2 = ln2.strip()
            
            # Check if line ends with subscription text after meaningful content (including bold **text**)
            subscription_match = re_import.search(r'^(.+?)\s+[➡→>⬇⬆⬅⬌↗↘↙↖]\s*(\*\*)?підписатися(\*\*)?\s*$', ln2, re_import.IGNORECASE)
            if subscription_match:
                # Extract the part before the subscription text
                main_content = subscription_match.group(1).strip()
                if main_content and len(main_content) > 5:  # Only keep if meaningful content
                    cleaned.append(main_content)
                continue
                
            # remove any line that is ONLY a subscribe CTA (including bold)
            if re_import.search(r'^[➡→>⬇⬆⬅⬌↗↘↙↖]?\s*(\*\*)?підписатися(\*\*)?\s*$', ln2, re_import.IGNORECASE):
                continue
            
            # Remove URLs and links from text
            ln2 = re_import.sub(r'https?://[^\s]+', '', ln2)  # Remove http/https links
            ln2 = re_import.sub(r'www\.[^\s]+', '', ln2)      # Remove www links
            ln2 = re_import.sub(r't\.me/[^\s]+', '', ln2)     # Remove Telegram links
            ln2 = re_import.sub(r'@[a-zA-Z0-9_]+', '', ln2)  # Remove @mentions
            ln2 = re_import.sub(r'_+', '', ln2)  # Remove leftover underscores
            ln2 = re_import.sub(r'[✙✚]+[^✙✚]*✙[^✙✚]*✙', '', ln2)  # Remove ✙...✙ patterns
            
            # Remove card numbers and bank details
            ln2 = re_import.sub(r'\d{4}\s*\d{4}\s*\d{4}\s*\d{4}', '', ln2)  # Card numbers
            ln2 = re_import.sub(r'[—-]\s*Картка:', '', ln2)  # Card labels
            ln2 = re_import.sub(r'[—-]\s*Банка:', '', ln2)   # Bank labels
            ln2 = re_import.sub(r'[—-]\s*Конверт:', '', ln2) # Envelope labels
            
            # Clean up multiple spaces and trim
            ln2 = re_import.sub(r'\s+', ' ', ln2).strip()
            
            # Skip empty lines after cleaning
            if not ln2:
                continue
                
            cleaned.append(ln2)
        return '\n'.join(cleaned)
    
    # PRIORITY: Check for trajectory patterns FIRST (before any processing)
    # Pattern: "з [source_region] на [target_region(s)]" - trajectory, not multi-target
    trajectory_pattern = r'(\d+(?:-\d+)?)?\s*шахед[іївыиє]*\s+з\s+([а-яіїєґ]+(щин|ччин)[ауиі])\s+на\s+([а-яіїєґ/]+(щин|ччин)[ауиіу])'
    trajectory_match = re.search(trajectory_pattern, text.lower(), re.IGNORECASE)
    
    if trajectory_match:
        count_str = trajectory_match.group(1)
        source_region = trajectory_match.group(2)
        target_regions = trajectory_match.group(4)
        
        print(f"DEBUG: Trajectory detected - {count_str or ''}шахедів з {source_region} на {target_regions}")
        return []
    
    # EARLY FILTERS: Check for messages that should be completely filtered out
    def _is_russian_strategic_aviation(t: str) -> bool:
        """Suppress messages about Russian strategic aviation (Tu-95, etc.) from Russian airbases"""
        t_lower = t.lower()
        
        # Check for Russian strategic bombers
        russian_bombers = ['ту-95', 'tu-95', 'ту-160', 'tu-160', 'ту-22', 'tu-22']
        has_bomber = any(bomber in t_lower for bomber in russian_bombers)
        
        # Check for Russian airbases and regions
        russian_airbases = ['енгельс', 'engels', 'энгельс', 'саратов', 'рязань', 'муром', 'украінка', 'українка']
        has_russian_airbase = any(airbase in t_lower for airbase in russian_airbases)
        
        # Check for Russian regions/areas
        russian_regions = ['саратовській області', 'саратовской области', 'тульській області', 'рязанській області']
        has_russian_region = any(region in t_lower for region in russian_regions)
        
        # Check for terms indicating Russian territory/airbases
        russian_territory_terms = ['аеродрома', 'аэродрома', 'з аеродрому', 'с аэродрома', 'мета вильоту невідома', 'цель вылета неизвестна']
        has_russian_territory = any(term in t_lower for term in russian_territory_terms)
        
        # Check for generic relocation/transfer terms without specific threats
        relocation_terms = ['передислокація', 'передислокация', 'переліт', 'перелет', 'відмічено', 'отмечено']
        has_relocation = any(term in t_lower for term in relocation_terms)
        
        # Suppress if it's about Russian bombers from Russian territory
        if has_bomber and (has_russian_airbase or has_russian_territory or has_russian_region):
            return True
            
        # Suppress relocation/transfer messages between Russian airbases
        if has_relocation and has_bomber and (has_russian_airbase or has_russian_region):
            return True
            
        # Also suppress general strategic aviation reports without specific Ukrainian targets
        if ('борт' in t_lower or 'борти' in t_lower) and ('мета вильоту невідома' in t_lower or 'цель вылета неизвестна' in t_lower):
            return True
            
        return False

    def _is_general_warning_without_location(t: str) -> bool:
        """Suppress general warnings without specific locations or threat details"""
        t_lower = t.lower()
        
        # Check for general warning phrases
        warning_phrases = [
            'протягом ночі уважним бути',
            'протягом дня уважним бути', 
            'уважним бути',
            'загальне попередження',
            'общее предупреждение'
        ]
        has_general_warning = any(phrase in t_lower for phrase in warning_phrases)
        
        # Check for alert messages that should only be in events, not on map
        alert_phrases = [
            'відбій тривоги',
            'повітряна тривога',
            'відбой тревоги',
            'воздушная тревога'
        ]
        has_alert_message = any(phrase in t_lower for phrase in alert_phrases)
        
        # Suppress alert messages - they should only be in events
        if has_alert_message:
            return True
        
        # Check for tactical threat messages first - these should NEVER be filtered
        tactical_phrases = [
            'бпла',
            'крилаті ракети',
            'ракет',
            'ракета',
            'ракети',
            'загроза',
            'курсом на',
            'наближається',
            'повз',
            'поблизу',
            'напрямок',
            'напрямку',
            'у напрямку',
            'кв шахед',
            'шахед',
            'каб',
            'умп',
            'іскандер'
        ]
        has_tactical_info = any(phrase in t_lower for phrase in tactical_phrases)
        
        # Check for informational/historical messages that should be filtered
        # even if they contain tactical terms
        informational_phrases = [
            'пролетів',
            'відвернув',
            'здійснив посадку',
            'посадку на аеродром',
            'активність бортів',
            'буду оновлювати',
            'в разі додаткової інформації',
            'наразі це єдина',
            'фактична активність'
        ]
        has_informational_content = any(phrase in t_lower for phrase in informational_phrases)
        
        # Check if this is actually a current location message (not brief update)
        current_location_phrases = [
            'над',
            'в районі',
            'атакував',
            'вибухи в',
            'влучання в',
            'збито в',
            'знищено в',
            'на херсонщині',
            'на дніпропетровщині',
            'на запоріжжі',
            'на харківщині',
            'в області',
            'область',
            'щині'
        ]
        has_current_location = any(phrase in t_lower for phrase in current_location_phrases)
        
        # Check for count prefix (e.g., "16х БпЛА", "3х БпЛА") - these are real threats
        has_count_prefix = re.search(r'\d+\s*[xх]\s*бпла', t_lower)
        
        # If message has threat count or current location, do NOT filter it
        if has_count_prefix or has_current_location:
            return False
        
        # Check for general status messages that contain tactical terms but are informational
        status_phrases = [
            'український | ппошник',
            'український|ппошник',
            'поділ лук\'янівка'
        ]
        has_status_message = any(phrase in t_lower for phrase in status_phrases)
        
        # Check for route/location listing messages (format: "city — city1/city2 | region:")
        route_listing_pattern = r'київ.*—.*жуляни.*вишневе.*київ'
        has_route_listing = re.search(route_listing_pattern, t_lower, re.IGNORECASE)
        
        # Filter route listing messages as they are informational
        if has_route_listing:
            return True
        
        # If message is informational/historical, filter it out
        if has_informational_content:
            return True
            
        # If message is a general status update with tactical info, filter it out
        if has_status_message and has_tactical_info:
            return True
        
        # If message contains tactical information and is not informational, do NOT filter it
        if has_tactical_info:
            return False
        
        # Check for donation/fundraising messages (use more specific phrases)
        donation_phrases = [
            'підтримайте мене',
            'підтримати канал',
            'реквізити',
            'картка:',
            'банка:',
            'грн на каву',
            'на каву та енергетики',
            'по бажанню',
            'підтримка тільки',
            'monobank.ua',
            'privat24.ua',
            'send.monobank',
            'www.privat24',
            'донати',
            'донат',
            'дуже вдячний',
            'вдячний вам за підтримку',
            'за підтримку',
            'дякую за підтримку'
        ]
        has_donation_message = any(phrase in t_lower for phrase in donation_phrases)
        
        # Suppress donation messages
        if has_donation_message:
            return True
        
        # Check for channel promotion messages
        promotion_phrases = [
            'підтримати канал',
            'спасибо за подписку',
            'подписывайтесь',
            'наш канал',
            'наш телеграм'
        ]
        has_promotion_message = any(phrase in t_lower for phrase in promotion_phrases)
        
        # Suppress promotion messages
        if has_promotion_message:
            return True
        
        # Check for general informational messages without threats
        info_phrases = [
            'наразі це єдина',
            'фактична активність',
            'буду оновлювати',
            'в разі додаткової інформації',
            'здійснив посадку',
            'посадку на аеродром',
            'активність бортів'
        ]
        has_info_message = any(phrase in t_lower for phrase in info_phrases)
        
        # Suppress general info messages
        if has_info_message:
            return True
        
        # Check for very broad regions without specific cities
        broad_regions = [
            'києву, київщина і західна україна',
            'київ, київщина і західна україна', 
            'центр і північ', 
            'південь і схід'
        ]
        has_broad_region = any(region in t_lower for region in broad_regions)
        
        # Suppress if it's a general warning with broad regions
        if has_general_warning and has_broad_region:
            return True
            
        # Also suppress very short messages that are just general alerts
        if len(t.strip()) < 50 and has_general_warning:
            return True
            
        return False

    # Apply early filters
    if _is_russian_strategic_aviation(text):
        return []
        
    if _is_general_warning_without_location(text):
        return []
    
    # AI ENHANCEMENT: Fix typos and improve text quality before parsing
    if GEMINI_ENABLED:
        try:
            original_text = text
            text = fix_message_typos(text)
            if text != original_text:
                add_debug_log(f"AI: Fixed typos in message (length: {len(original_text)} -> {len(text)})", "ai_typo_fix")
        except Exception as e:
            add_debug_log(f"AI: Error fixing typos: {e}", "ai_error")
            # Continue with original text if AI fails
    
    # PRIORITY: Handle directional movement patterns (у напрямку, в направлении)
    # These should show trajectory/direction, not markers at destination
    def _is_directional_movement_message(t: str) -> bool:
        """Check if message describes movement towards a destination"""
        t_lower = t.lower()
        
        # Patterns indicating movement toward destination, not presence at location
        directional_patterns = [
            'у напрямку',
            'в напрямку', 
            'напрямок',
            'рухається в напрямку',
            'летить у напрямку',
            'курс на',
            'прямує до'
        ]
        
        # Additional context that suggests this is about movement, not current location
        movement_context = [
            'з північного-сходу',
            'з півдня',
            'з заходу',
            'з сходу',  
            'рухається',
            'летить',
            'прямує'
        ]
        
        has_directional = any(pattern in t_lower for pattern in directional_patterns)
        has_movement_context = any(context in t_lower for context in movement_context)
        
        return has_directional and has_movement_context
    
    # Handle directional movement messages - create projected path instead of filtering
    if _is_directional_movement_message(text):
        return _create_directional_trajectory_markers(text, mid, date_str, channel)
    
    # PRIORITY: Try SpaCy enhanced processing first
    if SPACY_AVAILABLE:
        try:
            spacy_results = spacy_enhanced_geocoding(text)
            if spacy_results:
                # Convert SpaCy results to the format expected by the rest of the system
                threat_markers = []
                
                # Process cities with coordinates first
                cities_with_coords = [city for city in spacy_results if city['coords']]
                
                for spacy_city in cities_with_coords:
                    lat, lng = spacy_city['coords']
                    
                    # Determine threat type using our classify function
                    threat_type, icon = classify(text, spacy_city['name'])
                    
                    # Create a proper place label
                    place_label = spacy_city['name'].title()
                    if spacy_city['region']:
                        place_label += f" [{spacy_city['region'].title()}]"
                    
                    marker = {
                        'id': f"{mid}_spacy_{len(threat_markers)+1}",
                        'place': place_label,
                        'lat': lat,
                        'lng': lng,
                        'threat_type': threat_type,
                        'text': clean_text(text)[:500],
                        'date': date_str,
                        'channel': channel,
                        'marker_icon': icon,
                        'source_match': f'spacy_{spacy_city["source"]}',
                        'count': 1,
                        'confidence': spacy_city['confidence']
                    }
                    threat_markers.append(marker)
                    
                    add_debug_log(f"SPACY: Created marker for {spacy_city['name']} -> {spacy_city['normalized']} "
                                f"(case: {spacy_city.get('case', 'unknown')}, confidence: {spacy_city['confidence']})", 
                                "spacy_integration")
                
                if threat_markers:
                    add_debug_log(f"SPACY: Successfully processed message with {len(threat_markers)} markers", "spacy_integration")
                    return threat_markers
                    
        except Exception as e:
            add_debug_log(f"SPACY: Error processing message: {e}", "spacy_integration")
            # Continue with fallback processing
    
    # FALLBACK: Original regex-based processing continues below
    
    # PRIORITY: Handle "[city] на [region]" patterns early to avoid misprocessing
    regional_city_match = re.search(r'(\d+)\s+шахед[а-яіїєёыийї]*\s+на\s+([а-яіїєё\'\-\s]+?)\s+на\s+([а-яіїє]+щині?)', text.lower()) if text else None
    if regional_city_match:
        count_str = regional_city_match.group(1)
        city_raw = regional_city_match.group(2).strip()
        region_raw = regional_city_match.group(3).strip()
        
        # Use context-aware resolution
        coords = ensure_city_coords_with_message_context(city_raw, text)
        if coords:
            lat, lng, approx = coords
            add_debug_log(f"PRIORITY: Regional city pattern - {city_raw} на {region_raw} -> ({lat}, {lng})", "priority_regional_city")
            
            result_entry = {
                'id': f"{mid}_priority_regional",
                'place': f"{city_raw.title()} на {region_raw.title()}",
                'lat': lat, 'lng': lng,
                'type': 'shahed', 'count': int(count_str),
                'timestamp': date_str, 'channel': channel
            }
            return [result_entry]
    
    # EARLY CHECK: General multi-line threat detection (before specific cases)
    if not _disable_multiline:
        text_lines = (text or '').split('\n')
        threat_lines = []
        
        # Track current oblast context from headers like "Полтавщина:", "Харківщина:"
        current_oblast = None
        oblast_header_pattern = re.compile(r'^([а-яіїєґ]+(?:щина|ська\s+обл(?:асть)?\.?)):?\s*$', re.IGNORECASE)
        # Pattern for inline oblast: "Сумщина: 2 шахеди на Лебедин"
        inline_oblast_pattern = re.compile(r'^([а-яіїєґ]+(?:щина|ська\s+обл(?:асть)?\.?)):\s+(.+)$', re.IGNORECASE)
        
        # Look for lines that contain threats with quantities and targets
        for line in text_lines:
            line_stripped = line.strip()
            if not line_stripped:
                continue
            
            # Check if this line has inline oblast format: "Область: threat text"
            inline_match = inline_oblast_pattern.match(line_stripped)
            if inline_match:
                oblast_name = inline_match.group(1).lower()
                threat_text = inline_match.group(2).strip()
                
                # Add the threat with oblast context
                enhanced_line = f"{oblast_name}: {threat_text}"
                threat_lines.append(enhanced_line)
                add_debug_log(f"MULTI-LINE: Detected inline oblast threat: {oblast_name} -> {threat_text[:50]}", "multi_line_inline_oblast")
                continue
            
            # Check if this line is a standalone oblast header
            oblast_match = oblast_header_pattern.match(line_stripped)
            if oblast_match:
                current_oblast = oblast_match.group(1).lower()
                add_debug_log(f"MULTI-LINE: Detected oblast header: {current_oblast}", "multi_line_oblast")
                continue
                
            line_lower = line_stripped.lower()
            
            # Check if line contains threat patterns with quantities and targets
            has_threat_pattern = (
                # Pattern: "Ціль на [target]" - target city for missiles/drones
                (re.search(r'ціль\s+на\s+([а-яіїєё\'\-\s]+)', line_lower, re.IGNORECASE)) or
                # Pattern: "N БпЛА на [region]щині" - regional threats like "16х БпЛА на Херсонщині"
                (re.search(r'\d+\s*[xх×]?\s*бпла\s+на\s+([а-яіїєё]+щині)', line_lower, re.IGNORECASE)) or
                # Pattern: "БпЛА на [direction] [region]" - regional directional threats
                (re.search(r'бпла\s+на\s+(півночі|півдні|сході|заході|північ|південь|схід|захід)\s+([а-яіїєё]+щин[іауи]?)', line_lower, re.IGNORECASE)) or
                # Pattern: "БпЛА ... з акваторії Чорного моря" - Black Sea threats
                (re.search(r'бпла.*?(з\s+акваторії|з\s+моря|з\s+чорного\s+моря)', line_lower, re.IGNORECASE)) or
                # Pattern: "N x/× БпЛА курсом на [target]"
                (re.search(r'\d+\s*[xх×]\s*бпла.*?(курс|на)\s+([а-яіїєё\'\-\s]+)', line_lower)) or
                # Pattern: "N шахедів/шахеди на [target]" - all forms of Shahed
                (re.search(r'\d+\s+шахед[а-яіїєёыийї]*\s+на\s+([а-яіїєё\'\-\s]+)', line_lower)) or
                # Pattern: "N шахедів/шахеди біля [target]" - near target
                (re.search(r'\d+\s+шахед[а-яіїєёыийї]*\s+біля\s+([а-яіїєё\'\-\s]+)', line_lower)) or
                # Pattern: "N шахед маневрує в районі [target]" - maneuvering in area
                (re.search(r'\d+\s+шахед[а-яіїєёыийї]*\s+маневру[юєї]+\s+в\s+район[іуи]\s+([а-яіїєё\'\-\s]+)', line_lower)) or
                # Pattern: "N ударних БпЛА на [target]"
                (re.search(r'\d+\s+ударн.*?бпла.*?на\s+([а-яіїєё\'\-\s]+)', line_lower)) or
                # Pattern: "N БпЛА на [target]" or "N бпла на [target]"  
                (re.search(r'\d+\s+бпла.*?на\s+([а-яіїєё\'\-\s]+)', line_lower)) or
                # Pattern: "БпЛА курсом на [target]" (without count)
                (re.search(r'бпла.*?курс.*?на\s+([а-яіїєё\'\-\s]+)', line_lower)) or
                # Pattern: "N шахедів через [target]" - via target  
                (re.search(r'\d+\s+шахед[а-яіїєёыийї]*\s+через\s+([а-яіїєё\'\-\s]+)', line_lower)) or
                # Pattern: "N шахедів з боку [target]" - from direction of target
                (re.search(r'\d+\s+шахед[а-яіїєёыийї]*\s+з\s+боку\s+([а-яіїєё\'\-\s]+)', line_lower))
            )
            
            if has_threat_pattern:
                # If we have oblast context, prepend it to the line
                if current_oblast:
                    # Add oblast context to help city resolution
                    enhanced_line = f"{current_oblast}: {line_stripped}"
                    threat_lines.append(enhanced_line)
                    add_debug_log(f"MULTI-LINE: Added threat with oblast context: {current_oblast} -> {line_stripped[:50]}", "multi_line_context")
                else:
                    threat_lines.append(line_stripped)
        
        # If we have multiple threat lines, process them separately
        if len(threat_lines) >= 2:
            add_debug_log(f"MULTI-LINE THREAT PROCESSING: {len(threat_lines)} threat lines detected", "multi_line_threats")
            
            all_tracks = []
            for i, line in enumerate(threat_lines):
                if not line.strip():
                    continue
                    
                add_debug_log(f"Processing threat line {i+1}: {line[:100]}", "threat_line")
                
                # Process each line as a separate message with multiline disabled
                line_result = process_message(line.strip(), f"{mid}_threat_{i+1}", date_str, channel, _disable_multiline=True)
                if line_result and isinstance(line_result, list):
                    all_tracks.extend(line_result)
                    add_debug_log(f"Threat line {i+1} produced {len(line_result)} tracks", "threat_line_result")
                else:
                    add_debug_log(f"Threat line {i+1} produced no tracks", "threat_line_result")
            
            if all_tracks:
                add_debug_log(f"Multi-line threat processing complete: {len(all_tracks)} total tracks", "multi_line_threats_complete")
                return all_tracks
    
    # PRIORITY FIRST: All air alarm messages should be list-only (no map markers)
    # This must be checked BEFORE any other processing to prevent other logic from creating markers
    original_text = text or ''
    low_orig = original_text.lower()
    
    # Clear any previous priority result
    globals()['_current_priority_result'] = None
    
    # PRIORITY CHECK: Black Sea aquatory - must check BEFORE multi-regional processing
    # Messages like "БпЛА курсом на Миколаїв з акваторії Чорного моря" or "15 шахедів з моря на Ізмаїл" should NOT place markers on cities
    lower_text = original_text.lower()
    # Check for Black Sea references: акваторія OR "з моря" OR "з чорного моря"
    is_black_sea = (('акватор' in lower_text or 'акваторії' in lower_text) and ('чорного моря' in lower_text or 'чорне море' in lower_text or 'чорному морі' in lower_text)) or \
                   ('з моря' in lower_text and ('курс' in lower_text or 'на ' in lower_text)) or \
                   ('з чорного моря' in lower_text)
    
    if is_black_sea:
        # Extract target region/direction if mentioned
        m_target = re.search(r'курс(?:ом)?\s+на\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-]{3,})', lower_text)
        m_direction = re.search(r'на\s+(північ|південь|схід|захід|північний\s+схід|північний\s+захід|південний\s+схід|південний\s+захід)', lower_text)
        m_region = re.search(r'(одещин|одеськ|миколаїв|херсон)', lower_text)
        
        target_info = None
        sea_lat, sea_lng = 45.3, 30.7  # Default: northern Black Sea central coords
        
        # Adjust position based on direction/region
        if m_direction:
            direction = m_direction.group(1)
            if 'південь' in direction:
                sea_lat = 45.0  # Further south
            elif 'північ' in direction:
                sea_lat = 45.6  # Further north
            if 'схід' in direction:
                sea_lng = 31.2  # Further east
            elif 'захід' in direction:
                sea_lng = 30.2  # Further west
        
        if m_region:
            region_name = m_region.group(1)
            if 'одещин' in region_name or 'одеськ' in region_name:
                # South of Odesa region - in the sea 50km offshore
                sea_lat, sea_lng = 45.7, 30.7
                target_info = 'Одещини'
            elif 'миколаїв' in region_name:
                sea_lat, sea_lng = 45.9, 31.4
                target_info = 'Миколаївщини'
            elif 'херсон' in region_name:
                sea_lat, sea_lng = 45.7, 32.5
                target_info = 'Херсонщини'
        
        if m_target:
            tc = m_target.group(1).lower()
            tc = UA_CITY_NORMALIZE.get(tc, tc)
            target_info = tc.title()
        
        threat_type, icon = classify(original_text)
        place_label = 'Акваторія Чорного моря'
        if target_info:
            place_label += f' (на {target_info})'
        
        # Try to find target city coordinates for trajectory
        target_coords = None
        if m_target:
            tc_normalized = m_target.group(1).lower()
            tc_normalized = UA_CITY_NORMALIZE.get(tc_normalized, tc_normalized)
            if tc_normalized in CITY_COORDS:
                target_coords = CITY_COORDS[tc_normalized]
        
        result = {
            'id': str(mid), 'place': place_label, 'lat': sea_lat, 'lng': sea_lng,
            'threat_type': threat_type, 'text': original_text[:500], 'date': date_str, 'channel': channel,
            'marker_icon': icon, 'source_match': 'black_sea_course_priority'
        }
        
        # Add trajectory data if we have target coordinates
        if target_coords:
            result['trajectory'] = {
                'start': [sea_lat, sea_lng],
                'end': list(target_coords),
                'target': target_info
            }
        
        return [result]
    
    # IMMEDIATE CHECK: Multi-regional UAV messages (highest priority)
    text_lines = original_text.split('\n')
    region_count = sum(1 for line in text_lines if any(region in line.lower() for region in ['щина:', 'щина]', 'область:', 'край:']) or (
        'щина' in line.lower() and line.lower().strip().endswith(':')
    ) or any(region in line.lower() for region in ['щина)', 'щини', 'щину', 'одещина', 'чернігівщина', 'дніпропетровщина', 'харківщина', 'київщина']))
    # Look for lines with emoji + UAV mentions (more flexible detection)
    uav_lines = [line for line in text_lines if 'бпла' in line.lower() and ('🛵' in line or '🛸' in line)]
    uav_count = len(uav_lines)
    
    # NEW: Look for lines with Shahed mentions and regions (without emoji requirement)
    shahed_region_lines = [line for line in text_lines if 
                          ('шахед' in line.lower() or 'shahed' in line.lower()) and 
                          ('щина' in line.lower() or 'щину' in line.lower() or 'щині' in line.lower())]
    shahed_count = len(shahed_region_lines)
    
    # NEW: Check for multiple regional aviation/БПЛА threats in one message
    # Pattern: "🛫 Донеччина та Дніпропетровщина - загроза застосування авіаційних засобів ураження. 🛵 Харківщина - загроза застосування ударних БпЛА"
    aviation_threat_lines = []
    for line in text_lines:
        line_lower = line.lower().strip()
        if not line_lower:
            continue
        # Check if line contains region + aviation/БПЛА threat
        has_region = any(region in line_lower for region in ['щина', 'область'])
        has_aviation = any(pattern in line_lower for pattern in ['авіаційних засобів', 'авіації', 'тактична авіація'])
        has_bpla = 'бпла' in line_lower or 'безпілотн' in line_lower
        
        if has_region and (has_aviation or has_bpla):
            aviation_threat_lines.append(line)
    
    aviation_threat_count = len(aviation_threat_lines)
    
    add_debug_log(f"DEBUG COUNT CHECK: {region_count} regions, {uav_count} UAV lines, {shahed_count} Shahed+region lines, {aviation_threat_count} aviation threat lines", "count_check")
    
    # Process multiple regional aviation threats
    if aviation_threat_count >= 1:
        add_debug_log(f"MULTI-REGIONAL AVIATION THREATS: {aviation_threat_count} lines detected", "multi_aviation")
        
        all_tracks = []
        
        # Regional aviation coordinates mapping (Black Sea / oblast centers)
        region_aviation_coords = {
            'одещина': (46.373528, 31.284023),  # Black Sea near Odesa
            'одесщина': (46.373528, 31.284023),
            'донеччина': (48.5, 37.8),  # Donetsk oblast center
            'дніпропетровщина': (48.45, 35.0),  # Dnipro
            'харківщина': (49.9935, 36.2304),  # Kharkiv
            'луганщина': (48.567, 39.317),  # Luhansk oblast
            'запорожжя': (47.8388, 35.1396),  # Zaporizhzhia
            'херсонщина': (46.6354, 32.6169),  # Kherson
            'миколаївщина': (46.975, 32.0),  # Mykolaiv oblast
        }
        
        for line in aviation_threat_lines:
            line_stripped = line.strip()
            line_lower = line_stripped.lower()
            
            # Split by emoji or sentence patterns to separate different threats
            # Pattern: "🛫 Region - threat. 🛵 Region - threat"
            import re
            
            # Split by emoji patterns or full stops followed by emoji
            segments = re.split(r'[\.\!]\s*(?=[🛫🛵🛸⚠️])|(?<=[🛫🛵🛸⚠️])\s+(?=[А-ЯІЇЄа-яіїє])', line_stripped)
            if len(segments) <= 1:
                # No clear segments, treat as one line
                segments = [line_stripped]
            
            for segment in segments:
                segment = segment.strip()
                if not segment or len(segment) < 10:
                    continue
                    
                segment_lower = segment.lower()
                
                # Extract all regions from this segment
                regions_found = re.findall(r'(одещина|одесщина|донеччина|дніпропетровщина|харківщина|луганщина|запорожжя|херсонщина|миколаївщина)', segment_lower)
                
                # Determine threat type from segment content
                is_aviation = any(pattern in segment_lower for pattern in ['авіаційних засобів', 'авіації', 'тактична авіація'])
                is_bpla = 'бпла' in segment_lower or 'безпілотн' in segment_lower
                is_strike_bpla = 'ударних бпла' in segment_lower or 'ударних безпілотн' in segment_lower
                
                threat_type = 'avia' if is_aviation else ('shahed' if is_bpla else 'artillery')
                icon = 'avia.png' if is_aviation else ('shahed.png' if is_bpla else 'artillery.png')
                threat_label = 'Авіація' if is_aviation else ('Ударні БпЛА' if is_strike_bpla else 'БпЛА')
                
                # Create marker for each region mentioned in this segment
                for region in regions_found:
                    if region in region_aviation_coords:
                        coords = region_aviation_coords[region]
                        lat, lng = coords
                        
                        region_display = region.title()
                        place_name = f"{threat_label} [{region_display}]"
                        
                        track = {
                            'id': f"{mid}_aviation_{region}_{len(all_tracks)}",
                            'place': place_name,
                            'lat': lat,
                            'lng': lng,
                            'threat_type': threat_type,
                            'text': segment[:500],
                            'date': date_str,
                            'channel': channel,
                            'marker_icon': icon,
                            'source_match': 'multi_regional_aviation',
                            'count': 1
                        }
                        
                        all_tracks.append(track)
                        add_debug_log(f"Aviation threat: {place_name} at {coords} (segment: {segment[:50]})", "multi_aviation")
                    else:
                        add_debug_log(f"No coords for region: {region}", "multi_aviation")
        
        if all_tracks:
            add_debug_log(f"Multi-regional aviation processing complete: {len(all_tracks)} total tracks", "multi_aviation_complete")
            return all_tracks
    
    add_debug_log(f"DEBUG COUNT CHECK: {region_count} regions, {uav_count} UAV lines, {shahed_count} Shahed+region lines", "count_check")
    
    # If we have multiple Shahed lines with regions, process them separately
    if shahed_count >= 2:
        add_debug_log(f"MULTI-LINE SHAHED PROCESSING: {shahed_count} Shahed+region lines detected", "multi_shahed")
        
        all_tracks = []
        for i, line in enumerate(shahed_region_lines):
            if not line.strip():
                continue
                
            add_debug_log(f"Processing Shahed line {i+1}: {line[:100]}", "shahed_line")
            
            # Process each line as a separate message
            line_result = process_message(line.strip(), f"{mid}_shahed_{i+1}", date_str, channel, _disable_multiline=True)
            if line_result and isinstance(line_result, list):
                all_tracks.extend(line_result)
                add_debug_log(f"Shahed line {i+1} produced {len(line_result)} tracks", "shahed_line_result")
            else:
                add_debug_log(f"Shahed line {i+1} produced no tracks", "shahed_line_result")
        
        if all_tracks:
            add_debug_log(f"Multi-line Shahed processing complete: {len(all_tracks)} total tracks", "multi_shahed_complete")
            return all_tracks
    
    # If we have multiple UAV lines with emojis, process them separately even if they don't have explicit regions
    if uav_count >= 2 and (region_count >= 1 or any('району' in line.lower() or 'області' in line.lower() or 'обл.' in line.lower() for line in uav_lines)):
        add_debug_log(f"MULTI-LINE UAV PROCESSING: {uav_count} UAV lines detected", "multi_uav")
        
        all_tracks = []
        for i, line in enumerate(uav_lines):
            if not line.strip():
                continue
                
            add_debug_log(f"Processing UAV line {i+1}: {line[:100]}", "uav_line")
            
            # Process each line as a separate message
            line_result = process_message(line.strip(), f"{mid}_line_{i+1}", date_str, channel, _disable_multiline=True)
            if line_result and isinstance(line_result, list):
                all_tracks.extend(line_result)
                add_debug_log(f"Line {i+1} produced {len(line_result)} tracks", "uav_line_result")
            else:
                add_debug_log(f"Line {i+1} produced no tracks", "uav_line_result")
        
        if all_tracks:
            add_debug_log(f"Multi-line UAV processing complete: {len(all_tracks)} total tracks", "multi_uav_complete")
            return all_tracks
    
    # Legacy multi-regional detection (keep for backward compatibility)
    if region_count >= 2 and sum(1 for line in text_lines if 'бпла' in line.lower() and ('курс' in line.lower() or 'на ' in line.lower())) >= 3:
        add_debug_log(f"IMMEDIATE MULTI-REGIONAL UAV: {region_count} regions, {uav_count} UAVs - ENTERING EARLY PROCESSING", "multi_regional")
        # Process directly without going through other logic
        import re
        
        # Define essential functions inline for immediate processing
        def get_city_coords_quick(city_name, region_hint=None):
            """Quick coordinate lookup with accusative case normalization and regional context"""
            city_norm = city_name.strip().lower()
            
            # Handle specific multi-word cities in accusative case
            if city_norm == 'велику димерку':
                city_norm = 'велика димерка'
            elif city_norm == 'велику виску':
                city_norm = 'велика виска'
            elif city_norm == 'мену':
                city_norm = 'мена'
            elif city_norm == 'пісківку':
                city_norm = 'пісківка'
            elif city_norm == 'новгород-сіверський':
                city_norm = 'новгород-сіверський'
            elif city_norm == 'києвом':
                city_norm = 'київ'
            
            # General accusative case endings (винительный падеж)
            elif city_norm.endswith('у') and len(city_norm) > 3:
                city_norm = city_norm[:-1] + 'а'
            elif city_norm.endswith('ю') and len(city_norm) > 3:
                city_norm = city_norm[:-1] + 'я'
            elif city_norm.endswith('ку') and len(city_norm) > 4:
                city_norm = city_norm[:-2] + 'ка'
            
            # Apply UA_CITY_NORMALIZE rules
            if city_norm in UA_CITY_NORMALIZE:
                city_norm = UA_CITY_NORMALIZE[city_norm]
            
            # Use ONLY API geocoding with message context - NO CITY_COORDS fallback
            coords = ensure_city_coords_with_message_context(city_norm, text)
            
            add_debug_log(f"API-only lookup: '{city_name}' -> '{city_norm}' -> {coords}", "multi_regional")
            return coords
        
        threats = []
        processed_cities = set()  # Избегаем дубликатов
        
        for line in text_lines:
            line_stripped = line.strip()
            if not line_stripped or ':' in line_stripped[:20]:  # Skip region headers
                continue
            
            line_lower = line_stripped.lower()
            
            # PRIORITY: Handle "напрямок м.X" or "напрямок на X" pattern first
            napryamok_match = re.search(r'напрямок\s+(?:м\.|місто|на)?\s*([а-яїієґ\-]+)', line_lower)
            if napryamok_match:
                target_city = napryamok_match.group(1).strip()
                target_norm = target_city
                if target_norm.endswith('у') and len(target_norm) > 3:
                    target_norm = target_norm[:-1] + 'а'
                elif target_norm.endswith('ку') and len(target_norm) > 4:
                    target_norm = target_norm[:-2] + 'ка'
                if target_norm in UA_CITY_NORMALIZE:
                    target_norm = UA_CITY_NORMALIZE[target_norm]
                
                # Get coordinates using full message context
                target_coords = ensure_city_coords_with_message_context(target_norm, text)
                
                if target_coords:
                    if len(target_coords) == 3:
                        lat, lng, approx = target_coords
                    else:
                        lat, lng = target_coords[:2]
                    
                    # Check if not already processed
                    city_key = target_norm
                    if city_key not in processed_cities:
                        processed_cities.add(city_key)
                        
                        uav_count = 1
                        # Try to extract UAV count from line
                        count_match = re.search(r'(\d+)\s*[xх×]?\s*бпла', line_lower)
                        if count_match:
                            uav_count = int(count_match.group(1))
                        
                        threat_id = f"{mid}_napryamok_{len(threats)}"
                        threats.append({
                            'id': threat_id,
                            'place': target_norm.title(),
                            'lat': lat,
                            'lng': lng,
                            'threat_type': 'shahed',
                            'text': f"Напрямок → {target_norm.title()}",
                            'date': date_str,
                            'channel': channel,
                            'marker_icon': 'shahed.png',
                            'source_match': 'immediate_napryamok',
                            'count': uav_count
                        })
                        
                        add_debug_log(f"Напрямок pattern: {target_norm} at {target_coords}", "napryamok")
                        continue  # Skip other processing for this line
            
            # Look for UAV course patterns
            if 'бпла' in line_lower and ('курс' in line_lower or ' на ' in line_lower or 'над' in line_lower or 'повз' in line_lower):
                # Extract city name from patterns - handle both plain text and markdown links
                patterns = [
                    # Pattern for markdown links: БпЛА курсом на [Бровари](link)
                    r'(\d+(?:-\d+)?)?[xх×]?\s*бпла\s+(?:курсом?)?\s*(?:на|над)\s+\[([А-ЯІЇЄЁа-яіїєёʼ\'\-\s]+?)\]',
                    # Pattern for plain text: БпЛА курсом на Конотоп (improved to capture multi-word cities + districts)
                    # Fixed: Added " з " and " район" to lookahead to properly capture "Миколаїв з акваторії" and "Покровський район"
                    r'(\d+(?:-\d+)?)?[xх×]?\s*бпла\s+.*?курс(?:ом)?\s+на\s+(?:н\.п\.?\s*)?([А-ЯІЇЄЁа-яіїєёʼ\'\-\s]+?(?:\s+район)?)(?=\s*(?:\n|$|[,\.\!\?;]|\s+з\s+|\s+\d+[xх×]?\s*бпла|\s+[А-ЯІЇЄЁа-яіїєё]+щина:|\s+\())',
                    # PRIORITY: Pattern for "повз ... курсом на" (e.g., "БпЛА повз Юріївку курсом на Павлоград")
                    # Must be BEFORE the simple "повз" pattern to capture both cities correctly
                    # Ignored for marker creation - handled separately below to create marker at bypass city with trajectory
                ]
                
                # SPECIAL HANDLING: "повз ... курсом на" pattern - create marker at bypass city with trajectory to target
                povz_course_match = re.search(r'(\d+(?:-\d+)?)?[xх×]?\s*бпла\s+повз\s+([А-ЯІЇЄЁа-яіїєёʼ\'\-\s]{3,50}?)\s+курсом?\s+на\s+([А-ЯІЇЄЁа-яіїєёʼ\'\-\s]{3,50}?)(?=\s*(?:\n|$|[,\.\!\?;]))', line_lower, re.IGNORECASE)
                if povz_course_match:
                    count_str, bypass_city_raw, target_city_raw = povz_course_match.groups()
                    
                    # Normalize bypass city name
                    bypass_city = bypass_city_raw.strip()
                    bypass_norm = bypass_city.lower()
                    if bypass_norm.endswith('у') and len(bypass_norm) > 3:
                        bypass_norm = bypass_norm[:-1] + 'а'
                    elif bypass_norm.endswith('ку') and len(bypass_norm) > 4:
                        bypass_norm = bypass_norm[:-2] + 'ка'
                    if bypass_norm in UA_CITY_NORMALIZE:
                        bypass_norm = UA_CITY_NORMALIZE[bypass_norm]
                    
                    # Normalize target city name
                    target_city = target_city_raw.strip()
                    target_norm = target_city.lower()
                    if target_norm.endswith('у') and len(target_norm) > 3:
                        target_norm = target_norm[:-1] + 'а'
                    elif target_norm.endswith('ку') and len(target_norm) > 4:
                        target_norm = target_norm[:-2] + 'ка'
                    if target_norm in UA_CITY_NORMALIZE:
                        target_norm = UA_CITY_NORMALIZE[target_norm]
                    
                    # Get coordinates for bypass city using full message context for better accuracy
                    bypass_coords = ensure_city_coords_with_message_context(bypass_norm, text)
                    
                    if bypass_coords:
                        if len(bypass_coords) == 3:
                            lat, lng, approx = bypass_coords
                        else:
                            lat, lng = bypass_coords
                        
                        uav_count = 1
                        if count_str and count_str.isdigit():
                            uav_count = int(count_str)
                        
                        # Create marker at bypass city with trajectory info
                        threat_id = f"{mid}_povz_course_{len(threats)}"
                        threats.append({
                            'id': threat_id,
                            'place': bypass_norm.title(),
                            'lat': lat,
                            'lng': lng,
                            'threat_type': 'shahed',
                            'text': f"Повз {bypass_norm.title()} → {target_norm.title()}",
                            'date': date_str,
                            'channel': channel,
                            'marker_icon': 'shahed.png',
                            'source_match': 'immediate_povz_course',
                            'count': uav_count,
                            'course_source': bypass_norm,
                            'course_target': target_norm
                        })
                        
                        add_debug_log(f"Повз курсом на: {bypass_norm} -> {target_norm} at {bypass_coords}", "povz_course")
                        continue  # Skip normal processing for this line
                
                # Normal patterns (after special handling)
                patterns.append(
                    # Pattern for "повз" without "курсом на" (e.g., "БпЛА повз Славутич в бік Білорусі")
                    r'(\d+(?:-\d+)?)?[xх×]?\s*бпла\s+(?:.*?)?повз\s+([А-ЯІЇЄЁа-яіїєёʼ\'\-\s]{3,50}?)(?=\s+(?:в\s+бік|до|на|через|$|[,\.\!\?;]))'
                )
                
                # Also check for bracket city pattern like "Вилково (Одещина)"
                bracket_matches = re.finditer(r'([А-ЯІЇЄЁа-яіїєё\'\-\s]{3,30})\s*\(([А-ЯІЇЄЁа-яіїєё\'\-\s]+щина|[А-ЯІЇЄЁа-яіїєё\'\-\s]+обл\.?)\)', line_stripped, re.IGNORECASE)
                for bmatch in bracket_matches:
                    city_clean = bmatch.group(1).strip()
                    region_info = bmatch.group(2).strip()
                    
                    city_normalized = city_clean.lower()
                    city_key = city_normalized
                    
                    # Skip if already processed
                    if city_key in processed_cities:
                        continue
                    processed_cities.add(city_key)
                    
                    # Try to get coordinates
                    coords = get_city_coords_quick(city_clean)
                    
                    if coords:
                        if len(coords) == 3:
                            lat, lng, approx = coords
                        else:
                            lat, lng = coords
                        
                        threat_id = f"{mid}_imm_bracket_{len(threats)}"
                        threats.append({
                            'id': threat_id,
                            'place': city_clean.title(),
                            'lat': lat,
                            'lng': lng,
                            'threat_type': 'shahed',
                            'text': f"{line_stripped} (bracket city)",
                            'date': date_str,
                            'channel': channel,
                            'marker_icon': 'shahed.png',
                            'source_match': 'immediate_multi_regional_bracket',
                            'count': 1
                        })
                        
                        add_debug_log(f"Immediate Multi-regional bracket: {city_clean} -> {coords}", "multi_regional")
                    else:
                        add_debug_log(f"Immediate Multi-regional bracket: No coords for {city_clean}", "multi_regional")
                
                for pattern in patterns:
                    matches = re.finditer(pattern, line_stripped, re.IGNORECASE)
                    for match in matches:
                        if len(match.groups()) == 2:
                            count_str, city_raw = match.groups()
                        else:
                            count_str = None
                            city_raw = match.group(1)
                        
                        if not city_raw:
                            continue
                            
                        # Clean city name (remove trailing spaces)
                        city_clean = city_raw.strip()
                        
                        # Normalize city name for coordinate lookup  
                        city_normalized = city_clean.lower()
                        
                        # Normalize for display (convert accusative to nominative)
                        city_display = city_clean
                        if city_normalized == 'велику димерку':
                            city_display = 'Велика Димерка'
                        elif city_normalized == 'велику виску':
                            city_display = 'Велика Виска'
                        elif city_normalized == 'мену':
                            city_display = 'Мена'
                        elif city_normalized == 'пісківку':
                            city_display = 'Пісківка'
                        elif city_normalized == 'києвом':
                            city_display = 'Київ'
                            city_normalized = 'київ'  # Also normalize for lookup
                        elif city_normalized.endswith('ом') and len(city_normalized) > 4:
                            # Handle other accusative masculine endings
                            city_display = city_normalized[:-2]
                            city_display = city_display.title()
                            city_normalized = city_normalized[:-2]
                        elif city_normalized.endswith('у') and len(city_normalized) > 3:
                            city_display = city_normalized[:-1] + 'а'
                            city_display = city_display.title()
                        elif city_normalized.endswith('ю') and len(city_normalized) > 3:
                            city_display = city_normalized[:-1] + 'я'
                            city_display = city_display.title()
                        elif city_normalized.endswith('ку') and len(city_normalized) > 4:
                            city_display = city_normalized[:-2] + 'ка'
                            city_display = city_display.title()
                        else:
                            city_display = city_clean.title()
                        
                        city_key = city_normalized
                        
                        # Skip if already processed
                        if city_key in processed_cities:
                            continue
                        processed_cities.add(city_key)
                        
                        # Try to get coordinates
                        coords = get_city_coords_quick(city_clean)
                        
                        if coords:
                            if len(coords) == 3:
                                lat, lng, approx = coords
                            else:
                                lat, lng = coords
                            
                            # Extract count if present
                            uav_count_num = 1
                            if count_str and count_str.isdigit():
                                uav_count_num = int(count_str)
                            
                            # Create multiple tracks for multiple drones
                            tracks_to_create = max(1, uav_count_num)
                            for i in range(tracks_to_create):
                                track_display_name = city_display
                                if tracks_to_create > 1:
                                    track_display_name += f" #{i+1}"
                                
                                # Add small coordinate offsets to prevent marker overlap
                                marker_lat = lat
                                marker_lng = lng
                                if tracks_to_create > 1:
                                    # Create a chain pattern - drones one after another
                                    offset_distance = 0.03  # ~3km offset between each drone
                                    marker_lat += offset_distance * i
                                    marker_lng += offset_distance * i * 0.5
                                
                                threat_id = f"{mid}_imm_multi_{len(threats)}"
                                threats.append({
                                    'id': threat_id,
                                    'place': track_display_name,  # Use numbered display name for multiple drones
                                    'lat': marker_lat,
                                    'lng': marker_lng,
                                    'threat_type': 'shahed',
                                    'text': f"{line_stripped} (мультирегіональне)",
                                    'date': date_str,
                                    'channel': channel,
                                    'marker_icon': 'shahed.png',
                                    'source_match': f'immediate_multi_regional_uav_{uav_count_num}x',
                                    'count': 1  # Each track represents 1 drone
                                })
                            
                            add_debug_log(f"Immediate Multi-regional: {city_clean} ({uav_count_num}x) -> {tracks_to_create} tracks at {coords}", "multi_regional")
                        else:
                            add_debug_log(f"Immediate Multi-regional: No coords for {city_clean}", "multi_regional")
        
        # Also check for regional UAV references without specific cities
        for line in text_lines:
            line_stripped = line.strip()
            if not line_stripped:
                continue
            line_lower = line_stripped.lower()
            
            # Look for UAV + region patterns without specific cities
            if 'бпла' in line_lower and any(region in line_lower for region in ['щини', 'щину', 'одещина', 'чернігівщина', 'дніпропетровщини']):
                # Skip if this specific line contains a city that was already processed
                line_has_processed_city = False
                for city in processed_cities:
                    if city in line_lower:
                        line_has_processed_city = True
                        break
                
                if line_has_processed_city:
                    continue
                
                # Special case: movement messages with direction in parentheses
                # Pattern: "БпЛА на півдні Чернігівщини, рухаються на південь (Київщина)"
                # Here (Київщина) indicates direction, not location
                directional_movement = re.search(r'на\s+([\w\-\s/]+?)\s+([а-яіїєґ]+щини|[а-яіїєґ]+щину|дніпропетровщини|одещини|чернігівщини).*рухаються.*\(([^)]+)\)', line_lower)
                if directional_movement:
                    direction = directional_movement.group(1).strip()
                    region_raw = directional_movement.group(2).strip()
                    target_direction = directional_movement.group(3).strip()
                    
                    # Map region to oblast center (current location, not target)
                    region_coords = None
                    if 'дніпропетров' in region_raw:
                        region_coords = (48.45, 35.0)
                        region_name = 'Дніпропетровщини'
                    elif 'чернігів' in region_raw:
                        region_coords = (51.4982, 31.3044)
                        region_name = 'Чернігівщини'
                    elif 'одес' in region_raw:
                        region_coords = (46.5197, 30.7495)
                        region_name = 'Одещини'
                    
                    if region_coords:
                        # Apply directional offset for current location
                        lat, lng = region_coords
                        if 'півдн' in direction or 'южн' in direction:
                            lat -= 0.5
                        elif 'північ' in direction or 'север' in direction:
                            lat += 0.5
                        elif 'захід' in direction or 'запад' in direction:
                            lng -= 0.8
                        elif 'схід' in direction or 'восток' in direction:
                            lng += 0.8
                        
                        direction_label = direction.replace('півдн', 'південн').replace('північ', 'північн')
                        place_name = f"{region_name} ({direction_label}а частина) → {target_direction}"
                        
                        threat_id = f"{mid}_imm_regional_movement_{len(threats)}"
                        threats.append({
                            'id': threat_id,
                            'place': place_name,
                            'lat': lat,
                            'lng': lng,
                            'threat_type': 'shahed',
                            'text': f"{line_stripped} (рух у напрямку {target_direction})",
                            'date': date_str,
                            'channel': channel,
                            'marker_icon': 'shahed.png',
                            'source_match': 'immediate_multi_regional_movement',
                            'count': 1,
                            'movement_target': target_direction
                        })
                        
                        add_debug_log(f"Immediate Multi-regional movement: {place_name} -> {lat}, {lng} (target: {target_direction})", "multi_regional")
                        continue
                
                # Check if this is a directional reference like "на півдні Дніпропетровщини"
                region_match = re.search(r'на\s+([\w\-\s/]+?)\s+([а-яіїєґ]+щини|[а-яіїєґ]+щину|дніпропетровщини|одещини|чернігівщини)', line_lower)
                if region_match:
                    direction = region_match.group(1).strip()
                    region_raw = region_match.group(2).strip()
                    
                    # Map region to oblast center
                    region_coords = None
                    if 'дніпропетров' in region_raw:
                        region_coords = (48.45, 35.0)
                        region_name = 'Дніпропетровщини'
                    elif 'чернігів' in region_raw:
                        region_coords = (51.4982, 31.3044)
                        region_name = 'Чернігівщини'
                    elif 'одес' in region_raw:
                        region_coords = (46.5197, 30.7495)
                        region_name = 'Одещини'
                    
                    if region_coords:
                        # Apply directional offset
                        lat, lng = region_coords
                        if 'півдн' in direction or 'южн' in direction:
                            lat -= 0.5
                        elif 'північ' in direction or 'север' in direction:
                            lat += 0.5
                        elif 'захід' in direction or 'запад' in direction:
                            lng -= 0.8
                        elif 'схід' in direction or 'восток' in direction:
                            lng += 0.8
                        
                        direction_label = direction.replace('півдн', 'південн').replace('північ', 'північн')
                        place_name = f"{region_name} ({direction_label}а частина)"
                        
                        threat_id = f"{mid}_imm_regional_{len(threats)}"
                        threats.append({
                            'id': threat_id,
                            'place': place_name,
                            'lat': lat,
                            'lng': lng,
                            'threat_type': 'shahed',
                            'text': f"{line_stripped} (регіональний)",
                            'date': date_str,
                            'channel': channel,
                            'marker_icon': 'shahed.png',
                            'source_match': 'immediate_multi_regional_region',
                            'count': 1
                        })
                        
                        add_debug_log(f"Immediate Multi-regional regional: {place_name} -> {lat}, {lng}", "multi_regional")
        
        if threats:
            add_debug_log(f"IMMEDIATE MULTI-REGIONAL RESULT: {len(threats)} threats", "multi_regional")
            return threats
    
    if 'повітряна тривога' in low_orig or 'тривога' in low_orig or 'тривог' in low_orig:
        # Always event-only record (list), never create map markers for air alarms or cancellations
        place = None
        low = low_orig.lower()
        # Try to extract oblast/region info for place
        for name in ['запорізька', 'одеська', 'миколаївська', 'херсонська', 'київська', 'львівська', 'харківська', 'дніпропетровська', 'чернігівська', 'сумська', 'полтавська', 'тернопільська', 'волинська', 'рівненська', 'житомирська', 'вінницька', 'закарпатська', 'івано-франківська', 'кіровоградська', 'черкаська', 'хмельницька', 'луганська', 'донецька']:
            if name in low:
                place = name.title() + ' Обл.'
                break
        
        # Also try to find city names
        if not place:
            for city in ['запоріжжя', 'одеса', 'миколаїв', 'херсон', 'київ', 'львів', 'харків', 'дніпро', 'чернігів', 'суми', 'полтава']:
                if city in low:
                    place = city.title()
                    break
        
        # Determine if this is alarm start or cancellation
        threat_type = 'alarm_cancel' if ('відбій' in low_orig or 'отбой' in low_orig) else 'alarm'
        icon = 'vidboi.png' if threat_type == 'alarm_cancel' else 'trivoga.png'
        
        # Clean subscription links from air alarm messages before returning
        import re as re_import
        cleaned_text = original_text
        if original_text:
            # remove lines containing subscription prompts
            cleaned = []
            for ln in original_text.splitlines():
                ln2 = ln.strip()
                if not ln2:
                    continue
                # remove any line that is just a subscribe CTA or starts with arrow+subscribe
                if re_import.search(r'(підписатись|підписатися|підписатися|подписаться|подпишись|subscribe)', ln2, re_import.IGNORECASE):
                    continue
                # remove arrow+subscribe pattern specifically
                if re_import.search(r'[➡→>]\s*підписатися', ln2, re_import.IGNORECASE):
                    continue
                cleaned.append(ln2)
            cleaned_text = '\n'.join(cleaned)
        
        return [{
            'id': str(mid), 'place': place, 'lat': None, 'lng': None,
            'threat_type': threat_type, 'text': cleaned_text[:500], 'date': date_str, 'channel': channel,
            'marker_icon': icon, 'list_only': True
        }]

    # Define classify function at the start so it's available throughout process_message
    def classify(th: str, city_context: str = ""):
        import re  # Import re module locally for pattern matching
        l = th.lower()
        
        # Add debug logging (temporarily disabled)
        # print(f"[CLASSIFY DEBUG] Input text: {th}")
        # print(f"[CLASSIFY DEBUG] Lowercase text: {l}")
        # print(f"[CLASSIFY DEBUG] City context: {city_context}")
        # print(f"[CLASSIFY DEBUG] Contains 🚀: {'🚀' in th}")
        # print(f"[CLASSIFY DEBUG] Contains 'ціль': {'ціль' in l}")
        # print(f"[CLASSIFY DEBUG] Contains 'високошвидкісн': {'високошвидкісн' in l}")
        # print(f"[CLASSIFY DEBUG] Contains 'бпла': {'бпла' in l}")
        
        # PRIORITY: Artillery shelling warning (обстріл / загроза обстрілу) -> use obstril.png
        # This should have priority over FPV cities when explicit shelling threat is mentioned
        if 'обстріл' in l or 'обстрел' in l or 'загроза обстрілу' in l or 'угроза обстрела' in l:
            # print(f"[CLASSIFY DEBUG] Classified as artillery")
            return 'artillery', 'obstril.png'
        
        # Special override for specific cities - Kherson, Nikopol, Marhanets always get FPV icon
        city_lower = city_context.lower() if city_context else ""
        fpv_cities = ['херсон', 'никополь', 'нікополь', 'марганець', 'марганец']
        
        # Check both city context and message text for FPV cities
        if any(fpv_city in city_lower for fpv_city in fpv_cities) or any(fpv_city in l for fpv_city in fpv_cities):
            return 'fpv', 'fpv.png'
        # Recon / розвід дрони -> use pvo icon (rozved.png) per user request - PRIORITY: check BEFORE general БПЛА
        if 'розвід' in l or 'розвідуваль' in l or 'развед' in l:
            return 'rozved', 'rozved.png'
        # PRIORITY: КАБы (управляемые авиационные бомбы) -> rszv.png - check BEFORE пуски to avoid misclassification
        if any(k in l for k in ['каб','kab','умпк','umpk','модуль','fab','умпб','фаб','кабу']) or \
           ('авіаційн' in l and 'бомб' in l) or ('керован' in l and 'бомб' in l):
            return 'kab', 'rszv.png'
        # Launch site detections for Shahed / UAV launches ("пуски" + origin phrases). User wants pusk.png marker.
        # Exclude КАБ launches - they should be classified as КАБ, not пуски
        if ('пуск' in l or 'пуски' in l) and (any(k in l for k in ['shahed','шахед','шахеді','шахедів','бпла','uav','дрон']) or ('аеродром' in l) or ('аэродром' in l)) and not any(k in l for k in ['каб','kab','умпк','fab','фаб']):
            return 'pusk', 'pusk.png'
        # Explicit launches from occupied Berdyansk airbase (Запорізька область) should also show as pusk (not avia)
        if ('пуск' in l or 'пуски' in l) and 'бердян' in l and ('авіабаз' in l or 'аеродром' in l or 'авиабаз' in l):
            return 'pusk', 'pusk.png'
        # Air alarm start
        if ('повітряна тривога' in l or 'повітряна тривога.' in l or ('тривога' in l and 'повітр' in l)) and not ('відбій' in l or 'отбой' in l):
            return 'alarm', 'trivoga.png'
        # Air alarm cancellation
        if ('відбій тривоги' in l) or ('отбой тревоги' in l):
            return 'alarm_cancel', 'vidboi.png'
        # Explosions reporting -> vibuh icon (cover broader fixation phrases)
        if ('повідомляють про вибух' in l or 'повідомлено про вибух' in l or 'зафіксовано вибух' in l or 'зафіксовано вибухи' in l
            or 'фіксація вибух' in l or 'фіксують вибух' in l or re.search(r'\b(вибух|вибухи|вибухів)\b', l)):
            return 'vibuh', 'vibuh.png'
        # Alarm cancellation (відбій тривоги / отбой тревоги)
        if ('відбій' in l and 'тривог' in l) or ('отбой' in l and 'тревог' in l):
            print(f"[CLASSIFY DEBUG] Classified as alarm_cancel")
            return 'alarm_cancel', 'vidboi.png'
        
        # PRIORITY: High-speed targets / missile threats with rocket emoji (🚀) -> raketa.png
        # This should have priority over drones to handle missile-like threats with rocket emoji
        if '🚀' in th or any(k in l for k in ['ціль','цілей','цілі','високошвидкісн','high-speed']):
            print(f"[CLASSIFY DEBUG] Classified as raketa (high-speed targets/rocket emoji)")
            return 'raketa', 'raketa.png'
            
        # PRIORITY: drones (частая путаница). Если присутствуют слова шахед/бпла/дрон -> это shahed
        if any(k in l for k in ['shahed','шахед','шахеді','шахедів','geran','герань','дрон','дрони','бпла','uav']):
            print(f"[CLASSIFY DEBUG] Classified as shahed (drones/UAV)")
            return 'shahed', 'shahed.png'
        # PRIORITY: Aircraft activity & tactical aviation (avia) -> avia.png (jets, tactical aviation, но БЕЗ КАБов)
        if any(k in l for k in ['літак','самол','avia','tactical','тактичн','fighter','истребит','jets']) or \
           ('авіаційн' in l and ('засоб' in l or 'ураж' in l)):
            return 'avia', 'avia.png'
        # Rocket / missile attacks (ракета, ракети) -> raketa.png
        if any(k in l for k in ['ракет','rocket','міжконтинент','межконтинент','балістичн','крилат','cruise']):
            return 'raketa', 'raketa.png'
        # РСЗВ (MLRS, град, ураган, смерч) -> rszv.png
        if any(k in l for k in ['рсзв','mlrs','град','ураган','смерч','рсув','tор','tорнадо','торнадо']):
            return 'rszv', 'rszv.png'
        # Korabel (naval/ship-related threats) -> korabel.png
        if any(k in l for k in ['корабел','флот','корабл','ship','fleet','морськ','naval']):
            return 'korabel', 'korabel.png'
        # Artillery
        if any(k in l for k in ['арт','artillery','гармат','гаубиц','минометн','howitzer']):
            return 'artillery', 'artillery.png'
        # PVO (air defense activity) -> pvo.png
        if any(k in l for k in ['ппо','pvo','defense','оборон','зенітн','с-','patriot']):
            return 'pvo', 'pvo.png'
        # Naval mines -> neptun
        if any(k in l for k in ['міна','мін ','mine','neptun','нептун','противокорабел']):
            return 'neptun', 'neptun.jpg'
        # FPV drones -> fpv.png
        if any(k in l for k in ['fpv','фпв','камікадз','kamikaze']):
            print(f"[CLASSIFY DEBUG] Classified as fpv")
            return 'fpv', 'fpv.png'
        
        # AI ENHANCEMENT: Try to classify using AI if no pattern matched
        if GEMINI_ENABLED:
            try:
                ai_threat = classify_threat_type(th)
                if ai_threat:
                    threat_icon_map = {
                        'shahed': 'shahed.png',
                        'cruise_missile': 'raketa.png',
                        'ballistic_missile': 'raketa.png',
                        'aviation': 'avia.png',
                        'artillery': 'obstril.png',
                        'fpv_drone': 'fpv.png',
                        'reconnaissance': 'rozved.png',
                        'kab': 'rszv.png',
                        'mlrs': 'rszv.png'
                    }
                    icon = threat_icon_map.get(ai_threat, 'shahed.png')
                    add_debug_log(f"AI: Classified threat as '{ai_threat}' -> {icon}", "ai_classify")
                    return ai_threat, icon
            except Exception as e:
                add_debug_log(f"AI: Error classifying threat: {e}", "ai_error")
        
        # General fallback for unclassified threats
        print(f"[CLASSIFY DEBUG] Using default fallback: shahed")
        return 'shahed', 'shahed.png'  # default fallback
    
    # PRIORITY CHECK: District-level UAV messages (e.g., "вишгородський р-н київська обл.")
    # Added after classify function to ensure it's available
    lower_text = original_text.lower()
    district_pattern = re.compile(r'([а-яіїєґ\'\-\s]+ський|[а-яіїєґ\'\-\s]+цький)\s+р[-\s]*н\s+([а-яіїєґ\'\-\s]+(?:обл\.?|область|щина))', re.IGNORECASE)
    district_match = district_pattern.search(lower_text)
    
    if district_match and 'бпла' in lower_text:
        district_raw = district_match.group(1).strip()
        region_raw = district_match.group(2).strip()
        
        add_debug_log(f"DISTRICT UAV: found '{district_raw} р-н {region_raw}'", "district_uav")
        
        # Try to map district to city coordinates
        district_city = district_raw.replace('ський', '').replace('цький', '').strip()
        
        # Check if we have coordinates for this district city
        coords = CITY_COORDS.get(district_city)
        if not coords and district_city in UA_CITY_NORMALIZE:
            coords = CITY_COORDS.get(UA_CITY_NORMALIZE[district_city])
        
        if coords:
            lat, lng = coords
            threat_type, icon = classify(original_text, district_city)
            
            # Create district-level marker
            district_track = {
                'id': f"{mid}_district",
                'place': f"{district_city.title()} ({district_raw} р-н)",
                'lat': lat,
                'lng': lng,
                'threat_type': threat_type,
                'text': original_text[:500],
                'date': date_str,
                'channel': channel,
                'marker_icon': icon,
                'source_match': 'district_priority_uav',
                'count': 1
            }
            
            add_debug_log(f"DISTRICT UAV SUCCESS: {district_city} -> {coords}", "district_uav")
            return [district_track]
        else:
            add_debug_log(f"DISTRICT UAV: No coords for '{district_city}'", "district_uav")
    
    # PRIORITY CHECK: Single-region numbered UAV lists (н.п. patterns)
    # For messages like "Київщина:\n• н.п. Бровари - постійна загроза БпЛА"
    lower_text = original_text.lower()
    text_lines = original_text.split('\n')
    
    # Check if this is a single-region message with numbered н.п. cities
    region_lines = [line for line in text_lines if any(region in line.lower() for region in ['щина:', 'щина]', 'область:']) and line.strip().endswith(':')]
    np_lines = [line for line in text_lines if ('н.п.' in line.lower() or 'н. п.' in line.lower()) and 'бпла' in line.lower()]
    
    if len(region_lines) == 1 and len(np_lines) >= 1:  # Single region with н.п. cities
        region_line = region_lines[0]
        region_name = region_line.replace(':', '').strip()
        
        add_debug_log(f"SINGLE-REGION NUMBERED: found {len(np_lines)} н.п. cities in {region_name}", "single_region_numbered")
        
        numbered_tracks = []
        for i, line in enumerate(np_lines):
            # Extract city name from н.п. pattern
            np_match = re.search(r'н\.?\s*п\.?\s+([а-яіїєґ\'\-\s]+)', line.lower())
            if np_match:
                city_name_raw = np_match.group(1).strip()
                # Clean up - take only the city name before any separators
                city_name = city_name_raw.split(' - ')[0].split(' –')[0].split(' ')[0].strip()
                
                # Try to find coordinates for this city
                coords = CITY_COORDS.get(city_name)
                if not coords and city_name in UA_CITY_NORMALIZE:
                    coords = CITY_COORDS.get(UA_CITY_NORMALIZE[city_name])
                
                if coords:
                    lat, lng = coords
                    threat_type, icon = classify(line, city_name)
                    
                    numbered_tracks.append({
                        'id': f"{mid}_np_{i+1}",
                        'place': f"{city_name.title()} ({region_name})",
                        'lat': lat,
                        'lng': lng,
                        'threat_type': threat_type,
                        'text': line[:500],
                        'date': date_str,
                        'channel': channel,
                        'marker_icon': icon,
                        'source_match': 'single_region_numbered_np',
                        'count': 1
                    })
                    add_debug_log(f"NUMBERED UAV SUCCESS: {city_name} -> {coords}", "single_region_numbered")
                else:
                    # Fallback to region coordinates if city not found
                    region_key = region_name.lower().replace('щина', '').replace('область', '').strip()
                    region_coords = CITY_COORDS.get(region_key)
                    if region_coords:
                        lat, lng = region_coords
                        threat_type, icon = classify(line)
                        
                        numbered_tracks.append({
                            'id': f"{mid}_np_fallback_{i+1}",
                            'place': f"{region_name} (н.п. {city_name.title()})",
                            'lat': lat,
                            'lng': lng,
                            'threat_type': threat_type,
                            'text': line[:500],
                            'date': date_str,
                            'channel': channel,
                            'marker_icon': icon,
                            'source_match': 'single_region_numbered_np_fallback',
                            'count': 1
                        })
                        add_debug_log(f"NUMBERED UAV FALLBACK: {city_name} -> {region_name} {region_coords}", "single_region_numbered")
        
        if numbered_tracks:
            add_debug_log(f"SINGLE-REGION NUMBERED SUCCESS: {len(numbered_tracks)} markers created", "single_region_numbered")
            return numbered_tracks

    # HIGHEST PRIORITY: Check for region-district patterns immediately
    import re as _re_priority
    region_district_pattern = _re_priority.compile(r'([а-яіїєґ]+щин[ауи]?)\s*\(\s*([а-яіїєґ\'\-\s]+)\s+р[-\s]*н\)', _re_priority.IGNORECASE)
    region_district_match = region_district_pattern.search(original_text)
    
    if region_district_match:
        region_raw, district_raw = region_district_match.groups()
        target_city = district_raw.strip()
        
        add_debug_log(f"PRIORITY REGION-DISTRICT pattern FOUND: region='{region_raw}', district='{district_raw}'", "priority_region_district")
        
        # Normalize city name and try to find coordinates via API
        city_norm = target_city.lower()
        # Apply UA_CITY_NORMALIZE rules if available
        if 'UA_CITY_NORMALIZE' in globals():
            city_norm = UA_CITY_NORMALIZE.get(city_norm, city_norm)
        
        # Use API geocoding with message context
        coords_result = ensure_city_coords_with_message_context(city_norm, original_text)
        coords = (coords_result[0], coords_result[1]) if coords_result else None
        
        add_debug_log(f"Priority district city API lookup: '{target_city}' -> '{city_norm}' -> {coords}", "priority_region_district")
        
        if coords:
            lat, lng = coords
            threat_type, icon = classify(original_text)
            
            priority_result = [{
                'id': f"{mid}_priority_district",
                'place': target_city.title(),
                'lat': lat,
                'lng': lng,
                'threat_type': threat_type,
                'text': original_text[:500],
                'date': date_str,
                'channel': channel,
                'marker_icon': icon,
                'source_match': 'priority_region_district',
                'count': 1
            }]
            add_debug_log(f"Created PRIORITY region-district marker: {target_city.title()}", "priority_region_district")
            
            # Store priority result globally for combination with other results
            globals()['_current_priority_result'] = priority_result
            
            # Store priority result and continue with normal processing to catch other cities
            # This allows other parsers to find additional cities in the same message
        else:
            add_debug_log(f"No coordinates found for priority district city: '{target_city}' (normalized: '{city_norm}')", "priority_region_district")
            priority_result = None
    else:
        priority_result = None

    # ВСЕГДА логируем каждое входящее сообщение для отладки
    try:
        add_debug_log(f"process_message called - mid={mid}, channel={channel}, text_length={len(text or '')}", "message_processing")
        add_debug_log(f"message text preview: {(text or '')[:200]}...", "message_processing")
        # Check if this is our test message
        if 'чернігівщина' in (text or '').lower() and 'сумщина' in (text or '').lower():
            add_debug_log("MULTI-REGION MESSAGE DETECTED!", "multi_region")
            add_debug_log(f"Full text: {text}", "multi_region")
    except Exception:
        pass

    # PRIORITY: Handle emoji + city + oblast format BEFORE any other processing
    try:
        import re  # Import re module for pattern matching
        head = text.split('\n', 1)[0][:160] if text else ""
        
        # Handle general emoji + city + oblast format with any UAV threat (more flexible pattern)
        general_emoji_pattern = r'^[^\w\s]*\s*([А-ЯІЇЄЁа-яіїєё\'\-\s]+)\s*\(([^)]*обл[^)]*)\)'
        general_emoji_match = re.search(general_emoji_pattern, head, re.IGNORECASE)
        add_debug_log(f"PRIORITY: Testing general emoji pattern on head: {repr(head)}", "emoji_debug")
        add_debug_log(f"PRIORITY: General emoji match result: {general_emoji_match}", "emoji_debug")
        
        if general_emoji_match and any(uav_word in text.lower() for uav_word in ['бпла', 'дрон', 'шахед', 'активність', 'загроза', 'тривога', 'обстріл', 'обстрел']):
            city_from_general = general_emoji_match.group(1).strip()
            oblast_from_general = general_emoji_match.group(2).strip()
            add_debug_log(f"PRIORITY: Found city: {repr(city_from_general)}, oblast: {repr(oblast_from_general)}", "emoji_debug")
            
            if city_from_general and 2 <= len(city_from_general) <= 40:
                base = city_from_general.lower().replace('\u02bc',"'").replace('ʼ',"'").replace("'","'").replace('`',"'")
                base = re.sub(r'\s+',' ', base)
                norm = UA_CITY_NORMALIZE.get(base, base)
                
                # First try to find city+oblast specific coordinates
                oblast_key = oblast_from_general.lower()
                coords = None
                
                # Try different lookup strategies for city+oblast disambiguation
                if 'сум' in oblast_key and norm == 'миколаївка':
                    coords = (51.5667, 34.1333)  # Миколаївка, Сумська область
                    add_debug_log(f"PRIORITY: Using specific coordinates for Миколаївка (Сумська обл.): {coords}", "emoji_debug")
                elif 'миколаївськ' in oblast_key and norm == 'миколаївка':
                    coords = (47.0667, 31.8333)  # Миколаївка, Миколаївська область
                    add_debug_log(f"PRIORITY: Using specific coordinates for Миколаївка (Миколаївська обл.): {coords}", "emoji_debug")
                # Handle districts by mapping to their administrative centers
                elif 'район' in norm:
                    if 'синельниківський район' in norm:
                        coords = CITY_COORDS.get('синельникове')  # Синельникове - центр району
                        add_debug_log(f"PRIORITY: Mapping Синельниківський район -> Синельникове: {coords}", "emoji_debug")
                    elif 'миколаївський район' in norm and 'миколаївськ' in oblast_key:
                        coords = CITY_COORDS.get('миколаїв')  # Миколаїв - центр району
                        add_debug_log(f"PRIORITY: Mapping Миколаївський район -> Миколаїв: {coords}", "emoji_debug")
                    # For other districts, try to find coordinates in DISTRICT_CENTERS first
                    else:
                        # Extract district name without 'район' suffix
                        district_name = norm.replace('район', '').strip()
                        district_coords = DISTRICT_CENTERS.get(district_name)
                        if district_coords:
                            coords = district_coords
                            add_debug_log(f"PRIORITY: Found district coordinates for '{district_name}': {coords}", "emoji_debug")
                
                if not coords:
                    # Fallback to general lookup
                    coords = CITY_COORDS.get(norm)
                    add_debug_log(f"PRIORITY: General lookup: base={repr(base)}, norm={repr(norm)}, coords={coords}", "emoji_debug")
                
                if not coords and 'SETTLEMENTS_INDEX' in globals():
                    idx_map = globals().get('SETTLEMENTS_INDEX') or {}
                    coords = idx_map.get(norm)
                if coords:
                    lat, lon = coords[:2]
                    
                    # Check for threat cancellation BEFORE creating marker
                    text_lower = text.lower()
                    if ('відбій загрози' in text_lower or 
                        'відбій тривоги' in text_lower or
                        ('відбій' in text_lower and any(cancel_word in text_lower for cancel_word in ['загрози', 'тривоги']))):
                        # This is a cancellation message - create list_only entry, no map marker
                        track = {
                            'id': f"{mid}_priority_emoji_cancel_{city_from_general.replace(' ','_')}",
                            'place': city_from_general.title(),
                            'threat_type': 'alarm_cancel',
                            'text': clean_text(text)[:500], 
                            'date': date_str, 
                            'channel': channel,
                            'list_only': True,  # NO map marker for cancellation
                            'source_match': 'priority_emoji_cancel'
                        }
                        add_debug_log(f'PRIORITY CANCELLATION: {city_from_general} -> list_only=True (no marker)', "emoji_debug")
                        return [track]  # Early return - cancellation handled
                    
                    # Regular threat - create map marker
                    threat_type, icon = classify(text, city_from_general)
                    track = {
                        'id': f"{mid}_priority_emoji_{city_from_general.replace(' ','_')}",
                        'place': city_from_general.title(),
                        'lat': lat, 'lng': lon,
                        'threat_type': threat_type,
                        'text': clean_text(text)[:500], 'date': date_str, 'channel': channel,
                        'marker_icon': icon, 'source_match': 'priority_emoji_threat'
                    }
                    add_debug_log(f'PRIORITY EARLY RETURN: {city_from_general} -> {coords} -> {icon}', "emoji_debug")
                    return [track]  # Early return - highest priority
    except Exception as e:
        add_debug_log(f"PRIORITY emoji processing error: {e}", "emoji_debug")

    # PRIORITY: Handle emoji + oblast format (when only oblast is specified, place marker in regional center)
    try:
        import re  # Import re module for pattern matching
        head = text.split('\n', 1)[0][:160] if text else ""
        
        # Handle emoji + oblast format (e.g. "👁️ Миколаївська обл.")
        oblast_emoji_pattern = r'^[^\w\s]*\s*([А-ЯІЇЄЁа-яіїєё\'\-\s]*обл\.?)\s*\*\*'
        oblast_emoji_match = re.search(oblast_emoji_pattern, head, re.IGNORECASE)
        add_debug_log(f"PRIORITY: Testing oblast emoji pattern on head: {repr(head)}", "emoji_debug")
        add_debug_log(f"PRIORITY: Oblast emoji match result: {oblast_emoji_match}", "emoji_debug")
        
        if oblast_emoji_match and any(uav_word in text.lower() for uav_word in ['бпла', 'дрон', 'шахед', 'активність', 'загроза', 'тривога']):
            oblast_from_emoji = oblast_emoji_match.group(1).strip()
            add_debug_log(f"PRIORITY: Found oblast from emoji: {repr(oblast_from_emoji)}", "emoji_debug")
            
            # Map oblast to regional center
            regional_center = None
            coords = None
            
            oblast_key = oblast_from_emoji.lower()
            if 'миколаївськ' in oblast_key:
                regional_center = 'Миколаїв'
                coords = CITY_COORDS.get('миколаїв')
            elif 'дніпропетровськ' in oblast_key:
                regional_center = 'Дніпро'
                coords = CITY_COORDS.get('дніпро')
            elif 'харківськ' in oblast_key:
                regional_center = 'Харків'
                coords = CITY_COORDS.get('харків')
            elif 'сумськ' in oblast_key:
                regional_center = 'Суми'
                coords = CITY_COORDS.get('суми')
            elif 'херсонськ' in oblast_key:
                regional_center = 'Херсон'
                coords = CITY_COORDS.get('херсон')
            elif 'одеськ' in oblast_key:
                regional_center = 'Одеса'
                coords = CITY_COORDS.get('одеса')
            elif 'запорізьк' in oblast_key:
                regional_center = 'Запоріжжя'
                coords = CITY_COORDS.get('запоріжжя')
            elif 'полтавськ' in oblast_key:
                regional_center = 'Полтава'
                coords = CITY_COORDS.get('полтава')
            
            add_debug_log(f"PRIORITY: Oblast {oblast_from_emoji} -> regional center {regional_center} -> coords {coords}", "emoji_debug")
            
            if coords and regional_center:
                lat, lon = coords[:2]
                threat_type, icon = classify(text)
                track = {
                    'id': f"{mid}_priority_oblast_{regional_center.replace(' ','_')}",
                    'place': regional_center,
                    'lat': lat, 'lng': lon,
                    'threat_type': threat_type,
                    'text': text[:160], 'date': date_str, 'channel': channel,
                    'marker_icon': icon, 'source_match': 'priority_oblast_threat'
                }
                add_debug_log(f'PRIORITY OBLAST EARLY RETURN: {oblast_from_emoji} -> {regional_center} -> {coords} -> {icon}', "emoji_debug")
                return [track]  # Early return - highest priority
    except Exception as e:
        add_debug_log(f"PRIORITY oblast processing error: {e}", "emoji_debug")
    
    # Continue with existing logic...
    
    # Strip embedded links (Markdown [text](url) or raw URLs) while keeping core message text.
    # Requested: if message contains links, remove them but keep the rest.
    try:
        import re as _re_strip  # type: ignore
        if text:
            _orig_text = text
            # Remove markdown links [ ... ](http...). Keep the visible text (group 1) only.
            text = _re_strip.sub(r"\[([^\]]*)\]\((?:https?|tg|mailto)://[^)]+\)", lambda m: (m.group(1) or '').strip(), text)
            # Remove any residual raw URLs (http/https/t.me) leaving a single space
            text = _re_strip.sub(r"https?://\S+", " ", text)
            text = _re_strip.sub(r"t\.me/\S+", " ", text)
            # Remove lone decorative symbols (✙, •, ★) that may have surrounded links
            text = _re_strip.sub(r"[✙•★]{1,}", " ", text)
            # Collapse multiple spaces and trim each line
            cleaned_lines = []
            for _ln in text.splitlines():
                _cl = ' '.join(_ln.split())
                if _cl:
                    cleaned_lines.append(_cl)
            if cleaned_lines:
                text = '\n'.join(cleaned_lines)
            else:
                # If stripping removed everything, fall back to original
                text = _orig_text
    except Exception:
        pass
    # Ensure original_text is defined early to avoid UnboundLocalError in early parsing branches
    original_text = text
    
    # Special handling for oblast+raion format: "чернігівська область (чернігівський район), київська область (вишгородський район)"
    import re as _re_oblast
    oblast_raion_pattern = r'([а-яіїєґ]+ська\s+область)\s*\(([^)]*?райони?[^)]*?)\)'
    oblast_raion_matches = _re_oblast.findall(oblast_raion_pattern, text.lower(), _re_oblast.IGNORECASE)
    
    # Also check for pattern without requiring "райони" in parentheses - some messages might have just names
    if not oblast_raion_matches:
        oblast_raion_pattern_simple = r'([а-яіїєґ]+ська\s+область)\s*\(([^)]+)\)'
        oblast_raion_matches_simple = _re_oblast.findall(oblast_raion_pattern_simple, text.lower(), _re_oblast.IGNORECASE)
        # Filter to only those that contain district-like words
        oblast_raion_matches = [(oblast, raion) for oblast, raion in oblast_raion_matches_simple 
                               if any(word in raion for word in ['район', 'р-н', 'ський', 'цький'])]
    
    add_debug_log(f"Oblast+raion pattern check: found {len(oblast_raion_matches)} matches in text: {text[:200]}...", "oblast_raion")
    
    if oblast_raion_matches and any(word in text.lower() for word in ['бпла', 'загроза', 'укриття']):
        add_debug_log(f"Oblast+raion format detected: {oblast_raion_matches}", "oblast_raion")
        tracks = []
        
        for oblast_text, raion_text in oblast_raion_matches:
            add_debug_log(f"Processing oblast: '{oblast_text}', raion_text: '{raion_text}'", "oblast_raion")
            # Extract individual raions from the parentheses
            # Handle both single and multiple raions: "сумський, конотопський райони"
            raion_parts = _re_oblast.split(r',\s*|\s+та\s+', raion_text)
            add_debug_log(f"Split raion_parts: {raion_parts}", "oblast_raion")
            
            for raion_part in raion_parts:
                raion_part = raion_part.strip()
                if not raion_part:
                    continue
                    
                add_debug_log(f"Processing raion_part: '{raion_part}'", "oblast_raion")
                    
                # Extract raion name (remove "район"/"райони" suffix)
                raion_name = _re_oblast.sub(r'\s*(райони?|р-н\.?).*$', '', raion_part).strip()
                add_debug_log(f"After removing suffix, raion_name: '{raion_name}'", "oblast_raion")
                
                # Normalize raion name
                raion_normalized = _re_oblast.sub(r'(ському|ского|ського|ский|ськiй|ськой|ським|ском)$', 'ський', raion_name)
                add_debug_log(f"Normalized raion: '{raion_normalized}', checking in RAION_FALLBACK", "oblast_raion")
                
                if raion_normalized in RAION_FALLBACK:
                    lat, lng = RAION_FALLBACK[raion_normalized]
                    add_debug_log(f"Creating oblast+raion marker: {raion_normalized} at {lat}, {lng}", "oblast_raion")
                    
                    # Use classify function to determine correct threat type and icon
                    threat_type, icon = classify(original_text, raion_normalized)
                    
                    tracks.append({
                        'id': f"{mid}_raion_{raion_normalized}",
                        'place': f"{raion_normalized.title()} район",
                        'lat': lat,
                        'lng': lng,
                        'threat_type': threat_type,
                        'text': original_text[:500],
                        'date': date_str,
                        'channel': channel,
                        'marker_icon': icon,
                        'source_match': 'oblast_raion_format'
                    })
                else:
                    add_debug_log(f"Raion not found in RAION_FALLBACK: '{raion_normalized}'. Available keys: {list(RAION_FALLBACK.keys())[:10]}...", "oblast_raion")
        
        if tracks:
            add_debug_log(f"Returning {len(tracks)} oblast+raion markers", "oblast_raion")
            return tracks
    
    large_message_mode = False
    LARGE_THRESHOLD = 15000
    HARD_CUTOFF = 40000  # safety to avoid pathological regex backtracking
    parse_started_ts = time.perf_counter()
    if text and len(text) > LARGE_THRESHOLD:
        large_message_mode = True
        orig_len = len(text)
        if orig_len > HARD_CUTOFF:
            # Keep head + tail slices to retain some closing context
            head = text[:HARD_CUTOFF//2]
            tail = text[-2000:]
            text = head + "\n...TRUNCATED...\n" + tail
            log.debug(f"mid={mid} large_message_mode truncation {orig_len}->{len(text)} chars")
        else:
            log.debug(f"mid={mid} large_message_mode len={orig_len}")
        # Quick complexity metrics
        try:
            lc = text.lower()
            metrics = {
                'len': orig_len,
                'lines': text.count('\n') + 1,
                'bpla': lc.count('бпла'),
                'shahed': lc.count('шахед'),
                'course': lc.count('курс'),
                'napr': lc.count('напрям') + lc.count('напрямку')
            }
            log.debug(f"mid={mid} large_msg_metrics {metrics}")
        except Exception:
            pass
        # Pre-scan chunk optimization: if many repeated 'бпла курсом на', extract tokens fast before heavy regex blocks
        try:
            if text.lower().count('курс') > 8 and text.lower().count('бпла') > 8:
                fast_tokens = []
                for ln in text.split('\n'):
                    lnl = ln.lower()
                    if 'бпла' in lnl and 'курс' in lnl and ' на ' in lnl:
                        # light-weight extraction (avoid complex backtracking)
                        # Regex: capture token after 'курс(ом) на' up to 40 chars (letters, spaces, dashes)
                        m = re.search(r"курс(?:ом)?\s+на\s+([a-zа-яіїєґ\-\s]{3,40})", lnl, re.IGNORECASE)
                        if m:
                            tok = m.group(1).strip()
                            if tok and tok not in fast_tokens:
                                fast_tokens.append(tok)
                if fast_tokens:
                    log.debug(f"mid={mid} pre-scan collected {len(fast_tokens)} fast_tokens (will still run main parser)")
        except Exception as _e_fast:
            log.debug(f"mid={mid} pre-scan error: {_e_fast}")
    # Early benign filter: city name + emojis / hearts without any threat keywords -> ignore
    try:
        lt = (text or '').lower().strip()
        if lt:
            # threat indicator tokens (broad stems)
            threat_tokens = (
                'шахед','shahed','бпла','дрон','ракет','каб','вибух','прил','удар','загроз','тривог',
                'пуск','зліт','злет','avia','авіа','пво','обстр','mlrs','rszv','fpv','артил','зеніт','зенит'
            )
            if not any(t in lt for t in threat_tokens):
                # strip emojis & symbols leaving letters, spaces and apostrophes
                import re as _re_benign
                core = _re_benign.sub(r"[^a-zа-яіїєґ'’ʼ`\s-]","", lt)
                core = ' '.join(core.split())
                # If core matches exactly a known city (or its normalized form) and original text length small -> benign
                if 2 <= len(core) <= 30:
                    base = UA_CITY_NORMALIZE.get(core, core)
                    if base in CITY_COORDS or ('SETTLEMENTS_INDEX' in globals() and (globals().get('SETTLEMENTS_INDEX') or {}).get(base)):
                        # Ignore this message (no tracks)
                        add_debug_log(f"BENIGN FILTER blocked message mid={mid} - detected city name without threats: '{core}'", "filter")
                        return []
            # NEW suppression: reconnaissance-only notes ("дорозвідка по БпЛА") should not produce a marker
            # Pattern triggers if word 'дорозвідк' present together with UAV terms but no other threat verbs
            if 'дорозвідк' in lt and any(k in lt for k in ['бпла','shahed','шахед','дрон']):
                # Avoid suppressing if explosions or launches also present
                if not any(k in lt for k in ['вибух','удар','пуск','прил','обстріл','обстрел','зліт','злет']):
                    add_debug_log(f"RECONNAISSANCE FILTER blocked message mid={mid} - reconnaissance only", "filter")
                    return []
    except Exception:
        pass
    
    # SPECIAL: Handle multiple threats in one message BEFORE other parsing
    def handle_multiple_threats():
        """Check for messages with multiple different threats and process each separately"""
        all_threats = []
        text_lower = text.lower()
        
        # 1. Check for northeast tactical aviation threat
        if ('тактичн' in text_lower or 'авіаці' in text_lower or 'авиац' in text_lower) and (
            'північно-східн' in text_lower or 'північно східн' in text_lower or 'северо-восточ' in text_lower or 'північного-сходу' in text_lower
        ):
            lat, lng = 50.9, 34.8  # Near Sumy city (in Ukrainian territory)
            all_threats.append({
                'id': f"{mid}_ne_multi", 'place': 'Північно-східний напрямок', 'lat': lat, 'lng': lng,
                'threat_type': 'avia', 'text': text[:500], 'date': date_str, 'channel': channel,
                'marker_icon': 'avia.png', 'source_match': 'multiple_threats_northeast_aviation'
            })
        
        # 2. Check for reconnaissance UAV in Mykolaiv oblast (миколаївщини/миколаївщині)
        if ('розвід' in text_lower or 'розведуваль' in text_lower) and ('миколаївщини' in text_lower or 'миколаївщині' in text_lower or 'миколаївщина' in text_lower):
            # Use Mykolaiv city coordinates
            lat, lng = 46.9750, 31.9946
            all_threats.append({
                'id': f"{mid}_mykolaiv_recon", 'place': 'Миколаївщина', 'lat': lat, 'lng': lng,
                'threat_type': 'rozved', 'text': text[:500], 'date': date_str, 'channel': channel,
                'marker_icon': 'rozved.png', 'source_match': 'multiple_threats_mykolaiv_recon'
            })
        
        # 3. Check for general БПЛА threats in oblast format (миколаївщини/миколаївщині) without "розвід"
        elif ('бпла' in text_lower or 'дрон' in text_lower) and ('миколаївщини' in text_lower or 'миколаївщині' in text_lower or 'миколаївщина' in text_lower):
            lat, lng = 46.9750, 31.9946
            all_threats.append({
                'id': f"{mid}_mykolaiv_uav", 'place': 'Миколаївщина', 'lat': lat, 'lng': lng,
                'threat_type': 'shahed', 'text': clean_text(text)[:500], 'date': date_str, 'channel': channel,
                'marker_icon': 'shahed.png', 'source_match': 'multiple_threats_mykolaiv_uav'
            })
        
        return all_threats

    # Check if this is a multi-threat message
    if '🛬' in text and '🛸' in text:
        multi_threats = handle_multiple_threats()
        if multi_threats:
            add_debug_log(f"MULTIPLE THREATS DETECTED: Found {len(multi_threats)} threats", "multi_threats")
            return multi_threats

    # EARLY CHECK: Multi-regional UAV messages (before other logic can interfere)
    text_lines = text.split('\n')
    region_count = sum(1 for line in text_lines if any(region in line.lower() for region in ['щина:', 'щина]', 'область:', 'край:']) or (
        'щина' in line.lower() and line.lower().strip().endswith(':')
    ))
    uav_count = sum(1 for line in text_lines if 'бпла' in line.lower() and ('курс' in line.lower() or 'на ' in line.lower()))
    
    if region_count >= 2 and uav_count >= 3:
        add_debug_log(f"EARLY MULTI-REGIONAL UAV DETECTION: {region_count} regions, {uav_count} UAVs", "multi_regional")
        # We'll process this later when all functions are defined
        # Set a flag for now
        multi_regional_flag = True
    else:
        multi_regional_flag = False

    # ... existing parsing logic continues ...
    # At the very end of function (before return default) we'll log duration.
    # Air alarm region/raion tracking (start / cancel) before other parsing
    try:
        low_full = (text or '').lower()
        now_ep = time.time()
        lines = [l.strip() for l in (text or '').split('\n') if l.strip()][:3]
        if lines:
            header = lines[0].lower()
            header_norm = header.replace('область', 'обл.').replace('обл..','обл.')
            # Oblast alarm start: contains '<adj> обл.' and body has 'повітряна тривога'
            if ('повітр' in low_full or 'тривог' in low_full) and ' обл' in header_norm:
                m_obl = re.search(r"([а-яіїєґ\-']+?)\s+обл\.?", header_norm)
                if m_obl:
                    stem = m_obl.group(1)
                    # Match against OBLAST_CENTERS keys
                    for k in OBLAST_CENTERS.keys():
                        if k.startswith(stem):
                            is_new = k not in ACTIVE_OBLAST_ALARMS
                            rec = ACTIVE_OBLAST_ALARMS.setdefault(k, {'since': now_ep, 'last': now_ep})
                            if rec['since'] > now_ep: rec['since'] = now_ep
                            rec['last'] = now_ep
                            persist_alarm('oblast', k, rec['since'], rec['last'])
                            if is_new:
                                log_alarm_event('oblast', k, 'start', now_ep)
                            break
            # Raion alarm start: '<name> район'
            if ('повітр' in low_full or 'тривог' in low_full) and ' район' in header:
                m_r = re.search(r"([а-яіїєґ\-']+?)\s+район", header)
                if m_r:
                    rb = m_r.group(1).replace('’',"'").replace('ʼ',"'")
                    if rb in RAION_FALLBACK:
                        is_new_r = rb not in ACTIVE_RAION_ALARMS
                        rec = ACTIVE_RAION_ALARMS.setdefault(rb, {'since': now_ep, 'last': now_ep})
                        if rec['since'] > now_ep: rec['since'] = now_ep
                        rec['last'] = now_ep
                        persist_alarm('raion', rb, rec['since'], rec['last'])
                        if is_new_r:
                            log_alarm_event('raion', rb, 'start', now_ep)
        # Cancellation lines contain 'відбій тривоги' or 'отбой тревоги'
        if ('відбій' in low_full or 'отбой' in low_full) and ('тривог' in low_full or 'тревог' in low_full):
            # Precise: look for explicit oblast adjectives endings '-ська', '-цька', '-ницька', etc.
            # Pattern: відбій тривоги у / в <word...> області OR '<adj> обл.'
            m_cancel_obl = re.findall(r"(\b[а-яіїєґ\-']+?)(?:ська|цька|ницька|зька|жська)\s+обл(?:асть|\.|)", low_full)
            removed_any = False
            if m_cancel_obl:
                for stem in m_cancel_obl:
                    for k in list(ACTIVE_OBLAST_ALARMS.keys()):
                        if k.startswith(stem):
                            ACTIVE_OBLAST_ALARMS.pop(k, None); remove_alarm('oblast', k); log_alarm_event('oblast', k, 'cancel', now_ep); removed_any=True
            # Raion precise cancel: "відбій тривоги у <name> районі" (locative: -ському / -івському)
            m_cancel_r = re.findall(r"відбій[^\n]*?\b([а-яіїєґ\-']+?)(?:ському|івському|ському)\s+районі", low_full)
            if m_cancel_r:
                for stem in m_cancel_r:
                    for r in list(ACTIVE_RAION_ALARMS.keys()):
                        if r.startswith(stem):
                            ACTIVE_RAION_ALARMS.pop(r, None); remove_alarm('raion', r); log_alarm_event('raion', r, 'cancel', now_ep); removed_any=True
            # Fallback broad cancel if phrase generic and no explicit names matched
            if not removed_any and re.search(r"відбій\s+тривог|отбой\s+тревог", low_full):
                # remove all (global відбій)
                for k in list(ACTIVE_OBLAST_ALARMS.keys()):
                    ACTIVE_OBLAST_ALARMS.pop(k, None); remove_alarm('oblast', k); log_alarm_event('oblast', k, 'cancel', now_ep)
                for r in list(ACTIVE_RAION_ALARMS.keys()):
                    ACTIVE_RAION_ALARMS.pop(r, None); remove_alarm('raion', r); log_alarm_event('raion', r, 'cancel', now_ep)
        # Expire stale
        ttl_cut = now_ep - APP_ALARM_TTL_MINUTES*60
        for dct in (ACTIVE_OBLAST_ALARMS, ACTIVE_RAION_ALARMS):
            for k in list(dct.keys()):
                if dct[k]['last'] < ttl_cut:
                    level = 'oblast' if dct is ACTIVE_OBLAST_ALARMS else 'raion'
                    dct.pop(k, None)
                    remove_alarm(level, k)
                    log_alarm_event(level, k, 'expire', now_ep)
    except Exception as _e_alarm:
        log.debug(f'alarm tracking block error: {_e_alarm}')
    # Early single-city (bold/emoji tolerant) parser
    try:
        orig = text
        head = orig.split('\n',1)[0][:160]
        
        # NEW: Handle emoji-prefixed threat messages like "🛸 Звягель (Житомирська обл.) Загроза застосування БПЛА"
        emoji_threat_pattern = r'^[^\w\s]*\s*([А-ЯІЇЄЁа-яіїєё\'\-\s]+)\s*\([^)]*обл[^)]*\)\s*загроза\s+застосування\s+бпла'
        emoji_match = re.search(emoji_threat_pattern, head, re.IGNORECASE)
        if emoji_match:
            city_from_emoji = emoji_match.group(1).strip()
            if city_from_emoji and 2 <= len(city_from_emoji) <= 40:
                base = city_from_emoji.lower().replace('\u02bc',"'").replace('ʼ',"'").replace("'","'").replace('`',"'")
                base = re.sub(r'\s+',' ', base)
                norm = UA_CITY_NORMALIZE.get(base, base)
                coords = CITY_COORDS.get(norm)
                if not coords and 'SETTLEMENTS_INDEX' in globals():
                    idx_map = globals().get('SETTLEMENTS_INDEX') or {}
                    coords = idx_map.get(norm)
                if coords:
                    lat, lon = coords[:2]
                    threat_type, icon = classify(text)
                    track = {
                        'id': f"{mid}_emoji_threat_{city_from_emoji.replace(' ','_')}",
                        'place': city_from_emoji,
                        'lat': lat, 'lng': lon,
                        'threat_type': threat_type,
                        'text': clean_text(orig)[:500], 'date': date_str, 'channel': channel,
                        'marker_icon': icon, 'source_match': 'emoji_threat'
                    }
                    log.debug(f'Emoji threat parser: {city_from_emoji} -> {coords} -> {icon}')
                    return [track]  # Early return
        
        # NEW: Handle general emoji + city + oblast format with any UAV threat (more flexible pattern)
        general_emoji_pattern = r'^[^\w\s]*\s*([А-ЯІЇЄЁа-яіїєё\'\-\s]+)\s*\([^)]*обл[^)]*\)'
        general_emoji_match = re.search(general_emoji_pattern, head, re.IGNORECASE)
        add_debug_log(f"Testing general emoji pattern on head: {repr(head)}", "emoji_debug")
        add_debug_log(f"General emoji match result: {general_emoji_match}", "emoji_debug")
        
        if general_emoji_match and any(uav_word in text.lower() for uav_word in ['бпла', 'дрон', 'шахед', 'активність', 'загроза']):
            city_from_general = general_emoji_match.group(1).strip()
            add_debug_log(f"Found city from general emoji: {repr(city_from_general)}", "emoji_debug")
            
            if city_from_general and 2 <= len(city_from_general) <= 40:
                base = city_from_general.lower().replace('\u02bc',"'").replace('ʼ',"'").replace("'","'").replace('`',"'")
                base = re.sub(r'\s+',' ', base)
                norm = UA_CITY_NORMALIZE.get(base, base)
                coords = CITY_COORDS.get(norm)
                add_debug_log(f"Looking up coordinates: base={repr(base)}, norm={repr(norm)}, coords={coords}", "emoji_debug")
                
                if not coords and 'SETTLEMENTS_INDEX' in globals():
                    idx_map = globals().get('SETTLEMENTS_INDEX') or {}
                    coords = idx_map.get(norm)
                if coords:
                    lat, lon = coords[:2]
                    threat_type, icon = classify(text)
                    track = {
                        'id': f"{mid}_general_emoji_{city_from_general.replace(' ','_')}",
                        'place': city_from_general.title(),
                        'lat': lat, 'lng': lon,
                        'threat_type': threat_type,
                        'text': clean_text(text)[:500], 'date': date_str, 'channel': channel,
                        'marker_icon': icon, 'source_match': 'general_emoji_threat'
                    }
                    add_debug_log(f'EARLY RETURN: General emoji threat parser: {city_from_general} -> {coords} -> {icon}', "emoji_debug")
                    return [track]  # Early return
        
        if '(' in head and ('обл' in head.lower() or 'область' in head.lower()):
            import re as _re_early
            cleaned = head.replace('**','')
            for _zw in ('\u200b','\u200c','\u200d','\ufeff','\u2060','\u00a0'):
                cleaned = cleaned.replace(_zw,' ')
            cleaned = ' '.join(cleaned.split())
            cleaned = _re_early.sub(r'^[^A-Za-zА-Яа-яЇїІіЄєҐґ]+','', cleaned)
            # NEW: if pipe '|' separates multiple city headers in one line, attempt multi-city extraction here
            if '|' in cleaned:
                parts = [p.strip() for p in cleaned.split('|') if p.strip()]
                multi_tracks = []
                for idx, part in enumerate(parts, start=1):
                    if '(' not in part:
                        continue
                    par_pos = part.find('(')
                    if par_pos <= 1:
                        continue
                    city_candidate = part[:par_pos].strip()
                    if not (2 <= len(city_candidate) <= 40):
                        continue
                    try:
                        base = city_candidate.lower().replace('\u02bc',"'").replace('ʼ',"'").replace('’',"'").replace('`',"'")
                        base = _re_early.sub(r'\s+',' ', base)
                        norm = UA_CITY_NORMALIZE.get(base, base)
                        coords = CITY_COORDS.get(norm)
                        if not coords and 'SETTLEMENTS_INDEX' in globals():
                            idx_map = globals().get('SETTLEMENTS_INDEX') or {}
                            coords = idx_map.get(norm)
                        approx_flag = False
                        if not coords:
                            enriched = ensure_city_coords(norm)
                            if enriched:
                                if isinstance(enriched, tuple) and len(enriched) == 3:
                                    coords = (enriched[0], enriched[1])
                                    approx_flag = enriched[2]
                                else:
                                    coords = enriched
                        if not coords:
                            continue
                        # classification per segment
                        lseg = part.lower()
                        if any(ph in lseg for ph in ['повідомляють про вибух','повідомлено про вибух','зафіксовано вибух','зафіксовано вибухи','фіксація вибух','фіксують вибух',' вибух.',' вибухи.']):
                            threat, icon = 'vibuh','vibuh.png'
                        elif 'відбій загрози обстр' in lseg or 'відбій загрози застосування' in lseg or 'відбій загрози бпла' in lseg:
                            # treat as list-only cancellation fragment -> skip map marker for this part
                            multi_tracks.append({
                                'id': f"{mid}_p{idx}", 'text': part[:500], 'date': date_str, 'channel': channel,
                                'list_only': True, 'threat_type': 'alarm_cancel', 'place': city_candidate.title()
                            })
                            continue
                        elif 'загроза застосування бпла' in lseg or 'загроза застосування безпілот' in lseg:
                            threat, icon = 'shahed','shahed.png'
                        elif 'загроза обстрілу' in lseg or 'загроза обстрела' in lseg:
                            threat, icon = 'artillery','obstril.png'
                        else:
                            threat, icon = classify(part)
                        lat, lng = coords
                        track = {
                            'id': f"{mid}_p{idx}", 'place': city_candidate.title(), 'lat': lat, 'lng': lng,
                            'threat_type': threat, 'text': part[:500], 'date': date_str, 'channel': channel,
                            'marker_icon': icon, 'source_match': 'multi_city_pipe'
                        }
                        if approx_flag:
                            track['approx'] = True
                        multi_tracks.append(track)
                    except Exception:
                        continue
                # Return only if 2+ actual geo tracks (ignore if we only produced one, fall back to single-city logic)
                geo_count = sum(1 for t in multi_tracks if not t.get('list_only'))
                if geo_count >= 2:
                    return multi_tracks
            par = cleaned.find('(')
            if par > 1:
                city_candidate = cleaned[:par].strip()
                if 2 <= len(city_candidate) <= 40:
                    base = city_candidate.lower().replace('\u02bc',"'").replace('ʼ',"'").replace('’',"'").replace('`',"'")
                    base = _re_early.sub(r'\s+',' ', base)
                    norm = UA_CITY_NORMALIZE.get(base, base)
                    coords = CITY_COORDS.get(norm)
                    if not coords and 'SETTLEMENTS_INDEX' in globals():
                        idx = globals().get('SETTLEMENTS_INDEX') or {}
                        coords = idx.get(norm)
                    approx_flag = False
                    if not coords:
                        enriched = ensure_city_coords_with_message_context(norm, orig)
                        if enriched:
                            if isinstance(enriched, tuple) and len(enriched) == 3:
                                coords = (enriched[0], enriched[1])
                                approx_flag = enriched[2]
                            else:
                                coords = enriched
                    if coords:
                        l = orig.lower()
                        if any(ph in l for ph in ['повідомляють про вибух','повідомлено про вибух','зафіксовано вибух','зафіксовано вибухи','фіксація вибух','фіксують вибух',' вибух.',' вибухи.']):
                            threat, icon = 'vibuh','vibuh.png'
                        elif 'відбій загрози обстр' in l or 'відбій загрози застосування' in l or 'відбій загрози бпла' in l:
                            # Treat city-level cancellation as list event, not a geo marker
                            return [{
                                'id': str(mid), 'text': orig[:500], 'date': date_str, 'channel': channel,
                                'list_only': True, 'threat_type': 'alarm_cancel', 'place': city_candidate.title()
                            }]
                        elif 'загроза застосування бпла' in l or 'загроза застосування безпілот' in l:
                            threat, icon = 'shahed','shahed.png'
                        elif 'загроза обстрілу' in l or 'загроза обстрела' in l:
                            threat, icon = 'artillery','obstril.png'
                        else:
                            threat, icon = classify(orig)
                        lat,lng = coords
                        track = {
                            'id': str(mid), 'place': city_candidate.title(), 'lat': lat, 'lng': lng,
                            'threat_type': threat, 'text': orig[:500], 'date': date_str, 'channel': channel,
                            'marker_icon': icon, 'source_match': 'single_city_simple_early'
                        }
                        if approx_flag:
                            track['approx'] = True
                        return [track]
    except Exception:
        pass

    
    # Directional multi-region (e.g. "група БпЛА на Донеччині курсом на Дніпропетровщину") -> list-only, no fixed marker
    try:
        lorig = text.lower()
        # Skip if this message has route patterns (handled by route parser above)
        if 'через' in lorig or 'повз' in lorig:
            pass
        elif (('курс' in lorig or '➡' in lorig or '→' in lorig or 'напрям' in lorig) and ('бпла' in lorig or 'дрон' in lorig or 'груп' in lorig)) or ('бпла' in lorig and 'частин' in lorig) or ('дрон' in lorig and 'частин' in lorig):
            # Special case: BPLA current location with directional info
            # e.g., "БпЛА в північно-західній частині Полтавщини, курсом на Київщину"
            # or "БпЛА в південно-східній частині Харківщини"
            import re as _re_loc
            
            # Look for current location patterns
            location_match = _re_loc.search(r'(?:бпла|дрон[иа]?)\s+(?:в|на|над)\s+([а-яіїєґ\-\s]+(?:частин[іа]|район[іе]|округ[уі])\s+[а-яіїєґ]+щин[иаю])', lorig)
            if location_match:
                current_location = location_match.group(1).strip()
                print(f"DEBUG: Found current BPLA location: {current_location}")
                
                # Extract region from current location
                region_in_location = None
                for reg_key in OBLAST_CENTERS.keys():
                    if reg_key in current_location:
                        region_in_location = reg_key
                        break
                
                if region_in_location:
                    # Get region center and apply directional offset
                    region_coords = OBLAST_CENTERS.get(region_in_location, (50.0, 30.0))
                    
                    # Apply directional offset based on specified part of region
                    offset_lat, offset_lon = 0, 0
                    if 'північно-західн' in current_location:
                        offset_lat, offset_lon = 0.8, -0.8  # Northwest
                    elif 'північно-східн' in current_location:
                        offset_lat, offset_lon = 0.8, 0.8   # Northeast
                    elif 'південно-західн' in current_location:
                        offset_lat, offset_lon = -0.8, -0.8 # Southwest
                    elif 'південно-східн' in current_location:
                        offset_lat, offset_lon = -0.8, 0.8  # Southeast
                    elif 'північн' in current_location:
                        offset_lat, offset_lon = 0.8, 0     # North
                    elif 'південн' in current_location:
                        offset_lat, offset_lon = -0.8, 0    # South
                    elif 'західн' in current_location:
                        offset_lat, offset_lon = 0, -0.8    # West
                    elif 'східн' in current_location:
                        offset_lat, offset_lon = 0, 0.8     # East
                    elif 'центральн' in current_location:
                        offset_lat, offset_lon = 0, 0       # Center
                    
                    final_lat = region_coords[0] + offset_lat
                    final_lon = region_coords[1] + offset_lon
                    
                    # Clean up city name for display
                    region_name = region_in_location.replace('щини', 'щина').replace('щину', 'щина')
                    direction_part = ""
                    if 'північно-західн' in current_location:
                        direction_part = "Пн-Зх "
                    elif 'північно-східн' in current_location:
                        direction_part = "Пн-Сх "
                    elif 'південно-західн' in current_location:
                        direction_part = "Пд-Зх "
                    elif 'південно-східн' in current_location:
                        direction_part = "Пд-Сх "
                    elif 'північн' in current_location:
                        direction_part = "Пн "
                    elif 'південн' in current_location:
                        direction_part = "Пд "
                    elif 'західн' in current_location:
                        direction_part = "Зх "
                    elif 'східн' in current_location:
                        direction_part = "Сх "
                    elif 'центральн' in current_location:
                        direction_part = "Центр "
                    
                    display_name = f"{direction_part}{region_name.title()}"
                    
                    print(f"DEBUG: Location '{current_location}' in {region_in_location} -> ({final_lat}, {final_lon})")
                    
                    return [{
                        'id': str(mid), 'text': clean_text(text)[:600], 'date': date_str, 'channel': channel,
                        'lat': final_lat, 'lon': final_lon, 'city': display_name,
                        'source_match': 'trajectory_current_location'
                    }]
            
            # Quick reject if explicit single settlement in parentheses (handled elsewhere)
            if '(' not in lorig:
                present_regions = []
                for reg_key in OBLAST_CENTERS.keys():
                    if reg_key in lorig:
                        present_regions.append(reg_key)
                        if len(present_regions) >= 4:
                            break
                distinct = {r.split()[0] for r in present_regions}
                # Accept patterns like "нова група ударних БпЛА на Донеччині курсом на Дніпропетровщину"
                # even if only 2 region stems present
                if len(distinct) >= 2:
                    # Check if message contains specific cities that should create markers instead
                    city_keywords = ['на кролевец', 'на конотоп', 'на чернігів', 'на вишгород', 'на петрівці', 'на велика димерка', 'на білу церкву', 'на бровари', 'на суми', 'на харків', 'на дніпро', 'на кропивницький', 'на житомир', 'на миколаївку', 'на липовець', 'на ріпки', 'на терни', 'на павлоград']
                    has_specific_cities = any(city_kw in lorig for city_kw in city_keywords)
                    
                    # Also check for pattern "БпЛА на [city]" which should create markers
                    import re as _re_cities
                    bpla_na_pattern = _re_cities.findall(r'бпла\s+на\s+([a-zа-яіїєґʼ`\-\s]{3,20})', lorig)
                    if bpla_na_pattern:
                        has_specific_cities = True
                    
                    if has_specific_cities:
                        # Let multi-city parser handle this instead
                        pass
                    else:
                        # Extra guard: if a well-known large city (e.g. дніпро, харків, київ) appears ONLY because it's substring of region
                        # we still treat as region directional, not city marker
                        # But if message contains multiple explicit directional part-of-region clauses ("на сході <області>" ... "на сході <області>")
                        # then we want to produce separate segment markers instead of a single list-only event.
                        import re as _re_dd
                        dir_clause_count = len(_re_dd.findall(r'на\s+(?:північ|півден|схід|заход|північно|південно)[^\.]{0,40}?(?:щина|щини|щину)', lorig))
                        if dir_clause_count < 2:
                            return [{
                                'id': str(mid), 'text': clean_text(text)[:600], 'date': date_str, 'channel': channel,
                                'list_only': True, 'source_match': 'region_direction_multi'
                            }]
    except Exception:
        pass
    # Comparative directional relative to a city ("північніше Городні", "східніше Кролевця") -> use base city location
    try:
        import re as _re_rel
        low_txt = text.lower()
        # NEW: pattern "<city> - до вас БпЛА" -> marker at city
        m_dash = _re_rel.search(r"([a-zа-яіїєґ'ʼ’`\-]{3,40})\s*[-–—]\s*до вас\s+бпла", low_txt)
        if m_dash:
            raw_city = m_dash.group(1)
            raw_city = raw_city.replace('\u02bc',"'").replace('ʼ',"'").replace('’',"'").replace('`',"'")
            base = UA_CITY_NORMALIZE.get(raw_city, raw_city)
            coords = CITY_COORDS.get(base)
            if not coords and 'SETTLEMENTS_INDEX' in globals():
                coords = (globals().get('SETTLEMENTS_INDEX') or {}).get(base)
            if coords:
                lat,lng = coords
                threat, icon = 'shahed','shahed.png'
                return [{
                    'id': str(mid), 'place': base.title(), 'lat': lat, 'lng': lng,
                    'threat_type': threat, 'text': clean_text(text)[:500], 'date': date_str, 'channel': channel,
                    'marker_icon': icon, 'source_match': 'city_dash_uav'
                }]
        # NEW: pattern "БпЛА на <city>" or "бпла на <city>" -> marker at city
        uav_cities = _re_rel.findall(r"бпла\s+на\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ\`\s/]+?)(?=\s+(?:з|на|до|від|через|повз|курсом|напрям)\s|[,\.\!\?;:\n]|$)", low_txt)
        if uav_cities:
            threats = []
            for idx, rc in enumerate(uav_cities):
                rc = rc.replace('\u02bc',"'").replace('ʼ',"'").replace("'","'").replace('`',"'")
                
                # Handle cities separated by slash (e.g., "вишгород/петрівці")
                cities_to_process = []
                if '/' in rc:
                    cities_to_process.extend(rc.split('/'))
                else:
                    cities_to_process.append(rc)
                
                for city_idx, city in enumerate(cities_to_process):
                    city = city.strip()
                    if not city:
                        continue
                        
                    base = UA_CITY_NORMALIZE.get(city, city)
                    
                    # Special handling for Kyiv - show directional approach instead of center point
                    if base.lower() == 'київ':
                        kyiv_lat, kyiv_lng, kyiv_label, direction_info = get_kyiv_directional_coordinates(text, base)
                        threat_type, icon = classify(text)
                        
                        # Use specialized icon for directional Kyiv threats
                        if direction_info:
                            icon = 'shahed.png'  # Could create special directional icon later
                            
                        threats.append({
                            'id': f"{mid}_uav_{idx}_{city_idx}_kyiv_dir", 'place': kyiv_label, 'lat': kyiv_lat, 'lng': kyiv_lng,
                            'threat_type': threat_type, 'text': clean_text(text)[:500], 'date': date_str, 'channel': channel,
                            'marker_icon': icon, 'source_match': 'uav_on_city_kyiv_directional',
                            'direction_info': direction_info
                        })
                        continue
                    
                    coords = CITY_COORDS.get(base)
                    if not coords and 'SETTLEMENTS_INDEX' in globals():
                        coords = (globals().get('SETTLEMENTS_INDEX') or {}).get(base)
                    if coords:
                        lat,lng = coords
                        threats.append({
                            'id': f"{mid}_uav_{idx}_{city_idx}", 'place': base.title(), 'lat': lat, 'lng': lng,
                            'threat_type': 'shahed', 'text': clean_text(text)[:500], 'date': date_str, 'channel': channel,
                            'marker_icon': 'shahed.png', 'source_match': 'uav_on_city'
                        })
            if threats:
                return threats
        # pattern captures direction word + city morph form
        m_rel = _re_rel.search(r'(північніше|південніше|східніше|західніше)\s+([a-zа-яіїєґ\'ʼ’`\-]{3,40})', low_txt)
        if m_rel:
            raw_city = m_rel.group(2)
            # normalize apostrophes
            raw_city = raw_city.replace('\u02bc',"'").replace('ʼ',"'").replace('’',"'").replace('`',"'")
            base = UA_CITY_NORMALIZE.get(raw_city, raw_city)
            coords = CITY_COORDS.get(base)
            if not coords and 'SETTLEMENTS_INDEX' in globals():
                idx = globals().get('SETTLEMENTS_INDEX') or {}
                coords = idx.get(base)
            if not coords:
                enriched = ensure_city_coords(base)
                if enriched:
                    if isinstance(enriched, tuple) and len(enriched)==3:
                        coords = (enriched[0], enriched[1])
                    else:
                        coords = enriched
            if coords:
                lat,lng = coords
                threat_type, icon = classify(text)
                return [{
                    'id': str(mid), 'place': base.title(), 'lat': lat, 'lng': lng,
                    'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
                    'marker_icon': icon, 'source_match': 'relative_direction_city'
                }]
    except Exception:
        pass
    # Multi-segment UAV messages with pipe separator (e.g., "БпЛА курсом на Кагарлик | 2х БпЛА Білоцерківський район | 3х БпЛА Вишеньки / Українка")
    try:
        if '|' in text and 'бпла' in text.lower():
            segments = [seg.strip() for seg in text.split('|') if seg.strip()]
            if len(segments) >= 2:  # At least 2 segments
                threats = []
                import re as _re_multi
                
                for seg_idx, segment in enumerate(segments):
                    seg_lower = segment.lower()
                    if 'бпла' not in seg_lower:
                        continue
                    
                    # Pattern 1: "БпЛА курсом на [city]" (with optional н.п. prefix)
                    course_match = _re_multi.search(r'бпла\s+курсом?\s+на\s+(?:н\.п\.?\s*)?([а-яіїєґ\'\-\s]+?)(?:\s*$|\s*\|)', seg_lower)
                    if course_match:
                        city_name = course_match.group(1).strip()
                        city_norm = clean_text(city_name).lower()
                        
                        # Accusative case normalization (винительный падеж)
                        if city_norm == 'велику димерку':
                            city_norm = 'велика димерка'
                        elif city_norm == 'мену':
                            city_norm = 'мена'
                        elif city_norm == 'пісківку':
                            city_norm = 'пісківка'
                        elif city_norm == 'києвом':
                            city_norm = 'київ'
                        # General accusative case endings
                        elif city_norm.endswith('у') and len(city_norm) > 3:
                            city_norm = city_norm[:-1] + 'а'
                        elif city_norm.endswith('ю') and len(city_norm) > 3:
                            city_norm = city_norm[:-1] + 'я'
                        elif city_norm.endswith('ку') and len(city_norm) > 4:
                            city_norm = city_norm[:-2] + 'ка'
                        
                        if city_norm in UA_CITY_NORMALIZE:
                            city_norm = UA_CITY_NORMALIZE[city_norm]
                        
                        coords = ensure_city_coords_with_message_context(city_norm, text)
                        
                        if coords and isinstance(coords, tuple) and len(coords) >= 2:
                            lat, lng = coords[0], coords[1]
                            threat_type, icon = classify(text)
                            # Use normalized city name for display, not the original accusative form
                            display_name = city_norm.title()
                            threats.append({
                                'id': f"{mid}_multi_{seg_idx}",
                                'place': display_name,
                                'lat': lat,
                                'lng': lng,
                                'threat_type': threat_type,
                                'text': f"Курсом на {display_name}",
                                'date': date_str,
                                'channel': channel,
                                'marker_icon': icon,
                                'source_match': 'multi_segment_course',
                                'count': 1
                            })
                    
                    # Pattern 1.5: "БпЛА повз [city1] курсом на [city2]" - extract both cities  
                    povz_match = _re_multi.search(r'(\d+(?:-\d+)?)?[xх×]?\s*бпла\s+повз\s+([а-яіїєґ\'\-\s]+?)\s+курсом?\s+на\s+([а-яіїєґ\'\-\s]+?)(?:\s*$|\s*\|)', seg_lower)
                    if povz_match and not course_match:  # Don't double-process if already handled by Pattern 1
                        count_str, city1_name, city2_name = povz_match.groups()
                        count = int(count_str) if count_str and count_str.isdigit() else 1
                        
                        for city_idx, city_raw in enumerate([city1_name, city2_name]):
                            if not city_raw:
                                continue
                                
                            city_name = city_raw.strip()
                            city_norm = clean_text(city_name).lower()
                            
                            # Accusative case normalization for both cities
                            if city_norm == 'велику димерку':
                                city_norm = 'велика димерка'
                            elif city_norm == 'мену':
                                city_norm = 'мена'
                            elif city_norm == 'пісківку':
                                city_norm = 'пісківка'
                            elif city_norm == 'києвом':
                                city_norm = 'київ'
                            # General accusative case endings
                            elif city_norm.endswith('у') and len(city_norm) > 3:
                                city_norm = city_norm[:-1] + 'а'
                            elif city_norm.endswith('ю') and len(city_norm) > 3:
                                city_norm = city_norm[:-1] + 'я'
                            elif city_norm.endswith('ку') and len(city_norm) > 4:
                                city_norm = city_norm[:-2] + 'ка'
                            
                            if city_norm in UA_CITY_NORMALIZE:
                                city_norm = UA_CITY_NORMALIZE[city_norm]
                            
                            coords = ensure_city_coords(city_norm)
                            
                            if coords and isinstance(coords, tuple) and len(coords) >= 2:
                                lat, lng = coords[0], coords[1]
                                threat_type, icon = classify(text)
                                action = "Повз" if city_idx == 0 else "Курсом на"
                                # Use normalized city name for display
                                display_name = city_norm.title()
                                threats.append({
                                    'id': f"{mid}_multi_{seg_idx}_povz_{city_idx}",
                                    'place': display_name,
                                    'lat': lat,
                                    'lng': lng,
                                    'threat_type': threat_type,
                                    'text': f"{action} {display_name} ({count}x)",
                                    'date': date_str,
                                    'channel': channel,
                                    'marker_icon': icon,
                                    'source_match': 'multi_segment_povz',
                                    'count': count
                                })
                    
                    # Pattern 2: "[N]х БпЛА [location]" - extract cities
                    location_match = _re_multi.search(r'(\d+(?:-\d+)?)?[xх×]?\s*бпла\s+(.+?)(?:\.|$)', seg_lower)
                    if location_match and not course_match:  # Don't double-process course segments
                        count_str = location_match.group(1) or "1"
                        location_text = location_match.group(2).strip()
                        count = int(count_str) if count_str.isdigit() else 1
                        
                        # Split by common separators to get individual cities
                        cities = []
                        for sep in [' / ', ' та ', ' і ', ', ']:
                            if sep in location_text:
                                cities = [c.strip() for c in location_text.split(sep) if c.strip()]
                                break
                        if not cities:
                            cities = [location_text]
                        
                        for city_idx, city in enumerate(cities):
                            city = city.strip()
                            if not city:
                                continue
                            
                            # Handle district references (e.g., "Білоцерківський район")
                            if 'район' in city:
                                # Extract district name and try to find main city
                                district_name = city.replace('район', '').replace('ський', '').replace('цький', '').strip()
                                
                                # Special case mappings
                                if 'білоцерків' in district_name:
                                    district_name = 'біла церква'
                                
                                if district_name:
                                    city = district_name
                                else:
                                    continue
                                
                            city_norm = clean_text(city).lower()
                            if city_norm in UA_CITY_NORMALIZE:
                                city_norm = UA_CITY_NORMALIZE[city_norm]
                            
                            coords = ensure_city_coords(city_norm)
                            
                            if coords and isinstance(coords, tuple) and len(coords) >= 2:
                                lat, lng = coords[0], coords[1]
                                threat_type, icon = classify(text)
                                threats.append({
                                    'id': f"{mid}_multi_{seg_idx}_{city_idx}",
                                    'place': city.title(),
                                    'lat': lat,
                                    'lng': lng,
                                    'threat_type': threat_type,
                                    'text': f"{count}х БпЛА на {city.title()}",
                                    'date': date_str,
                                    'channel': channel,
                                    'marker_icon': icon,
                                    'source_match': f'multi_segment_location_{count}x',
                                    'count': count
                                })
                
                if threats:
                    # ALSO: Extract cities from emoji structure in the same text 
                    # Pattern for "| 🛸 Город (Область)"
                    emoji_pattern = r'\|\s*🛸\s*([А-ЯІЇЄЁа-яіїєё\'\-\s]+?)\s*\([^)]*обл[^)]*\)'
                    emoji_matches = re.finditer(emoji_pattern, text, re.IGNORECASE)
                    
                    for match in emoji_matches:
                        city_raw = match.group(1).strip()
                        if not city_raw or len(city_raw) < 2:
                            continue
                            
                        city_norm = clean_text(city_raw).lower()
                        if city_norm in UA_CITY_NORMALIZE:
                            city_norm = UA_CITY_NORMALIZE[city_norm]
                        
                        coords = ensure_city_coords(city_norm)
                        
                        if coords:
                            lat, lng = coords[:2]
                            threat_type, icon = classify(text)
                            
                            threat_id = f"{mid}_emoji_struct_{len(threats)}"
                            threats.append({
                                'id': threat_id,
                                'place': city_raw.title(),
                                'lat': lat,
                                'lng': lng,
                                'threat_type': threat_type,
                                'text': f"Загроза в {city_raw}",
                                'date': date_str,
                                'channel': channel,
                                'marker_icon': icon,
                                'source_match': 'emoji_structure_multi',
                                'count': 1
                            })
                            
                            add_debug_log(f"Multi emoji structure: {city_raw} -> {coords}", "emoji_struct_multi")
                        else:
                            add_debug_log(f"Multi emoji structure: No coords for {city_raw}", "emoji_struct_multi")
                    
                    # Check for priority result to combine
                    if '_current_priority_result' in globals() and globals()['_current_priority_result']:
                        combined_result = globals()['_current_priority_result'] + threats
                        add_debug_log(f"MULTI-SEGMENT: Combined priority result ({len(globals()['_current_priority_result'])}) with threats ({len(threats)}) = {len(combined_result)} total", "priority_combine")
                        # Clear the global priority result after use
                        globals()['_current_priority_result'] = None
                        return combined_result
                    return threats
                    
    except Exception:
        pass
    
    # Course towards single city ("курс(ом) на Батурин") -> place marker at that city
    try:
        import re as _re_course
        low_txt2 = text.lower()
        m_course = _re_course.search(r"курс(?:ом)?\s+на\s+([a-zа-яіїєґ\'ʼ'`\-\s]{3,60})(?=\s*(?:$|[,\.\!\?;]|\n))", low_txt2)
        if m_course:
            raw_city = m_course.group(1).strip()
            raw_city = raw_city.replace('\u02bc',"'").replace('ʼ',"'").replace('’',"'").replace('`',"'")
            base = UA_CITY_NORMALIZE.get(raw_city, raw_city)
            
            # Use enhanced coordinate lookup with Nominatim fallback
            coords = get_coordinates_enhanced(base, context="БпЛА курсом на")
            
            if not coords:
                # Legacy fallback for backwards compatibility
                enriched = ensure_city_coords(base)
                if enriched:
                    if isinstance(enriched, tuple) and len(enriched)==3:
                        coords = (enriched[0], enriched[1])
                    else:
                        coords = enriched
                    if isinstance(enriched, tuple) and len(enriched)==3:
                        coords = (enriched[0], enriched[1])
                    else:
                        coords = enriched
            if coords:
                lat,lng = coords
                threat_type, icon = classify(text)
                
                # Extract course information for Shahed threats
                course_info = None
                if threat_type == 'shahed':
                    course_info = extract_shahed_course_info(text)
                
                # Extract count from text (look for pattern like "10х БпЛА")
                uav_count = 1
                import re as _re_count
                count_match = _re_count.search(r'(\d+)\s*[xх×]\s*бпла', low_txt2)
                if count_match:
                    uav_count = int(count_match.group(1))
                
                # Create multiple tracks for multiple drones
                tracks_to_create = max(1, uav_count)
                threat_tracks = []
                
                for i in range(tracks_to_create):
                    track_name = base.title()
                    if tracks_to_create > 1:
                        track_name += f" #{i+1}"
                    
                    # Add small coordinate offsets to prevent marker overlap
                    marker_lat = lat
                    marker_lng = lng
                    if tracks_to_create > 1:
                        # Create a chain pattern - drones one after another
                        offset_distance = 0.03  # ~3km offset between each drone
                        marker_lat += offset_distance * i
                        marker_lng += offset_distance * i * 0.5
                    
                    threat_data = {
                        'id': f"{mid}_{i+1}", 'place': track_name, 'lat': marker_lat, 'lng': marker_lng,
                        'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
                        'marker_icon': icon, 'source_match': 'course_to_city', 'count': 1
                    }
                    
                    # Add course information if available
                    if course_info:
                        threat_data.update({
                            'course_source': course_info.get('source_city'),
                            'course_target': course_info.get('target_city'),
                            'course_direction': course_info.get('course_direction'),
                            'course_type': course_info.get('course_type')
                        })
                    
                    threat_tracks.append(threat_data)
                
                return threat_tracks
    except Exception:
        pass
    
    # --- PRIORITY: Early explicit pattern for districts - MOVED UP TO AVOID CONFLICTS ---
    # Check before region direction processing to prevent fallback to oblast centers
    try:
        import re as _re_raion
        # Pattern 1: "<RaionName> район (<Oblast ...>)"
        m_raion_oblast = _re_raion.search(r'([A-Za-zА-Яа-яЇїІіЄєҐґ\'\-]{4,})\s+район\s*\(([^)]*обл[^)]*)\)', text)
        if m_raion_oblast:
            raion_token = m_raion_oblast.group(1).strip().lower()
            # Normalize morphological endings
            raion_base = _re_raion.sub(r'(ському|ского|ського|ский|ськiй|ськой|ським|ском)$', 'ський', raion_token)
            if raion_base in RAION_FALLBACK:
                lat, lng = RAION_FALLBACK[raion_base]
                threat_type, icon = classify(text)
                add_debug_log(f"PRIORITY: Early district processing - {raion_base} район -> {lat}, {lng}", "district_early")
                return [{
                    'id': str(mid), 'place': f"{raion_base.title()} район", 'lat': lat, 'lng': lng,
                    'threat_type': threat_type, 'text': text[:500],
                    'date': date_str, 'channel': channel, 'marker_icon': icon, 'source_match': 'raion_oblast_combo_early'
                }]
            else:
                add_debug_log(f"Early district processing - {raion_base} not found in RAION_FALLBACK", "district_early")

        # Pattern 2: "<RaionName> район <OblastName>" (без дужок)
        m_raion_oblast2 = _re_raion.search(r'([A-Za-zА-Яа-яЇїІіЄєҐґ\'\-]{4,})\s+район\s+([\w\']+(?:щини|щину|области|області))', text)
        if m_raion_oblast2:
            raion_token = m_raion_oblast2.group(1).strip().lower()
            # Normalize morphological endings
            raion_base = _re_raion.sub(r'(ському|ского|ського|ский|ськiй|ськой|ським|ском)$', 'ський', raion_token)
            if raion_base in RAION_FALLBACK:
                lat, lng = RAION_FALLBACK[raion_base]
                threat_type, icon = classify(text)
                add_debug_log(f"PRIORITY: Early district processing (format 2) - {raion_base} район -> {lat}, {lng}", "district_early")
                return [{
                    'id': str(mid), 'place': f"{raion_base.title()} район", 'lat': lat, 'lng': lng,
                    'threat_type': threat_type, 'text': text[:500],
                    'date': date_str, 'channel': channel, 'marker_icon': icon, 'source_match': 'raion_oblast_combo_early_v2'
                }]
            else:
                add_debug_log(f"Early district processing (format 2) - {raion_base} not found in RAION_FALLBACK", "district_early")
    except Exception as e:
        add_debug_log(f"Early district processing error: {e}", "district_early")
    
    # Region directional segments specifying part of oblast ("на сході Дніпропетровщини") possibly multiple in one line
    try:
        import re as _re_seg
        lower_full = text.lower()
        pattern = _re_seg.compile(r'на\s+([\w\-\s/]+?)\s+(?:частині\s+)?([a-zа-яіїєґ]+щина|[a-zа-яіїєґ]+щини|[a-zа-яіїєґ]+щину)')
        seg_matches = list(pattern.finditer(lower_full))
        seg_tracks = []
        used_spans = []
        if seg_matches:
            # Map Ukrainian directional forms to codes
            dir_map_words = {
                'північ':'n','південь':'s','схід':'e','захід':'w','сході':'e','заході':'w','півночі':'n','півдні':'s',
                'північно-схід':'ne','північно-сход':'ne','північно схід':'ne','південно-схід':'se','південно схід':'se',
                'північно-захід':'nw','північно захід':'nw','південно-захід':'sw','південно захід':'sw'
            }
            def direction_codes(raw:str):
                parts = [p.strip() for p in raw.replace('–','-').split('/') if p.strip()]
                out = []
                for p in parts:
                    # compress multiple spaces
                    p2 = ' '.join(p.split())
                    # find best match in dir_map_words by prefix
                    code=None
                    for k,v in dir_map_words.items():
                        if k in p2:
                            code=v; break
                    if not code:
                        # try simple endings
                        if p2.startswith('схід'): code='e'
                        elif p2.startswith('захід'): code='w'
                    if code and code not in out:
                        out.append(code)
                return out or ['center']
            for m in seg_matches:
                dir_raw = m.group(1).strip()
                region_raw = m.group(2).strip()
                # Normalize region key to match OBLAST_CENTERS keys
                region_key = None
                for k in OBLAST_CENTERS.keys():
                    if region_raw in k:
                        region_key = k
                        break
                if not region_key:
                    continue
                base_lat, base_lng = OBLAST_CENTERS[region_key]
                codes = direction_codes(dir_raw)
                for idx, code in enumerate(codes,1):
                    # offset placement (reuse logic similar to later region_direction block)
                    def offset(lat,lng,code):
                        lat_step = 0.55
                        lng_step = 0.85 / max(0.2, abs(math.cos(math.radians(lat))))
                        if code=='n': return lat+lat_step, lng
                        if code=='s': return lat-lat_step, lng
                        if code=='e': return lat, lng+lng_step
                        if code=='w': return lat, lng-lng_step
                        lat_diag=lat_step*0.8; lng_diag=lng_step*0.8
                        if code=='ne': return lat+lat_diag, lng+lng_diag
                        if code=='nw': return lat+lat_diag, lng-lng_diag
                        if code=='se': return lat-lat_diag, lng+lng_diag
                        if code=='sw': return lat-lat_diag, lng-lng_diag
                        return lat, lng
                    lat_o, lng_o = offset(base_lat, base_lng, code)
                    label_region = region_key.split()[0].title()
                    dir_label_map = {
                        'n':'північна частина','s':'південна частина','e':'східна частина','w':'західна частина',
                        'ne':'північно-східна частина','nw':'північно-західна частина','se':'південно-східна частина','sw':'південно-західна частина','center':'частина'
                    }
                    label = f"{label_region} ({dir_label_map.get(code,'частина')})"
                    threat_type, icon = classify(text)
                    
                    # Skip if this segment contains "курсом на [city]" after the region match
                    # to give priority to specific city course tracking
                    segment_after = text[m.end():]
                    if _re_seg.search(r'курсом?\s+на\s+(?:н\.п\.?\s*)?[А-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,}', segment_after, _re_seg.IGNORECASE):
                        continue
                    
                    seg_tracks.append({
                        'id': f"{mid}_rd{len(seg_tracks)+1}", 'place': label, 'lat': lat_o, 'lng': lng_o,
                        'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
                        'marker_icon': icon, 'source_match': 'region_direction_segment'
                    })
            if seg_tracks:
                return seg_tracks
    except Exception as e:
        try: log.debug(f'region_dir_segments error: {e}')
        except: pass
    # --- Pre-split case: several bold oblast headers inside a single line (e.g. **Полтавщина:** ... **Дніпропетровщина:** ... ) ---
    try:
        import re as _pre_hdr_re
        # Detect two or more bold oblast headers
        hdr_pat = re.compile(r'(\*\*[A-Za-zА-Яа-яЇїІіЄєҐґ]+щина\*\*:)')
        if text.count('**') >= 4:  # quick filter
            matches = list(hdr_pat.finditer(text))
            if len(matches) >= 2:
                # Insert newline before each header (except first) if not already line-start
                # Build new text chunk-wise
                new_parts = []
                last = 0
                for i, m in enumerate(matches):
                    start = m.start()
                    if i == 0 and start > 0 and text[start-1] != '\n':
                        # ensure header is at line start
                        new_parts.append(text[last:start])
                    elif i > 0:
                        # append text before header ensuring newline separation
                        segment = text[last:start]
                        if not segment.endswith('\n'):
                            segment += '\n'
                        new_parts.append(segment)
                    last = start
                # append remaining
                new_parts.append(text[last:])
                new_text_joined = ''.join(new_parts)
                if new_text_joined != text:
                    text = new_text_joined
    except Exception:
        pass
    # --- Спец. обработка многострочных сообщений с заголовками-областями и списком городов ---
    import unicodedata
    def normalize_city_name(name):
        # Привести к нижнему регистру, заменить все апострофы на стандартный, убрать лишние пробелы
        n = name.lower().strip()
        n = n.replace('ʼ', "'").replace('’', "'").replace('`', "'")
        n = unicodedata.normalize('NFC', n)
        
        # Convert mixed Latin/Cyrillic to full Cyrillic (e.g. "Kov'яги" -> "ков'яги")
        # Common Latin-Cyrillic lookalikes in Ukrainian city names
        latin_to_cyrillic = {
            'a': 'а', 'e': 'е', 'i': 'і', 'o': 'о', 'p': 'р', 'c': 'с', 
            'y': 'у', 'x': 'х', 'k': 'к', 'h': 'н', 't': 'т', 'm': 'м',
            'b': 'в', 'v': 'в', 'n': 'н', 's': 'с', 'r': 'р'
        }
        
        # Only convert if string contains mixed Latin + Cyrillic (heuristic: has both ranges)
        has_cyrillic = any(ord(c) >= 0x0400 and ord(c) <= 0x04FF for c in n)
        has_latin = any('a' <= c <= 'z' for c in n)
        
        if has_cyrillic and has_latin:
            # Convert Latin lookalikes to Cyrillic
            n_converted = ''
            for c in n:
                if 'a' <= c <= 'z':
                    n_converted += latin_to_cyrillic.get(c, c)
                else:
                    n_converted += c
            n = n_converted
        
        return n

    def sanitize_course_destination(name: str) -> str:
        if not name:
            return ''
        cleaned = name.strip()
        cleaned = re.sub(r'[\\/|]+', ' ', cleaned)
        cleaned = re.sub(r'\s+', ' ', cleaned)
        cleaned = re.sub(r'(район|району|районі|районів|района|р-н|область|області|обл\.|громада|громаді|громади|community|district|sector|сектор|місто|місті)$', '', cleaned, flags=re.IGNORECASE).strip()
        cleaned = re.sub(r'\b(район|району|районі|района|р-н|область|області|обл\.|громада|громади|community|district|sector|сектор|місто|місті)\b', '', cleaned, flags=re.IGNORECASE)
        cleaned = re.sub(r'\s+', ' ', cleaned).strip(" .,'-\"")
        return cleaned

    def extract_course_targets(raw: str):
        if not raw:
            return []
        parts = re.split(r'\s*(?:[\\/|,;]|\s+та\s+|\s+і\s+|\s+и\s+|\s+або\s+|\s+or\s+)\s*', raw, flags=re.IGNORECASE)
        targets = []
        for part in parts:
            candidate = sanitize_course_destination(part)
            if candidate:
                targets.append(candidate)
        if targets:
            return targets
        cleaned = sanitize_course_destination(raw)
        return [cleaned] if cleaned else []
    # Если сообщение содержит несколько строк с заголовками-областями и городами
    # Предварительно уберём чисто донатные/подписи строки из многострочного блока, чтобы они не мешали
    raw_lines = text.splitlines()
    
    # NEW: Handle single-line messages with multiple regions like "Чернігівщина: 1 БпЛА на Козелець ... Сумщина: 3 БпЛА..."
    # First try to split by region headers in single line
    single_line_regions = ['чернігівщин', 'сумщин', 'харківщин', 'полтавщин', 'херсонщин', 'донецьк', 'луганщин']
    if len(raw_lines) == 1 and any(region in text.lower() for region in single_line_regions):
        add_debug_log(f"Single-line multi-region message detected, raw_lines count: {len(raw_lines)}", "multi_region")
        # Split by oblast headers that have colon after them
        import re as _re_split
        region_split = _re_split.split(r'([А-ЯІЇЄЁа-яіїєё]+щина):\s*', text)
        add_debug_log(f"Region split result: {region_split}", "multi_region")
        if len(region_split) > 2:  # We have actual splits
            new_lines = []
            for i in range(1, len(region_split), 2):  # Take every odd element (region name) and next even (content)
                if i+1 < len(region_split):
                    region_name = region_split[i]
                    content = region_split[i+1].strip()
                    new_lines.append(f"{region_name}:")
                    new_lines.append(content)
                    add_debug_log(f"Added region header: '{region_name}:' and content: '{content}'", "multi_region")
            if new_lines:
                raw_lines = new_lines
                add_debug_log(f"Split single line into {len(raw_lines)} lines for multi-region processing", "multi_region")
        else:
            add_debug_log("Region split failed, keeping original format", "multi_region")
    
    cleaned_for_multiline = []
    import re as _re_clean
    donation_keys = ['монобанк','send.monobank','patreon','donat','донат','підтримати канал','підтримати']
    for l in raw_lines:
        ls = l.strip()
        if not ls:
            continue
        # If line combines header and content ("Хмельниччина: Група КР ..." possibly with formatting ** **)
        m_comb = _re_clean.match(r'^\**([A-Za-zА-Яа-яЇїІіЄєҐґ]+щина)\**:\s*(.+)$', ls)
        if m_comb:
            header_part = m_comb.group(1) + ':'
            rest_part = m_comb.group(2).strip()
            cleaned_for_multiline.append(header_part)
            ls = rest_part  # continue processing rest_part below (could still contain links)
        low_ls = ls.lower()
        # Strip markdown links / segments that are purely donation or service references, keep threat fragment
        def _strip_bad_links(s: str):
            # Remove any [text](url) where text or url contains donation_keys
            def _repl(m):
                inner_text = m.group(1).lower()
                url = m.group(2).lower()
                if any(k in inner_text or k in url for k in donation_keys):
                    return ''
                return m.group(0)
            s2 = _re_clean.sub(r'\[([^\]]{0,60})\]\(([^) ]+?)\)', _repl, s)
            return s2
        ls_no_links = _strip_bad_links(ls)
        low_no_links = ls_no_links.lower()
        if any(k in low_no_links for k in donation_keys):
            # If after stripping links still only donation noise and no threat keywords, skip.
            if not any(t in low_no_links for t in ['бпла','курс','ракета','ракети','рупа','група','кр']):
                continue
            # Else remove the donation substrings explicitly.
            for k in donation_keys:
                low_no_links = low_no_links.replace(k,' ')
            ls_no_links = ' '.join(low_no_links.split())
        cleaned_for_multiline.append(ls_no_links.strip())
    lines = cleaned_for_multiline
    
    oblast_hdr = None
    multi_city_tracks = []
    processed_lines_count = 0
    add_debug_log(f"Processing {len(lines)} cleaned lines for multi-city tracks", "multi_region")
    
    for ln in lines:
        processed_lines_count += 1
        add_debug_log(f"Processing line {processed_lines_count}/{len(lines)}: '{ln[:80]}...'", "multi_region")
        
        # PRIORITY: Check for specific region-city patterns FIRST
        import re as _re_region_city
        ln_lower = ln.lower()
        
        # Pattern 1: "на [region] [count] шахедів на [city]"
        region_city_pattern1 = _re_region_city.compile(r'на\s+([а-яіїєґ]+щин[іау]?)\s+(\d+)\s+шахед[іїв]*\s+на\s+([а-яіїєґ\'\-\s]+)', _re_region_city.IGNORECASE)
        region_city_match1 = region_city_pattern1.search(ln_lower)
        
        # Pattern 2: "[region] - шахеди на [city]"
        region_city_pattern2 = _re_region_city.compile(r'([а-яіїєґ]+щин[ауи]?)\s*-\s*шахед[іїив]*\s+на\s+([а-яіїєґ\'\-\s]+)', _re_region_city.IGNORECASE)
        region_city_match2 = region_city_pattern2.search(ln_lower)
        
        # Pattern 3: "[region] ([city] р-н)" - for district headquarters
        region_district_pattern = _re_region_city.compile(r'([а-яіїєґ]+щин[ауи]?)\s*\(\s*([а-яіїєґ\'\-\s]+)\s+р[-\s]*н\)', _re_region_city.IGNORECASE)
        region_district_match = region_district_pattern.search(ln_lower)
        
        add_debug_log(f"CHECKING region-city patterns for line: '{ln_lower}'", "region_city_debug")
        
        region_city_match = region_city_match1 or region_city_match2
        
        if region_district_match:
            # Handle "чернігівщина (новгород-сіверський р-н)" format
            region_raw, district_raw = region_district_match.groups()
            target_city = district_raw.strip()
            
            add_debug_log(f"REGION-DISTRICT pattern FOUND: region='{region_raw}', district='{district_raw}'", "region_district")
            
            # Normalize city name and try to find coordinates
            city_norm = target_city.lower()
            # Apply UA_CITY_NORMALIZE rules if available
            if 'UA_CITY_NORMALIZE' in globals():
                city_norm = UA_CITY_NORMALIZE.get(city_norm, city_norm)
            coords = CITY_COORDS.get(city_norm)
            
            add_debug_log(f"District city lookup: '{target_city}' -> '{city_norm}' -> {coords}", "region_district")
            
            if coords:
                lat, lng = coords
                threat_type, icon = classify(ln)
                
                multi_city_tracks.append({
                    'id': f"{mid}_region_district_{len(multi_city_tracks)+1}",
                    'place': target_city.title(),
                    'lat': lat,
                    'lng': lng,
                    'threat_type': threat_type,
                    'text': ln[:500],
                    'date': date_str,
                    'channel': channel,
                    'marker_icon': icon,
                    'source_match': 'region_district',
                    'count': 1
                })
                add_debug_log(f"Created region-district marker: {target_city.title()}", "region_district")
                continue  # Skip further processing of this line
            else:
                add_debug_log(f"No coordinates found for district city: '{target_city}' (normalized: '{city_norm}')", "region_district")
        
        elif region_city_match:
            if region_city_match1:
                region_raw, count_str, city_raw = region_city_match1.groups()
                count = int(count_str) if count_str.isdigit() else 1
            else:  # region_city_match2
                region_raw, city_raw = region_city_match2.groups()
                count = 1  # default count for pattern 2
                
            target_city = city_raw.strip()
            
            add_debug_log(f"REGION-CITY pattern FOUND: region='{region_raw}', count={count}, city='{target_city}'", "region_city")
            
            # Normalize city name and try to find coordinates
            city_norm = target_city.lower()
            # Apply UA_CITY_NORMALIZE rules if available
            if 'UA_CITY_NORMALIZE' in globals():
                city_norm = UA_CITY_NORMALIZE.get(city_norm, city_norm)
            coords = CITY_COORDS.get(city_norm)
            
            add_debug_log(f"City lookup: '{target_city}' -> '{city_norm}' -> {coords}", "region_city")
            
            if coords:
                lat, lng = coords
                threat_type, icon = classify(ln)
                
                multi_city_tracks.append({
                    'id': f"{mid}_region_city_{len(multi_city_tracks)+1}",
                    'place': target_city.title(),
                    'lat': lat,
                    'lng': lng,
                    'threat_type': threat_type,
                    'text': ln[:500],
                    'date': date_str,
                    'channel': channel,
                    'marker_icon': icon,
                    'source_match': 'region_city_shahed',
                    'count': count
                })
                add_debug_log(f"Created region-city marker: {target_city.title()} ({count} шахедів)", "region_city")
                continue  # Skip further processing of this line
            else:
                add_debug_log(f"No coordinates found for city: '{target_city}' (normalized: '{city_norm}')", "region_city")
        else:
            add_debug_log(f"REGION-CITY pattern NOT FOUND for line: '{ln_lower}'", "region_city_debug")
        
        # NEW: Pattern "БпЛА на [direction] [region_genitive] курсом на [target]"
        # Example: "БпЛА на півночі Херсонщини курсом на Миколаївщину"
        regional_course_pattern = re.search(r'(бпла|безпілотник|шахед|дрон).*(на\s+(півночі|півдні|сході|заході|центрі))?\s*([а-яіїєґ]+щин[іуиа])\s*.*курсом\s+на\s+([а-яіїєґ\'\-\s]+)', ln_lower, re.IGNORECASE)
        if regional_course_pattern:
            direction_part = regional_course_pattern.group(3) if regional_course_pattern.group(2) else None
            region_genitive = regional_course_pattern.group(4)
            target_raw = regional_course_pattern.group(5).strip()
            
            # Normalize target (could be city or region)
            target_norm = target_raw.replace('щину', 'щина').replace('щини', 'щина').strip()
            
            add_debug_log(f"REGIONAL COURSE pattern: direction={direction_part}, region={region_genitive}, target={target_raw} -> {target_norm}", "regional_course")
            
            # Try to find coordinates for target
            target_city = normalize_city_name(target_norm)
            target_city = UA_CITY_NORMALIZE.get(target_city, target_city)
            coords = CITY_COORDS.get(target_city)
            if not coords and SETTLEMENTS_INDEX:
                coords = SETTLEMENTS_INDEX.get(target_city)
            
            # If target is a region (щина), use region center
            if not coords and ('щина' in target_city or 'щини' in target_city):
                # Try to get region center coordinates
                region_centers = {
                    'миколаївщина': (46.975, 31.995),
                    'херсонщина': (46.635, 32.617),
                    'чернігівщина': (51.4982, 31.2893),
                    'сумщина': (50.9077, 34.7981),
                    'полтавщина': (49.5883, 34.5514),
                    'харківщина': (49.9935, 36.2304),
                    'дніпропетровщина': (48.4647, 35.0462),
                    'запоріжжя': (47.8388, 35.1396),
                    'донеччина': (48.0159, 37.8028),
                }
                coords = region_centers.get(target_city)
                if coords:
                    add_debug_log(f"Using region center for '{target_city}': {coords}", "regional_course")
            
            if coords:
                lat, lng = coords
                threat_type, icon = classify(ln)
                
                # Extract count if present
                count_match = re.search(r'(\d+)\s*[xх×]?\s*(бпла|шахед)', ln_lower)
                count = int(count_match.group(1)) if count_match else 1
                
                place_label = target_norm.title()
                if direction_part:
                    place_label += f" ({direction_part})"
                
                multi_city_tracks.append({
                    'id': f"{mid}_regional_course_{len(multi_city_tracks)+1}",
                    'place': place_label,
                    'lat': lat,
                    'lng': lng,
                    'threat_type': threat_type,
                    'text': clean_text(ln)[:500],
                    'date': date_str,
                    'channel': channel,
                    'marker_icon': icon,
                    'source_match': 'regional_course',
                    'count': count
                })
                add_debug_log(f"Created regional course marker: {place_label} at {lat}, {lng}", "regional_course")
                continue
            else:
                add_debug_log(f"No coordinates for regional course target: '{target_raw}' (norm: '{target_city}')", "regional_course")
        
        # NEW: Check for regional direction patterns WITHOUT specific city (e.g. "БпЛА на сході Сумщини ➡️ курсом на південь")
        # These should create regional markers, not skip
        region_direction_pattern = re.search(r'(бпла|безпілотник|шахед|дрон).*(на\s+(півночі|півдні|сході|заході)).*([а-яіїєґ]+щин[іуиа])', ln_lower, re.IGNORECASE)
        if region_direction_pattern and not region_city_match and not regional_course_pattern:
            add_debug_log(f"REGIONAL DIRECTION pattern detected (no specific city): {ln[:100]}", "regional_direction")
            # This line should be processed by regional parser - don't add to multi_city_tracks yet
            # Instead, extract the region and direction to create a regional marker later
            # For now, just mark it for special processing
        
        # Check if line contains БпЛА information without specific course
        ln_lower = ln.lower()
        # Support both Cyrillic БпЛА and Latin-mixed БпЛA variants, and also Shahed
        has_uav = 'бпла' in ln_lower or 'бпла' in ln_lower or 'безпілотник' in ln_lower or 'дрон' in ln_lower or 'bpla' in ln_lower or 'шахед' in ln_lower or 'shahed' in ln_lower
        if has_uav:
            add_debug_log(f"Line contains UAV keywords", "multi_region")
            if not any(keyword in ln_lower for keyword in ['курс', 'на ', 'районі']):
                add_debug_log(f"UAV line lacks direction keywords (курс/на/районі) - general activity message", "multi_region")
        else:
            add_debug_log(f"Line does not contain UAV keywords", "multi_region")
        # Если строка — это заголовок области (например, "Сумщина:")
        # Заголовок области: строка, заканчивающаяся на ':' (возможен пробел перед / после) или формой '<область>:' с лишними пробелами
        # NEW: Also handle format like "**🚨 Конотопський район (Сумська обл.)**"
        import re
        oblast_hdr_match = None
        
        # Standard format: "Сумщина:" or "Чернігівщина:"
        if re.match(r'^[A-Za-zА-Яа-яЇїІіЄєҐґ\-ʼ`\s]+:\s*$', ln):
            oblast_hdr = ln.split(':')[0].strip().lower()
            oblast_hdr_match = True
            add_debug_log(f"Standard region header format detected: '{oblast_hdr}'", "multi_region")
        
        # NEW format: "**🚨 Конотопський район (Сумська обл.)**" or similar with oblast in parentheses
        elif re.search(r'\(([А-ЯІЇЄЁа-яіїєё]+ська\s+обл\.?)\)', ln):
            oblast_match = re.search(r'\(([А-ЯІЇЄЁа-яіїєё]+ська\s+обл\.?)\)', ln)
            if oblast_match:
                oblast_full = oblast_match.group(1).lower().strip()
                # Convert "сумська обл." to "сумщина"
                oblast_hdr = oblast_full.replace('ська обл.', 'щина').replace('ська обл', 'щина')
                oblast_hdr_match = True
                add_debug_log(f"Parentheses region header format detected: '{oblast_full}' -> '{oblast_hdr}'", "multi_region")
        
        # NEW format: "Харківщина — БпЛА на Гути" - region with dash followed by content
        elif re.search(r'^([А-ЯІЇЄЁа-яіїєё]+щина)\s*[-–—]\s*(.+)', ln):
            dash_match = re.search(r'^([А-ЯІЇЄЁа-яіїєё]+щина)\s*[-–—]\s*(.+)', ln)
            if dash_match:
                oblast_hdr = dash_match.group(1).lower().strip()
                remaining_content = dash_match.group(2).strip()
                oblast_hdr_match = True
                add_debug_log(f"Dash region header format detected: '{oblast_hdr}' with content: '{remaining_content}'", "multi_region")
                # Set the line content to just the remaining part after dash for further processing
                ln = remaining_content
        
        # NEW: Detect regional genitive forms like "Сумщини", "Харківщини", etc.
        elif re.search(r'\b([а-яіїєґ]+щин[иі])\b', ln_lower):
            genitive_match = re.search(r'\b([а-яіїєґ]+щин[иі])\b', ln_lower)
            if genitive_match:
                genitive_form = genitive_match.group(1)
                # Convert genitive to nominative: "сумщини" -> "сумщина"
                potential_oblast = genitive_form.replace('щини', 'щина').replace('щині', 'щина')
                
                # Validate that this is actually a known region, not just any word ending with щин[иі]
                known_regions = ['сумщина', 'чернігівщина', 'харківщина', 'полтавщина', 'херсонщина', 
                               'донеччина', 'луганщина', 'запорожжя', 'дніпропетровщина', 'київщина',
                               'львівщина', 'івано-франківщина', 'тернопільщина', 'хмельниччина',
                               'рівненщина', 'волинщина', 'житомирщина', 'вінниччина', 'черкащина',
                               'кіровоградщина', 'миколаївщина', 'одещина']
                
                if potential_oblast in known_regions:
                    oblast_hdr = potential_oblast
                    oblast_hdr_match = True
                    add_debug_log(f"Genitive region format detected: '{genitive_form}' -> '{oblast_hdr}' in line: '{ln}'", "multi_region")
                    add_debug_log(f"POTENTIAL ISSUE: Oblast set to '{oblast_hdr}' from genitive pattern in: '{ln}'", "oblast_detection")
                else:
                    add_debug_log(f"Ignored potential genitive form '{genitive_form}' -> '{potential_oblast}' (not in known regions) in line: '{ln}'", "multi_region")
        
        if oblast_hdr_match:
            add_debug_log(f"Region header detected: '{oblast_hdr}'", "multi_region")
            if oblast_hdr.startswith('на '):  # handle 'на харківщина:' header variant
                oblast_hdr = oblast_hdr[3:].strip()
            if oblast_hdr and oblast_hdr[0] in ('е','є') and oblast_hdr.endswith('гівщина'):
                # восстановить черниговщина -> чернігівщина (fix dropped leading Ч)
                oblast_hdr = 'чернігівщина'
            # Доп. почин восстановлений первых букв для областей (потеря первой буквы)
            if oblast_hdr and oblast_hdr.endswith('ївщина') and oblast_hdr != 'київщина':
                oblast_hdr = 'київщина'
            if oblast_hdr and oblast_hdr.endswith('нниччина') and oblast_hdr != 'вінниччина':
                oblast_hdr = 'вінниччина'
            # header detected
            add_debug_log(f"Final region header: '{oblast_hdr}'", "multi_region")
            continue
        try:
            add_debug_log(f"MLINE_LINE oblast={oblast_hdr} raw='{ln}'", "multi_region")
        except Exception:
            pass
        
        # NEW: Check for specific direction patterns before falling back to general UAV activity
        import re
        ln_lower = ln.lower()
        
        # NEW: Pattern "кружляє над/над [city]"
        if 'кружляє' in ln_lower or 'кружля' in ln_lower:
            kruzhlia_match = re.search(r'кружля[єюя]\s+(?:над\s+)?([А-ЯІЇЄЁа-яіїєё\'\-\s]+?)(?:\s*[\.\,\!\?;]|$)', ln, re.IGNORECASE)
            if kruzhlia_match:
                city_raw = kruzhlia_match.group(1).strip()
                city_norm = normalize_city_name(city_raw)
                city_norm = UA_CITY_NORMALIZE.get(city_norm, city_norm)
                coords = CITY_COORDS.get(city_norm) or (SETTLEMENTS_INDEX.get(city_norm) if SETTLEMENTS_INDEX else None)
                
                if coords:
                    lat, lng = coords
                    threat_type, icon = classify(ln)
                    count_match = re.search(r'(\d+)[xх×]?\s*бпла', ln_lower)
                    count = int(count_match.group(1)) if count_match else 1
                    
                    # Create multiple tracks if count > 1
                    for i in range(count):
                        place_label = city_norm.title()
                        if count > 1:
                            place_label += f" #{i+1} (кружляє)"
                        else:
                            place_label += f" (кружляє)"
                        
                        # Add offset for multiple drones
                        marker_lat, marker_lng = lat, lng
                        if count > 1:
                            offset_distance = 0.03
                            marker_lat += offset_distance * i
                            marker_lng += offset_distance * i * 0.5
                        
                        multi_city_tracks.append({
                            'id': f"{mid}_kruzhlia_{len(multi_city_tracks)+1}",
                            'place': place_label,
                            'lat': marker_lat,
                            'lng': marker_lng,
                            'threat_type': threat_type,
                            'text': clean_text(ln)[:500],
                            'date': date_str,
                            'channel': channel,
                            'marker_icon': icon,
                            'source_match': 'kruzhlia_nad',
                            'count': 1
                        })
                    add_debug_log(f"Created {count} marker(s) for 'кружляє': {city_norm.title()}", "kruzhlia")
                    continue
        
        # NEW: Pattern "північніше/південніше/східніше/західніше [city]"
        if any(direction in ln_lower for direction in ['північніше', 'південніше', 'східніше', 'західніше']):
            direction_match = re.search(r'(північніше|південніше|східніше|західніше)\s+([А-ЯІЇЄЁа-яіїєё\'\-\s]+?)(?:\s*[\.\,\!\?;]|$)', ln, re.IGNORECASE)
            if direction_match:
                direction_type = direction_match.group(1).lower()
                city_raw = direction_match.group(2).strip()
                city_norm = normalize_city_name(city_raw)
                city_norm = UA_CITY_NORMALIZE.get(city_norm, city_norm)
                coords = CITY_COORDS.get(city_norm) or (SETTLEMENTS_INDEX.get(city_norm) if SETTLEMENTS_INDEX else None)
                
                if coords:
                    lat, lng = coords
                    # Apply directional offset based on direction type
                    offset = 0.15  # ~15km
                    if direction_type == 'північніше':
                        lat += offset
                    elif direction_type == 'південніше':
                        lat -= offset
                    elif direction_type == 'східніше':
                        lng += offset
                    elif direction_type == 'західніше':
                        lng -= offset
                    
                    threat_type, icon = classify(ln)
                    count_match = re.search(r'(\d+)[xх×]?\s*бпла', ln_lower)
                    count = int(count_match.group(1)) if count_match else 1
                    
                    # Create multiple tracks if count > 1
                    for i in range(count):
                        place_label = f"{direction_type.title()} {city_norm.title()}"
                        if count > 1:
                            place_label += f" #{i+1}"
                        
                        # Add offset for multiple drones
                        marker_lat, marker_lng = lat, lng
                        if count > 1:
                            offset_distance = 0.03
                            marker_lat += offset_distance * i
                            marker_lng += offset_distance * i * 0.5
                        
                        multi_city_tracks.append({
                            'id': f"{mid}_direction_{len(multi_city_tracks)+1}",
                            'place': place_label,
                            'lat': marker_lat,
                            'lng': marker_lng,
                            'threat_type': threat_type,
                            'text': clean_text(ln)[:500],
                            'date': date_str,
                            'channel': channel,
                            'marker_icon': icon,
                            'source_match': f'directional_{direction_type}',
                            'count': 1
                        })
                    add_debug_log(f"Created {count} marker(s) for '{direction_type}': {city_norm.title()}", "directional")
                    continue
        
        # NEW: Pattern "на/через [city]" - combined "на" and "через"
        if re.search(r'на/через\s+[А-ЯІЇЄЁа-яіїєё]', ln, re.IGNORECASE):
            na_cherez_match = re.search(r'(\d+)[xх×]?\s*бпла\s+на/через\s+([А-ЯІЇЄЁа-яіїєё\'\-\s]+?)(?:\s*[\.\,\!\?;]|$)', ln, re.IGNORECASE)
            if na_cherez_match:
                count = int(na_cherez_match.group(1)) if na_cherez_match.group(1) else 1
                city_raw = na_cherez_match.group(2).strip()
                city_norm = normalize_city_name(city_raw)
                city_norm = UA_CITY_NORMALIZE.get(city_norm, city_norm)
                coords = CITY_COORDS.get(city_norm) or (SETTLEMENTS_INDEX.get(city_norm) if SETTLEMENTS_INDEX else None)
                
                if coords:
                    lat, lng = coords
                    threat_type, icon = classify(ln)
                    
                    # Create multiple tracks if count > 1
                    for i in range(count):
                        place_label = city_norm.title()
                        if count > 1:
                            place_label += f" #{i+1} (на/через)"
                        else:
                            place_label += f" (на/через)"
                        
                        # Add offset for multiple drones
                        marker_lat, marker_lng = lat, lng
                        if count > 1:
                            offset_distance = 0.03
                            marker_lat += offset_distance * i
                            marker_lng += offset_distance * i * 0.5
                        
                        multi_city_tracks.append({
                            'id': f"{mid}_na_cherez_{len(multi_city_tracks)+1}",
                            'place': place_label,
                            'lat': marker_lat,
                            'lng': marker_lng,
                            'threat_type': threat_type,
                            'text': clean_text(ln)[:500],
                            'date': date_str,
                            'channel': channel,
                            'marker_icon': icon,
                            'source_match': 'na_cherez',
                            'count': 1
                        })
                    add_debug_log(f"Created {count} marker(s) for 'на/через': {city_norm.title()}", "na_cherez")
                    continue
        
        # NEW: Pattern "з ТОТ в напрямку [city]" - drones from occupied territory
        if 'з тот' in ln_lower or 'з tot' in ln_lower:
            tot_match = re.search(r'(\d+)[xх×]?\s*бпла\s+з\s+тот\s+(?:в\s+напрямку|на)\s+([А-ЯІЇЄЁа-яіїєё\'\-\s]+?)(?:\s*[\.\,\!\?;]|$)', ln, re.IGNORECASE)
            if tot_match:
                count = int(tot_match.group(1)) if tot_match.group(1) else 1
                city_raw = tot_match.group(2).strip()
                city_norm = normalize_city_name(city_raw)
                city_norm = UA_CITY_NORMALIZE.get(city_norm, city_norm)
                coords = CITY_COORDS.get(city_norm) or (SETTLEMENTS_INDEX.get(city_norm) if SETTLEMENTS_INDEX else None)
                
                if coords:
                    lat, lng = coords
                    threat_type, icon = classify(ln)
                    
                    # Create multiple tracks if count > 1
                    for i in range(count):
                        place_label = city_norm.title()
                        if count > 1:
                            place_label += f" #{i+1} (з ТОТ)"
                        else:
                            place_label += f" (з ТОТ)"
                        
                        # Add offset for multiple drones
                        marker_lat, marker_lng = lat, lng
                        if count > 1:
                            offset_distance = 0.03
                            marker_lat += offset_distance * i
                            marker_lng += offset_distance * i * 0.5
                        
                        multi_city_tracks.append({
                            'id': f"{mid}_tot_{len(multi_city_tracks)+1}",
                            'place': place_label,
                            'lat': marker_lat,
                            'lng': marker_lng,
                            'threat_type': threat_type,
                            'text': clean_text(ln)[:500],
                            'date': date_str,
                            'channel': channel,
                            'marker_icon': icon,
                            'source_match': 'z_tot',
                            'count': 1
                        })
                    add_debug_log(f"Created {count} marker(s) for 'з ТОТ': {city_norm.title()}", "z_tot")
                    continue
        
        # Check if line has БпЛА or starts with a number (implying drones)
        has_bpla = 'бпла' in ln_lower
        starts_with_number = re.match(r'^\d+', ln.strip())
        has_direction_pattern = any(pattern in ln_lower for pattern in ['у напрямку', 'через', 'повз'])
        
        if (has_bpla or starts_with_number) and has_direction_pattern:
            target_cities = []
            
            # Pattern 1: "у напрямку [city]"
            naprym_pattern = r'у\s+напрямку\s+([А-ЯІЇЄЁа-яіїєё\'\-\s]+?)(?:\s*[\.\,\!\?;]|$)'
            naprym_matches = re.findall(naprym_pattern, ln, re.IGNORECASE)
            for city_raw in naprym_matches:
                target_cities.append(('у напрямку', city_raw.strip()))
            
            # Pattern 2: "через [city]"
            cherez_pattern = r'через\s+([А-ЯІЇЄЁа-яіїєё\'\-\s]+?)(?:\s*[\.\,\!\?;]|$)'
            cherez_matches = re.findall(cherez_pattern, ln, re.IGNORECASE)
            for city_raw in cherez_matches:
                target_cities.append(('через', city_raw.strip()))
            
            # Pattern 3: "повз [city]"
            povz_pattern = r'повз\s+([А-ЯІЇЄЁа-яіїєё\'\-\s]+?)(?:\s*[\.\,\!\?;]|$)'
            povz_matches = re.findall(povz_pattern, ln, re.IGNORECASE)
            for city_raw in povz_matches:
                target_cities.append(('повз', city_raw.strip()))
            
            # Process extracted target cities
            for direction_type, city_raw in target_cities:
                city_clean = city_raw.strip()
                city_norm = city_clean.lower()
                
                # Apply UA_CITY_NORMALIZE rules
                if city_norm in UA_CITY_NORMALIZE:
                    city_norm = UA_CITY_NORMALIZE[city_norm]
                
                # Try to get coordinates
                coords = CITY_COORDS.get(city_norm)
                if not coords and SETTLEMENTS_INDEX:
                    coords = SETTLEMENTS_INDEX.get(city_norm)
                if not coords:
                    coords = SETTLEMENT_FALLBACK.get(city_norm) if 'SETTLEMENT_FALLBACK' in globals() else None
                
                add_debug_log(f"Direction pattern '{direction_type}' found city: '{city_raw}' -> '{city_norm}' -> coords: {coords}", "direction_processing")
                
                if coords:
                    lat, lng = coords
                    threat_type, icon = classify(ln)
                    
                    # Create label showing direction
                    place_label = city_clean.title()
                    if direction_type == 'у напрямку':
                        place_label += f" (напрямок)"
                    elif direction_type == 'через':
                        place_label += f" (через)"
                    elif direction_type == 'повз':
                        place_label += f" (повз)"
                    
                    multi_city_tracks.append({
                        'id': f"{mid}_direction_{len(multi_city_tracks)+1}",
                        'place': place_label,
                        'lat': lat,
                        'lng': lng,
                        'threat_type': threat_type,
                        'text': clean_text(ln)[:500],
                        'date': date_str,
                        'channel': channel,
                        'marker_icon': icon,
                        'source_match': f'direction_{direction_type.replace(" ", "_")}',
                        'count': 1
                    })
                    add_debug_log(f"Created direction marker: {place_label} ({direction_type})", "direction_processing")
                else:
                    add_debug_log(f"No coordinates found for direction target: '{city_raw}' (normalized: '{city_norm}')", "direction_processing")
            
            # If we found any target cities with valid coordinates, skip general UAV processing
            if any(coords for _, coords in [(city_norm, CITY_COORDS.get(UA_CITY_NORMALIZE.get(city_raw.strip().lower(), city_raw.strip().lower()))) for _, city_raw in target_cities]):
                add_debug_log(f"Direction processing complete, skipping general UAV activity for line: '{ln}'", "direction_processing")
                continue
        
        # NEW: Create markers for general UAV activity messages (without specific direction)
        if 'бпла' in ln_lower or 'безпілотник' in ln_lower or 'дрон' in ln_lower:
            add_debug_log(f"UAV activity detected in line: '{ln}', oblast_hdr: '{oblast_hdr}'", "uav_processing")
            
            # CRITICAL: Check if message has specific directional patterns - if yes, skip general marker
            # Let the main parser handle "курсом на", "напрямок на", "у напрямку", "на [місто]" etc.
            has_directional_pattern = any(pattern in ln_lower for pattern in [
                'курсом на', 'курс на', 'напрямок на', 'напрямку на', 
                'ціль на', 'у напрямку', 'у бік', 'в бік', 'через', 'повз',
                'маневрує в районі', 'в районі', 'бпла на ', 'дрон на '
            ])
            
            # Check for emoji arrows BUT only if there's actual text (city name) after the arrow
            if '➡' in ln and not has_directional_pattern:
                # Extract text after arrow to see if there's a city name
                arrow_match = re.search(r'➡[️\s]*(.{3,})', ln)
                if arrow_match:
                    text_after_arrow = arrow_match.group(1).strip().strip('ㅤ️ ').strip()
                    # If there's meaningful text after arrow (not just punctuation/links), treat as directional
                    if text_after_arrow and len(text_after_arrow) > 1 and not text_after_arrow.startswith(('http', '[', '**', '➡')):
                        has_directional_pattern = True
            
            if has_directional_pattern:
                add_debug_log(f"SKIP general UAV marker - has directional pattern: '{ln}'", "uav_processing")
                # Don't create general marker - let main parser extract specific city
                continue
            
            # Check if we have a region and this is a UAV message
            if oblast_hdr:
                add_debug_log(f"Processing UAV with region context: '{oblast_hdr}'", "uav_processing")
                # Find the main city of the region to place the marker
                region_cities = {
                    'сумщина': 'суми',
                    'чернігівщина': 'чернігів',
                    'херсонщина': 'херсон',
                    'харківщина': 'харків',
                    'донеччина': 'краматорськ',  # safer than донецьк
                    'луганщина': 'сєвєродонецьк',
                    'запорожжя': 'запоріжжя',
                    'дніпропетровщина': 'дніпро',
                    'полтавщина': 'полтава',
                    'київщина': 'київ',
                    'львівщина': 'львів',
                    'івано-франківщина': 'івано-франківськ',
                    'тернопільщина': 'тернопіль',
                    'хмельниччина': 'хмельницький',
                    'рівненщина': 'рівне',
                    'волинщина': 'луцьк',
                    'житомирщина': 'житомир',
                    'вінниччина': 'вінниця',
                    'черкащина': 'черкаси',
                    'кіровоградщина': 'кропивницький',
                    'миколаївщина': 'миколаїв',
                    'одещина': 'одеса'
                }
                
                # Special coordinates for aviation threats over regions (e.g., aircraft over Black Sea for Odesa)
                region_aviation_coords = {
                    'одещина': (46.373528, 31.284023),  # Black Sea near Odesa for aviation threats
                    'одесщина': (46.373528, 31.284023),
                }
                
                region_city = region_cities.get(oblast_hdr)
                if region_city:
                    # Check if message refers to entire region rather than specific city
                    # Skip marker creation for some regional threats, but create for KAB/aviation bombs
                    genitive_form = oblast_hdr.replace('щина', 'щини')  # сумщина -> сумщини
                    dative_form = oblast_hdr.replace('щина', 'щині')    # сумщина -> сумщині
                    accusative_form = oblast_hdr + 'у'                  # сумщина -> сумщину
                    
                    is_regional_threat = any(regional_ref in ln_lower for regional_ref in [
                        f'на {oblast_hdr}', f'{accusative_form}', f'{genitive_form}', f'{dative_form}',
                        f'для {genitive_form}', f'по {dative_form}'
                    ])
                    
                    # For KAB/aviation bombs and aviation threats, always create marker even for regional threats
                    has_kab = any(kab_word in ln_lower for kab_word in ['каб', 'авіабомб', 'авиабомб'])
                    has_aviation_threat = any(avia_word in ln_lower for avia_word in [
                        'авіаційних засобів ураження', 'авіаційних засобів', 'застосування авіації',
                        'тактична авіація', 'тактичної авіації'
                    ])
                    
                    if is_regional_threat and not has_kab and not has_aviation_threat:
                        add_debug_log(f"Skipping regional threat marker - affects entire region: {oblast_hdr} (found: {[ref for ref in [f'на {oblast_hdr}', accusative_form, genitive_form, dative_form] if ref in ln_lower]})", "multi_region")
                        continue
                    
                    # Check if this is an aviation threat and use special coordinates if available
                    coords = None
                    if has_aviation_threat and oblast_hdr in region_aviation_coords:
                        coords = region_aviation_coords[oblast_hdr]
                        label = f"Авіація [{oblast_hdr.title()}]"
                        add_debug_log(f"Using aviation coordinates for {oblast_hdr}: {coords}", "aviation_region")
                    
                    # Otherwise, try to find coordinates for the region's main city
                    if not coords:
                        base_city = normalize_city_name(region_city)
                        base_city = UA_CITY_NORMALIZE.get(base_city, base_city)
                        coords = CITY_COORDS.get(base_city) or (SETTLEMENTS_INDEX.get(base_city) if SETTLEMENTS_INDEX else None)
                        label = base_city.title()
                        label += f" [{oblast_hdr.title()}]"
                    
                    if coords:
                        lat, lng = coords
                        
                        # Determine threat type based on message content using classify function
                        threat_type, icon = classify(ln)
                        # Keep shahed as default for UAV if classify doesn't return anything specific
                        if not threat_type:
                            threat_type = 'shahed'
                        
                        multi_city_tracks.append({
                            'id': f"{mid}_general_uav_{len(multi_city_tracks)+1}",
                            'place': label,
                            'lat': lat,
                            'lng': lng,
                            'threat_type': threat_type,
                            'text': clean_text(ln)[:500],
                            'date': date_str,
                            'channel': channel,
                            'marker_icon': icon,
                            'source_match': 'general_uav_activity',
                            'count': 1
                        })
                        add_debug_log(f"Created general UAV marker: {label} ({threat_type})", "multi_region")
                        add_debug_log(f"MARKER CREATION: oblast_hdr='{oblast_hdr}', region_city='{region_city}', coords=({lat}, {lng})", "marker_creation")
                        continue  # move to next line
        
        # NEW: Handle UAV messages without region but with city name
        ln_lower = ln.lower()
        if (not oblast_hdr) and ('бпла' in ln_lower or 'безпілотник' in ln_lower or 'дрон' in ln_lower or 'обстріл' in ln_lower or 'вибух' in ln_lower):
            # Try to extract city name from the message
            import re
            # Pattern for messages like "❗️ Синельникове — 1х БпЛА довкола" or "💥 Херсон — обстріл"
            city_match = re.search(r'[❗️⚠️🛸💥]*\s*([А-ЯІЇЄа-яіїєґ][А-Яа-яІіЇїЄєґ\-\'ʼ]{2,30}(?:ське|цьке|ський|ський район|ове|еве|ине|ино|івка|івськ|ськ|град|город)?)', ln)
            if city_match:
                city_name = city_match.group(1).strip()
                
                # Normalize city name
                base_city = normalize_city_name(city_name)
                base_city = UA_CITY_NORMALIZE.get(base_city, base_city)
                coords = CITY_COORDS.get(base_city) or (SETTLEMENTS_INDEX.get(base_city) if SETTLEMENTS_INDEX else None)
                
                if coords:
                    lat, lng = coords
                    label = base_city.title()
                    
                    # Determine threat type based on message content using classify function
                    threat_type, icon = classify(ln)
                    # Keep shahed as default for UAV if classify doesn't return anything specific
                    if not threat_type:
                        threat_type = 'shahed'
                        icon = 'shahed.png'
                    
                    multi_city_tracks.append({
                        'id': f"{mid}_city_threat_{len(multi_city_tracks)+1}",
                        'place': label,
                        'lat': lat,
                        'lng': lng,
                        'threat_type': threat_type,
                        'text': clean_text(ln)[:500],
                        'date': date_str,
                        'channel': channel,
                        'marker_icon': icon,
                        'source_match': 'city_threat_activity',
                        'count': 1
                    })
                    add_debug_log(f"Created city threat marker: {label} ({threat_type})", "multi_region")
                    continue  # move to next line
        
        # --- NEW: БпЛА курсом на [city] pattern (e.g., "4х БпЛА курсом на Конотоп") ---
        # ВАЖЛИВО: Підтримка багатослівних назв міст (наприклад "Жовті Води")
        uav_course_city = None
        uav_course_count = 1
        # Pattern: "Nх БпЛА курсом на [city]" or "БпЛА курсом на [city]"
        # Захоплює назву міста до кінця рядка або до розділових знаків
        m_uav_course = re.search(r'(?:^|\b)(?:([0-9]+)[xх×]?\s*)?(?:бпла|шахед(?:и|ів)?|дрон(?:и)?)\s+курс(?:ом)?\s+на\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]+?)(?:\s*$|[,\.\!\?;])', ln, re.IGNORECASE)
        if m_uav_course:
            if m_uav_course.group(1):
                try:
                    uav_course_count = int(m_uav_course.group(1))
                except:
                    uav_course_count = 1
            uav_course_city = m_uav_course.group(2).strip()
            
            add_debug_log(f"UAV course pattern found: {uav_course_count}x БпЛА курсом на '{uav_course_city}'", "multi_region")
        
        if uav_course_city:
            candidate_cities = extract_course_targets(uav_course_city)
            add_debug_log(f"extract_course_targets('{uav_course_city}') returned: {candidate_cities}", "multi_region")
            per_marker_count = uav_course_count if len(candidate_cities) <= 1 else 1
            created_course_markers = False
            for dest_city in candidate_cities or [uav_course_city]:
                if not dest_city:
                    continue
                base_uav = normalize_city_name(dest_city)
                base_uav = UA_CITY_NORMALIZE.get(base_uav, base_uav)
                coords_uav = CITY_COORDS.get(base_uav) or (SETTLEMENTS_INDEX.get(base_uav) if SETTLEMENTS_INDEX else None)
                add_debug_log(f"Geocoding '{dest_city}' -> normalized: '{base_uav}' -> coords: {coords_uav}", "multi_region")
                
                # Try region-specific lookup if oblast_hdr is set
                if not coords_uav and oblast_hdr:
                    combo_uav = f"{base_uav} {oblast_hdr}"
                    coords_uav = CITY_COORDS.get(combo_uav) or (SETTLEMENTS_INDEX.get(combo_uav) if SETTLEMENTS_INDEX else None)
                    add_debug_log(f"Trying region combo: '{combo_uav}' -> {coords_uav}", "multi_region")
                
                if not coords_uav:
                    add_debug_log(f"No coords found for '{dest_city}' (normalized: '{base_uav}', oblast: '{oblast_hdr}')", "multi_region")
                    continue
                created_course_markers = True
                lat, lng = coords_uav
                label = UA_CITY_NORMALIZE.get(base_uav, base_uav).title()
                if per_marker_count > 1:
                    label += f" ({per_marker_count}x)"
                if oblast_hdr and oblast_hdr not in label.lower():
                    label += f" [{oblast_hdr.title()}]"
                
                multi_city_tracks.append({
                    'id': f"{mid}_mc{len(multi_city_tracks)+1}",
                    'place': label,
                    'lat': lat,
                    'lng': lng,
                    'threat_type': 'shahed',
                    'text': clean_text(ln)[:500],
                    'date': date_str,
                    'channel': channel,
                    'marker_icon': 'shahed.png',
                    'source_match': 'multiline_uav_course',
                    'count': per_marker_count
                })
                add_debug_log(f"Created UAV course marker: {label}", "multi_region")
            if created_course_markers:
                continue  # move to next line
            else:
                base_uav = normalize_city_name(sanitize_course_destination(uav_course_city))
                add_debug_log(f"No coordinates found for UAV course city: '{uav_course_city}' (normalized: '{base_uav}')", "multi_region")
        
        # Continue processing other patterns even if UAV course didn't match
        # Don't skip the line completely
        
        # Пытаемся найти город и количество (например, "2х БпЛА курсом на Десну")
        import re
        # --- NEW: распознавание ракетных строк внутри многострочного блока ---
        # Примеры: "1 ракета на Холми", "2 ракети на Лубни", "3 ракеты на Лубни", "ракета на <місто>"
        rocket_city = None; rocket_count = 1
        mr = re.search(r'(?:^|\b)(?:([0-9]+)\s*)?(ракета|ракети|ракет)\s+на\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{2,40})', ln, re.IGNORECASE)
        if mr:
            if mr.group(1):
                try: rocket_count = int(mr.group(1))
                except: rocket_count = 1
            rocket_city = mr.group(3)
        if rocket_city:
            base_r = normalize_city_name(rocket_city)
            base_r = UA_CITY_NORMALIZE.get(base_r, base_r)
            coords_r = CITY_COORDS.get(base_r) or (SETTLEMENTS_INDEX.get(base_r) if SETTLEMENTS_INDEX else None)
            if not coords_r and oblast_hdr:
                combo_r = f"{base_r} {oblast_hdr}"
                coords_r = CITY_COORDS.get(combo_r) or (SETTLEMENTS_INDEX.get(combo_r) if SETTLEMENTS_INDEX else None)
            if coords_r:
                lat, lng = coords_r
                label = UA_CITY_NORMALIZE.get(base_r, base_r).title()
                if rocket_count > 1:
                    label += f" ({rocket_count})"
                if oblast_hdr and oblast_hdr not in label.lower():
                    label += f" [{oblast_hdr.title()}]"
                multi_city_tracks.append({
                    'id': f"{mid}_mc{len(multi_city_tracks)+1}", 'place': label, 'lat': lat, 'lng': lng,
                    'threat_type': 'rszv', 'text': clean_text(ln)[:500], 'date': date_str, 'channel': channel,
                    'marker_icon': 'rszv.png', 'source_match': 'multiline_oblast_city_rocket', 'count': rocket_count
                })
                continue  # переходим к следующей строке (не пытаемся распознать как БпЛА)
        # --- NEW: группы крылатых ракет ("Група/Групи КР курсом на <город>") ---
        kr_city = None; kr_count = 1
        # Primary straightforward pattern for "Група/Групи КР курсом на <місто>"
        mkr = re.search(r'(?:^|\b)(?:([0-9]+)[xх×]?\s*)?груп[аи]\s+кр\b.*?курс(?:ом)?\s+на\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,40}?)(?=[,\.\!\?;]|$)', ln, re.IGNORECASE)
        if not mkr:
            # Tolerant pattern allowing missing leading "г" or space glitches / lost letters
            mkr = re.search(r'(?:^|\b)(?:([0-9]+)[xх×]?\s*)?(?:г)?руп[аи]\s*(?:к)?р\b.*?курс(?:ом)?\s+на\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,40}?)(?=[,\.\!\?;]|$)', ln, re.IGNORECASE)
        if not mkr and 'груп' in ln.lower() and 'курс' in ln.lower() and ' на ' in ln.lower():
            # Very loose fallback if 'КР' fragment dropped; capture after last 'на'
            after = ln.rsplit('на',1)[-1].strip()
            after = re.split(r'[,.!?:;]', after)[0].strip()
            if len(after) >= 3:
                class Dummy: pass
                mkr = Dummy(); mkr.group = lambda i: None if i==1 else after
        if mkr:
            try:
                log.info(f"KR_MATCH line='{ln}' groups={mkr.groups()}")
            except Exception:
                pass
            if mkr.group(1):
                try: kr_count = int(mkr.group(1))
                except: kr_count = 1
            kr_city = mkr.group(2)
        if kr_city:
            base_k = normalize_city_name(kr_city)
            base_k = UA_CITY_NORMALIZE.get(base_k, base_k)
            coords_k = CITY_COORDS.get(base_k) or (SETTLEMENTS_INDEX.get(base_k) if SETTLEMENTS_INDEX else None)
            if not coords_k and oblast_hdr:
                combo_k = f"{base_k} {oblast_hdr}"
                coords_k = CITY_COORDS.get(combo_k) or (SETTLEMENTS_INDEX.get(combo_k) if SETTLEMENTS_INDEX else None)
            if coords_k:
                lat, lng = coords_k
                label = UA_CITY_NORMALIZE.get(base_k, base_k).title()
                if kr_count > 1:
                    label += f" ({kr_count})"
                if oblast_hdr and oblast_hdr not in label.lower():
                    label += f" [{oblast_hdr.title()}]"
                multi_city_tracks.append({
                    'id': f"{mid}_mc{len(multi_city_tracks)+1}", 'place': label, 'lat': lat, 'lng': lng,
                    'threat_type': 'raketa', 'text': ln[:500], 'date': date_str, 'channel': channel,
                    'marker_icon': 'raketa.png', 'source_match': 'multiline_oblast_city_kr_group', 'count': kr_count
                })
                continue
        # Universal KR fallback (handles degraded OCR lines like '3х рупи  курсом на рилуки')
        low_ln = ln.lower()
        if ('курс' in low_ln and ' на ' in low_ln and ('груп' in low_ln or ' кр' in low_ln)):
            # Extract count if present at start or before 'груп'
            mcnt = re.search(r'^(\d+(?:-\d+)?)[xх×]?\s*', low_ln)
            count_guess = 1
            if mcnt:
                try: count_guess = int(mcnt.group(1))
                except: pass
            # Try after last 'на '
            parts = low_ln.rsplit(' на ', 1)
            if len(parts) == 2:
                cand = parts[1]
                cand = re.split(r'[\n,.!?:;]', cand)[0].strip()
                # strip residual non-letter chars
                cand_clean = re.sub(r"[^A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]", '', cand).strip()
                if len(cand_clean) >= 3:
                    base_f = normalize_city_name(cand_clean)
                    base_f = UA_CITY_NORMALIZE.get(base_f, base_f)
                    coords_f = CITY_COORDS.get(base_f) or (SETTLEMENTS_INDEX.get(base_f) if SETTLEMENTS_INDEX else None)
                    if not coords_f and oblast_hdr:
                        combo_f = f"{base_f} {oblast_hdr}"
                        coords_f = CITY_COORDS.get(combo_f) or (SETTLEMENTS_INDEX.get(combo_f) if SETTLEMENTS_INDEX else None)
                    # Fuzzy repair: if still not found, try restoring a potentially lost first letter
                    if not coords_f:
                        for pref in ['н','к','ч','п','г','с','в','б','д','м','т','л']:
                            test_base = pref + base_f
                            coords_try = CITY_COORDS.get(test_base) or (SETTLEMENTS_INDEX.get(test_base) if SETTLEMENTS_INDEX else None)
                            if not coords_try and oblast_hdr:
                                combo_try = f"{test_base} {oblast_hdr}"
                                coords_try = CITY_COORDS.get(combo_try) or (SETTLEMENTS_INDEX.get(combo_try) if SETTLEMENTS_INDEX else None)
                            if coords_try:
                                base_f = test_base
                                coords_f = coords_try
                                try: log.info(f"KR_FUZZ_REPAIR first_letter pref='{pref}' -> {base_f}")
                                except Exception: pass
                                break
                    if coords_f:
                        lat, lng = coords_f
                        label = UA_CITY_NORMALIZE.get(base_f, base_f).title()
                        if count_guess > 1:
                            label += f" ({count_guess})"
                        if oblast_hdr and oblast_hdr not in label.lower():
                            label += f" [{oblast_hdr.title()}]"
                        multi_city_tracks.append({
                            'id': f"{mid}_mc{len(multi_city_tracks)+1}", 'place': label, 'lat': lat, 'lng': lng,
                            'threat_type': 'raketa', 'text': ln[:500], 'date': date_str, 'channel': channel,
                            'marker_icon': 'raketa.png', 'source_match': 'multiline_oblast_city_kr_group_fallback2', 'count': count_guess
                        })
                        continue
        # Generic course fallback (any remaining 'курс' + ' на ' line not yet matched)
        if 'курс' in low_ln and ' на ' in low_ln and not any(tag in low_ln for tag in ['бпла','shahed']) and not any(mt['id'] == f"{mid}_mc{len(multi_city_tracks)+1}" for mt in multi_city_tracks):
            parts = low_ln.rsplit(' на ',1)
            if len(parts)==2:
                cand = re.split(r'[\n,.!?:;]', parts[1])[0].strip()
                cand = re.sub(r"[^A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]", '', cand)
                if len(cand) >= 3:
                    base_g = normalize_city_name(cand)
                    base_g = UA_CITY_NORMALIZE.get(base_g, base_g)
                    coords_g = CITY_COORDS.get(base_g) or (SETTLEMENTS_INDEX.get(base_g) if SETTLEMENTS_INDEX else None)
                    if not coords_g and oblast_hdr:
                        combo_g = f"{base_g} {oblast_hdr}"
                        coords_g = CITY_COORDS.get(combo_g) or (SETTLEMENTS_INDEX.get(combo_g) if SETTLEMENTS_INDEX else None)
                    # NEW: allow oblast center lookup if destination is a region (e.g. полтавщина / полтавщину)
                    if not coords_g and base_g in OBLAST_CENTERS:
                        coords_g = OBLAST_CENTERS[base_g]
                        try: log.info(f"GENERIC_COURSE_REGION dest='{base_g}' -> oblast center")
                        except Exception: pass
                    if not coords_g:
                        for pref in ['к','с','о','л','б','в','ж','т','я','у','р','н','п','г','ч']:
                            test = pref + base_g
                            coords_try = CITY_COORDS.get(test) or (SETTLEMENTS_INDEX.get(test) if SETTLEMENTS_INDEX else None)
                            if not coords_try and oblast_hdr:
                                combo_try = f"{test} {oblast_hdr}"
                                coords_try = CITY_COORDS.get(combo_try) or (SETTLEMENTS_INDEX.get(combo_try) if SETTLEMENTS_INDEX else None)
                            if coords_try:
                                base_g = test
                                coords_g = coords_try
                                try: log.info(f"GENERIC_FUZZ_CITY pref='{pref}' -> {base_g}")
                                except Exception: pass
                                break
                    if not coords_g:
                        for pref in ['н','к','ч','п','г','с','в','б','д','м','т','л']:
                            test_base = pref + base_g
                            coords_try = CITY_COORDS.get(test_base) or (SETTLEMENTS_INDEX.get(test_base) if SETTLEMENTS_INDEX else None)
                            if not coords_try and oblast_hdr:
                                combo_try = f"{test_base} {oblast_hdr}"
                                coords_try = CITY_COORDS.get(combo_try) or (SETTLEMENTS_INDEX.get(combo_try) if SETTLEMENTS_INDEX else None)
                            if coords_try:
                                base_g = test_base
                                coords_g = coords_try
                                try: log.info(f"GENERIC_COURSE_FUZZ pref='{pref}' -> {base_g}")
                                except Exception: pass
                                break
                    if coords_g:
                        lat, lng = coords_g
                        label = UA_CITY_NORMALIZE.get(base_g, base_g).title()
                        if oblast_hdr and oblast_hdr not in label.lower():
                            label += f" [{oblast_hdr.title()}]"
                        multi_city_tracks.append({
                            'id': f"{mid}_mc{len(multi_city_tracks)+1}", 'place': label, 'lat': lat, 'lng': lng,
                            'threat_type': 'raketa', 'text': ln[:500], 'date': date_str, 'channel': channel,
                            'marker_icon': 'raketa.png', 'source_match': 'multiline_oblast_city_course_generic', 'count': 1
                        })
                        continue
        # Fallback KR pattern if above failed but line mentions 'КР' and 'курс'
        if 'кр' in ln.lower() and 'курс' in ln.lower() and ' на ' in f" {ln.lower()} ":
            mkr2 = re.search(r'курс(?:ом)?\s+на\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,40}?)(?=[,\.\!\?;]|$)', ln, re.IGNORECASE)
            if mkr2:
                base_k2 = normalize_city_name(mkr2.group(1))
                base_k2 = UA_CITY_NORMALIZE.get(base_k2, base_k2)
                coords_k2 = CITY_COORDS.get(base_k2) or (SETTLEMENTS_INDEX.get(base_k2) if SETTLEMENTS_INDEX else None)
                if not coords_k2 and oblast_hdr:
                    combo_k2 = f"{base_k2} {oblast_hdr}"
                    coords_k2 = CITY_COORDS.get(combo_k2) or (SETTLEMENTS_INDEX.get(combo_k2) if SETTLEMENTS_INDEX else None)
                if not coords_k2:
                    for pref in ['н','к','ч','п','г','с','в','б','д','м','т','л']:
                        test_base = pref + base_k2
                        coords_try = CITY_COORDS.get(test_base) or (SETTLEMENTS_INDEX.get(test_base) if SETTLEMENTS_INDEX else None)
                        if not coords_try and oblast_hdr:
                            combo_try = f"{test_base} {oblast_hdr}"
                            coords_try = CITY_COORDS.get(combo_try) or (SETTLEMENTS_INDEX.get(combo_try) if SETTLEMENTS_INDEX else None)
                        if coords_try:
                            base_k2 = test_base
                            coords_k2 = coords_try
                            try: log.info(f"KR_FALLBACK_FUZZ pref='{pref}' -> {base_k2}")
                            except Exception: pass
                            break
                if coords_k2:
                    lat, lng = coords_k2
                    label = UA_CITY_NORMALIZE.get(base_k2, base_k2).title()
                    if oblast_hdr and oblast_hdr not in label.lower():
                        label += f" [{oblast_hdr.title()}]"
                    multi_city_tracks.append({
                        'id': f"{mid}_mc{len(multi_city_tracks)+1}", 'place': label, 'lat': lat, 'lng': lng,
                        'threat_type': 'raketa', 'text': ln[:500], 'date': date_str, 'channel': channel,
                        'marker_icon': 'raketa.png', 'source_match': 'multiline_oblast_city_kr_group_fallback', 'count': 1
                    })
                    continue
        # Разрешаем многословные названия (до 3 слов) до конца строки / знака препинания
        m = re.search(r'(\d+)[xх×]?\s*бпла.*?курс(?:ом)?\s+на\s+(?:н\.п\.?\s*)?([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,40}?)(?=[,\.\!\?;]|$)', ln, re.IGNORECASE)
        if m:
            count = int(m.group(1))
            city = m.group(2)
        else:
            # Дополнительно поддерживаем строки вида "7х БпЛА повз <місто> ..." или "БпЛА повз <місто>"
            m2 = re.search(r'бпла.*?курс(?:ом)?\s+на\s+(?:н\.п\.?\s*)?([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,40}?)(?=[,\.\!\?;]|$)', ln, re.IGNORECASE)
            if m2:
                count = 1
                city = m2.group(1)
            else:
                m3 = re.search(r'(\d+)[xх×]?\s*бпла.*?повз\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,40}?)(?=[,\.\!\?;]|$)', ln, re.IGNORECASE)
                if m3:
                    count = int(m3.group(1))
                    city = m3.group(2)
                else:
                    m4 = re.search(r'бпла.*?повз\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,40}?)(?=[,\.\!\?;]|$)', ln, re.IGNORECASE)
                    count = 1
                    city = m4.group(1) if m4 else None
        # --- NEW: Shahed lines inside multi-line block (e.g. '2 шахеди на Старий Салтів', '1 шахед на Мерефа / Борки') ---
        if not city:
            m_sha = re.search(r'^(?:([0-9]+)\s*[xх×]?\s*)?шахед(?:и|ів)?\s+на\s+(.+)$', ln.strip(), re.IGNORECASE)
            if m_sha:
                try:
                    scount = int(m_sha.group(1) or '1')
                except Exception:
                    scount = 1
                cities_part = m_sha.group(2)
                # Apply extract_course_targets to properly sanitize destinations (removes /район, etc.)
                raw_parts = extract_course_targets(cities_part)
                add_debug_log(f"Shahed pattern: '{cities_part}' -> sanitized targets: {raw_parts}", "multi_region")
                for ci in raw_parts:
                    c_raw = ci.strip().strip('.').strip()
                    if not c_raw or len(c_raw) < 2:
                        continue
                    cbase = normalize_city_name(c_raw)
                    cbase = UA_CITY_NORMALIZE.get(cbase, cbase)
                    coords_s = CITY_COORDS.get(cbase) or (SETTLEMENTS_INDEX.get(cbase) if SETTLEMENTS_INDEX else None)
                    add_debug_log(f"Shahed geocoding: '{ci}' -> normalized '{cbase}' -> coords {coords_s}", "multi_region")
                    if not coords_s and oblast_hdr:
                        combo_s = f"{cbase} {oblast_hdr}"
                        coords_s = CITY_COORDS.get(combo_s) or (SETTLEMENTS_INDEX.get(combo_s) if SETTLEMENTS_INDEX else None)
                    if not coords_s:
                        for pref in ['с','м','к','б','г','ч','н','п','т','в','л']:
                            test = pref + cbase
                            coords_try = CITY_COORDS.get(test) or (SETTLEMENTS_INDEX.get(test) if SETTLEMENTS_INDEX else None)
                            if not coords_try and oblast_hdr:
                                combo_try = f"{test} {oblast_hdr}"
                                coords_try = CITY_COORDS.get(combo_try) or (SETTLEMENTS_INDEX.get(combo_try) if SETTLEMENTS_INDEX else None)
                            if coords_try:
                                cbase = test; coords_s = coords_try; break
                    if not coords_s:
                        add_debug_log(f"No coords found for shahed dest '{ci}' (norm: '{cbase}')", "multi_region")
                        continue
                    lat, lng = coords_s
                    label = UA_CITY_NORMALIZE.get(cbase, cbase).title()
                    per_count = scount if len(raw_parts) == 1 else 1
                    if oblast_hdr and oblast_hdr not in label.lower():
                        label += f" [{oblast_hdr.title()}]"
                    
                    # Create multiple tracks for multiple shaheds
                    tracks_to_create = max(1, per_count)
                    for i in range(tracks_to_create):
                        track_label = label
                        if tracks_to_create > 1:
                            track_label += f" #{i+1}"
                        
                        # Add small coordinate offsets to prevent marker overlap
                        marker_lat = lat
                        marker_lng = lng
                        if tracks_to_create > 1:
                            # Create a chain pattern - drones one after another
                            offset_distance = 0.03  # ~3km offset between each drone
                            marker_lat += offset_distance * i
                            marker_lng += offset_distance * i * 0.5
                        
                        multi_city_tracks.append({
                            'id': f"{mid}_mc{len(multi_city_tracks)+1}", 'place': track_label, 'lat': marker_lat, 'lng': marker_lng,
                            'threat_type': 'shahed', 'text': clean_text(ln)[:500], 'date': date_str, 'channel': channel,
                            'marker_icon': 'shahed.png', 'source_match': 'multiline_oblast_city_shahed', 'count': 1
                        })
                continue
        
        # --- NEW: Pattern "N на City1 N на City2..." (e.g. "Харківщина 1 на Вільшани 1 на Kov'яги 1 на Бірки") ---
        # Handles multiple "number + на + city" sequences in a single line WITHOUT repeating "БпЛА"
        # IMPORTANT: Pattern supports mixed Cyrillic/Latin city names (e.g. "Kov'яги")
        if re.search(r'(\d+)\s+на\s+[A-ZА-ЯІЇЄa-zа-яіїєґ\'\-]+', ln, re.IGNORECASE):
            # Find all "N на City" patterns in the line (supports mixed Cyrillic/Latin)
            multi_na_pattern = re.findall(r'(\d+)\s+на\s+([A-ZА-ЯІЇЄa-zа-яіїєґ\'\-]+(?:/[A-ZА-ЯІЇЄa-zа-яіїєґ\'\-]+)?)', ln, re.IGNORECASE)
            
            if len(multi_na_pattern) > 1:  # Multiple "N на City" patterns found - this is our case!
                add_debug_log(f"MULTI-NA pattern found {len(multi_na_pattern)} cities in line: '{ln}'", "multi_na")
                add_debug_log(f"MULTI-NA current region header (oblast_hdr): '{oblast_hdr}'", "multi_na")
                
                # Regional overrides for cities with duplicate names in different oblasts
                REGIONAL_CITY_COORDS = {
                    'харківщина': {
                        'вільшани': (50.177, 35.398),  # Вільшани, Харківська обл., Богодухівський район
                        'ковяги': (49.75, 36.12),       # Ков'яги, Харківська обл.
                        'березівка': (49.583, 36.450),  # Березівка, Харківська обл.
                    },
                    # Add more regional overrides as needed
                }
                
                for count_str, city_raw in multi_na_pattern:
                    count = int(count_str) if count_str.isdigit() else 1
                    city_name = city_raw.strip()
                    
                    # Normalize city name (handle Latin/Cyrillic mix)
                    city_norm = normalize_city_name(city_name)
                    city_norm = UA_CITY_NORMALIZE.get(city_norm, city_norm)
                    
                    # TRY 1: Regional override if oblast_hdr is set (e.g. "Харківщина:")
                    coords = None
                    if oblast_hdr and oblast_hdr in REGIONAL_CITY_COORDS:
                        region_coords = REGIONAL_CITY_COORDS[oblast_hdr]
                        coords = region_coords.get(city_norm)
                        if coords:
                            add_debug_log(f"  Multi-NA city: '{city_name}' ({count}x) -> norm: '{city_norm}' -> REGIONAL OVERRIDE coords: {coords} (oblast: {oblast_hdr})", "multi_na")
                    
                    # TRY 2: Default database lookup if no regional override
                    if not coords:
                        coords = CITY_COORDS.get(city_norm)
                        if coords:
                            add_debug_log(f"  Multi-NA city: '{city_name}' ({count}x) -> norm: '{city_norm}' -> DATABASE coords: {coords}", "multi_na")
                    
                    # TRY 3: Settlements index fallback
                    if not coords and SETTLEMENTS_INDEX:
                        coords = SETTLEMENTS_INDEX.get(city_norm)
                        if coords:
                            add_debug_log(f"  Multi-NA city: '{city_name}' ({count}x) -> norm: '{city_norm}' -> SETTLEMENTS coords: {coords}", "multi_na")
                    
                    if not coords:
                        add_debug_log(f"  WARNING: No coordinates for '{city_name}' (normalized: '{city_norm}', oblast: {oblast_hdr})", "multi_na")
                        continue
                    
                    if coords:
                        lat, lng = coords
                        threat_type, icon = classify(ln)
                        
                        # Create separate markers for each count
                        for i in range(count):
                            place_label = city_norm.title()
                            if count > 1:
                                place_label += f" #{i+1}"
                            
                            # Add offset for multiple drones at same location
                            marker_lat, marker_lng = lat, lng
                            if count > 1:
                                offset_distance = 0.03  # ~3km offset
                                marker_lat += offset_distance * i
                                marker_lng += offset_distance * i * 0.5
                            
                            multi_city_tracks.append({
                                'id': f"{mid}_multi_na_{len(multi_city_tracks)+1}",
                                'place': place_label,
                                'lat': marker_lat,
                                'lng': marker_lng,
                                'threat_type': threat_type,
                                'text': clean_text(ln)[:500],
                                'date': date_str,
                                'channel': channel,
                                'marker_icon': icon,
                                'source_match': 'multi_na_pattern',
                                'count': 1
                            })
                        add_debug_log(f"  Created {count} marker(s) for '{city_norm.title()}'", "multi_na")
                    else:
                        add_debug_log(f"  WARNING: No coordinates for '{city_name}' (normalized: '{city_norm}')", "multi_na")
                
                add_debug_log(f"Multi-NA pattern processed: {len(multi_city_tracks)} total markers created", "multi_na")
                continue  # Skip further processing of this line
        
        # --- NEW: Simple "X БпЛА на <city>" pattern (e.g. '1 БпЛА на Козелець', '2 БпЛА на Куликівку') ---
        # Also handle "Ціль на <city>" pattern for missile/rocket targets
        if not city:
            print(f"DEBUG: Checking simple БпЛА/Ціль pattern for line: '{ln}'")
            
            # Pattern 1: "Ціль на <city>" - rocket/missile target
            m_target = re.search(r'ціль\s+на\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,40}?)(?=\s|$|[,\.\!\?;\[])', ln, re.IGNORECASE)
            if m_target:
                city = m_target.group(1).strip()
                count = 1  # Default count for target
                print(f"DEBUG: Found 'Ціль на' pattern - city: '{city}'")
            # Pattern 2: "X БпЛА на <city>"
            elif re.search(r'(\d+)\s+бпла\s+на\s+', ln, re.IGNORECASE):
                m_simple = re.search(r'(\d+)\s+бпла\s+на\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,40}?)(?=\s|$|[,\.\!\?;])', ln, re.IGNORECASE)
                if m_simple:
                    try:
                        count = int(m_simple.group(1))
                    except Exception:
                        count = 1
                    city = m_simple.group(2).strip()
                    print(f"DEBUG: Found simple БпЛА pattern - count: {count}, city: '{city}'")
            # Pattern 3: "БпЛА на <city>" without count
            elif re.search(r'бпла\s+на\s+[A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,}', ln, re.IGNORECASE):
                # Fallback for "БпЛА на <city>" without count - handle cities with parentheses like "Кривий ріг (Дніпропетровщина)"
                m_simple_no_count = re.search(r'бпла\s+на\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,}?)(?:\s*\([^)]*\))?(?=\s*$|[,\.\!\?;])', ln, re.IGNORECASE)
                if m_simple_no_count:
                    count = 1
                    city = m_simple_no_count.group(1).strip()
                    print(f"DEBUG: Found simple БпЛА pattern (no count) - city: '{city}'")
        
        # --- NEW: Handle "X у напрямку City1, City2" pattern (e.g. "4 у напрямку Карлівки, Полтави") ---
        if not city:
            print(f"DEBUG: Checking 'X у напрямку' pattern for line: '{ln}'")
            m_naprymku = re.search(r'(\d+)\s+у\s+напрямку\s+([А-ЯІЇЄЁа-яіїєё\'\-\s,]{5,})(?=\s*$|[,\.\!\?;])', ln, re.IGNORECASE)
            if m_naprymku:
                try:
                    count = int(m_naprymku.group(1))
                except Exception:
                    count = 1
                cities_raw = m_naprymku.group(2).strip()
                print(f"DEBUG: Found 'у напрямку' pattern - count: {count}, cities: '{cities_raw}'")
                
                # Split cities by comma
                cities_list = [c.strip() for c in cities_raw.split(',') if c.strip()]
                for city_name in cities_list:
                    base = normalize_city_name(city_name)
                    base = UA_CITY_NORMALIZE.get(base, base)
                    coords = CITY_COORDS.get(base)
                    
                    # If not found, try to handle declensions (ending with -и, -ми, -у, etc)
                    if not coords and base:
                        if base.endswith('і') or base.endswith('и'):
                            base_nom = base[:-1] + 'а'  # карлівки -> карлівка
                            coords = CITY_COORDS.get(base_nom)
                        elif base.endswith('у'):
                            base_nom = base[:-1] + 'а'  # полтаву -> полтава  
                            coords = CITY_COORDS.get(base_nom)
                        elif base.endswith('ми'):
                            base_nom = base[:-2] + 'а'  # київми -> києва -> doesn't work, try other variants
                            coords = CITY_COORDS.get(base_nom)
                    
                    if coords:
                        lat, lng = coords
                        multi_city_tracks.append({
                            'id': f"{mid}_naprymku{len(multi_city_tracks)+1}", 'place': city_name.title(), 'lat': lat, 'lng': lng,
                            'threat_type': 'shahed', 'text': clean_text(ln)[:500], 'date': date_str, 'channel': channel,
                            'marker_icon': 'shahed.png', 'source_match': 'naprymku_pattern', 'count': count
                        })
                        print(f"DEBUG: Added marker for '{city_name}' at {lat}, {lng}")
                if multi_city_tracks:
                    continue
                
        # --- NEW: Handle "X БпЛА City1 / City2" pattern (e.g. "2х БпЛА Гнідин / Бориспіль") ---
        if not city:
            print(f"DEBUG: Checking БпЛА city/city pattern for line: '{ln}'")
            m_cities = re.search(r'(\d+)х?\s+бпла\s+(?:на\s+)?([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,30}?)\s*/\s*([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,30}?)(?=\s|$|[,\.\!\?;])', ln, re.IGNORECASE)
            if m_cities:
                try:
                    count = int(m_cities.group(1))
                except Exception:
                    count = 1
                city1 = m_cities.group(2).strip()
                city2 = m_cities.group(3).strip()
                print(f"DEBUG: Found БпЛА city/city pattern - count: {count}, cities: '{city1}' / '{city2}'")
                
                # Process both cities separately
                for city_name in [city1, city2]:
                    base = normalize_city_name(city_name)
                    base = UA_CITY_NORMALIZE.get(base, base)
                    coords = CITY_COORDS.get(base)
                    if coords:
                        print(f"DEBUG: Creating БпЛА track for {city_name} at {coords}")
                        multi_city_tracks.append({
                            'lat': coords[0],
                            'lon': coords[1],
                            'name': city_name,
                            'type': 'БпЛА',
                            'time': date_str,
                            'id': mid,
                            'message': text[:100] + ('...' if len(text) > 100 else ''),
                            'channel': channel
                        })
                    else:
                        print(f"DEBUG: No coordinates found for {city_name} (base: {base})")
                
                # Set city to processed to prevent further processing
                city = f"{city1} / {city2}"
        # --- NEW: Handle "між X та Y" pattern (e.g. "між Корюківкою та Меною") ---
        if not city:
            m_between = re.search(r'між\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,30}?)\s+та\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,30}?)(?=\s|$|[,\.\!\?;])', ln, re.IGNORECASE)
            if m_between:
                city1 = m_between.group(1).strip()
                city2 = m_between.group(2).strip()
                # Try to geocode both cities and place marker at midpoint
                base1 = normalize_city_name(city1)
                base2 = normalize_city_name(city2)
                base1 = UA_CITY_NORMALIZE.get(base1, base1)
                base2 = UA_CITY_NORMALIZE.get(base2, base2)
                
                coords1 = CITY_COORDS.get(base1) or (SETTLEMENTS_INDEX.get(base1) if SETTLEMENTS_INDEX else None)
                coords2 = CITY_COORDS.get(base2) or (SETTLEMENTS_INDEX.get(base2) if SETTLEMENTS_INDEX else None)
                
                if not coords1 and oblast_hdr:
                    combo1 = f"{base1} {oblast_hdr}"
                    coords1 = CITY_COORDS.get(combo1) or (SETTLEMENTS_INDEX.get(combo1) if SETTLEMENTS_INDEX else None)
                if not coords2 and oblast_hdr:
                    combo2 = f"{base2} {oblast_hdr}"
                    coords2 = CITY_COORDS.get(combo2) or (SETTLEMENTS_INDEX.get(combo2) if SETTLEMENTS_INDEX else None)
                
                if coords1 and coords2:
                    # Place marker at midpoint
                    lat = (coords1[0] + coords2[0]) / 2
                    lng = (coords1[1] + coords2[1]) / 2
                    label = f"Між {base1.title()} та {base2.title()}"
                    if oblast_hdr and oblast_hdr not in label.lower():
                        label += f" [{oblast_hdr.title()}]"
                    
                    # Extract count from beginning of line if present
                    count_match = re.search(r'^(\d+(?:-\d+)?)\s*бпла', ln, re.IGNORECASE)
                    count = int(count_match.group(1)) if count_match else 1
                    
                    multi_city_tracks.append({
                        'id': f"{mid}_mc{len(multi_city_tracks)+1}", 'place': label, 'lat': lat, 'lng': lng,
                        'threat_type': 'shahed', 'text': clean_text(ln)[:500], 'date': date_str, 'channel': channel,
                        'marker_icon': 'shahed.png', 'source_match': 'multiline_oblast_city_between', 'count': count
                    })
                    continue
        
        # --- NEW: Handle "неподалік X" pattern (e.g. "неподалік Ічні") ---
        if not city:
            m_near = re.search(r'неподалік\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,30}?)(?=\s|$|[,\.\!\?;])', ln, re.IGNORECASE)
            if m_near:
                city = m_near.group(1).strip()
                # Extract count from beginning of line if present
                count_match = re.search(r'^(\d+(?:-\d+)?)\s*бпла', ln, re.IGNORECASE)
                count = int(count_match.group(1)) if count_match else 1
        
        # --- NEW: Handle "в районі X" pattern (e.g. "в районі Конотопу") ---
        if not city:
            m_area = re.search(r'в\s+районі\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,30}?)(?=\s|$|[,\.\!\?;])', ln, re.IGNORECASE)
            if m_area:
                city = m_area.group(1).strip()
                # Extract count from beginning of line if present
                count_match = re.search(r'^(\d+(?:-\d+)?)\s*бпла', ln, re.IGNORECASE)
                count = int(count_match.group(1)) if count_match else 1
        
        if city:
            print(f"DEBUG: Processing city '{city}' with oblast_hdr '{oblast_hdr}' and count {count}")
            base = normalize_city_name(city)
            print(f"DEBUG: Normalized city name: '{base}'")
            # Простейшая нормализация винительного падежа -> именительный ("велику димерку" -> "велика димерка")
            if base.endswith('у димерку') and 'велик' in base:
                base = 'велика димерка'
            # Общая морфология: заменяем окончания "ку"->"ка", "ю"->"я" для последнего слова
            if base.endswith('ку '):
                base = base[:-3] + 'ка '
            elif base.endswith('ку'):
                base = base[:-2] + 'ка'
            if base.endswith('ю '):
                base = base[:-3] + 'я '
            elif base.endswith('ю'):
                base = base[:-1] + 'я'
            # Приводим многословные формы через UA_CITY_NORMALIZE если есть
            base = UA_CITY_NORMALIZE.get(base, base)
            if base == 'троєщину':
                base = 'троєщина'
                
            # Use enhanced coordinate lookup with Nominatim fallback and region context
            coords = get_coordinates_enhanced(base, region=oblast_hdr, context="БпЛА курсом на")
            
            print(f"DEBUG: Enhanced lookup for '{base}'" + (f" in {oblast_hdr}" if oblast_hdr else "") + f": {coords}")
            
            if not coords and oblast_hdr:
                # Legacy combo lookup as fallback
                combo = f"{base} {oblast_hdr}"
                print(f"DEBUG: Trying legacy combo lookup for '{combo}'")
                coords = CITY_COORDS.get(combo)
                if not coords and SETTLEMENTS_INDEX:
                    coords = SETTLEMENTS_INDEX.get(combo)
                print(f"DEBUG: Combo lookup result: {coords}")
            if not coords:
                print(f"DEBUG: Calling ensure_city_coords_with_message_context for '{base}' with oblast context '{oblast_hdr}'")
                # Try with full message context first to get oblast-specific coordinates
                context_message = f"{oblast_hdr} {original_text if 'original_text' in locals() else text}"
                coords = ensure_city_coords_with_message_context(base, context_message)
                if not coords:
                    print(f"DEBUG: Context-based lookup failed, trying standard ensure_city_coords for '{base}'")
                    coords = ensure_city_coords(base)
                print(f"DEBUG: ensure_city_coords result: {coords}")
            if coords:
                print(f"DEBUG: Found coords {coords} for city '{base}', creating track")
                # Handle both 2-tuple (lat, lng) and 3-tuple (lat, lng, approx_flag) returns
                if len(coords) == 3:
                    lat, lng, approx_flag = coords
                else:
                    lat, lng = coords
                    approx_flag = False
                threat_type, icon = 'shahed', 'shahed.png'
                label = UA_CITY_NORMALIZE.get(base, base).title()
                if oblast_hdr and oblast_hdr not in label.lower():
                    label += f" [{oblast_hdr.title()}]"
                
                # Create multiple tracks for multiple drones instead of one track with count
                tracks_to_create = max(1, count)
                for i in range(tracks_to_create):
                    track_label = label
                    if tracks_to_create > 1:
                        track_label += f" #{i+1}"
                    
                    # Add small coordinate offsets to prevent marker overlap
                    marker_lat = lat
                    marker_lng = lng
                    if tracks_to_create > 1:
                        # Create a chain pattern - drones one after another
                        offset_distance = 0.03  # ~3km offset between each drone
                        marker_lat += offset_distance * i
                        marker_lng += offset_distance * i * 0.5
                    
                    print(f"DEBUG: Creating track {i+1}/{tracks_to_create} with label '{track_label}' at {marker_lat}, {marker_lng}")
                    multi_city_tracks.append({
                        'id': f"{mid}_mc{len(multi_city_tracks)+1}", 'place': track_label, 'lat': marker_lat, 'lng': marker_lng,
                        'threat_type': threat_type, 'text': clean_text(ln)[:500], 'date': date_str, 'channel': channel,
                        'marker_icon': icon, 'source_match': 'multiline_oblast_city', 'count': 1
                    })
            else:
                print(f"DEBUG: No coordinates found for city '{base}'")
    print(f"DEBUG: Multi-city tracks processing complete. Found {len(multi_city_tracks)} tracks")
    add_debug_log(f"Multi-region processing complete: {len(multi_city_tracks)} markers from {processed_lines_count} lines", "multi_region")
    
    if multi_city_tracks:
        print(f"DEBUG: Returning {len(multi_city_tracks)} multi-city tracks")
        add_debug_log(f"Returning {len(multi_city_tracks)} multi-city tracks: {[t['place'] for t in multi_city_tracks]}", "multi_region")
        # Combine with priority result if available
        if 'priority_result' in locals() and priority_result:
            combined_result = priority_result + multi_city_tracks
            add_debug_log(f"Combined priority result ({len(priority_result)}) with multi-city tracks ({len(multi_city_tracks)}) = {len(combined_result)} total", "priority_combine")
            return combined_result
        return multi_city_tracks
    else:
        # If no multi-city tracks were created, continue with main parsing logic
        # This allows regional direction messages like "БпЛА на сході Сумщини" to be processed by regional parser
        add_debug_log(f"No multi-city tracks created, continuing to main parser", "multi_region_fallback")
    # --- Detect and split multiple city targets in one message ---
    import re
    multi_city_tracks = []
    # 1. Patterns: 'на <город>', 'повз <город>'
    # Захватываем одно- или многословные названия после "на" / "повз" до знака препинания / конца строки
    city_patterns = re.findall(r'(?:на|повз)\s+([A-Za-zА-Яа-яЇїІіЄєҐґʼ`’\-\s]{3,40}?)(?=[,\.\n;:!\?]|$)', text.lower())
    # 2. Patterns: перечисление через запятую или слэш (например: "шишаки, глобине, ромодан" или "малин/гранітне")
    # Только если в сообщении нет явного одного города в начале
    city_enumerations = []
    for part in re.split(r'[\n\|]', text.lower()):
        # ищем перечисления через запятую
        if ',' in part:
            city_enumerations += [c.strip() for c in part.split(',') if len(c.strip()) > 2]
        # ищем перечисления через слэш
        if '/' in part:
            city_enumerations += [c.strip() for c in part.split('/') if len(c.strip()) > 2]
    # Объединяем все найденные города
    all_cities = set(city_patterns + city_enumerations)
    # Фильтруем по наличию в CITY_COORDS (или SETTLEMENTS_INDEX)
    found_cities = []
    def _resolve_city_candidate(raw: str):
        cand = raw.strip().lower()
        cand = re.sub(r'["“”«»\(\)\[\]]','', cand)
        
        # CRITICAL: Remove trailing geographic qualifiers (e.g., "Канів по межі з Київщиною" → "Канів")
        trailing_patterns = [
            r'\s+по\s+межі\s+з\s+.*$',
            r'\s+на\s+межі\s+з\s+.*$',
            r'\s+в\s+районі\s+.*$',
            r'\s+біля\s+кордону\s+.*$',
            r'\s+на\s+околицях\s+.*$',
            r'\s+поблизу\s+.*$',
        ]
        for pattern in trailing_patterns:
            cand = re.sub(pattern, '', cand).strip()
        
        cand = re.sub(r'\s+',' ', cand)
        # Пробуем от длинного к короткому (до 3 слов достаточно для наших случаев)
        words = cand.split()
        if not words:
            return None
        for ln in range(min(3, len(words)), 0, -1):
            sub = ' '.join(words[:ln])
            base = UA_CITY_NORMALIZE.get(sub, sub)
            if base in CITY_COORDS or (SETTLEMENTS_INDEX and base in SETTLEMENTS_INDEX):
                return base
            # Морфология окончания винительного/родительного последнего слова
            sub_mod = re.sub(r'у\b','а', sub)
            sub_mod = re.sub(r'ю\b','я', sub_mod)
            sub_mod = re.sub(r'ої\b','а', sub_mod)
            base2 = UA_CITY_NORMALIZE.get(sub_mod, sub_mod)
            if base2 in CITY_COORDS or (SETTLEMENTS_INDEX and base2 in SETTLEMENTS_INDEX):
                return base2
        return UA_CITY_NORMALIZE.get(cand, cand)
    for city in all_cities:
        norm = _resolve_city_candidate(city)
        if not norm:
            continue
        coords = CITY_COORDS.get(norm)
        if not coords and SETTLEMENTS_INDEX:
            coords = SETTLEMENTS_INDEX.get(norm)
        if coords:
            found_cities.append((norm, coords))
    # Если найдено 2 и более города — создаём отдельный маркер для каждого
    if len(found_cities) >= 2:
        threat_type, icon = 'shahed', 'shahed.png'  # можно доработать auto-classify
        
        # Extract course information for Shahed threats
        course_info = None
        if threat_type == 'shahed':
            course_info = extract_shahed_course_info(original_text)
        
        for idx, (city, (lat, lng)) in enumerate(found_cities, 1):
            track = {
                'id': f"{mid}_mc{idx}", 'place': city.title(), 'lat': lat, 'lng': lng,
                'threat_type': threat_type, 'text': clean_text(original_text)[:500], 'date': date_str, 'channel': channel,
                'marker_icon': icon, 'source_match': 'multi_city_auto'
            }
            
            # Add course information if available
            if course_info:
                track.update({
                    'course_source': course_info.get('source_city'),
                    'course_target': course_info.get('target_city'),
                    'course_direction': course_info.get('course_direction'),
                    'course_type': course_info.get('course_type')
                })
            
            multi_city_tracks.append(track)
        if multi_city_tracks:
            return multi_city_tracks
    """Extract coordinates or try simple city geocoding (lightweight)."""
    original_text = text
    # ---------------- Global region (oblast) hint detection for universal settlement binding ----------------
    region_hint_global = None
    try:
        low_rt = original_text.lower()
        for obl_name in OBLAST_CENTERS.keys():
            if obl_name in low_rt:
                region_hint_global = obl_name  # first hit
                break
    except Exception:
        region_hint_global = None
    # Additional: detect section headers like "Сумщина:" "Полтавщина:" at line starts to set region hint
    if not region_hint_global:
        for line in original_text.split('\n'):
            l = line.strip().lower()
            if l.endswith(':'):
                base = l[:-1]
                if base in OBLAST_CENTERS:
                    region_hint_global = base
                    break

    def region_enhanced_coords(base_name: str, region_hint_override: str = None):
        """Resolve coordinates for a settlement name by weighted order (remote first):
        1) External geocode (region-qualified, then plain)
        2) Exact local datasets (CITY_COORDS, SETTLEMENTS_INDEX)
        3) Fuzzy approximate local match (Levenshtein-like via difflib)

        Rationale (user requirement): prefer freshest external resolution, fall back to local known list,
        and only then attempt approximate similarity mapping.
        """
        if not base_name:
            return None
        name_norm = UA_CITY_NORMALIZE.get(base_name, base_name).strip().lower()
        # --- 1. Remote geocode first ---
        region_for_query = region_hint_override or region_hint_global
        if region_for_query:
            canon = REGION_GEOCODE_CANON.get(region_for_query)
            if canon:
                region_for_query = canon
        # Region-qualified
        if OPENCAGE_API_KEY and region_for_query:
            try:
                combo = f"{name_norm} {region_for_query}".replace('  ', ' ').strip()
                c = geocode_opencage(combo)
                if c and 43.0 <= c[0] <= 53.8 and 20.0 <= c[1] <= 42.0:
                    return c
            except Exception:
                pass
        # Plain name remote
        if OPENCAGE_API_KEY:
            try:
                c = geocode_opencage(name_norm)
                if c and 43.0 <= c[0] <= 53.8 and 20.0 <= c[1] <= 42.0:
                    return c
            except Exception:
                pass
        # --- 2. Exact local datasets ---
        coord = CITY_COORDS.get(name_norm)
        if not coord and SETTLEMENTS_INDEX:
            coord = SETTLEMENTS_INDEX.get(name_norm)
        # Explicit settlement fallback (manual corrections for mis-geocoded small places)
        if not coord:
            coord = SETTLEMENT_FALLBACK.get(name_norm)
        if coord:
            return coord
        # --- 3. Fuzzy approximate search (only if not found) ---
        try:
            if SETTLEMENTS_INDEX:
                import difflib
                # Choose candidate list limited for performance
                names = list(SETTLEMENTS_INDEX.keys())
                # High cutoff to avoid bad matches
                best = difflib.get_close_matches(name_norm, names, n=1, cutoff=0.86)
                if best:
                    b = best[0]
                    return SETTLEMENTS_INDEX.get(b)
        except Exception:
            pass
        return None
    # ---- Fundraising / donation solicitation handling ----
    # Previous behavior: fully suppressed entire message if donation links found (blocked napramok multi-line threat posts with footer links)
    # New behavior: If donation lines present BUT the message also contains threat indicators, strip only the donation lines and continue parsing.
    low_full = original_text.lower()
    DONATION_KEYS = [
        'монобанк','monobank','mono.bank','privat24','приват24','реквізит','реквизит','донат','donat','iban','paypal','patreon','send.monobank.ua','jar/','банка: http','карта(','карта(monobank)','карта(privat24)','підтримати канал'
    ]
    donation_present = any(k in low_full for k in DONATION_KEYS) or re.search(r'\b\d{16}\b', low_full)
    # Pure subscription / invite promo suppression (no threats, mostly t.me invite links + short call to action)
    if not any(w in low_full for w in ['бпла','дрон','шахед','shahed','ракета','каб','артил','града','смерч','ураган','mlrs','iskander','s-300','s300','border','trivoga','тривога','повітряна тривога']) and \
       low_full.count('t.me/') >= 1 and len(re.sub(r'\s+',' ', low_full)) < 260 and \
       len([ln for ln in low_full.splitlines() if ln.strip()]) <= 6:
        if all(tok not in low_full for tok in ['загроза','укритт','alert','launch','start','вильот','вихід','пуски','air','strike']):
            return None
    if donation_present:
        # Threat keyword heuristic (lightweight; don't rely on later THREAT_KEYS definition yet)
        threat_tokens = ['бпла','дрон','шахед','shahed','geran','ракета','ракети','missile','iskander','s-300','s300','каб','артил','града','смерч','ураган','mlrs']
        has_threat_word = any(tok in low_full for tok in threat_tokens)
        if has_threat_word:
            # НЕ удаляем строки с донатами если есть угрозы - просто продолжаем парсинг
            log.debug(f"mid={mid} donation_present but has_threats - continuing without stripping")
            # text остается без изменений
        else:
            return [{
                'id': str(mid), 'place': None, 'lat': None, 'lng': None,
                'threat_type': None, 'text': original_text[:500], 'date': date_str, 'channel': channel,
                'list_only': True, 'suppress': True, 'suppress_reason': 'donation_only'
            }]
    # --- Universal link stripping (any clickable invite / http) ---
    def _strip_links(s: str) -> str:
        if not s:
            return s
        # markdown links [text](url)
        # handle bold inside brackets [**Text**](url) by stripping ** first
        s = re.sub(r'\*\*','', s)
        s = re.sub(r'\[([^\]]{0,80})\]\((https?://|t\.me/)[^\)]+\)', lambda m: (m.group(1) or '').strip(), s, flags=re.IGNORECASE)
        # bare urls
        s = re.sub(r'(https?://\S+|t\.me/\S+)', '', s, flags=re.IGNORECASE)
        # collapse whitespace and drop empty lines
        cleaned = []
        for ln in s.splitlines():
            ln2 = ln.strip()
            if not ln2:
                continue
            # pure decoration (arrows, bullets) or subscribe call to action lines
            if re.fullmatch(r'[>➡→\-\s·•]*', ln2):
                continue
            # remove any line that is just a subscribe CTA or starts with arrow+subscribe
            if re.search(r'(підписатись|підписатися|підписатися|подписаться|подпишись|subscribe)', ln2, re.IGNORECASE):
                continue
            # remove arrow+subscribe pattern specifically
            if re.search(r'[➡→>]\s*підписатися', ln2, re.IGNORECASE):
                continue
            cleaned.append(ln2)
        return '\n'.join(cleaned)
    new_text = _strip_links(text)
    if new_text != text:
        text = new_text
    new_orig = _strip_links(original_text)
    if new_orig != original_text:
        original_text = new_orig
    # --- Explicit launch site detection (multi-line). Create one marker per detected launch location.
    low_work = text.lower()
    if ('пуск' in low_work or 'пуски' in low_work or '+ пуски' in low_work):
        # find quoted or dash-separated site tokens: «Name», "Name", or after 'з ' preposition
        sites_found = set()
        # Quoted tokens
        for m in re.findall(r'«([^»]{2,40})»', text):
            sites_found.add(m.strip().lower())
        for m in re.findall(r'"([^"\n]{2,40})"', text):
            sites_found.add(m.strip().lower())
        # Phrases after 'з ' (from) up to comma
        for m in re.findall(r'з\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-]{2,40})', low_work):
            sites_found.add(m.strip().lower())
        # tokens after 'аеродрому' or 'аэродрома' inside quotes
        for m in re.findall(r'аеродром[ау]\s+«([^»]{2,40})»', low_work):
            sites_found.add(m.strip().lower())
        for m in re.findall(r'аэродром[ау]\s+«([^»]{2,40})»', low_work):
            sites_found.add(m.strip().lower())
        tracks = []
        threat_type = 'pusk'
        icon = 'pusk.png'
        idx = 0
        for raw_site in sites_found:
            norm_key = raw_site.replace(' — ','-').replace(' – ','-').replace('—','-').replace('–','-')
            norm_key = norm_key.replace('  ',' ').strip()
            base_variants = [norm_key, norm_key.replace('полігон ','').replace('полигон ','')]
            coord = None
            chosen_name = raw_site
            for bv in base_variants:
                if bv in LAUNCH_SITES:
                    coord = LAUNCH_SITES[bv]
                    chosen_name = bv
                    break
            if not coord:
                continue
            idx += 1
            lat,lng = coord
            tracks.append({
                'id': f"{mid}_l{idx}", 'place': chosen_name.title(), 'lat': lat, 'lng': lng,
                'threat_type': threat_type, 'text': original_text[:500], 'date': date_str, 'channel': channel,
                'marker_icon': icon, 'source_match': 'launch_site'
            })
        if tracks:
            return tracks
    # ---- Daily / periodic situation summary ("ситуація станом на HH:MM" + sectional bullets) ----
    # User request: do NOT create map markers for such aggregated status reports.
    # Heuristics: phrase "ситуація станом" (uk) or "ситуация на" (ru), OR presence of 2+ bullet headers like "• авіація", "• бпла", "• флот" in same message.
    bullet_headers = 0
    for hdr in ['• авіація', '• авиа', '• бпла', '• дро', '• флот', '• кораб', '• ракети', '• ракеты']:
        if hdr in low_full:
            bullet_headers += 1
    if re.search(r'ситуац[ія][яi]\s+станом', low_full) or re.search(r'ситуац[ия]\s+на\s+\d{1,2}:\d{2}', low_full) or bullet_headers >= 2:
        # User clarified: completely skip (no site display at all)
        return [{
            'id': str(mid), 'place': None, 'lat': None, 'lng': None,
            'threat_type': None, 'text': original_text[:800], 'date': date_str, 'channel': channel,
            'list_only': True, 'summary': True, 'suppress': True
        }]
    # ---- Imprecise directional-only messages (no exact city location) suppression ----
    # User request: messages that only state relative / directional movement without a clear city position
    # Examples: "групи ... рухаються північніше X у напрямку Y"; "... курс західний (місто)"; region-only with direction
    # Allow cases with explicit target form "курс на <city>" (precise intent) or patterns we already map like 'повз <city>' or multi-city slash/comma lists.
    def _has_threat_local(txt: str):
        l = txt.lower()
        return any(k in l for k in ['бпла','дрон','шахед','shahed','geran','ракета','ракети','missile'])
    lower_all = original_text.lower()
    if _has_threat_local(lower_all):
        directional_course = 'курс' in lower_all and any(w in lower_all for w in ['північ','півден','схід','захід']) and not re.search(r'курс(?:ом)?\s+на\s+[A-Za-zА-Яа-яЇїІіЄєҐґ\-]{3,}', lower_all)
        relative_dir_tokens = any(tok in lower_all for tok in ['північніше','південніше','східніше','західніше'])
        # Multi-city list heuristic (comma or slash separated multiple city tokens at start)
        multi_city_pattern = r"^[^\n]{0,120}?([A-Za-zА-Яа-яЇїІіЄєҐґ'`’ʼ\-]{3,}\s*,\s*){1,}[A-Za-zА-Яа-яЇїІіЄєҐґ'`’ʼ\-]{3,}"
        multi_city_enumeration = bool(re.match(multi_city_pattern, lower_all)) or ('/' in lower_all)
        has_pass_near = 'повз ' in lower_all
        if (directional_course or relative_dir_tokens) and not has_pass_near and not multi_city_enumeration:
            return [{
                'id': str(mid), 'place': None, 'lat': None, 'lng': None,
                'threat_type': None, 'text': original_text[:500], 'date': date_str, 'channel': channel,
                'list_only': True, 'suppress': True, 'suppress_reason': 'imprecise_direction_only'
            }]
    # Не удаляем полностью "Повітряна тривога" теперь: нужно показывать в списке событий.
    # Сохраняем текст как есть для event list.
    # Убираем markdown * _ ` и базовые эмодзи-иконки в начале строк
    text = re.sub(r'[\*`_]+', '', text)
    # Удаляем ведущие эмодзи/иконки перед словами
    text = re.sub(r'^[\W_]+', '', text)
    # Общий набор ключевых слов угроз
    THREAT_KEYS = ['бпла','дрон','шахед','shahed','geran','ракета','ракети','missile','iskander','s-300','s300','каб','артил','града','смерч','ураган','mlrs','avia','авіа','авиа','бомба','високошвидкісн']
    def has_threat(txt: str):
        l = txt.lower()
        return any(k in l for k in THREAT_KEYS)
    
    # PRIORITY: Structured messages with regional headers (e.g., "Область:\n city details")
    if not _disable_multiline and has_threat(original_text):
        import re as _struct_re
        # Look for pattern: "RegionName:\n threats with cities"
        region_header_pattern = r'^([А-Яа-яЇїІіЄєҐґ]+щина):\s*$'
        text_lines = original_text.split('\n')
        
        structured_sections = []
        current_region = None
        current_threats = []
        
        for line in text_lines:
            line = line.strip()
            if not line or 'підписатися' in line.lower():
                continue
                
            # Check if line is a region header
            region_match = _struct_re.match(region_header_pattern, line)
            if region_match:
                # Save previous section
                if current_region and current_threats:
                    structured_sections.append((current_region, current_threats))
                # Start new section
                current_region = region_match.group(1)
                current_threats = []
            elif current_region and ('шахед' in line.lower() or 'бпла' in line.lower()):
                # This is a threat line under current region
                current_threats.append(line)
        
        # Don't forget last section
        if current_region and current_threats:
            structured_sections.append((current_region, current_threats))
        
        # Process structured sections if we found any
        if len(structured_sections) >= 2:
            add_debug_log(f"STRUCTURED REGIONS: Found {len(structured_sections)} regions with threats", "structured_regions")
            
            all_structured_tracks = []
            for region_name, threat_lines in structured_sections:
                add_debug_log(f"Processing region {region_name} with {len(threat_lines)} threats", "structured_region_detail")
                
                for threat_line in threat_lines:
                    # Process each threat line with region context
                    region_context_text = f"{region_name}:\n{threat_line}"
                    line_tracks = process_message(region_context_text, f"{mid}_{region_name}_{len(all_structured_tracks)}", 
                                                date_str, channel, _disable_multiline=True)
                    if line_tracks:
                        all_structured_tracks.extend(line_tracks)
                        add_debug_log(f"Region {region_name} threat '{threat_line[:50]}...' produced {len(line_tracks)} tracks", "structured_threat_result")
            
            if all_structured_tracks:
                add_debug_log(f"Structured processing complete: {len(all_structured_tracks)} total tracks", "structured_complete")
                return all_structured_tracks
    
    # NEW: Handle UAV messages with "через [city]" and "повз [city]" patterns - BEFORE trajectory_phrase  
    try:
        lorig = text.lower()
        if 'бпла' in lorig and ('через' in lorig or 'повз' in lorig):
            threats = []
            
            # Extract cities from "через [city1], [city2]" pattern
            import re as _re_route
            route_pattern = r'через\s+([А-ЯІЇЄЁа-яіїєё\s\',\-]+?)(?:\s*\.\s+|$)'
            route_matches = _re_route.findall(route_pattern, text, re.IGNORECASE)
            
            for route_match in route_matches:
                # Split by comma to get individual cities
                cities_raw = [c.strip() for c in route_match.split(',') if c.strip()]
                
                for city_raw in cities_raw:
                    city_clean = city_raw.strip().strip('.,')
                    city_norm = clean_text(city_clean).lower()
                    
                    # Apply normalization rules
                    if city_norm in UA_CITY_NORMALIZE:
                        city_norm = UA_CITY_NORMALIZE[city_norm]
                    
                    # Try to get coordinates
                    coords = region_enhanced_coords(city_norm)
                    if not coords:
                        coords = ensure_city_coords(city_norm)
                    
                    if coords:
                        # Handle different coordinate formats
                        if isinstance(coords, tuple) and len(coords) >= 2:
                            lat, lng = coords[0], coords[1]
                        else:
                            continue
                        
                        threat_type, icon = classify(text)
                        
                        # Extract count from text context (look for patterns like "15х БпЛА через")
                        count = 1
                        count_match = _re_route.search(rf'(\d+)[xх×]?\s*бпла.*?через.*?{re.escape(city_clean)}', text, re.IGNORECASE)
                        if count_match:
                            count = int(count_match.group(1))
                        
                        threats.append({
                            'id': f"{mid}_route_{len(threats)}",
                            'place': city_clean.title(),
                            'lat': lat,
                            'lng': lng,
                            'threat_type': threat_type,
                            'text': f"Через {city_clean.title()} (з повідомлення про маршрут)",
                            'date': date_str,
                            'channel': channel,
                            'marker_icon': icon,
                            'source_match': f'route_via_{count}x',
                            'count': count
                        })
                        
                        add_debug_log(f"Route via: {city_clean} ({count}x) -> {coords}", "route_via")
            
            # Extract cities from "повз [city]" pattern
            past_pattern = r'повз\s+([А-ЯІЇЄЁа-яіїєё\s\',\-]+?)(?:\s*\.\s*|$)'
            past_matches = _re_route.findall(past_pattern, text, re.IGNORECASE)
            
            for past_match in past_matches:
                city_clean = past_match.strip().strip('.,')
                city_norm = clean_text(city_clean).lower()
                
                # Apply normalization rules
                if city_norm in UA_CITY_NORMALIZE:
                    city_norm = UA_CITY_NORMALIZE[city_norm]
                
                # Try to get coordinates
                coords = region_enhanced_coords(city_norm)
                if not coords:
                    coords = ensure_city_coords_with_message_context(city_norm, text)
                
                # Fallback: try accusative case normalization (e.g., "олександрію" -> "олександрія")
                if not coords and city_norm.endswith('ію'):
                    accusative_fallback = city_norm[:-2] + 'ія'
                    coords = region_enhanced_coords(accusative_fallback)
                    if not coords:
                        coords = ensure_city_coords_with_message_context(accusative_fallback, text)
                    if coords:
                        city_norm = accusative_fallback
                        city_clean = accusative_fallback.title()  # Use normalized name for display
                
                if coords:
                    # Handle different coordinate formats
                        if isinstance(coords, tuple) and len(coords) >= 2:
                            lat, lng = coords[0], coords[1]
                        else:
                            continue
                        
                        threat_type, icon = classify(text)
                        
                        # Extract count from text context (look for patterns like "4х БпЛА повз")
                        count = 1
                        count_match = _re_route.search(rf'(\d+)[xх×]?\s*бпла.*?повз.*?{re.escape(city_clean)}', text, re.IGNORECASE)
                        if count_match:
                            count = int(count_match.group(1))
                    
                        threats.append({
                            'id': f"{mid}_past_{len(threats)}",
                            'place': city_clean.title(),
                            'lat': lat,
                            'lng': lng,
                            'threat_type': threat_type,
                            'text': f"Повз {city_clean.title()} (з повідомлення про маршрут)",
                            'date': date_str,
                            'channel': channel,
                            'marker_icon': icon,
                            'source_match': f'route_past_{count}x',
                            'count': count
                        })
                        
                        add_debug_log(f"Route past: {city_clean} ({count}x) -> {coords}", "route_past")
            
            if threats:
                return threats
            else:
                pass
                
    except Exception:
        pass
    
    # --- Trajectory phrase pattern: "з дніпропетровщини через харківщину у напрямку полтавщини" ---
    # We map region stems to canonical OBLAST_CENTERS keys (simplistic stem matching).
    lower_full = text.lower()
    if has_threat(lower_full) and ' через ' in lower_full and (' у напрямку ' in lower_full or ' напрямку ' in lower_full or ' в напрямку ' in lower_full):
        # Extract sequence tokens after prepositions з/із/від -> start, через -> middle(s), напрямку -> target
        # Very heuristic; splits by key words.
        try:
            norm = re.sub(r'\s+', ' ', lower_full)
            norm = norm.replace('із ', 'з ').replace('від ', 'з ')
            if ' через ' in norm:
                front, after = norm.split(' через ', 1)
                start_token = front.split(' з ')[-1].strip()
                target_part = None; mid_part = ''
                for marker in [' у напрямку ', ' в напрямку ', ' напрямку ']:
                    if marker in after:
                        mid_part, target_part = after.split(marker, 1)
                        break
                if target_part:
                    mid_token = mid_part.strip().split('.')[0]
                    target_token = target_part.strip().split('.')[0]
                    def region_center(token: str):
                        token = token.strip()
                        for k,(lat,lng) in OBLAST_CENTERS.items():
                            if token.startswith(k.split()[0][:6]) or token in k:
                                return (k,(lat,lng))
                        return None
                    seq = []
                    for tk in [start_token, mid_token, target_token]:
                        rc = region_center(tk)
                        if rc and (not seq or seq[-1][0] != rc[0]):
                            seq.append(rc)
                    if len(seq) >= 2:
                        threat_type, icon = classify(text)
                        tracks = []
                        for idx,(name,(lat,lng)) in enumerate(seq,1):
                            base = name.split()[0].title()
                            tracks.append({
                                'id': f"{mid}_t{idx}", 'place': base, 'lat': lat, 'lng': lng,
                                'threat_type': threat_type, 'text': original_text[:500], 'date': date_str, 'channel': channel,
                                'marker_icon': icon, 'source_match': 'trajectory_phrase'
                            })
                        return tracks
        except Exception:
            pass
    # direct coordinates pattern
    # --- Direction with parenthetical specific settlement e.g. "у напрямку білгород-дністровського району одещини (затока)" ---
    if has_threat(lower_full) and 'у напрямку' in lower_full and '(' in lower_full and ')' in lower_full:
        # capture last parenthetical token (short) that is a known settlement
        try:
            paren_tokens = re.findall(r'\(([a-zа-яіїєґ\-\s]{3,})\)', lower_full)
            if paren_tokens:
                candidate = paren_tokens[-1].strip().lower()
                # trim descriptors like 'смт ' , 'с.' etc
                candidate = re.sub(r'^(смт|с\.|м\.|місто|селище)\s+','', candidate)
                norm = UA_CITY_NORMALIZE.get(candidate, candidate)
                coords = CITY_COORDS.get(norm)
                if not coords and SETTLEMENTS_INDEX:
                    coords = SETTLEMENTS_INDEX.get(norm)
                if not coords:
                    coords = SETTLEMENT_FALLBACK.get(norm)
                log.debug(f"parenthetical_dir detect mid={mid} candidate={candidate} norm={norm} found={bool(coords)}")
                if coords:
                    lat,lng = coords
                    threat_type, icon = classify(text)
                    return [{
                        'id': f"{mid}_dirp", 'place': norm.title(), 'lat': lat, 'lng': lng,
                        'threat_type': threat_type, 'text': original_text[:500], 'date': date_str, 'channel': channel,
                        'marker_icon': icon, 'source_match': 'direction_parenthetical'
                    }]
        except Exception:
            pass
    # --- Region-level shelling threat (e.g. "Харківська обл. Загроза обстрілу прикордонних територій") ---
    try:
        if re.search(r'(загроза обстрілу|угроза обстрела)', lower_full):
            # attempt to match any oblast token present
            region_hit = None
            for reg_key in OBLAST_CENTERS.keys():
                if reg_key in lower_full:
                    region_hit = reg_key
                    log.debug(f"region_shelling candidate mid={mid} match={reg_key}")
                    break
            if region_hit:
                # Only emit if we haven't already returned a more specific structure earlier (heuristic: continue)
                lat, lng = OBLAST_CENTERS[region_hit]
                threat_type, icon = classify(text)
                # Enforce obstril icon for shelling phrasing even if classify changed in future
                if re.search(r'(загроза обстрілу|угроза обстрела|обстріл|обстрел)', lower_full):
                    threat_type = 'artillery'; icon = 'obstril.png'
                border_shell = bool(re.search(r'прикордон|пригранич', lower_full))
                place_label = region_hit
                if border_shell:
                    place_label += ' (прикордоння)'
                log.debug(f"region_shelling emit mid={mid} region={region_hit} border={border_shell}")
                return [{
                    'id': f"{mid}_region_shell", 'place': place_label, 'lat': lat, 'lng': lng,
                    'threat_type': threat_type, 'text': original_text[:500], 'date': date_str, 'channel': channel,
                    'marker_icon': icon, 'source_match': 'region_shelling', 'border_shelling': border_shell
                }]
    except Exception:
        pass
    # Special handling for KAB threats with regional mentions (e.g., "Загроза КАБ для прифронтових громад Сумщини")
    kab_region_match = re.search(r'(каб|авіабомб|авиабомб|авіаційних.*бомб|керован.*бомб)[^\.]*?(сумщин[иіа]|харківщин[иіа]|чернігівщин[иіа]|полтавщин[иіа])', text.lower())
    if kab_region_match:
        region_mention = kab_region_match.group(2)
        # Convert genitive/dative to nominative
        if 'сумщин' in region_mention:
            region_key = 'сумщина'
        elif 'харківщин' in region_mention:
            region_key = 'харківщина'
        elif 'чернігівщин' in region_mention:
            region_key = 'чернігівщина'
        elif 'полтавщин' in region_mention:
            region_key = 'полтавщина'
        else:
            region_key = None
            
        if region_key and region_key in OBLAST_CENTERS:
            lat, lng = OBLAST_CENTERS[region_key]
            # For KAB threats, offset coordinates slightly from city center to avoid implying direct city impact
            if region_key == 'сумщина':
                lat += 0.1  # Move north of Sumy city
                lng -= 0.1  # Move west of Sumy city
            elif region_key == 'харківщина':
                lat += 0.1  # Move north of Kharkiv city
                lng -= 0.1  # Move west of Kharkiv city
            add_debug_log(f"Creating KAB regional threat marker for {region_key}: lat={lat}, lng={lng}", "kab_regional")
            return [{
                'id': f"{mid}_kab_regional", 'place': region_key.title(), 'lat': lat, 'lng': lng,
                'threat_type': 'raketa', 'text': original_text[:500], 'date': date_str, 'channel': channel,
                'marker_icon': 'raketa.png', 'source_match': 'kab_regional_threat'
            }]
    
    # SPECIAL: Handle multi-regional UAV messages (like the user's example)
    def handle_multi_regional_uav():
        """Handle messages with multiple regional UAV threats listed separately"""
        threats = []
        text_lines = text.split('\n')
        
        # Check if this looks like a multi-regional UAV message
        region_count = 0
        uav_count = 0
        for line in text_lines:
            line_lower = line.lower().strip()
            if not line_lower:
                continue
                
            # Count regions mentioned
            if any(region in line_lower for region in ['щина:', 'область:', 'край:']):
                region_count += 1
            
            # Count UAV mentions
            if 'бпла' in line_lower and ('курс' in line_lower or 'на ' in line_lower):
                uav_count += 1
        
        # If we have multiple regions and multiple UAV mentions, process each line
        if region_count >= 2 and uav_count >= 3:
            add_debug_log(f"MULTI-REGIONAL UAV MESSAGE: {region_count} regions, {uav_count} UAVs", "multi_regional")
            
            for line in text_lines:
                line_stripped = line.strip()
                if not line_stripped or ':' in line_stripped[:20]:  # Skip region headers
                    continue
                
                line_lower = line_stripped.lower()
                
                # Look for UAV course patterns
                if 'бпла' in line_lower and ('курс' in line_lower or ' на ' in line_lower):
                    # Extract city name from patterns like "БпЛА курсом на Конотоп" or "2х БпЛА курсом на Велику Димерку"
                    patterns = [
                        r'(\d+(?:-\d+)?)?[xх×]?\s*бпла\s+курсом?\s+на\s+([А-ЯІЇЄЁа-яіїєё\'\-\s]+?)(?:\s*$|\s*[,\.\!\?\|])',
                        r'бпла\s+курсом?\s+на\s+([А-ЯІЇЄЁа-яіїєё\'\-\s]+?)(?:\s*$|\s*[,\.\!\?\|])',
                        r'(\d+(?:-\d+)?)?[xх×]?\s*бпла\s+на\s+([А-ЯІЇЄЁа-яіїєё\'\-\s]+?)(?:\s*$|\s*[,\.\!\?\|])'
                    ]
                    
                    for pattern in patterns:
                        matches = re.finditer(pattern, line_stripped, re.IGNORECASE)
                        for match in matches:
                            if len(match.groups()) == 2:
                                count_str, city_raw = match.groups()
                            else:
                                count_str = None
                                city_raw = match.group(1)
                            
                            if not city_raw:
                                continue
                                
                            # Clean and normalize city name
                            city_clean = city_raw.strip()
                            city_norm = clean_text(city_clean).lower()
                            
                            # Apply normalization rules
                            if city_norm in UA_CITY_NORMALIZE:
                                city_norm = UA_CITY_NORMALIZE[city_norm]
                            
                            # Try to get coordinates
                            coords = region_enhanced_coords(city_norm)
                            if not coords:
                                coords = ensure_city_coords(city_norm)
                            
                            if coords:
                                lat, lng = coords
                                threat_type, icon = classify(text)
                                
                                # Extract count if present
                                uav_count_num = 1
                                if count_str and count_str.isdigit():
                                    uav_count_num = int(count_str)
                                
                                threat_id = f"{mid}_multi_{len(threats)}"
                                threats.append({
                                    'id': threat_id,
                                    'place': city_clean.title(),
                                    'lat': lat,
                                    'lng': lng,
                                    'threat_type': threat_type,
                                    'text': f"{line_stripped} (з багаторегіонального повідомлення)",
                                    'date': date_str,
                                    'channel': channel,
                                    'marker_icon': icon,
                                    'source_match': f'multi_regional_uav_{uav_count_num}x',
                                    'count': uav_count_num
                                })
                                
                                add_debug_log(f"Multi-regional UAV: {city_clean} ({uav_count_num}x) -> {coords}", "multi_regional")
                            else:
                                add_debug_log(f"Multi-regional UAV: No coords for {city_clean}", "multi_regional")
        
        return threats

    # SPECIAL: Handle single UAV course mentions in regular messages
    def handle_single_uav_courses():
        """Handle UAV course mentions like '4х БпЛА курсом на Добротвір' in regular alert messages"""
        threats = []
        
        # Look for UAV course patterns in the entire message
        patterns = [
            r'(\d+(?:-\d+)?)?[xх×]?\s*бпла\s+курсом?\s+на\s+([А-ЯІЇЄЁа-яіїєё\'\-\s]+?)(?:\s*$|\s*[,\.\!\?\|\(])',
            r'бпла\s+курсом?\s+на\s+([А-ЯІЇЄЁа-яіїєё\'\-\s]+?)(?:\s*$|\s*[,\.\!\?\|\(])',
            r'(\d+(?:-\d+)?)?[xх×]?\s*бпла\s+на\s+([А-ЯІЇЄЁа-яіїєё\'\-\s]+?)(?:\s*$|\s*[,\.\!\?\|\(])'
        ]
        
        for pattern in patterns:
            matches = re.finditer(pattern, text, re.IGNORECASE)
            for match in matches:
                if len(match.groups()) == 2:
                    count_str, city_raw = match.groups()
                else:
                    count_str = None
                    city_raw = match.group(1)
                
                if not city_raw:
                    continue
                    
                # Clean and normalize city name
                city_clean = city_raw.strip()
                city_norm = clean_text(city_clean).lower()
                
                # Apply normalization rules
                if city_norm in UA_CITY_NORMALIZE:
                    city_norm = UA_CITY_NORMALIZE[city_norm]
                
                # Try to get coordinates
                coords = region_enhanced_coords(city_norm)
                if not coords:
                    coords = ensure_city_coords(city_norm)
                
                if coords:
                    lat, lng = coords[:2]
                    threat_type, icon = classify(text)
                    
                    # Extract count if present
                    uav_count_num = 1
                    if count_str and count_str.isdigit():
                        uav_count_num = int(count_str)
                    
                    threat_id = f"{mid}_uav_course_{len(threats)}"
                    threats.append({
                        'id': threat_id,
                        'place': city_clean.title(),
                        'lat': lat,
                        'lng': lng,
                        'threat_type': threat_type,
                        'text': f"БпЛА курсом на {city_clean} ({uav_count_num}x)",
                        'date': date_str,
                        'channel': channel,
                        'marker_icon': icon,
                        'source_match': f'single_uav_course_{uav_count_num}x',
                        'count': uav_count_num
                    })
                    
                    add_debug_log(f"Single UAV course: {city_clean} ({uav_count_num}x) -> {coords}", "single_uav")
                else:
                    add_debug_log(f"Single UAV course: No coords for {city_clean}", "single_uav")
        
        # ALSO: Extract cities from emoji structure in the same text 
        # Pattern for "| 🛸 Город (Область)"
        emoji_pattern = r'\|\s*🛸\s*([А-ЯІЇЄЁа-яіїєё\'\-\s]+?)\s*\([^)]*обл[^)]*\)'
        emoji_matches = re.finditer(emoji_pattern, text, re.IGNORECASE)
        
        for match in emoji_matches:
            city_raw = match.group(1).strip()
            if not city_raw or len(city_raw) < 2:
                continue
                
            city_norm = clean_text(city_raw).lower()
            if city_norm in UA_CITY_NORMALIZE:
                city_norm = UA_CITY_NORMALIZE[city_norm]
            
            coords = region_enhanced_coords(city_norm)
            if not coords:
                coords = ensure_city_coords(city_norm)
            
            if coords:
                lat, lng = coords[:2]
                threat_type, icon = classify(text)
                
                threat_id = f"{mid}_emoji_struct_{len(threats)}"
                threats.append({
                    'id': threat_id,
                    'place': city_raw.title(),
                    'lat': lat,
                    'lng': lng,
                    'threat_type': threat_type,
                    'text': f"Загроза в {city_raw}",
                    'date': date_str,
                    'channel': channel,
                    'marker_icon': icon,
                    'source_match': 'emoji_structure',
                    'count': 1
                })
                
                add_debug_log(f"Emoji structure: {city_raw} -> {coords}", "emoji_struct")
            else:
                add_debug_log(f"Emoji structure: No coords for {city_raw}", "emoji_struct")
        
        return threats

    # Check for single UAV course mentions first (before multi-regional check)
    single_uav_threats = handle_single_uav_courses()
    if single_uav_threats:
        add_debug_log(f"SINGLE UAV COURSES: Found {len(single_uav_threats)} threats", "single_uav")
        # Continue processing to also get regular location markers
        # Don't return early - we want both UAV course markers AND location markers

    # Check for multi-regional UAV messages
    if multi_regional_flag:
        multi_regional_threats = handle_multi_regional_uav()
        if multi_regional_threats:
            add_debug_log(f"MULTI-REGIONAL UAV: Found {len(multi_regional_threats)} threats", "multi_regional")
            return multi_regional_threats

    # Southeast-wide tactical aviation activity (no specific settlement): place a synthetic marker off SE border.
    se_phrase = lower if 'lower' in locals() else original_text.lower()
    if ('тактичн' in se_phrase or 'авіаці' in se_phrase or 'авиац' in se_phrase) and ('південно-східн' in se_phrase or 'південно східн' in se_phrase or 'юго-восточ' in se_phrase or 'південного-сходу' in se_phrase):
        # Approx point in Azov Sea off SE (between Mariupol & Berdyansk) to avoid implying exact impact
        lat, lng = 46.5, 37.5
        return [{
            'id': f"{mid}_se", 'place': 'Південно-східний напрямок', 'lat': lat, 'lng': lng,
            'threat_type': 'avia', 'text': original_text[:500], 'date': date_str, 'channel': channel,
            'marker_icon': 'avia.png', 'source_match': 'southeast_aviation'
        }]
    # North-east tactical aviation activity - coordinates moved to Ukrainian territory
    # Original coordinates (50.4, 36.8) were too close to Russian border
    # SKIP if this is a multi-threat message (handled separately above)
    if ('тактичн' in se_phrase or 'авіаці' in se_phrase or 'авиац' in se_phrase) and (
        'північно-східн' in se_phrase or 'північно східн' in se_phrase or 'северо-восточ' in se_phrase or 'північного-сходу' in se_phrase
    ) and not ('🛬' in original_text and '🛸' in original_text):
        # Moved coordinates to Sumy area (clearly in Ukrainian territory)
        lat, lng = 50.9, 34.8  # Near Sumy city
        return [{
            'id': f"{mid}_ne", 'place': 'Північно-східний напрямок', 'lat': lat, 'lng': lng,
            'threat_type': 'avia', 'text': original_text[:500], 'date': date_str, 'channel': channel,
            'marker_icon': 'avia.png', 'source_match': 'northeast_aviation'
        }]
    m = re.search(r'(\d{1,2}\.\d+),(\d{1,3}\.\d+)', text)
    if m:
        lat = float(m.group(1)); lng = float(m.group(2))
        threat_type, icon = classify(text)
        return [{
            'id': str(mid), 'place': 'Unknown', 'lat': lat, 'lng': lng,
            'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
            'marker_icon': icon
        }]
    # Alarm cancellation always list-only
    if re.search(r'відбій\s+тривог|отбой\s+тревог', original_text.lower()):
        return [{
            'id': str(mid), 'place': None, 'lat': None, 'lng': None,
            'threat_type': 'alarm_cancel', 'text': original_text[:500], 'date': date_str, 'channel': channel,
            'marker_icon': 'vidboi.png', 'list_only': True
        }]
    lower = text.lower()
    # Specialized single-line pattern: direction from one oblast toward another (e.g. 'бпла ... курсом на полтавщину')
    import re as _re_one
    m_dir_oblast = _re_one.search(r'бпла[^\n]*курс(?:ом)?\s+на\s+([a-zа-яїієґ\-]+щин[ауі])', lower)
    if m_dir_oblast:
        dest = m_dir_oblast.group(1)
        # normalize accusative -> nominative
        dest_norm = dest.replace('щину','щина').replace('щини','щина')
        if dest_norm in OBLAST_CENTERS:
            lat, lng = OBLAST_CENTERS[dest_norm]
            return [{
                'id': f"{mid}_dir_oblast", 'place': dest_norm.title(), 'lat': lat, 'lng': lng,
                'threat_type': 'uav', 'text': original_text[:500], 'date': date_str, 'channel': channel,
                'marker_icon': 'shahed.png', 'source_match': 'singleline_oblast_course'
            }]
    # Extract drone / shahed count pattern (e.g. "7х бпла", "6x дронів", "10 х бпла") early so later branches can reuse
    drone_count = None
    m_count = re.search(r'(\b\d{1,3})\s*[xх]\s*(?:бпла|дрон|дрони|шахед|шахеди|шахедів)', lower)
    if m_count:
        try:
            drone_count = int(m_count.group(1))
        except ValueError:
            drone_count = None
    # Normalize some genitive forms ("дніпропетровської" -> base) to capture multiple oblasts in one message
    GENITIVE_NORMALIZE = {
        'дніпропетровської': 'дніпропетровська область',
        'днепропетровской': 'дніпропетровська область',
        'чернігівської': 'чернігівська обл.',
        'черниговской': 'чернігівська обл.',
        'сумської': 'сумська область',
        'сумской': 'сумська область',
        'харківської': 'харківська обл.',
        'харьковской': 'харківська обл.'
    }
    for gform, base_form in GENITIVE_NORMALIZE.items():
        if gform in lower:
            lower = lower.replace(gform, base_form)
    # Locative / prepositional oblast & region endings -> base ("дніпропетровщині" -> "дніпропетровщина")
    LOCATIVE_NORMALIZE = {
        'дніпропетровщині': 'дніпропетровщина',
        'донеччині': 'донеччина',
        'сумщині': 'сумщина',
        'харківщині': 'харківщина',
        'чернігівщині': 'чернігівщина',
        'миколаївщині': 'миколаївщина'
    }
    for lform, base_form in LOCATIVE_NORMALIZE.items():
        if lform in lower:
            lower = lower.replace(lform, base_form)
    # City genitive -> nominative (subset) for settlement detection
    CITY_GENITIVE = [
        ('харкова','харків'), ('києва','київ'), ('львова','львів'), ('одеси','одеса'), ('дніпра','дніпро')
    ]
    for gform, base in CITY_GENITIVE:
        if gform in lower:
            lower = lower.replace(gform, base)
    # Normalize some accusative oblast forms to nominative for matching
    lower = lower.replace('донеччину','донеччина').replace('сумщину','сумщина')
    text = lower  # downstream logic mostly uses lower-case comparisons
    # Санітизація дублювань типу "область області" -> залишаємо один раз
    text = re.sub(r'(область|обл\.)\s+област[іи]', r'\1', text)

    # --- Simple sanitization of formatting noise (bold asterisks, stray stars) ---
    # Keeps Ukrainian characters while removing leading/trailing markup like ** or * around segments
    if '**' in text or '*' in text:
        # remove isolated asterisks not part of words
        text = re.sub(r'\*+', '', text)

    # --- Early explicit pattern: "<RaionName> район (<Oblast ...>)" (e.g. "Запорізький район (Запорізька обл.)") ---
    # Sometimes such messages were slipping through as raw because the pre-parenthesis token ended with 'район'.
    m_raion_oblast = re.search(r'([A-Za-zА-Яа-яЇїІіЄєҐґ\-]{4,})\s+район\s*\(([^)]*обл[^)]*)\)', text)
    if m_raion_oblast:
        raion_token = m_raion_oblast.group(1).strip().lower()
        # Normalize morphological endings similar to later norm_raion logic
        raion_base = re.sub(r'(ському|ского|ського|ский|ськiй|ськой|ським|ском)$', 'ський', raion_token)
        if raion_base in RAION_FALLBACK:
            lat, lng = RAION_FALLBACK[raion_base]
            threat_type, icon = classify(original_text if 'original_text' in locals() else text)
            # Maintain active raion alarm state
            if threat_type == 'alarm':
                RAION_ALARMS[raion_base] = {'place': f"{raion_base.title()} район", 'lat': lat, 'lng': lng, 'since': time.time()}
            elif threat_type == 'alarm_cancel':
                RAION_ALARMS.pop(raion_base, None)
            return [{
                'id': str(mid), 'place': f"{raion_base.title()} район", 'lat': lat, 'lng': lng,
                'threat_type': threat_type, 'text': (original_text if 'original_text' in locals() else text)[:500],
                'date': date_str, 'channel': channel, 'marker_icon': icon, 'source_match': 'raion_oblast_combo'
            }]
        else:
            log.debug(f"raion_oblast primary matched token={raion_token} base={raion_base} no coords")
    else:
        # Secondary heuristic fallback if formatting (emoji / markup) broke regex
        if 'район (' in text and ' обл' in text and has_threat(text):
            try:
                prefix = text.split('район (',1)[0]
                cand = prefix.strip().split()[-1].lower()
                cand_base = re.sub(r'(ському|ского|ського|ский|ськiй|ськой|ським|ском)$', 'ський', cand)
                if cand_base in RAION_FALLBACK:
                    lat,lng = RAION_FALLBACK[cand_base]
                    threat_type, icon = classify(original_text if 'original_text' in locals() else text)
                    log.debug(f"raion_oblast secondary emit cand={cand} base={cand_base}")
                    return [{
                        'id': str(mid), 'place': f"{cand_base.title()} район", 'lat': lat, 'lng': lng,
                        'threat_type': threat_type, 'text': (original_text if 'original_text' in locals() else text)[:500],
                        'date': date_str, 'channel': channel, 'marker_icon': icon, 'source_match': 'raion_oblast_secondary'
                    }]
                else:
                    log.debug(f"raion_oblast secondary no coords cand={cand} base={cand_base}")
            except Exception as _e:
                log.debug(f"raion_oblast secondary error={_e}")

    # --- Russian strategic aviation suppression ---
    def _is_russian_strategic_aviation(t: str) -> bool:
        """Suppress messages about Russian strategic aviation (Tu-95, etc.) from Russian airbases"""
        t_lower = t.lower()
        
        # Check for Russian strategic bombers
        russian_bombers = ['ту-95', 'tu-95', 'ту-160', 'tu-160', 'ту-22', 'tu-22']
        has_bomber = any(bomber in t_lower for bomber in russian_bombers)
        
        # Check for Russian airbases and regions
        russian_airbases = ['енгельс', 'engels', 'энгельс', 'саратов', 'рязань', 'муром', 'украінка', 'українка']
        has_russian_airbase = any(airbase in t_lower for airbase in russian_airbases)
        
        # Check for Russian regions/areas
        russian_regions = ['саратовській області', 'саратовской области', 'тульській області', 'рязанській області']
        has_russian_region = any(region in t_lower for region in russian_regions)
        
        # Check for terms indicating Russian territory/airbases
        russian_territory_terms = ['аеродрома', 'аэродрома', 'з аеродрому', 'с аэродрома', 'мета вильоту невідома', 'цель вылета неизвестна']
        has_russian_territory = any(term in t_lower for term in russian_territory_terms)
        
        # Check for generic relocation/transfer terms without specific threats
        relocation_terms = ['передислокація', 'передислокация', 'переліт', 'перелет', 'відмічено', 'отмечено']
        has_relocation = any(term in t_lower for term in relocation_terms)
        
        # Suppress if it's about Russian bombers from Russian territory
        if has_bomber and (has_russian_airbase or has_russian_territory or has_russian_region):
            return True
            
        # Suppress relocation/transfer messages between Russian airbases
        if has_relocation and has_bomber and (has_russian_airbase or has_russian_region):
            return True
            
        # Also suppress general strategic aviation reports without specific Ukrainian targets
        if ('борт' in t_lower or 'борти' in t_lower) and ('мета вильоту невідома' in t_lower or 'цель вылета неизвестна' in t_lower):
            return True
            
        return False

    # --- General warning suppression ---

    if _is_russian_strategic_aviation(text):
        return None
        
    if _is_general_warning_without_location(text):
        return None

    # --- Western border drone reconnaissance suppression ---
    def _is_western_border_reconnaissance(t: str) -> bool:
        """Suppress messages about drones crossing western borders (Hungary, etc.) - not related to Russian threats"""
        t_lower = t.lower()
        
        # Check for western border crossing indicators
        border_crossing_terms = [
            'перетнув державний кордон', 'пересек государственную границу',
            'перетнув кордон', 'пересек границу',
            'з боку угорщини', 'со стороны венгрии',
            'з території угорщини', 'с территории венгрии'
        ]
        has_border_crossing = any(term in t_lower for term in border_crossing_terms)
        
        # Check for western regions (primarily Zakarpattya)
        western_regions = ['закарпатт', 'закарпать', 'ужгород', 'мукачев']
        has_western_region = any(region in t_lower for region in western_regions)
        
        # Check for reconnaissance/monitoring context (not combat threats)
        recon_terms = ['радари зсу', 'радары всу', 'зафіксували проліт', 'зафиксировали пролет', 'стежити за обстановкою', 'следить за обстановкой']
        has_recon_context = any(term in t_lower for term in recon_terms)
        
        # Suppress if it's about western border reconnaissance
        if has_border_crossing and has_western_region:
            return True
            
        # Also suppress general monitoring messages about western regions
        if has_western_region and has_recon_context and ('дрон' in t_lower or 'бпла' in t_lower):
            return True
            
        return False

    if _is_western_border_reconnaissance(text):
        return None

    # --- Aggregate / statistical summary suppression ---
    def _is_aggregate_summary(t: str) -> bool:
        # Situation report override: if starts with 'обстановка' we evaluate full logic first (word 'загроза' inside shouldn't unblock)
        starts_obst = t.startswith('обстановка')
        # Do not suppress if explicit real-time warning words present (unless it's a structured situation report)
        if not starts_obst and any(w in t for w in ['загроза','перейдіть в укриття','укриття!']):
            return False
        verbs = ['збито/подавлено','збито / подавлено','збито-подавлено','збито','подавлено','знищено']
        context = ['станом на','за попередніми даними','у ніч на','повітряний напад','протиповітряною обороною','протиповітряна оборона','підрозділи реб','мобільні вогневі групи','обстановка']
        objects_re = re.compile(r'\b\d{1,3}[\-–]?(ма|)?\s*(ворожих|)\s*(бпла|shahed|дрон(?:ів|и)?|ракет|ракети)')
        verb_hit = any(v in t for v in verbs)
        ctx_hits = sum(1 for c in context if c in t)
        obj_hit = bool(objects_re.search(t))
        # Strong aggregate if all three categories present OR multiple context + objects
        if (verb_hit and obj_hit and ctx_hits >= 1) or (ctx_hits >= 2 and obj_hit):
            return True
        # Long multiline with origins list and many commas plus 'типу shahed'
        if 'типу shahed' in t and t.count('\n') >= 2 and obj_hit:
            return True
        # Situation report structure: starts with 'обстановка станом на' or begins with 'обстановка' and multiple category lines (— стратегічна авіація, — бпла, — флот)
        if starts_obst:
            dash_lines = sum(1 for line in t.split('\n') if line.strip().startswith('—'))
            if dash_lines >= 2:
                return True
        return False
    if _is_aggregate_summary(text):
        return None

    # --- Pattern: City (Oblast ...) e.g. "Павлоград (Дніпропетровська обл.)" ---
    bracket_city = re.search(r'([A-Za-zА-Яа-яЇїІіЄєҐґ\-]{3,})\s*\(([^)]+)\)', text)
    if bracket_city:
        raw_city = bracket_city.group(1).strip().lower()
        raw_inside = bracket_city.group(2).lower()
        # Особый случай: "дніпропетровська область (павлоградський р-н)" -> ставим Павлоград
        if ('область' in raw_city or 'обл' in raw_city) and ('павлоград' in raw_inside):
            pav_key = 'павлоградський'
            if pav_key in RAION_FALLBACK:
                lat,lng = RAION_FALLBACK[pav_key]
                threat_type, icon = classify(text)
                return [{
                    'id': str(mid), 'place': 'Павлоградський район', 'lat': lat, 'lng': lng,
                    'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
                    'marker_icon': icon, 'source_match': 'oblast_raion_combo'
                }]
        # Пропускаем случаи вида "<область> (<район ...>)" чтобы не трактовать слово 'область' как город
        if raw_city in {'область','обл','обл.'} or raw_city.endswith('область'):
            bracket_city = None
    if bracket_city and raw_city != 'район':
            norm_city = UA_CITY_NORMALIZE.get(raw_city, raw_city)
            # Initial local attempt (static minimal list)
            coords = CITY_COORDS.get(norm_city)
            # Region hint extraction
            region_hint = None
            if any(tok in raw_inside for tok in ['обл', 'область']):
                region_hint = raw_inside.strip()
            # 1) Explicit override for (city, region) if provided
            if region_hint:
                override_key = (norm_city, region_hint)
                if override_key in OBLAST_CITY_OVERRIDES:
                    coords = OBLAST_CITY_OVERRIDES[override_key]
            # 2) If we have region hint and NO coords yet, attempt region-qualified geocode first (priority to enforce oblast binding)
            region_combo_tried = False
            if not coords and region_hint and OPENCAGE_API_KEY:
                combo_query = f"{norm_city} {region_hint}".replace('  ',' ').strip()
                try:
                    refined = geocode_opencage(combo_query)
                    if refined:
                        coords = refined
                    region_combo_tried = True
                except Exception:
                    pass
            # 3) Attempt city alone geocode only if still no coords
            if not coords and OPENCAGE_API_KEY:
                try:
                    coords = geocode_opencage(norm_city)
                except Exception:
                    pass
            # 4) If region hint exists and we got coords from plain city geocode but city is potentially duplicated across oblasts,
            # try region-qualified geocode as refinement (unless already tried).
            if region_hint and OPENCAGE_API_KEY and not region_combo_tried and coords and norm_city in ['борова','миколаївка','николаевка']:
                try:
                    combo_query = f"{norm_city} {region_hint}".replace('  ',' ').strip()
                    refined2 = geocode_opencage(combo_query)
                    if refined2:
                        coords = refined2
                except Exception:
                    pass
            # Ambiguous manual mapping fallback (if still no coords or mismatch with region)
            if region_hint:
                # derive stem like 'харківськ', 'львівськ'
                rh_low = region_hint.lower()
                # choose first word containing 'харків' etc
                region_key = None
                for stem in ['харків','львів','київ','дніпропетров','полтав','сум','черніг','волин','запор','одес','микола','черка','житом','хмельниць','рівн','івано','терноп','ужгород','кропив','луган','донець','чернівц']:
                    if stem in rh_low:
                        region_key = stem
                        break
                AMBIGUOUS_CITY_REGION = {
                    ('золочів','харків'): (50.2788, 36.3644),  # Zolochiv Kharkiv oblast
                    ('золочів','львів'): (49.8078, 24.9002),   # Zolochiv Lviv oblast
                }
                if region_key:
                    key = (norm_city, region_key)
                    mapped = AMBIGUOUS_CITY_REGION.get(key)
                    if mapped:
                        coords = mapped
            if coords:
                lat,lng = coords
                threat_type, icon = classify(text)
                return [{
                    'id': str(mid), 'place': norm_city.title(), 'lat': lat, 'lng': lng,
                    'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
                    'marker_icon': icon, 'source_match': 'bracket_city'
                }]

    # --- Multi-segment / enumerated lines (1. 2. 3.) region extraction ---
    # Разбиваем по переносам, собираем упоминания нескольких областей; создаём отдельные маркеры
    
    # PRIORITY: Detect trajectory patterns BEFORE multi-region processing
    # Pattern: "з [source_region] на [target_region(s)]" - trajectory, not multi-target
    trajectory_pattern = r'(\d+(?:-\d+)?)?\s*шахед[іївыиє]*\s+з\s+([а-яіїєґ]+(щин|ччин)[ауиі])\s+на\s+([а-яіїєґ/]+(щин|ччин)[ауиіу])'
    trajectory_match = re.search(trajectory_pattern, text.lower(), re.IGNORECASE)
    
    if trajectory_match:
        count_str = trajectory_match.group(1)
        source_region = trajectory_match.group(2)
        target_regions = trajectory_match.group(4)
        
        print(f"DEBUG: Trajectory detected - {count_str or ''}шахедів з {source_region} на {target_regions}")
        
        # For trajectory messages, we should NOT create markers in region centers
        # This represents movement through airspace, not attacks on specific locations
        # Options:
        # 1. Don't create any markers (trajectory only)
        # 2. Create trajectory line visualization 
        # 3. Create border crossing markers
        
        # For now, suppress markers for pure trajectory messages
        print(f"DEBUG: Suppressing region markers for trajectory message")
        return None
    
    region_hits = []  # list of (display_name, (lat,lng), snippet)
    # Treat semicolons as separators like newlines for multi-segment parsing
    seg_text = text.replace(';', '\n')
    lines = [ln.strip() for ln in seg_text.split('\n') if ln.strip()]
    # Pre-flag launch site style multi-line posts to avoid RAW fallback – treat each line with a launch phrase as separate pseudo-track (no coords yet)
    launch_mode = any(ln.lower().startswith('відмічені пуски') or ln.lower().startswith('+ пуски') for ln in lines)
    for ln in lines:
        ln_low = ln.lower()
        local_regions = []
        for name, coords in OBLAST_CENTERS.items():
            if name in ln_low:
                local_regions.append((name, coords))
        # если в строке более 1— сохраняем все, иначе одну
        for (rn, rc) in local_regions:
            region_hits.append((rn.title(), rc, ln[:180]))
    # Якщо знайшли >=2 регіональних маркери в різних пунктах списку — формуємо множинні треки
    if len(region_hits) >= 2 and not launch_mode:
        # ВИДАЛЕНО перевірку course_line_present - тепер завжди дозволяємо region markers + course parsing
        if True:  # завжди виконуємо блок регіональних маркерів
            # Пропускаем если нет ни одного упоминания угрозы вообще
            if not has_threat(text):
                return None
            threat_type, icon = classify(text)
            tracks = []
            # deduplicate by name
            seen_names = set()
            # Directional offset helper
            def directional_offset(rlabel: str, lat: float, lng: float):
                base = rlabel.lower().split()[0]
                full = text  # already lower
                # detect "на схід <base>", "схід <base>", etc., but ignore origins "з південного сходу" for that base
                # We only tag if phrase contains base key AFTER direction (targeting side), not originating "з <dir> ..." alone.
                directions = [
                    ('схід', 'east', (0.0, 0.9)),
                    ('захід', 'west', (0.0, -0.9)),
                    ('північ', 'north', (0.7, 0.0)),
                    ('південь', 'south', (-0.7, 0.0))
                ]
                applied = None
                for word, code, (dlat, dlng) in directions:
                    patterns = [f"на {word} {base}", f" {word} {base}"]
                    if any(pat in full for pat in patterns) and f"з {word}" not in full:
                        applied = (code, dlat, dlng)
                        break
                if not applied:
                    return lat, lng, rlabel
                _, dlat, dlng = applied
                nlat = max(43.0, min(53.5, lat + dlat))
                nlng = max(21.0, min(41.0, lng + dlng))
                human = {'east':'схід','west':'захід','north':'північ','south':'південь'}[applied[0]]
                return nlat, nlng, f"{rlabel} ({human})"
            for idx, (rname, (lat,lng), snippet) in enumerate(region_hits, 1):
                if rname in seen_names: continue
                seen_names.add(rname)
                adj_lat, adj_lng, adj_label = directional_offset(rname, lat, lng)
                tracks.append({
                    'id': f"{mid}_{idx}", 'place': adj_label, 'lat': adj_lat, 'lng': adj_lng,
                    'threat_type': threat_type, 'text': snippet[:500], 'date': date_str, 'channel': channel,
                    'marker_icon': icon, 'source_match': 'region_multi'
                })
            if tracks:
                return tracks

    # --- Single border oblast KAB launch: place marker at predefined border point ---
    if len(region_hits) == 1 and 'каб' in lower and ('пуск' in lower or 'пуски' in lower):
        rname, (olat, olng), snippet = region_hits[0]
        # базовые ключи для соответствия
        key = rname.lower()
        BORDER_POINTS = {
            'донеччина': (48.20, 37.90),
            'донецька область': (48.20, 37.90),
            'сумщина': (51.30, 34.40),
            'сумська область': (51.30, 34.40),
            'чернігівщина': (51.75, 31.60),
            'чернігівська обл.': (51.75, 31.60),
            'харківщина': (50.25, 36.85),
            'харківська обл.': (50.25, 36.85),
            'луганщина': (48.90, 39.40),
            'луганська область': (48.90, 39.40),
            'запорізька обл.': (47.55, 35.60),
            'херсонська обл.': (46.65, 32.60)
        }
        # нормализация ключа (удаляем регистр / лишние пробелы)
        k_simple = key.replace('’','').replace("'",'').strip()
        # попытка прямого поиска
        coord = None
        for bk, bcoord in BORDER_POINTS.items():
            if bk in k_simple:
                coord = bcoord
                break
        if coord:
            threat_type, icon = classify(text)
            return [{
                'id': str(mid), 'place': rname + ' (кордон)', 'lat': coord[0], 'lng': coord[1],
                'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
                'marker_icon': icon, 'source_match': 'border_kab'
            }]

    # --- Pattern: multiple shaheds with counts / directions / near-pass ("повз") ---
    # Handles composite direction phrases (південного сходу -> південний схід, північно-захід тощо)
    # Examples: "14 шахедів ... 3 на Покровське з півдня, 9 на Петропавлівку з південного сходу, 2 на Шахтарське з півдня"
    #           "16 шахедів ... 2 повз Терентівку на північ, 6 на Юріївку з півдня, 7 повз Межову північно-захід" etc.
    if 'шахед' in lower and ((' на ' in lower) or (' повз ' in lower)):
        segs = re.split(r'[\n,⚠;]+', lower)
        found = []
        # Direction phrases may appear after 'з', 'зі', 'із', 'на'. Capture full tail then normalize.
        pat_on = re.compile(r'(\d{1,2})\s+на\s+([a-zа-яіїєґ\-ʼ\']{3,})(?:у|а|е)?(?:\s+((?:з|зі|із|на)\s+[a-zа-яіїєґ\-\s]+))?')
        pat_povz = re.compile(r'(\d{1,2})\s+повз\s+([a-zа-яіїєґ\-ʼ\']{3,})(?:у|а|е)?(?:\s+(?:на\s+)?([a-zа-яіїєґ\-\s]+))?')
        def normalize_direction(raw_dir: str) -> str:
            if not raw_dir:
                return ''
            d = raw_dir.lower().strip()
            # remove leading prepositions
            d = re.sub(r'^(з|зі|із|на|від)\s+', '', d)
            d = d.replace('–','-')
            # unify hyphen variants to space-separated tokens
            d = d.replace('-', ' ')
            d = re.sub(r'\s+', ' ', d).strip()
            # morphological endings -> base cardinal forms
            repl = [
                (r'південного сходу', 'південний схід'),
                (r'північного сходу', 'північний схід'),
                (r'південного заходу', 'південний захід'),
                (r'північного заходу', 'північний захід'),
                (r'півдня', 'південь'),
                (r'півночі', 'північ'),
                (r'сходу', 'схід'),
                (r'заходу', 'захід')
            ]
            for pat, rep in repl:
                d = re.sub(pat, rep, d)
            # collapse duplicate words
            parts = []
            seen = set()
            for tok in d.split():
                if tok in seen:
                    continue
                seen.add(tok)
                parts.append(tok)
            return ' '.join(parts)
        for seg in segs:
            # Strip common trailing separators (colon, semicolon, space, slash, backslash)
            s = seg.strip(':; /\\')
            if not s or s.isdigit():
                continue
            matches = []
            matches.extend(list(pat_on.finditer(s)))
            matches.extend(list(pat_povz.finditer(s)))
            for m in matches:
                cnt = int(m.group(1))
                place_token = (m.group(2) or '').strip("-'ʼ")
                raw_dir = ''
                # pat_on group(3); pat_povz group(3)
                if len(m.groups()) >= 3:
                    raw_dir = (m.group(3) or '').strip()
                direction = normalize_direction(raw_dir)
                place_token = place_token.replace('ʼ',"'")
                variants = {place_token}
                # heuristic nominative recovery
                if place_token.endswith('ку'): variants.add(place_token[:-2]+'ка')
                if place_token.endswith('ву'): variants.add(place_token[:-2]+'ва')
                if place_token.endswith('ову'): variants.add(place_token[:-3]+'ова')
                if place_token.endswith('ю'):
                    variants.add(place_token[:-1]+'я'); variants.add(place_token[:-1]+'а')
                if place_token.endswith('у'): variants.add(place_token[:-1]+'а')
                if place_token.endswith('ому'):
                    variants.add(place_token[:-3]+'е'); variants.add(place_token[:-3])
                matched_coord = None; matched_name = None
                for var in variants:
                    if var in CITY_COORDS:
                        matched_coord = CITY_COORDS[var]; matched_name = var; break
                if matched_coord:
                    plat, plng = matched_coord
                    found.append((matched_name, plat, plng, cnt, direction, s[:160]))
        if found:
            threat_type, icon = classify(text)
            tracks = []
            for idx,(p, plat, plng, cnt, direction, snippet) in enumerate(found,1):
                base_label = f"{p.title()} ({cnt})"
                if direction:
                    base_label += f" ←{direction}"
                tracks.append({
                    'id': f"{mid}_s{idx}", 'place': base_label, 'lat': plat, 'lng': plng,
                    'threat_type': threat_type, 'text': snippet[:500], 'date': date_str, 'channel': channel,
                    'marker_icon': icon, 'source_match': 'multi_shah_ed', 'count': cnt
                })
            if found and not tracks:
                log.debug(f"multi_shah_ed matched segments but no tracks mid={mid} raw={found}")
            if tracks:
                log.debug(f"multi_shah_ed tracks mid={mid} -> {[t['place'] for t in tracks]}")
                return tracks

    # --- Per-line UAV course / area city targeting ("БпЛА курсом на <місто>", "8х БпЛА в районі <міста>", "БпЛА на <місто>") ---
    # Triggered when region multi list suppressed earlier due to presence of course lines or simple "на" pattern.
    if 'бпла' in lower and ('курс' in lower or 'в районі' in lower or 'в напрямку' in lower or 'в бік' in lower or 'від' in lower or 'околиц' in lower or 'сектор' in lower or 'бпла на ' in lower or (re.search(r'\d+\s*[xх×]?\s*бпла\s+на\s+', lower))):
        add_debug_log(f"UAV course parser triggered for message length: {len(text)} chars", "uav_course")
        
        # --- EARLY CHECK: Black Sea aquatory (e.g. "курсом на Миколаїв з акваторії Чорного моря" or "15 шахедів з моря на Ізмаїл") ---
        # Must check BEFORE "курсом на" parser to prevent placing marker on target city
        is_black_sea = (('акватор' in lower or 'акваторії' in lower) and ('чорного моря' in lower or 'чорне море' in lower or 'чорному морі' in lower)) or \
                       ('з моря' in lower and ('курс' in lower or 'на ' in lower)) or \
                       ('з чорного моря' in lower)
        
        if is_black_sea:
            # Extract target region/direction if mentioned
            m_target = re.search(r'курс(?:ом)?\s+на\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-]{3,})', lower)
            m_direction = re.search(r'на\s+(північ|південь|схід|захід|північний\s+схід|північний\s+захід|південний\s+схід|південний\s+захід)', lower)
            m_region = re.search(r'(одещин|одеськ|миколаїв|херсон)', lower)
            
            target_info = None
            sea_lat, sea_lng = 45.3, 30.7  # Default: northern Black Sea central coords
            
            # Adjust position based on direction/region
            if m_direction:
                direction = m_direction.group(1)
                if 'південь' in direction:
                    sea_lat = 45.0  # Further south
                elif 'північ' in direction:
                    sea_lat = 45.6  # Further north
                if 'схід' in direction:
                    sea_lng = 31.2  # Further east
                elif 'захід' in direction:
                    sea_lng = 30.2  # Further west
            
            if m_region:
                region_name = m_region.group(1)
                if 'одещин' in region_name or 'одеськ' in region_name:
                    # South of Odesa region - in the sea 50km offshore
                    sea_lat, sea_lng = 45.7, 30.7
                    target_info = 'Одещини'
                elif 'миколаїв' in region_name:
                    sea_lat, sea_lng = 45.9, 31.4
                    target_info = 'Миколаївщини'
                elif 'херсон' in region_name:
                    sea_lat, sea_lng = 45.7, 32.5
                    target_info = 'Херсонщини'
            
            if m_target:
                tc = m_target.group(1).lower()
                tc = UA_CITY_NORMALIZE.get(tc, tc)
                target_info = tc.title()
            
            threat_type, icon = classify(text)
            place_label = 'Акваторія Чорного моря'
            if target_info:
                place_label += f' (на {target_info})'
            
            # Try to find target city coordinates for trajectory
            target_coords = None
            if m_target:
                tc_normalized = m_target.group(1).lower()
                tc_normalized = UA_CITY_NORMALIZE.get(tc_normalized, tc_normalized)
                if tc_normalized in CITY_COORDS:
                    target_coords = CITY_COORDS[tc_normalized]
            
            result = {
                'id': str(mid), 'place': place_label, 'lat': sea_lat, 'lng': sea_lng,
                'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
                'marker_icon': icon, 'source_match': 'black_sea_course'
            }
            
            # Add trajectory data if we have target coordinates
            if target_coords:
                result['trajectory'] = {
                    'start': [sea_lat, sea_lng],
                    'end': list(target_coords),
                    'target': target_info
                }
            
            return [result]
        
        original_text_norm = re.sub(r'(?i)(\b[А-Яа-яЇїІіЄєҐґ\-]{3,}(?:щина|область|обл\.)):(?!\s*\n)', r'\1:\n', original_text)
        lines_with_region = []
        current_region_hdr = None
        for raw_ln in original_text_norm.splitlines():
            ln_stripped = raw_ln.strip()
            if not ln_stripped:
                continue
            low_ln = ln_stripped.lower()
            # Allow region header if line ends with ':' even if preceded by emoji or bullets
            if low_ln.endswith(':'):
                # remove leading emojis/symbols
                cleaned_hdr = re.sub(r'^[^a-zа-яіїєґ]+','', low_ln[:-1])
                base_hdr = cleaned_hdr.strip()
                log.debug(f"mid={mid} region_header_check: '{low_ln}' -> cleaned: '{base_hdr}' -> found: {base_hdr in OBLAST_CENTERS}")
                if base_hdr in OBLAST_CENTERS:
                    current_region_hdr = base_hdr
                    log.debug(f"mid={mid} region_header_set: '{base_hdr}'")
                continue
            # split by semicolons; also break on pattern like " 2х БпЛА курсом" inside the same segment later
            subparts = [p.strip() for p in re.split(r'[;]+', ln_stripped) if p.strip()]
            for part in subparts:
                lines_with_region.append((part, current_region_hdr))
        # Further split segments that contain multiple "БпЛА курс" phrases glued together
        multi_start_re = re.compile(r'(?:\d+\s*[xх×]?\s*)?бпла\s*курс', re.IGNORECASE)
        expanded = []
        for part, region_hdr in lines_with_region:
            low_part = part.lower()
            starts = [m.start() for m in multi_start_re.finditer(low_part)]
            if len(starts) <= 1:
                expanded.append((part, region_hdr))
                continue
            for idx, s in enumerate(starts):
                seg_start = s
                seg_end = starts[idx+1] if idx+1 < len(starts) else len(low_part)
                segment = part[seg_start:seg_end].strip()
                if segment:
                    expanded.append((segment, region_hdr))
        if expanded:
            lines_with_region = expanded
        course_tracks = []
        pat_count_course = re.compile(r'^(\d+(?:-\d+)?)\s*[xх×]?\s*бпла(?:\s+пролетіли)?.*?курс(?:ом)?\s+на\s+(?:н\.п\.?\s*)?([A-Za-zА-Яа-яЇїІіЄєҐґ\-’ʼ`\s]{3,40}?)(?=[,\.\n;:!\?]|$)', re.IGNORECASE)
        pat_course = re.compile(r'бпла(?:\s+пролетіли)?.*?курс(?:ом)?\s+на\s+(?:н\.п\.?\s*)?([A-Za-zА-Яа-яЇїІіЄєҐґ\-’ʼ`\s]{3,40}?)(?=[,\.\n;:!\?]|$)', re.IGNORECASE)
        pat_area = re.compile(r'(\d+(?:-\d+)?)?[xх×]?\s*бпла\s+(?:.*?\s+)?в\s+районі\s+(?:н\.п\.?\s*)?([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,60}?)(?=[,\.\n;:!\?]|$)', re.IGNORECASE)  # Fixed: added н.п. support
        pat_napramku = re.compile(r'(\d+(?:-\d+)?)?[xх×]?\s*бпла\s+[➡️⬆️⬇️⬅️↗️↘️↙️↖️]*\s*(?:в|у)\s+напрямку\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,40}?)(?=[,\.\n;:!\?]|$)', re.IGNORECASE)
        pat_sektor = re.compile(r'(\d+(?:-\d+)?)?[xх×]?\s*бпла\s+в\s+секторі\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,40}?)(?=[,\.\n;:!\?]|$)', re.IGNORECASE)
        pat_simple_na = re.compile(r'(\d+(?:-\d+)?)?[xх×]?\s*бпла\s+на\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,40}?)(?=[,\.\n;:!\?]|$)', re.IGNORECASE)
        pat_complex_napramku = re.compile(r'(\d+(?:-\d+)?)?[xх×]?\s*бпла\s+на/через\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,40}?)\s+в\s+напрямку\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,40}?)(?=[,\.\n;:!\?]|$)', re.IGNORECASE)
        pat_napramku_ta = re.compile(r'(\d+(?:-\d+)?)?[xх×]?\s*бпла\s+(?:в|у)\s+напрямку\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,40}?)\s+та\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,40}?)(?=[,\.\n;:!\?]|$)', re.IGNORECASE)
        pat_okolytsi = re.compile(r'(\d+(?:-\d+)?)?[xх×]?\s*бпла\s+на\s+околицях\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,40}?)(?=[,\.\n;:!\?]|$)', re.IGNORECASE)
        pat_vid_do = re.compile(r'(\d+(?:-\d+)?)?[xх×]?\s*бпла\s+від\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,40}?)\s+до\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,40}?)(?=[,\.\n;:!\?]|$)', re.IGNORECASE)
        pat_vik = re.compile(r'(\d+(?:-\d+)?)?[xх×]?\s*бпла\s+[➡️⬆️⬇️⬅️↗️↘️↙️↖️]*\s*(?:в|у)\s+бік\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,40}?)(?=[,\.\n;:!\?]|$)', re.IGNORECASE)
        if re.search(r'бпла.*?курс(?:ом)?\s+на\s+кіпт[ії]', lower):
            coords = SETTLEMENT_FALLBACK.get('кіпті')
            if coords:
                lat, lng = coords
                threat_type, icon = classify(original_text)
                return [{
                    'id': f"{mid}_kipti_course", 'place': 'Кіпті', 'lat': lat, 'lng': lng,
                    'threat_type': threat_type, 'text': original_text[:500], 'date': date_str, 'channel': channel,
                    'marker_icon': icon, 'source_match': 'course_kipti'
                }]
        def norm_city_token(tok: str) -> str:
            t = tok.lower().strip(" .,'’ʼ`-:")
            t = t.replace("'", "'")  # Normalize curly quotes
            if t.endswith('ку'): t = t[:-2] + 'ка'
            elif t.endswith('ву'): t = t[:-2] + 'ва'
            elif t.endswith('ову'): t = t[:-3] + 'ова'
            elif t.endswith('ю'): t = t[:-1] + 'я'
            elif t.endswith('у'): t = t[:-1] + 'а'
            if t.startswith('нову '):
                t = 'нова ' + t[5:]
            t = t.replace('водолагу','водолога')
            return t
        for ln, region_hdr in lines_with_region:
            ln_low = ln.lower()
            if 'бпла' not in ln_low:
                continue
            add_debug_log(f"Processing UAV line: '{ln[:100]}...' (region: {region_hdr})", "uav_course")
            
            # Check for complex pattern "на/через X в напрямку Y" first
            m_complex = pat_complex_napramku.search(ln_low)
            if m_complex:
                count = int(m_complex.group(1)) if m_complex.group(1) else 1
                city1 = m_complex.group(2)  # через це місто
                city2 = m_complex.group(3)  # в напрямку цього міста
                
                # Process both cities
                for city_raw in [city1, city2]:
                    multi_norm = _resolve_city_candidate(city_raw)
                    base = norm_city_token(multi_norm)
                    coords = CITY_COORDS.get(base) or (SETTLEMENTS_INDEX.get(base) if SETTLEMENTS_INDEX else None)
                    if not coords:
                        try:
                            coords = region_enhanced_coords(base, region_hint_override=region_hdr)
                        except Exception:
                            coords = None
                    # Try Nominatim API if still no coordinates
                    if not coords and NOMINATIM_AVAILABLE:
                        try:
                            nominatim_coords = get_coordinates_nominatim(base, region=region_hdr)
                            if nominatim_coords:
                                coords = nominatim_coords
                                CITY_COORDS[base] = coords
                        except Exception:
                            pass
                    if coords:
                        lat, lng = coords
                        threat_type, icon = classify(text)
                        for i in range(1, count+1):
                            label = base.title()
                            if count > 1:
                                label += f" ({i}/{count})"
                            if region_hdr and region_hdr not in label.lower():
                                label += f" [{region_hdr.title()}]"
                            course_tracks.append({
                                'id': f"{mid}_complex_{base}_{i}", 'place': label, 'lat': lat, 'lng': lng,
                                'threat_type': threat_type, 'text': ln[:500], 'date': date_str, 'channel': channel,
                                'marker_icon': icon, 'source_match': 'uav_complex', 'count': 1
                            })
                continue  # Skip to next line
            
            # Check for "від X до Y" pattern (trajectory)
            m_vid_do = pat_vid_do.search(ln_low)
            if m_vid_do:
                count = int(m_vid_do.group(1)) if m_vid_do.group(1) else 1
                city1 = m_vid_do.group(2)  # від цього міста
                city2 = m_vid_do.group(3)  # до цього міста
                
                # Process both cities
                for city_raw in [city1, city2]:
                    multi_norm = _resolve_city_candidate(city_raw)
                    base = norm_city_token(multi_norm)
                    coords = CITY_COORDS.get(base) or (SETTLEMENTS_INDEX.get(base) if SETTLEMENTS_INDEX else None)
                    if not coords:
                        try:
                            coords = region_enhanced_coords(base, region_hint_override=region_hdr)
                        except Exception:
                            coords = None
                    if not coords and NOMINATIM_AVAILABLE:
                        try:
                            nominatim_coords = get_coordinates_nominatim(base, region=region_hdr)
                            if nominatim_coords:
                                coords = nominatim_coords
                                CITY_COORDS[base] = coords
                        except Exception:
                            pass
                    if coords:
                        lat, lng = coords
                        threat_type, icon = classify(text)
                        for i in range(1, count+1):
                            label = base.title()
                            if count > 1:
                                label += f" ({i}/{count})"
                            if region_hdr and region_hdr not in label.lower():
                                label += f" [{region_hdr.title()}]"
                            course_tracks.append({
                                'id': f"{mid}_viddo_{base}_{i}", 'place': label, 'lat': lat, 'lng': lng,
                                'threat_type': threat_type, 'text': ln[:500], 'date': date_str, 'channel': channel,
                                'marker_icon': icon, 'source_match': 'uav_vid_do', 'count': 1
                            })
                continue
            
            # Check for "в напрямку X та Y" pattern (multiple cities)
            m_ta = pat_napramku_ta.search(ln_low)
            if m_ta:
                count = int(m_ta.group(1)) if m_ta.group(1) else 1
                city1 = m_ta.group(2)
                city2 = m_ta.group(3)
                
                # Process both cities
                for city_raw in [city1, city2]:
                    multi_norm = _resolve_city_candidate(city_raw)
                    base = norm_city_token(multi_norm)
                    coords = CITY_COORDS.get(base) or (SETTLEMENTS_INDEX.get(base) if SETTLEMENTS_INDEX else None)
                    if not coords:
                        try:
                            coords = region_enhanced_coords(base, region_hint_override=region_hdr)
                        except Exception:
                            coords = None
                    if not coords and NOMINATIM_AVAILABLE:
                        try:
                            nominatim_coords = get_coordinates_nominatim(base, region=region_hdr)
                            if nominatim_coords:
                                coords = nominatim_coords
                                CITY_COORDS[base] = coords
                        except Exception:
                            pass
                    if coords:
                        lat, lng = coords
                        threat_type, icon = classify(text)
                        for i in range(1, count+1):
                            label = base.title()
                            if count > 1:
                                label += f" ({i}/{count})"
                            if region_hdr and region_hdr not in label.lower():
                                label += f" [{region_hdr.title()}]"
                            course_tracks.append({
                                'id': f"{mid}_ta_{base}_{i}", 'place': label, 'lat': lat, 'lng': lng,
                                'threat_type': threat_type, 'text': ln[:500], 'date': date_str, 'channel': channel,
                                'marker_icon': icon, 'source_match': 'uav_ta', 'count': 1
                            })
                continue
            
            count = None; city = None; approx_flag = False
            m1 = pat_count_course.search(ln_low)
            if m1:
                count = int(m1.group(1)); city = m1.group(2)
            else:
                m2 = pat_area.search(ln_low)
                if m2:
                    if m2.group(1):
                        count = int(m2.group(1))
                    city = m2.group(2)
                else:
                    m3 = pat_napramku.search(ln_low)
                    if m3:
                        if m3.group(1):
                            count = int(m3.group(1))
                        city = m3.group(2)
                    else:
                        m3_sektor = pat_sektor.search(ln_low)
                        if m3_sektor:
                            if m3_sektor.group(1):
                                count = int(m3_sektor.group(1))
                            city = m3_sektor.group(2)
                        else:
                            m4 = pat_course.search(ln_low)
                            if m4:
                                city = m4.group(1)
                            else:
                                m5 = pat_okolytsi.search(ln_low)
                                if m5:
                                    if m5.group(1):
                                        count = int(m5.group(1))
                                    city = m5.group(2)
                                else:
                                    m6 = pat_simple_na.search(ln_low)
                                    if m6:
                                        if m6.group(1):
                                            count = int(m6.group(1))
                                        city = m6.group(2)
                                    else:
                                        m7 = pat_vik.search(ln_low)
                                        if m7:
                                            if m7.group(1):
                                                count = int(m7.group(1))
                                            city = m7.group(2)
            if not city:
                add_debug_log("No city found in UAV line", "uav_course")
                continue
            add_debug_log(f"Found city '{city}' in UAV line", "uav_course")
            multi_norm = _resolve_city_candidate(city)
            base = norm_city_token(multi_norm)
            add_debug_log(f"City normalized to '{base}'", "uav_course")
            
            # FILTER: Skip oblast/region names (e.g., "БпЛА на Дніпропетровщині" should be regional threat, not city marker)
            oblast_suffixes = ['щина', 'щині', 'область', 'обл']
            if any(base.endswith(suffix) for suffix in oblast_suffixes):
                add_debug_log(f"Skipping oblast name '{base}' - this is a regional threat, not a city target", "uav_course")
                continue
            
            # PRIORITY: Try region-specific variant first (e.g., "шевченкове(миколаївська)" for "шевченкове" with region_hdr="миколаївщина")
            coords = None
            if region_hdr:
                # Try variant with region suffix
                region_variant = f"{base}({region_hdr})"
                coords = CITY_COORDS.get(region_variant)
                if coords:
                    add_debug_log(f"Found region-specific coordinates for '{region_variant}': {coords}", "uav_course")
            
            # Fallback to base name without region
            if not coords:
                coords = CITY_COORDS.get(base) or (SETTLEMENTS_INDEX.get(base) if SETTLEMENTS_INDEX else None)
                add_debug_log(f"Coordinates lookup for '{base}': {coords}", "uav_course")
            if not coords:
                try:
                    coords = region_enhanced_coords(base, region_hint_override=region_hdr)
                except Exception:
                    coords = None
            # Try Nominatim API if still no coordinates
            if not coords and NOMINATIM_AVAILABLE:
                try:
                    add_debug_log(f"Trying Nominatim API for city '{base}'", "uav_course")
                    nominatim_coords = get_coordinates_nominatim(base, region=region_hdr)
                    if nominatim_coords:
                        coords = nominatim_coords
                        CITY_COORDS[base] = coords  # Cache for future use
                        add_debug_log(f"Nominatim found coordinates for '{base}': {coords}", "uav_course")
                except Exception as e:
                    add_debug_log(f"Nominatim API error for '{base}': {e}", "uav_course")
            if not coords:
                # Fallback: if we have a region header, place placeholder near its oblast center with slight jitter
                if region_hdr and region_hdr in OBLAST_CENTERS:
                    rlat, rlng = OBLAST_CENTERS[region_hdr]
                    # deterministic jitter based on hash of city token
                    h = abs(hash(base)) % 1000 / 1000.0
                    lat = max(43.0, min(53.5, rlat + (h - 0.5) * 0.4))
                    lng = max(21.0, min(41.0, rlng + (h - 0.5) * 0.6))
                    coords = (lat, lng)
                    approx_flag = True
                else:
                    # skip THIS city but continue processing other cities
                    add_debug_log(f"Skipping unrecognized city '{base}' - no coordinates and no region context", "uav_course")
                    continue
            if base not in CITY_COORDS:
                CITY_COORDS[base] = coords
            lat, lng = coords
            threat_type, icon = classify(text)
            # Generate individual markers per drone for progressive map loading
            total = count or 1
            for i in range(1, total+1):
                label = base.title()
                if total > 1:
                    label += f" ({i}/{total})"
                if region_hdr and region_hdr not in label.lower():
                    label += f" [{region_hdr.title()}]"
                if approx_flag:
                    label += ' ~'
                course_tracks.append({
                    'id': f"{mid}_c{len(course_tracks)+1}", 'place': label, 'lat': lat, 'lng': lng,
                    'threat_type': threat_type, 'text': ln[:500], 'date': date_str, 'channel': channel,
                    'marker_icon': icon, 'source_match': 'course_city_unit', 'count': 1
                })
                add_debug_log(f"Created course track for '{label}' at {lat}, {lng}", "uav_course")
        add_debug_log(f"Total course tracks generated: {len(course_tracks)}", "uav_course")
        log.debug(f"mid={mid} course_tracks_generated: {len(course_tracks)} tracks")
        if course_tracks:
            return course_tracks
        # Salvage fallback: large multi-line message with many 'бпла курсом' but parser produced nothing
        try:
            ll_full = text.lower()
            if course_tracks == [] and ll_full.count('бпла') >= 5 and ll_full.count('курс') >= 5:
                pat_salv = re.compile(r'(?:\d+\s*[xх×]?\s*)?бпла[^\n]{0,60}?курс(?:ом)?\s+на\s+([a-zа-яіїєґ\-ʼ"“”\'`\s]{3,40})', re.IGNORECASE)
                raw_hits = [m.group(1).strip() for m in pat_salv.finditer(ll_full)]
                uniq = []
                for h in raw_hits:
                    if h and h not in uniq:
                        uniq.append(h)
                salvage_tracks = []
                for idx, token in enumerate(uniq, 1):
                    base_tok = _resolve_city_candidate(token)
                    base_tok = norm_city_token(base_tok)
                    coords = CITY_COORDS.get(base_tok) or (SETTLEMENTS_INDEX.get(base_tok) if SETTLEMENTS_INDEX else None)
                    if not coords:
                        continue
                    lat, lng = coords
                    threat_type, icon = classify(text)
                    salvage_tracks.append({
                        'id': f"{mid}_sf{idx}", 'place': base_tok.title(), 'lat': lat, 'lng': lng,
                        'threat_type': threat_type, 'text': token[:120], 'date': date_str, 'channel': channel,
                        'marker_icon': icon, 'source_match': 'salvage_course_multi'
                    })
                if salvage_tracks:
                    log.debug(f"salvage_course_multi generated {len(salvage_tracks)} tracks mid={mid}")
                    return salvage_tracks
        except Exception as _e_salv:
            log.debug(f'salvage fallback error mid={mid}: {_e_salv}')

    # --- Generic multi-line UAV near-pass counts (e.g. "5х бпла повз Барвінкове") ---
    if 'бпла' in lower and 'повз' in lower and re.search(r'\d+[xх]\s*бпла', lower):
        lines_near = [ln.strip() for ln in lower.split('\n') if ln.strip()]
        near_tracks = []
        pat_near = re.compile(r'(\d+)[xх]\s*бпла[^\n]*?повз\s+([a-zа-яіїєґ\-ʼ\']{3,})')
        for ln in lines_near:
            m = pat_near.search(ln)
            if not m:
                continue
            cnt = int(m.group(1))
            place = (m.group(2) or '').strip("-'ʼ")
            variants = {place}
            if place.endswith('е'): variants.add(place[:-1])
            if place.endswith('ю'):
                variants.add(place[:-1]+'я'); variants.add(place[:-1]+'а')
            if place.endswith('у'):
                variants.add(place[:-1]+'а')
            if place.endswith('ому'):
                variants.add(place[:-3])
            if place.endswith('ове'):
                variants.add(place[:-2]+'’я')  # crude alt
            matched=None; mname=None
            for v in variants:
                if v in CITY_COORDS:
                    matched=CITY_COORDS[v]; mname=v; break
            if not matched and SETTLEMENTS_INDEX:
                for v in variants:
                    if v in SETTLEMENTS_INDEX:
                        matched=SETTLEMENTS_INDEX[v]; mname=v; break
            if not matched:
                # OpenCage fallback
                try:
                    for v in variants:
                        oc = region_enhanced_coords(v)
                        if oc:
                            matched=oc; mname=v; break
                except Exception:
                    matched=None
            if matched:
                if mname not in CITY_COORDS:
                    CITY_COORDS[mname]=matched
                lat,lng = matched
                threat_type, icon = classify(text)
                near_tracks.append({
                    'id': f"{mid}_n{len(near_tracks)+1}", 'place': f"{mname.title()} ({cnt})", 'lat': lat, 'lng': lng,
                    'threat_type': threat_type, 'text': ln[:500], 'date': date_str, 'channel': channel,
                    'marker_icon': icon, 'source_match': 'uav_near_pass', 'count': cnt
                })
        if near_tracks:
            return near_tracks

    # --- Late parenthetical specific settlement fallback (e.g. direction to oblast but (затока)) ---
    if has_threat(original_text.lower()) and '(' in original_text and ')' in original_text:
        p_tokens = re.findall(r'\(([A-Za-zА-Яа-яЇїІіЄєҐґ\-\s]{3,})\)', original_text.lower())
        if p_tokens:
            cand = p_tokens[-1].strip()
            cand = re.sub(r'^(смт|с\.|м\.|місто|селище)\s+','', cand)
            base_cand = UA_CITY_NORMALIZE.get(cand, cand)
            coords = CITY_COORDS.get(base_cand) or SETTLEMENTS_INDEX.get(base_cand)
            log.debug(f"late_parenthetical mid={mid} cand={cand} base={base_cand} found={bool(coords)}")
            if coords:
                lat,lng = coords
                threat_type, icon = classify(original_text)
                return [{
                    'id': str(mid), 'place': base_cand.title(), 'lat': lat, 'lng': lng,
                    'threat_type': threat_type, 'text': original_text[:500], 'date': date_str, 'channel': channel,
                    'marker_icon': icon, 'source_match': 'late_parenthetical'
                }]

    # --- Settlement matching using external dataset (if provided) (single first match) ---
    if not region_hits:
        # 1) Multi-list form: "Новгород-сіверський, Шостка, Короп, Кролевець - уважно по БПЛА"
        # support both hyphen - and en dash – between list and tail
        dash_idx = None
        for dch in [' - ', ' – ', '- ', '– ']:
            if dch in lower:
                dash_idx = lower.index(dch)
                break
        if ('уважно' in lower or 'по бпла' in lower or 'бпла' in lower) and (',' in lower) and dash_idx is not None:
            left = lower[:dash_idx]
            right = lower[dash_idx+1:]
            if any(k in right for k in ['бпла','дрон','шахед','uav']):
                raw_places = [p.strip() for p in left.split(',') if p.strip()]
                tracks = []
                threat_type, icon = classify(text)
                seen = set()
                for idx, rp in enumerate(raw_places,1):
                    key = rp.replace('й,','й').strip()
                    coords = region_enhanced_coords(key)
                    if coords and key not in seen:
                        seen.add(key)
                        lat,lng = coords
                        tracks.append({
                            'id': f"{mid}_m{idx}", 'place': key.title(), 'lat': lat, 'lng': lng,
                            'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
                            'marker_icon': icon, 'source_match': 'multi_settlement'
                        })
                if tracks:
                    return tracks
        # 2) Single settlement search (fallback) with word-boundary and specificity prioritization
        if SETTLEMENTS_INDEX:
            cand_hits = []
            text_len = len(lower)
            for name in SETTLEMENTS_ORDERED:
                start = 0
                while True:
                    idx = lower.find(name, start)
                    if idx == -1:
                        break
                    before_ok = (idx == 0) or not lower[idx-1].isalnum()
                    after_idx = idx + len(name)
                    after_ok = (after_idx == text_len) or not lower[after_idx].isalnum()
                    if before_ok and after_ok:
                        cand_hits.append(name)
                        break  # only need first occurrence
                    start = idx + 1
            if cand_hits:
                # Prefer longer names; deprioritize generic oblast centers when more specific present
                def score(n: str):
                    base_penalty = -5 if n in ['суми'] and len(cand_hits) > 1 else 0
                    return (len(n) + base_penalty)
                cand_hits.sort(key=score, reverse=True)
                chosen = cand_hits[0]
                lat, lng = SETTLEMENTS_INDEX[chosen]
                threat_type, icon = classify(text)
                return [{
                    'id': str(mid), 'place': chosen.title(), 'lat': lat, 'lng': lng,
                    'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
                    'marker_icon': icon,
                    'source_match': 'settlement'
                }]

    # --- Raion (district) detection ---
    # Ищем конструкции вида "Покровський район", а также множественные "Конотопський та Сумський районы".
    def norm_raion(token: str):
        t = token.lower().strip('- ')
        # унификация дефисов
        t = t.replace('–','-')
        # морфологические окончания -> базовая форма -ський
        t = re.sub(r'(ському|ского|ського|ский|ськiй|ськой|ським|ском)$','ський', t)
        return t
    raion_matches = []
    # множественное 'райони'
    plural_pattern = re.compile(r'([А-ЯA-ZЇІЄҐЁа-яa-zїієґё,\-\s]{4,}?)райони', re.IGNORECASE)
    for pm in plural_pattern.finditer(text):
        segment = pm.group(1)
        # разделяем по 'та' или запятым
        parts = re.split(r'\s+та\s+|,', segment)
        for p in parts:
            cand = p.strip()
            if not cand:
                continue
            # берём последнее слово (Конотопський)
            last = cand.split()[-1]
            base = norm_raion(last)
            if base in RAION_FALLBACK:
                raion_matches.append((base, RAION_FALLBACK[base]))
    # одиночное 'район' (любой падеж: район, району, районом, района)
    raion_pattern = re.compile(r'([А-ЯA-ZЇІЄҐЁа-яa-zїієґё\-]{4,})\s+район(?:у|ом|а)?', re.IGNORECASE)
    for m_r in raion_pattern.finditer(text):
        base = norm_raion(m_r.group(1))
        if base in RAION_FALLBACK:
            raion_matches.append((base, RAION_FALLBACK[base]))
    # Аббревиатура "р-н" (у т.ч. варианты "р-н.", "рн", "р-н," )
    raion_abbrev_pattern = re.compile(r'([А-ЯA-ZЇІЄҐЁа-яa-zїієґё\-]{4,})\s+р\s*[-–]?\s*н\.?', re.IGNORECASE)
    for m_ra in raion_abbrev_pattern.finditer(text):
        base = norm_raion(m_ra.group(1))
        if base in RAION_FALLBACK:
            raion_matches.append((base, RAION_FALLBACK[base]))
    if raion_matches:
        threat_type, icon = classify(text)
        tracks = []
        seen = set()
        for idx,(name,(lat,lng)) in enumerate(raion_matches,1):
            # For some districts, show the main city name instead of district name
            district_to_city_mapping = {
                'павлоградський': 'Павлоград',
                'білоцерківський': 'Біла Церква',
                'кременчуцький': 'Кременчук',
                'миколаївський': 'Миколаїв',
                'дніпровський': 'Дніпро'
            }
            
            if name.lower() in district_to_city_mapping:
                title = district_to_city_mapping[name.lower()]
            else:
                title = f"{name.title()} район"
            if title in seen: continue
            seen.add(title)
            # Maintain alarm overlay state
            if threat_type == 'alarm':
                RAION_ALARMS[name] = {'place': title, 'lat': lat, 'lng': lng, 'since': time.time()}
            elif threat_type == 'alarm_cancel':
                RAION_ALARMS.pop(name, None)
            tracks.append({
                'id': f"{mid}_d{idx}", 'place': title, 'lat': lat, 'lng': lng,
                'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
                'marker_icon': icon, 'source_match': 'raion'
            })
        if tracks:
            log.debug(f"RAION_MATCH mid={mid} -> {[t['place'] for t in tracks]}")
            return tracks

    # --- Hromada detection (e.g., "Хотінська територіальна громада") ---
    hromada_pattern = re.compile(r'([А-ЯA-ZЇІЄҐЁа-яa-zїієґё\-]{4,})\s+територіал(?:ьна|ьної)?\s+громада', re.IGNORECASE)
    hromada_matches = []
    for m_h in hromada_pattern.finditer(text):
        token = m_h.group(1).lower()
        # normalize adjective endings to 'ська'
        base = re.sub(r'(ської|ской|ська|ской)$', 'ська', token)
        if base in HROMADA_FALLBACK:
            hromada_matches.append((base, HROMADA_FALLBACK[base]))
    if hromada_matches:
        threat_type, icon = classify(text)
        tracks = []
        seen = set()
        for idx,(name,(lat,lng)) in enumerate(hromada_matches,1):
            title = f"{name.title()} територіальна громада"
            if title in seen: continue
            seen.add(title)
            tracks.append({
                'id': f"{mid}_h{idx}", 'place': title, 'lat': lat, 'lng': lng,
                'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
                'marker_icon': icon, 'source_match': 'hromada'
            })
        if tracks:
            return tracks

    # --- Slash separated settlements PRIORITY (moved earlier so it can't be overridden by region logic) ---
    lower_full_for_slash = text.lower()
    if '/' in lower_full_for_slash and ('бпла' in lower_full_for_slash or 'дрон' in lower_full_for_slash) and any(x in lower_full_for_slash for x in ['х бпла','x бпла',' бпла']):
        # take portion before first dash (— or -) which usually separates counts/other text
        left_part = re.split(r'[—-]', lower_full_for_slash, 1)[0]
        # Remove trailing count token like "5х бпла" from left part to isolate pure settlements
        left_part = re.sub(r'\b\d+[xх]\s*бпла.*$', '', left_part).strip()
        parts = [p.strip() for p in re.split(r'/|\\', left_part) if p.strip()]
        found = []
        # Derive a region stem from any well-known city token to bias geocoding of other parts
        inferred_region = None
        for p in parts:
            base_inf = UA_CITY_NORMALIZE.get(p, p)
            if base_inf in CITY_TO_OBLAST:
                inferred_region = CITY_TO_OBLAST[base_inf]
                break
        for p in parts:
            base = UA_CITY_NORMALIZE.get(p, p)
            coords = CITY_COORDS.get(base)
            if not coords and SETTLEMENTS_INDEX:
                coords = SETTLEMENTS_INDEX.get(base)
            if not coords:
                # If we have inferred region stem, attempt region-qualified geocode first
                if inferred_region and OPENCAGE_API_KEY:
                    oblast_variants = [
                        f"{base} {inferred_region}щина",
                        f"{base} {inferred_region}ська область",
                        f"{base} {inferred_region}ская область"
                    ]
                    for q in oblast_variants:
                        try:
                            coords = geocode_opencage(q)
                            if coords:
                                break
                        except Exception:
                            pass
                if not coords:
                    try:
                        coords = region_enhanced_coords(base)
                    except Exception:
                        coords = None
            if coords:
                found.append((base.title(), coords))
        if found:
            threat_type, icon = classify(text)
            tracks = []
            for idx,(nm,(lat,lng)) in enumerate(found,1):
                if 'курс захід' in lower_full_for_slash:
                    lng -= 0.4
                tracks.append({
                    'id': f"{mid}_s{idx}", 'place': nm, 'lat': lat, 'lng': lng,
                    'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
                    'marker_icon': icon, 'source_match': 'slash_combo', 'count': drone_count
                })
            if tracks:
                try:
                    log.debug(f"SLASH_COMBO mid={mid} parts={parts} tracks={[(t['place'], t['lat'], t['lng']) for t in tracks]}")
                except Exception:
                    pass
            if tracks:
                return tracks

    # --- Black Sea aquatory: place marker in sea, not on target city (e.g. "в акваторії чорного моря, курсом на одесу" or "з моря на Ізмаїл") ---
    lower_sea = text.lower()
    is_black_sea = (('акватор' in lower_sea or 'акваторії' in lower_sea) and ('чорного моря' in lower_sea or 'чорне море' in lower_sea or 'чорному морі' in lower_sea)) or \
                   ('з моря' in lower_sea and ('курс' in lower_sea or 'на ' in lower_sea)) or \
                   ('з чорного моря' in lower_sea)
    
    if is_black_sea:
        # Extract target region/direction if mentioned
        m_target = re.search(r'курс(?:ом)?\s+на\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-]{3,})', lower_sea)
        m_direction = re.search(r'на\s+(північ|південь|схід|захід|північний\s+схід|північний\s+захід|південний\s+схід|південний\s+захід)', lower_sea)
        m_region = re.search(r'(одещин|одеськ|миколаїв|херсон)', lower_sea)
        
        target_info = None
        sea_lat, sea_lng = 45.3, 30.7  # Default: northern Black Sea central coords
        
        # Adjust position based on direction/region
        if m_direction:
            direction = m_direction.group(1)
            if 'південь' in direction:
                sea_lat = 45.0  # Further south
            elif 'північ' in direction:
                sea_lat = 45.6  # Further north
            if 'схід' in direction:
                sea_lng = 31.2  # Further east
            elif 'захід' in direction:
                sea_lng = 30.2  # Further west
        
        if m_region:
            region_name = m_region.group(1)
            if 'одещин' in region_name or 'одеськ' in region_name:
                # South of Odesa region - in the sea 50km offshore
                sea_lat, sea_lng = 45.7, 30.7
                target_info = 'Одещини'
            elif 'миколаїв' in region_name:
                sea_lat, sea_lng = 45.9, 31.4
                target_info = 'Миколаївщини'
            elif 'херсон' in region_name:
                sea_lat, sea_lng = 45.7, 32.5
                target_info = 'Херсонщини'
        
        if m_target:
            tc = m_target.group(1).lower()
            tc = UA_CITY_NORMALIZE.get(tc, tc)
            target_info = tc.title()
        
        threat_type, icon = classify(text)
        place_label = 'Акваторія Чорного моря'
        if target_info:
            place_label += f' (на {target_info})'
        
        # Try to find target city coordinates for trajectory
        target_coords = None
        if m_target:
            tc_normalized = m_target.group(1).lower()
            tc_normalized = UA_CITY_NORMALIZE.get(tc_normalized, tc_normalized)
            if tc_normalized in CITY_COORDS:
                target_coords = CITY_COORDS[tc_normalized]
        
        result = {
            'id': str(mid), 'place': place_label, 'lat': sea_lat, 'lng': sea_lng,
            'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
            'marker_icon': icon, 'source_match': 'black_sea_course'
        }
        
        # Add trajectory data if we have target coordinates
        if target_coords:
            result['trajectory'] = {
                'start': [sea_lat, sea_lng],
                'end': list(target_coords),
                'target': target_info
            }
        
        return [result]

    # --- Bilhorod-Dnistrovskyi coastal UAV patrol ("вздовж узбережжя Білгород-Дністровського району") ---
    if (('узбереж' in lower_sea or 'вздовж узбереж' in lower_sea) and
        ('білгород-дністровського' in lower_sea or 'белгород-днестровского' in lower_sea) and
        ('бпла' in lower_sea or 'дрон' in lower_sea)):
        # Base approximate city coordinate; push 0.22° south into sea
        city_lat, city_lng = 46.186, 30.345
        lat = city_lat - 0.22
        lng = city_lng
        threat_type, icon = classify(text)
        return [{
            'id': str(mid), 'place': 'Узбережжя Білгород-Дністровського р-ну', 'lat': lat, 'lng': lng,
            'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
            'marker_icon': icon, 'source_match': 'bilhorod_dnistrovskyi_coast'
        }]

    # --- "повз <city>" (passing near) with optional direction target "у напрямку <city>" ---
    lower_pass = text.lower()
    pass_near_detected = False
    if 'повз ' in lower_pass and ('бпла' in lower_pass or 'дрон' in lower_pass):
        pass_match = re.search(r"повз\s+([A-Za-zА-Яа-яЇїІіЄєҐґ'’ʼ`\-]{3,})", lower_pass)
        dir_match = re.search(r"напрямку\s+([A-Za-zА-Яа-яЇїІіЄєҐґ'’ʼ`\-]{3,})(?:\s+([A-Za-zА-Яа-яЇїІіЄєҐґ'’ʼ`\-]{3,}))?", lower_pass)
        places = []
        def norm_c(s: str):
            if not s: return None
            s = s.strip().lower().strip(".,:;()!?")
            s = UA_CITY_NORMALIZE.get(s, s)
            # Morphological heuristics: convert common Ukrainian/Russian case endings to nominative
            candidates = [s]
            if s.endswith('у') and len(s) > 4:
                candidates.append(s[:-1] + 'а')
            if s.endswith('ю') and len(s) > 4:
                candidates.append(s[:-1] + 'я')
            if s.endswith('и') and len(s) > 4:
                candidates.append(s[:-1] + 'а')
            if s.endswith('ої') and len(s) > 5:
                candidates.append(s[:-2] + 'а')
            if s.endswith('оїї') and len(s) > 6:
                candidates.append(s[:-3] + 'а')
            for cand in candidates:
                if region_enhanced_coords(cand):
                    return cand
            return s
        if pass_match:
            c1 = norm_c(pass_match.group(1))
            if c1:
                coords1 = region_enhanced_coords(c1)
                if coords1:
                    places.append((c1.title(), coords1, 'pass_near'))
        if dir_match:
            c2_first = norm_c(dir_match.group(1))
            c2_second_raw = dir_match.group(2)
            full_phrase = None
            if c2_first and c2_second_raw:
                c2_second = norm_c(c2_second_raw)
                cand_phrase = f"{c2_first} {c2_second}".strip()
                if cand_phrase in CITY_COORDS or (SETTLEMENTS_INDEX and cand_phrase in SETTLEMENTS_INDEX):
                    full_phrase = cand_phrase
            c2_key = full_phrase or c2_first
            if c2_key and c2_key != (places[0][0].lower() if places else None):
                coords2 = region_enhanced_coords(c2_key)
                if coords2:
                    places.append((c2_key.title(), coords2, 'direction_target'))
        if places:
            threat_type, icon = classify(text)
            out_tracks = []
            for idx,(nm,(lat,lng),tag) in enumerate(places,1):
                out_tracks.append({
                    'id': f"{mid}_pv{idx}", 'place': nm, 'lat': lat, 'lng': lng,
                    'threat_type': threat_type, 'text': text[:500], 'date': date_str,
                    'channel': channel, 'marker_icon': icon, 'source_match': tag, 'count': drone_count
                })
            if out_tracks:
                pass_near_detected = True
                return out_tracks

    # --- Pattern: "рухалися на <city1>, змінили курс на <city2>" ---
    lower_course_change = text.lower()
    if 'змінили курс на' in lower_course_change and ('рухал' in lower_course_change or 'рухались' in lower_course_change or 'рухалися' in lower_course_change):
        m_to = re.search(r'змінили\s+курс\s+на\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-]{3,})', lower_course_change)
        m_from = re.search(r'рухал(?:ися|ись|и|ась)?\s+на\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-]{3,})', lower_course_change)
        places = []
        def norm_simple(s):
            if not s: return None
            s = s.strip().lower().strip(".,:;()!")
            return UA_CITY_NORMALIZE.get(s, s)
        if m_from:
            c_from = norm_simple(m_from.group(1))
            coords_from = region_enhanced_coords(c_from)
            if coords_from:
                places.append((c_from.title(), coords_from, 'course_from'))
        if m_to:
            c_to = norm_simple(m_to.group(1))
            coords_to = region_enhanced_coords(c_to)
            if coords_to:
                # avoid duplicate if same
                if not any(p[0].lower()==c_to for p in places):
                    places.append((c_to.title(), coords_to, 'course_changed_to'))
        if places:
            threat_type, icon = classify(text)
            out = []
            for idx,(name,(lat,lng),tag) in enumerate(places,1):
                out.append({
                    'id': f"{mid}_cc{idx}", 'place': name, 'lat': lat, 'lng': lng,
                    'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
                    'marker_icon': icon, 'source_match': tag
                })
            if out:
                return out

    # --- Relative direction near a city: "північніше кам'янського у напрямку кременчука" ---
    rel_dir_lower = text.lower()
    if any(k in rel_dir_lower for k in ['північніше','південніше','східніше','західніше']) and ('бпла' in rel_dir_lower or 'дрон' in rel_dir_lower):
        # Allow letters plus apostrophes/hyphen
        m_rel = re.search(r"(північніше|південніше|східніше|західніше)\s+([A-Za-zА-Яа-яЇїІіЄєҐґ'`’ʼ\-]{4,})", rel_dir_lower)
        target_dir = re.search(r'напрямку\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-]{3,})', rel_dir_lower)
        if m_rel:
            dir_word = m_rel.group(1)
            raw_city = m_rel.group(2).strip(".,:;()!?")
            def norm_rel_city(s):
                s = s.lower()
                # нормализация окончаний родительного падежа '-ського' -> 'ське'
                if s.endswith('ського'):
                    s = s[:-6] + 'ське'
                if s.endswith('ого') and len(s) > 5:
                    s = s[:-3] + 'о'
                return UA_CITY_NORMALIZE.get(s, s)
            base_city = norm_rel_city(raw_city)
            coords_base = region_enhanced_coords(base_city)
            coords_target = None
            target_name = None
            if target_dir:
                tn = target_dir.group(1).lower().strip('.:,;()!?')
                tn = UA_CITY_NORMALIZE.get(tn, tn)
                coords_target = region_enhanced_coords(tn)
                target_name = tn
            if coords_base:
                lat_b, lng_b = coords_base
                # offset ~0.35 deg lat/long depending on direction
                lat_off, lng_off = 0,0
                if 'північ' in dir_word: lat_off = 0.35
                elif 'півден' in dir_word: lat_off = -0.35
                elif 'східн' in dir_word: lng_off = 0.55
                elif 'західн' in dir_word: lng_off = -0.55
                rel_lat, rel_lng = lat_b + lat_off, lng_b + lng_off
                threat_type, icon = classify(text)
                tracks = [{
                    'id': f"{mid}_rel1", 'place': base_city.title(), 'lat': rel_lat, 'lng': rel_lng,
                    'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
                    'marker_icon': icon, 'source_match': 'relative_dir'
                }]
                if coords_target:
                    tracks.append({
                        'id': f"{mid}_rel2", 'place': target_name.title(), 'lat': coords_target[0], 'lng': coords_target[1],
                        'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
                        'marker_icon': icon, 'source_match': 'direction_target'
                    })
                return tracks

    # --- Parenthetical course city e.g. "курс західний (кременчук)" ---
    if 'курс' in lower and '(' in lower and ')' in lower and ('бпла' in lower or 'дрон' in lower):
        m_par = re.search(r'курс[^()]{0,30}\(([A-Za-zА-Яа-яЇїІіЄєҐґ\-]{3,})\)', lower)
        if m_par:
            pc = m_par.group(1).lower()
            pc = UA_CITY_NORMALIZE.get(pc, pc)
            coords = region_enhanced_coords(pc)
            if coords:
                threat_type, icon = classify(text)
                return [{
                    'id': f"{mid}_pc", 'place': pc.title(), 'lat': coords[0], 'lng': coords[1],
                    'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
                    'marker_icon': icon, 'source_match': 'course_parenthetical'
                }]

    # --- Comma separated settlements followed by threat keyword (e.g. "Обухівка, Курилівка, Петриківка увага БПЛА") ---
    lower_commas = text.lower()
    if 'бпла' in lower_commas and ',' in lower_commas:
        # Identify first threat keyword position
        threat_kw_idx = None
        for kw in ['увага','проліт','пролёт','уважно','уважно.','уважно,']:
            pos = lower_commas.find(kw)
            if pos != -1:
                threat_kw_idx = pos
                break
        if threat_kw_idx is not None:
            left_seg = lower_commas[:threat_kw_idx]
            # quick guard to ensure segment not too long
            if 3 <= len(left_seg) <= 180:
                cand_parts = [p.strip() for p in left_seg.split(',') if p.strip()]
                found = []
                for cand in cand_parts:
                    # normalize basic endings (remove trailing punctuation)
                    base = cand.strip(" .!?:;()[]'`’ʼ")
                    if len(base) < 3:
                        continue
                    norm = UA_CITY_NORMALIZE.get(base, base)
                    coords = region_enhanced_coords(norm)
                    if coords:
                        found.append((norm.title(), coords))
                if found:
                    threat_type, icon = classify(text)
                    tracks = []
                    seenp = set()
                    for idx,(nm,(lat,lng)) in enumerate(found,1):
                        if nm in seenp: continue
                        seenp.add(nm)
                        tracks.append({
                            'id': f"{mid}_m{idx}", 'place': nm, 'lat': lat, 'lng': lng,
                            'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
                            'marker_icon': icon, 'source_match': 'multi_settlement_comma', 'count': drone_count
                        })
                    if tracks:
                        return tracks

    # --- PRIORITY: Direction patterns (у напрямку, через, повз) - BEFORE region boundary logic ---
    try:
        import re as _re_direction
        
        if has_threat(text) and any(pattern in text.lower() for pattern in ['у напрямку', 'через', 'повз']):
            direction_targets = []
            
            # Pattern 1: "у напрямку [city], [oblast]"
            naprym_pattern = r'у\s+напрямку\s+([А-Яа-яЇїІіЄєҐґ\'\-\s]+?)(?:\s*,\s*([А-Яа-яЇїІіЄєҐґ\'\-\s]*області?))?(?:[\.\,\!\?;]|$)'
            naprym_matches = _re_direction.findall(naprym_pattern, text, _re_direction.IGNORECASE)
            for city_raw, oblast_raw in naprym_matches:
                direction_targets.append(('у напрямку', city_raw.strip(), oblast_raw.strip() if oblast_raw else ''))
            
            # Process direction targets
            for direction_type, city_raw, oblast_raw in direction_targets:
                if direction_type == 'у напрямку':
                    city_norm = city_raw.lower().replace('\u02bc',"'").replace('ʼ',"'").replace("'","'").replace('`',"'")
                    city_norm = re.sub(r'\s+',' ', city_norm).strip()
                    
                    # Try exact lookup
                    coords = CITY_COORDS.get(city_norm)
                    if not coords:
                        # Try normalized lookup
                        city_base = UA_CITY_NORMALIZE.get(city_norm, city_norm)
                        coords = CITY_COORDS.get(city_base)
                    
                    if coords:
                        lat, lng = coords
                        threat_type, icon = classify(text)
                        
                        # Extract drone count
                        import re as _re_count
                        count_match = _re_count.search(r'(\d+)\s*[хx]?\s*(?:бпла|дрон|шахед)', text.lower())
                        drone_count = int(count_match.group(1)) if count_match else 1
                        
                        add_debug_log(f"PRIORITY: Direction target found - {city_norm} -> {coords}", "direction_priority")
                        return [{
                            'id': str(mid), 'place': city_raw.title(), 'lat': lat, 'lng': lng,
                            'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
                            'marker_icon': icon, 'source_match': 'direction_target_priority', 'count': drone_count
                        }]
                    else:
                        add_debug_log(f"PRIORITY: Direction target not found - {city_norm}", "direction_priority")
    except Exception as e:
        add_debug_log(f"Direction priority processing error: {e}", "direction_priority")

    # PRIORITY: Various Shahed patterns - Process before region boundary logic
    try:
        import re as _re_shahed
        all_shahed_tracks = []
        
        # Pattern 1: "N шахедів біля [city]" or "N шахедів біля [city1]/[city2]"
        bilya_pattern = r'(\d+)\s+шахед[а-яіїєёыийї]*\s+біля\s+([А-Яа-яЏїІіЄєҐґ\'\-\s\/]+?)(?:\s+та\s+район)?(?:\s+на\s+[А-Яа-яЇїІіЄєҐґ\'\-\s]+)?(?:[\.\,\!\?;]|$)'
        bilya_matches = _re_shahed.findall(bilya_pattern, text, _re_shahed.IGNORECASE)
        
        # Pattern 2: "N шахед на [city]"
        na_pattern = r'(\d+)\s+шахед[а-яіїєёыийї]*\s+на\s+([А-Яа-яЇїІіЄєҐґ\'\-\s]+?)(?:[\.\,\!\?;]|$)'
        na_matches = _re_shahed.findall(na_pattern, text, _re_shahed.IGNORECASE)
        
        # Pattern 3: "N шахедів з боку [city]"
        z_boku_pattern = r'(\d+)\s+шахед[а-яіїєёыийї]*\s+з\s+боку\s+([А-Яа-яЇїІіЄєҐґ\'\-\s]+?)(?:[\.\,\!\?;]|$)'
        z_boku_matches = _re_shahed.findall(z_boku_pattern, text, _re_shahed.IGNORECASE)
        
        # Pattern 4: "N шахедів через [city1]/[city2]" - multiple cities
        cherez_multi_pattern = r'(\d+)\s+шахед[а-яіїєёыийї]*\s+через\s+([А-Яа-яЇїІіЄєҐґ\'\-\s\/]+?)(?:\s+район)?(?:\s+на\s+[А-Яа-яЇїІіЄєҐґ\'\-\s]+)?(?:[\.\,\!\?;]|$)'
        cherez_matches = _re_shahed.findall(cherez_multi_pattern, text, _re_shahed.IGNORECASE)
        
        all_patterns = [
            (bilya_matches, 'bilya'),
            (na_matches, 'na'), 
            (z_boku_matches, 'z_boku'),
            (cherez_matches, 'cherez')
        ]
        
        for matches, pattern_type in all_patterns:
            for count_str, city_raw in matches:
                # Handle multiple cities separated by /
                cities = [c.strip() for c in city_raw.split('/')]
                
                for city_part in cities:
                    city_norm = city_part.lower().replace('\u02bc',"'").replace('ʼ',"'").replace("'","'").replace('`',"'")
                    city_norm = re.sub(r'\s+',' ', city_norm).strip()
                    
                    # Special handling for "[city] на [region]" patterns
                    region_match = re.match(r'^(.+?)\s+на\s+([а-яіїє]+щині?|[а-яіїє]+ській?\s+обл?\.?|[а-яіїє]+ській?\s+області?)$', city_norm)
                    if region_match:
                        city_norm = region_match.group(1).strip()
                        region_hint = region_match.group(2).strip()
                        # Use full message context for resolution
                        coords = ensure_city_coords_with_message_context(city_norm, text)
                        if coords:
                            lat, lng, approx = coords
                            add_debug_log(f"SHAHED: Regional pattern found - {city_norm} на {region_hint} -> ({lat}, {lng})", "shahed_regional")
                            
                            result_entry = {
                                'id': f"{mid}_sha_{len(threats)+1}",
                                'place': f"{city_part.title()}",
                                'lat': lat, 'lng': lng,
                                'type': 'shahed', 'count': int(count_str),
                                'timestamp': date_str, 'channel': channel
                            }
                            threats.append(result_entry)
                            continue  # Skip regular processing for this city
                    
                    # Apply normalization rules for accusative/genitive cases
                    original_norm = city_norm
                    if city_norm in UA_CITY_NORMALIZE:
                        city_norm = UA_CITY_NORMALIZE[city_norm]
                    
                    # Try accusative endings for cities like "миколаєва" -> "миколаїв", "полтави" -> "полтава"
                    if not (city_norm in CITY_COORDS or region_enhanced_coords(city_norm)):
                        # Try various ending transformations
                        variants = [city_norm]
                        if city_norm.endswith('а'):
                            variants.extend([city_norm[:-1] + 'ів', city_norm[:-1] + 'і'])
                        elif city_norm.endswith('и'):
                            variants.extend([city_norm[:-1] + 'а', city_norm[:-1] + 'я'])
                        elif city_norm.endswith('у'):
                            variants.extend([city_norm[:-1] + 'п', city_norm[:-1] + 'к'])
                        
                        for variant in variants:
                            if variant in CITY_COORDS or region_enhanced_coords(variant):
                                city_norm = variant
                                break
                    
                    # Try to get coordinates
                    coords = region_enhanced_coords(city_norm)
                    if not coords:
                        context_result = ensure_city_coords_with_message_context(city_norm, text)
                        if context_result:
                            coords = context_result[:2]  # Take only lat, lng
                    
                    if coords:
                        lat, lng = coords
                        threat_type, icon = classify(text)
                        count = int(count_str) if count_str.isdigit() else 1
                        
                        # Create multiple tracks for multiple drones
                        tracks_to_create = max(1, count)
                        for i in range(tracks_to_create):
                            track_label = city_part.title()
                            if tracks_to_create > 1:
                                track_label += f" #{i+1}"
                            
                            # Add small coordinate offsets to prevent marker overlap
                            marker_lat = lat
                            marker_lng = lng
                            if tracks_to_create > 1:
                                # Create a chain pattern - drones one after another
                                offset_distance = 0.03  # ~3km offset between each drone
                                marker_lat += offset_distance * i
                                marker_lng += offset_distance * i * 0.5
                                
                            all_shahed_tracks.append({
                                'id': f"{mid}_{pattern_type}_{len(all_shahed_tracks)}", 
                                'place': track_label, 
                                'lat': marker_lat, 
                                'lng': marker_lng,
                                'threat_type': threat_type, 
                                'text': text[:500], 
                                'date': date_str, 
                                'channel': channel,
                                'marker_icon': icon, 
                                'source_match': f'{pattern_type}_shahed_priority', 
                                'count': 1
                            })
                        add_debug_log(f"SHAHED {pattern_type.upper()}: {city_norm} ({count}x) -> {coords}", f"shahed_{pattern_type}")
        
        if all_shahed_tracks:
            return all_shahed_tracks
    except Exception as e:
        add_debug_log(f"Shahed patterns processing error: {e}", "shahed_priority")

    # Region boundary logic (fallback single or midpoint for exactly two)
    matched_regions = []
    for name, coords in OBLAST_CENTERS.items():
        if name in lower:
            matched_regions.append((name, coords))
    if matched_regions:
        # НОВОЕ: Проверка контекстного геокодинга перед региональными маркерами
        if CONTEXT_GEOCODER_AVAILABLE:
            context_result = get_coordinates_context_aware(text)
            if context_result:
                lat, lng, target_city = context_result
                threat_type, icon = classify(text)
                
                print(f"DEBUG Context-aware geocoding: Found primary target '{target_city}' at ({lat}, {lng})")
                
                return [{
                    'id': str(mid), 'place': target_city.title(), 'lat': lat, 'lng': lng,
                    'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
                    'marker_icon': icon, 'source_match': 'context_aware_geocoding', 'count': 1
                }]
        
        # Если только области упомянуты и нет ключей угроз, пропускаем.
        # Дополнительная защита: иногда в messages.json могли сохраниться старые записи без угроз.
        if not has_threat(text):
            # чистый список областей? (только названия + двоеточия/пробелы/переводы строк)
            stripped = re.sub(r'[\s:]+', ' ', text.lower()).strip()
            only_regions = all(rn in OBLAST_CENTERS for rn in stripped.split() if rn)
            if only_regions or len(text) < 120:
                return None
        # --- Направления внутри области (північно-західний / південно-західний и т.п.) ---
        def detect_direction(lower_txt: str):
            # Support full adjectives with endings (-ний / -ня / -ньому) by searching stems
            if 'північно-захід' in lower_txt or 'північно-західн' in lower_txt: return 'nw'
            if 'південно-захід' in lower_txt or 'південно-західн' in lower_txt: return 'sw'
            if 'північно-схід' in lower_txt or 'північно-східн' in lower_txt: return 'ne'
            if 'південно-схід' in lower_txt or 'південно-східн' in lower_txt: return 'se'
            # Single directions (allow stems 'північн', 'південн')
            if re.search(r'\bпівніч(?!о-с)(?:н\w*)?\b', lower_txt): return 'n'
            if re.search(r'\bпівденн?\w*\b', lower_txt): return 's'
            if re.search(r'\bсхідн?\w*\b', lower_txt): return 'e'
            if re.search(r'\bзахідн?\w*\b', lower_txt): return 'w'
            return None
        direction_code = None
    if len(matched_regions) == 1 and not raion_matches and not pass_near_detected:
            direction_code = detect_direction(lower)
            # If message also contains course info referencing cities/slash – skip region-level marker to allow city parsing later
            course_words = (' курс ' in lower or lower.startswith('курс '))
            # Treat city present only if it appears as a standalone word (to avoid 'дніпро' inside 'дніпропетровщини')
            has_city_token = False
            try:
                import re as _re_ct
                for c_name in CITY_COORDS.keys():
                    if _re_ct.search(r'\b'+_re_ct.escape(c_name)+r'\b', lower):
                        has_city_token = True; break
            except Exception:
                has_city_token = any(c in lower for c in CITY_COORDS.keys())
            has_slash_combo = '/' in lower
            if direction_code and not (course_words and (has_city_token or has_slash_combo)):
                # ---- Special: sector course pattern inside region directional message ----
                # e.g. "курс(ом) в бік сектору перещепине - губиниха"
                sector_match = re.search(r'курс(?:ом)?\s+в\s+бік\s+сектору\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-]{3,})(?:\s*[-–]\s*([A-Za-zА-Яа-яЇїІіЄєҐґ\-]{3,}))?', lower)
                if sector_match:
                    c1 = sector_match.group(1)
                    c2 = sector_match.group(2)
                    def norm_city(n):
                        if not n: return None
                        n = n.strip().lower()
                        n = re.sub(r'["`ʼ’\'.,:;()]+', '', n)
                        return UA_CITY_NORMALIZE.get(n, n)
                    c1n = norm_city(c1)
                    c2n = norm_city(c2) if c2 else None
                    coords1 = CITY_COORDS.get(c1n) or (SETTLEMENTS_INDEX.get(c1n) if SETTLEMENTS_INDEX else None)
                    coords2 = CITY_COORDS.get(c2n) or (SETTLEMENTS_INDEX.get(c2n) if (c2n and SETTLEMENTS_INDEX) else None)
                    if coords1 or coords2:
                        if coords1 and coords2:
                            lat_o = (coords1[0]+coords2[0])/2
                            lng_o = (coords1[1]+coords2[1])/2
                            place_label = f"{c1n.title()} - {c2n.title()} (сектор)"
                        else:
                            (lat_o,lng_o) = coords1 or coords2
                            place_label = (c1n or c2n).title()
                        threat_type, icon = classify(text)
                        return [{
                            'id': str(mid), 'place': place_label, 'lat': lat_o, 'lng': lng_o,
                            'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
                            'marker_icon': icon, 'source_match': 'course_sector', 'count': drone_count
                        }]
                (reg_name, (base_lat, base_lng)) = matched_regions[0]
                
                # Define offset function for coordinate calculations
                def offset(lat, lng, code):
                    # Уменьшенные дельты для более точного позиционирования в пределах области
                    # (широта ~111 км, долгота * cos(lat))
                    import math
                    lat_step = 0.35  # Примерно 35-40 км вместо 60 км
                    lng_step = 0.55 / max(0.2, abs(math.cos(math.radians(lat))))  # Примерно 35-40 км
                    if code == 'n': return lat+lat_step, lng
                    if code == 's': return lat-lat_step, lng
                    if code == 'e': return lat, lng+lng_step
                    if code == 'w': return lat, lng-lng_step
                    # диагонали немного меньше по каждой оси
                    lat_diag = lat_step * 0.8
                    lng_diag = lng_step * 0.8
                    if code == 'ne': return lat+lat_diag, lng+lng_diag
                    if code == 'nw': return lat+lat_diag, lng-lng_diag
                    if code == 'se': return lat-lat_diag, lng+lng_diag
                    if code == 'sw': return lat-lat_diag, lng-lng_diag
                    return lat, lng
                
                # SPECIAL: Handle messages with start position + course direction
                # e.g. "на півночі тернопільщини ➡️ курсом на південно-західний напрямок"
                start_direction = None
                course_direction = None
                
                # Detect start position (на півночі/півдні/сході/заході)
                if re.search(r'\bна\s+півночі\b', lower) or re.search(r'\bпівнічн\w+\s+частин\w*\b', lower):
                    start_direction = 'n'
                elif re.search(r'\bна\s+півдні\b', lower) or re.search(r'\bпівденн\w+\s+частин\w*\b', lower):
                    start_direction = 's'
                elif re.search(r'\bна\s+сході\b', lower) or re.search(r'\bсхідн\w+\s+частин\w*\b', lower):
                    start_direction = 'e'
                elif re.search(r'\bна\s+заході\b', lower) or re.search(r'\bзахідн\w+\s+частин\w*\b', lower):
                    start_direction = 'w'
                
                # Detect course direction (курсом на направление)
                # Support patterns: "курсом на", "рух на", "продовжує рух на", "прямують на", "в напрямку"
                has_direction_keyword = ('курс' in lower and 'напрямок' in lower) or ('➡' in lower or '→' in lower) or \
                                       ('рух' in lower and 'на' in lower) or ('прямують' in lower and 'на' in lower) or \
                                       ('продовжує' in lower and ('рух' in lower or 'на' in lower)) or \
                                       ('в' in lower and ('напрямку' in lower or 'напрямок' in lower or 'напрям' in lower))
                
                if has_direction_keyword:
                    if 'північно-західн' in lower or 'північно-захід' in lower:
                        course_direction = 'nw'
                    elif 'південно-західн' in lower or 'південно-захід' in lower:
                        course_direction = 'sw'
                    elif 'північно-східн' in lower or 'північно-схід' in lower:
                        course_direction = 'ne'
                    elif 'південно-східн' in lower or 'південно-схід' in lower:
                        course_direction = 'se'
                    # Single directions in course - support "курсом на", "рух на", "в [напрямок] напрямку"
                    elif re.search(r'(курс\w*|рух|прямують|продовжує)\s+(на\s+)?північ', lower) or re.search(r'в\s+північн\w*\s+напрям', lower):
                        course_direction = 'n'
                    elif re.search(r'(курс\w*|рух|прямують|продовжує)\s+(на\s+)?південь|півд', lower) or re.search(r'в\s+півден\w*\s+напрям', lower):
                        course_direction = 's'
                    elif re.search(r'(курс\w*|рух|прямують|продовжує)\s+(на\s+)?схід', lower) or re.search(r'в\s+східн\w*\s+напрям', lower):
                        course_direction = 'e'
                    elif re.search(r'(курс\w*|рух|прямують|продовжує)\s+(на\s+)?захід', lower) or re.search(r'в\s+захід\w*\s+напрям', lower):
                        course_direction = 'w'
                
                # If we have both start position and course direction, apply them sequentially
                if start_direction and course_direction:
                    # First offset: move to start position within region
                    lat_start, lng_start = offset(base_lat, base_lng, start_direction)
                    # Second offset: apply course direction from start position  
                    lat_final, lng_final = offset(lat_start, lng_start, course_direction)
                    
                    # Create descriptive label with arrow for trajectory visualization
                    start_labels = {'n':'півночі', 's':'півдні', 'e':'сході', 'w':'заході'}
                    course_labels = {
                        'n':'північ', 's':'південь', 'e':'схід', 'w':'захід',
                        'ne':'північний схід', 'nw':'північний захід', 
                        'se':'південний схід', 'sw':'південний захід'
                    }
                    # Direction labels for arrow (Ukrainian names compatible with frontend)
                    arrow_labels = {
                        'n':'північ', 's':'півдня', 'e':'сходу', 'w':'заходу',
                        'ne':'північного сходу', 'nw':'північного заходу',
                        'se':'південного сходу', 'sw':'південного заходу'
                    }
                    start_label = start_labels.get(start_direction, 'області')
                    course_label = course_labels.get(course_direction, 'напрямок')
                    arrow_label = arrow_labels.get(course_direction, '')
                    base_disp = reg_name.split()[0].title()
                    
                    # Add arrow to place name for trajectory visualization in frontend
                    place_name = f"{base_disp} (з {start_label})"
                    if arrow_label:
                        place_name += f" ←{arrow_label}"
                    
                    trajectory = {
                        'start': [lat_start, lng_start],
                        'end': [lat_final, lng_final],
                        'source': base_disp,
                        'target': course_label,
                        'kind': 'region_start_course'
                    }

                    threat_type, icon = classify(text)
                    return [{
                        'id': str(mid), 'place': place_name, 
                        'lat': lat_final, 'lng': lng_final,
                        'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
                        'marker_icon': icon, 'source_match': 'region_start_course', 'count': drone_count,
                        'trajectory': trajectory,
                        'course_direction': f"курс на {course_label}",
                        'course_source': base_disp,
                        'course_target': course_label,
                        'course_type': 'region_start_course'
                    }]
                
                # If only course_direction (no start position), use it as the direction
                if course_direction and not start_direction:
                    direction_code = course_direction
                
                # смещение ~50-70 км в сторону указанного направления (fallback for single direction)
                lat_o, lng_o = offset(base_lat, base_lng, direction_code)
                threat_type, icon = classify(text)
                dir_label_map = {
                    'n':'північна частина', 's':'південна частина', 'e':'східна частина', 'w':'західна частина',
                    'ne':'північно-східна частина', 'nw':'північно-західна частина',
                    'se':'південно-східна частина', 'sw':'південно-західна частина'
                }
                # Direction labels for arrow (Ukrainian names compatible with frontend)
                arrow_labels = {
                    'n':'північ', 's':'півдня', 'e':'сходу', 'w':'заходу',
                    'ne':'північного сходу', 'nw':'північного заходу',
                    'se':'південного сходу', 'sw':'південного заходу'
                }
                dir_phrase = dir_label_map.get(direction_code, 'частина')
                arrow_label = arrow_labels.get(direction_code, '')
                base_disp = reg_name.split()[0].title()
                
                # Add arrow to place name for trajectory visualization
                place_name = f"{base_disp} ({dir_phrase})"
                if arrow_label:
                    place_name += f" ←{arrow_label}"
                
                return [{
                    'id': str(mid), 'place': place_name, 'lat': lat_o, 'lng': lng_o,
                    'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
                    'marker_icon': icon, 'source_match': 'region_direction', 'count': drone_count
                }]
            # если нет направления — продолжаем анализ (ищем конкретные цели типа "курс на <місто>")
    # Midpoint for explicit course between two regions (e.g. "... на запоріжжі курсом на дніпропетровщину")
    if len(matched_regions) == 2 and ('курс' in lower or '➡' in lower or '→' in lower) and (' на ' in lower):
            # ensure we really reference both regions in a course sense: one mentioned before 'курс' and the other after 'курс' / arrow
            parts_course = re.split(r'курс|➡|→', lower, 1)
            if len(parts_course) == 2:
                before, after_part = parts_course
                r1, r2 = matched_regions[0], matched_regions[1]
                bnames = [r1[0].split()[0].lower(), r2[0].split()[0].lower()]
                # If both region stems appear across the split segments, build midpoint
                cond_split = (any(n[:5] in before for n in bnames) and any(n[:5] in after_part for n in bnames))
                # Fallback heuristic: pattern 'на <region1>' earlier then arrow/"курс" then 'на <region2>'
                if not cond_split:
                    # Extract simple region stems from OBLAST_CENTERS keys
                    stems = ['запоріж','запор', 'дніпропетров','дніпропет']
                    if any(st in lower for st in stems):
                        if re.search(r'на\s+запоріж', lower) and re.search(r'на\s+дніпропетров', lower):
                            cond_split = True
                if cond_split:
                    (n1,(a1,b1)), (n2,(a2,b2)) = matched_regions

                    def region_variants(name: str):
                        base = name.split()[0].lower()
                        variants = {base}
                        cleaned = base.replace('область', '').replace('області', '').strip()
                        if cleaned:
                            variants.add(cleaned)
                        if cleaned.endswith('ська'):
                            stem = cleaned[:-4]
                            variants.update({stem + 'щина', stem + 'щини', stem + 'щин', stem})
                        elif cleaned.endswith('ської'):
                            stem = cleaned[:-5]
                            variants.update({stem + 'щина', stem + 'щини', stem + 'щин', stem})
                        return [v for v in variants if v]

                    def segment_has(segment: str, name: str) -> bool:
                        for variant in region_variants(name):
                            if variant in segment:
                                return True
                        return False

                    def region_position(full_text: str, name: str) -> int:
                        positions = []
                        for variant in region_variants(name):
                            idx = full_text.find(variant)
                            if idx != -1:
                                positions.append(idx)
                        return min(positions) if positions else 10**6

                    # Determine source and target based on message structure
                    source_entry = matched_regions[0]
                    target_entry = matched_regions[1]
                    before_region = next((entry for entry in matched_regions if segment_has(before, entry[0])), None)
                    after_region = next((entry for entry in matched_regions if segment_has(after_part, entry[0])), None)

                    if before_region and after_region and before_region != after_region:
                        source_entry = before_region
                        target_entry = after_region
                    elif before_region and not after_region:
                        source_entry = before_region
                        target_entry = next(entry for entry in matched_regions if entry != source_entry)
                    elif after_region and not before_region:
                        target_entry = after_region
                        source_entry = next(entry for entry in matched_regions if entry != target_entry)
                    else:
                        # fallback to textual order
                        ordered = sorted(matched_regions, key=lambda entry: region_position(lower, entry[0]))
                        if len(ordered) == 2 and ordered[0] != ordered[1]:
                            source_entry, target_entry = ordered[0], ordered[1]

                    (source_name, (src_lat, src_lng)) = source_entry
                    (target_name, (tgt_lat, tgt_lng)) = target_entry

                    source_region = source_name.split()[0].title()
                    target_region = target_name.split()[0].title()

                    # Calculate direction from source to target for arrow labels
                    dlat = tgt_lat - src_lat
                    dlng = tgt_lng - src_lng

                    def direction_token(dy: float, dx: float):
                        if abs(dy) < 1e-6 and abs(dx) < 1e-6:
                            return None
                        if abs(dy) > abs(dx) * 1.4:
                            return 'n' if dy > 0 else 's'
                        if abs(dx) > abs(dy) * 1.4:
                            return 'e' if dx > 0 else 'w'
                        if dy >= 0 and dx >= 0:
                            return 'ne'
                        if dy >= 0 and dx < 0:
                            return 'nw'
                        if dy < 0 and dx >= 0:
                            return 'se'
                        return 'sw'

                    dir_token = direction_token(dlat, dlng)
                    arrow_label_map = {
                        'n': 'півночі', 's': 'півдня', 'e': 'сходу', 'w': 'заходу',
                        'ne': 'північного сходу', 'nw': 'північного заходу',
                        'se': 'південного сходу', 'sw': 'південного заходу'
                    }
                    course_label_map = {
                        'n': 'північ', 's': 'південь', 'e': 'схід', 'w': 'захід',
                        'ne': "північний схід", 'nw': "північний захід",
                        'se': "південний схід", 'sw': "південний захід"
                    }
                    arrow_direction = arrow_label_map.get(dir_token, '')
                    course_direction_text = course_label_map.get(dir_token)

                    # Position marker near the border (keep bias toward source to avoid city centers)
                    border_bias = 0.7  # 70% source, 30% target
                    lat = src_lat * border_bias + tgt_lat * (1 - border_bias)
                    lng = src_lng * border_bias + tgt_lng * (1 - border_bias)

                    # Create place name with arrow for trajectory visualization
                    place_name = f"{source_region} → {target_region}"
                    if arrow_direction:
                        place_name += f" ←{arrow_direction}"

                    trajectory = {
                        'start': [src_lat, src_lng],
                        'end': [tgt_lat, tgt_lng],
                        'target': target_region,
                        'source': source_region,
                        'kind': 'region_course'
                    }

                    threat_type, icon = classify(text)
                    result = {
                        'id': str(mid), 'place': place_name, 'lat': lat, 'lng': lng,
                        'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
                        'marker_icon': icon, 'source_match': 'region_course_trajectory', 'count': drone_count,
                        'trajectory': trajectory,
                        'course_source': source_region,
                        'course_target': target_region,
                        'course_type': 'region_to_region'
                    }
                    if course_direction_text:
                        result['course_direction'] = f"курс на {course_direction_text}"
                    else:
                        result['course_direction'] = f"курс на {target_region}"
                    return [result]

    if len(matched_regions) == 2 and any(w in lower for w in ['межі','межу','межа','между','границі','граница']):
            (n1,(a1,b1)), (n2,(a2,b2)) = matched_regions
            lat = (a1+a2)/2; lng = (b1+b2)/2
            threat_type, icon = classify(text)
            return [{
                'id': str(mid), 'place': f"Межа {n1.split()[0].title()}/{n2.split()[0].title()}" , 'lat': lat, 'lng': lng,
                'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
                'marker_icon': icon, 'count': drone_count
            }]
    else:
            # If message contains explicit course targets (parsed later), don't emit plain region markers
            course_target_hint = False
            for ln in text.split('\n'):
                ll = ln.lower()
                if 'бпла' in ll and 'курс' in ll and re.search(r'курс(?:ом)?\s+(?:на|в|у)\s+[A-Za-zА-Яа-яЇїІіЄєҐґ\-]{3,}', ll):
                    course_target_hint = True
                    break
            if not course_target_hint:
                threat_type, icon = classify(text)
                
                # Extract course information for Shahed threats
                course_info = None
                if threat_type == 'shahed':
                    course_info = extract_shahed_course_info(original_text or text)
                
                tracks = []
                seen = set()
                for idx,(n1,(lat,lng)) in enumerate(matched_regions,1):
                    base = n1.split()[0].title()
                    if base in seen: continue
                    seen.add(base)
                    
                    track = {
                        'id': f"{mid}_r{idx}", 'place': base, 'lat': lat, 'lng': lng,
                        'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
                        'marker_icon': icon, 'source_match': 'region_multi_simple', 'count': drone_count
                    }
                    
                    # Add course information if available
                    if course_info:
                        track.update({
                            'course_source': course_info.get('source_city'),
                            'course_target': course_info.get('target_city'),
                            'course_direction': course_info.get('course_direction'),
                            'course_type': course_info.get('course_type')
                        })
                    
                    tracks.append(track)
                if tracks:
                    return tracks
    # City fallback scan (ensure whole-word style match to avoid false hits inside oblast words, e.g. 'дніпро' in 'дніпропетровщина')
    for city in UA_CITIES:
        if re.search(r'(?<![a-zа-яїієґ])' + re.escape(city) + r'(?![a-zа-яїієґ])', lower):
            norm = UA_CITY_NORMALIZE.get(city, city)
            # City fallback: attempt region-qualified first
            coords = None
            if region_hint_global and OPENCAGE_API_KEY:
                coords = geocode_opencage(f"{norm} {region_hint_global}")
            if not coords:
                coords = region_enhanced_coords(norm)
            # If областной контекст уже определён (matched_regions) ограничим города той же области
            if matched_regions:
                # берем первый stem области
                stem = None
                for (rn, _c) in matched_regions:
                    for s in ['харків','львів','київ','дніпропетров','полтав','сум','черніг','волин','запор','одес','микола','черка','житом','хмельниць','рівн','івано','терноп','ужгород','кропив','луган','донець','чернівц']:
                        if s in rn:
                            stem = s; break
                    if stem: break
                if stem and norm in CITY_TO_OBLAST and CITY_TO_OBLAST[norm] != stem:
                    continue
            if coords:
                lat, lng = coords
                threat_type, icon = classify(text)
                return [{
                    'id': str(mid), 'place': norm.title(), 'lat': lat, 'lng': lng,
                    'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
                    'marker_icon': icon, 'count': drone_count
                }]
            # if city found but no coords even in fallback, continue scanning others (no break)
    # --- Slash separated settlements with drone count (e.g. "дніпро / самар — 6х бпла ... курс західний") ---
    if '/' in lower and ('бпла' in lower or 'дрон' in lower) and any(x in lower for x in ['х бпла','x бпла',' бпла']):
        left_part = lower.split('—')[0].split('-',1)[0]
        parts = [p.strip() for p in re.split(r'/|\\', left_part) if p.strip()]
        found = []
        for p in parts:
            if p in CITY_COORDS:
                found.append((p.title(), CITY_COORDS[p]))
        if found:
            threat_type, icon = classify(text)
            tracks = []
            for idx,(nm,(lat,lng)) in enumerate(found,1):
                # If course west mentioned, offset west a bit
                if 'курс захід' in lower or 'курс запад' in lower:
                    lng -= 0.4
                tracks.append({
                    'id': f"{mid}_s{idx}", 'place': nm, 'lat': lat, 'lng': lng,
                    'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
                    'marker_icon': icon, 'source_match': 'slash_combo'
                })
            if tracks:
                return tracks
    # --- Single city with westward course ("курс західний") adjust marker to west to avoid mistaken northern region offsets ---
    if 'курс захід' in lower and 'бпла' in lower:
        for c in CITY_COORDS.keys():
            if c in lower:
                lat,lng = CITY_COORDS[c]
                threat_type, icon = classify(text)
                return [{
                    'id': str(mid), 'place': c.title(), 'lat': lat, 'lng': lng - 0.4,
                    'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
                    'marker_icon': icon, 'source_match': 'course_west'
                }]
    # --- Drone course target parsing (e.g. "БпЛА курсом на Ніжин") ---
    def _normalize_course_city(w: str):
        # Preserve internal single space for multi-word (e.g. "липова долина") before stripping punctuation
        w = re.sub(r'\s+', ' ', w.strip().lower())
        # Remove punctuation but keep spaces and hyphen
        w = re.sub(r'["`ʼ’\'.,:;()]+', '', w)
        # Allow letters, spaces, hyphen
        w = re.sub(r'[^a-zа-яїієґё\- ]', '', w)
        # Accusative to nominative heuristic for each word (handles phrases like 'велику багачку', 'липову долину')
        parts = [p for p in w.split(' ') if p]
        norm_parts = []
        for p in parts:
            base = p
            # Common feminine accusative endings -> nominative
            if len(base) > 4 and base.endswith(('у','ю')):
                base = base[:-1] + 'а'
            # Handle '-у/ю' endings for multi-word second element 'долину' -> 'долина'
            if len(base) > 5 and base.endswith('ину'):
                base = base[:-2] + 'на'
            # Special handling for oblast names ending in 'щину' -> 'щина'
            if len(base) > 6 and base.endswith('щину'):
                base = base[:-1] + 'а'
            norm_parts.append(base)
        w = ' '.join(norm_parts)
        # Apply explicit manual normalization map last (covers irregular)
        if w in UA_CITY_NORMALIZE:
            w = UA_CITY_NORMALIZE[w]
        return w
    course_matches = []
    # Ищем каждую строку с шаблоном
    for line in text.split('\n'):
        line_low = line.lower()
        if 'бпла' in line_low and 'курс' in line_low and (' на ' in line_low or ' в ' in line_low or ' у ' in line_low):
            # Capture one or two words as target, allowing hyphens and apostrophes
            m = re.search(r'курс(?:ом)?\s+(?:на|в|у)\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-]{3,}(?:\s+[A-Za-zА-Яа-яЇїІіЄєҐґ\-]{3,})?)', line, flags=re.IGNORECASE)
            if m:
                raw_city = m.group(1)
                norm_city = _normalize_course_city(raw_city)
                if norm_city:
                    # If the captured target looks like an oblast (region) name (e.g. 'дніпропетровщина', 'черкаська область'),
                    # we intentionally SKIP adding a precise course target marker to avoid falsely placing it at the oblast's capital city.
                    # User requirement: phrases like 'курс(ом) на Дніпропетровщину' must NOT create a marker right in 'Дніпро'.
                    # Check both nominative and accusative forms (щина/щину)
                    if re.search(r'(щина|щину|область)$', norm_city) or re.search(r'(щина|щину|область)$', raw_city.lower()):
                        log.debug(f'skip course_target oblast_only={norm_city} raw={raw_city} mid={mid}')
                        continue
                    coords = region_enhanced_coords(norm_city)
                    if not coords:
                        log.debug(f'course_target_lookup miss city={norm_city} mid={mid} line={line.strip()[:120]!r} region_hint={region_hint_global}')
                        coords = ensure_city_coords(norm_city)
                        # Try context-based lookup if standard lookup fails
                        if not coords:
                            context_result = ensure_city_coords_with_message_context(norm_city, text)
                            if context_result:
                                coords = context_result[:2]  # Take only lat, lng
                    # Oblast stem disambiguation: if global hint exists and known expected stem differs, re-query with region-qualified geocode
                    if coords and region_hint_global and norm_city in CITY_TO_OBLAST:
                        expected_stem = CITY_TO_OBLAST[norm_city]
                        if expected_stem != region_hint_global[:len(expected_stem)]:
                            # attempt region-qualified geocode with expected stem to refine
                            if OPENCAGE_API_KEY:
                                try:
                                    region_phrase = None
                                    # derive full oblast phrase from stem heuristically (simple mapping subset)
                                    stem_map = {
                                        'сум': 'сумська область', 'полтав': 'полтавська область', 'дніпропетров': 'дніпропетровська область',
                                        'харків': 'харківська область'
                                    }
                                    region_phrase = stem_map.get(expected_stem)
                                    if region_phrase:
                                        refined = geocode_opencage(f"{norm_city} {region_phrase}")
                                        if refined:
                                            coords = refined
                                except Exception:
                                    pass
                    if coords:
                        log.debug(f'course_target_match city={norm_city} coords={coords} region_hint={region_hint_global} mid={mid}')
                    # If still no coords AND we have a region hint + OpenCage, try region-qualified query directly for multi-word ambiguous city
                    if not coords and region_hint_global and OPENCAGE_API_KEY:
                        try:
                            refined2 = geocode_opencage(f"{norm_city} {region_hint_global}")
                            if refined2:
                                coords = refined2
                        except Exception:
                            pass
                    if coords:
                        # Extract line-specific drone count if present (e.g. "4х БпЛА")
                        line_count = None
                        m_lc = re.search(r'(\b\d{1,3})\s*[xх]\s*бпла', line_low)
                        if m_lc:
                            try:
                                line_count = int(m_lc.group(1))
                            except Exception:
                                line_count = None
                        # Ensure coords is a tuple of exactly 2 elements (lat, lng)
                        if len(coords) >= 2:
                            coords = coords[:2]
                        course_matches.append((norm_city.title(), coords, line[:200], line_count))
    if course_matches:
        threat_type, icon = classify(text)
        tracks = []
        seen_places = set()
        for idx,(name,(lat,lng),snippet,line_count) in enumerate(course_matches,1):
            if name in seen_places: continue
            seen_places.add(name)
            
            # Extract Shahed course information if this is a Shahed threat
            course_info = None
            if threat_type == 'shahed':
                course_info = extract_shahed_course_info(original_text or text)
            
            # Determine how many tracks to create
            count = line_count if line_count else drone_count
            tracks_to_create = max(1, count if count else 1)
            
            # Create multiple tracks for multiple drones
            for i in range(tracks_to_create):
                track_name = name
                if tracks_to_create > 1:
                    track_name += f" #{i+1}"
                
                # Add small coordinate offsets to prevent marker overlap
                marker_lat = lat
                marker_lng = lng
                if tracks_to_create > 1:
                    # Create a chain pattern - drones one after another
                    offset_distance = 0.03  # ~3km offset between each drone
                    marker_lat += offset_distance * i
                    marker_lng += offset_distance * i * 0.5
                
                track = {
                    'id': f"{mid}_c{idx}_{i+1}", 'place': track_name, 'lat': marker_lat, 'lng': marker_lng,
                    'threat_type': threat_type, 'text': snippet[:500], 'date': date_str, 'channel': channel,
                    'marker_icon': icon, 'source_match': 'course_target', 'count': 1
                }
                
                # Add course information if available
                if course_info:
                    track.update({
                        'course_source': course_info.get('source_city'),
                        'course_target': course_info.get('target_city'),
                        'course_direction': course_info.get('course_direction'),
                        'course_type': course_info.get('course_type')
                    })
                
                tracks.append(track)
        if tracks:
            return tracks
    
    # Логируем длинные сообщения, которые не сгенерировали треков
    try:
        if text and len(text) > 1000:
            print(f"DEBUG: LONG MESSAGE NO TRACKS - mid={mid}, length={len(text)}, preview: {text[:200]}...")
            # Проверим наличие ключевых слов
            lower_check = text.lower()
            keywords = {'бпла': lower_check.count('бпла'), 'шахед': lower_check.count('шахед'), 
                       'курс': lower_check.count('курс'), 'район': lower_check.count('район')}
            print(f"DEBUG: Long message keywords: {keywords}")
    except Exception:
        pass
    
    # Final check: if we found single UAV threats earlier but no other tracks, return the UAV threats
    if 'single_uav_threats' in locals() and single_uav_threats:
        add_debug_log(f"FINAL: Returning single UAV threats only: {len(single_uav_threats)}", "final_single_uav")
        return single_uav_threats
    
    return None

async def fetch_loop():
    log.info('fetch_loop() started')
    if not client:
        log.warning('Telegram client not configured; skipping fetch loop.')
        return
    log.info('fetch_loop: client exists, proceeding')
    async def ensure_connected():
        log.info('ensure_connected() called')
        if client.is_connected():
            log.info('Client already connected')
            auth_status = await client.is_user_authorized()
            log.info(f'Authorization status: {auth_status}')
            return auth_status
        try:
            log.info('Connecting client...')
            await client.connect()
            log.info('Client connected successfully')
            # If bot token provided and not authorized yet, try bot login
            if BOT_TOKEN and not await client.is_user_authorized():
                try:
                    log.info('Trying bot token login...')
                    await client.start(bot_token=BOT_TOKEN)
                except Exception as be:
                    log.error(f'Bot start failed: {be}')
            auth_status = await client.is_user_authorized()
            log.info(f'Final authorization status: {auth_status}')
            if not auth_status:
                log.error('Not authorized. Use /auth/start & /auth/complete to login or set TELEGRAM_SESSION.')
                return False
            return True
        except AuthKeyDuplicatedError:
            log.error('AuthKeyDuplicatedError: duplicate session. Provide new TELEGRAM_SESSION or re-auth.')
            return False
        except AuthKeyUnregisteredError:
            log.error('AuthKeyUnregisteredError: Session invalid/expired. Re-auth needed.')
            return False
        except FloodWaitError as fe:
            wait = int(getattr(fe, 'seconds', 60))
            log.warning(f'FloodWait: sleeping {wait}s before reconnect.')
            await asyncio.sleep(wait)
            return False
        except Exception as e:
            log.warning(f'ensure_connected error: {e}')
            return False

    if not await ensure_connected():
        AUTH_STATUS.update({'authorized': False, 'reason': 'not_authorized_initial'})
        await asyncio.sleep(180)
        return
    else:
        AUTH_STATUS.update({'authorized': True, 'reason': 'ok'})
    tz = pytz.timezone('Europe/Kyiv')
    processed = {m.get('id') for m in load_messages()}
    all_data = load_messages()
    # -------- Initial backfill (last BACKFILL_MINUTES, default 50) --------
    try:
        backfill_minutes = int(os.getenv('BACKFILL_MINUTES', '50'))
    except ValueError:
        backfill_minutes = 50
    backfill_cutoff = datetime.now(tz) - timedelta(minutes=backfill_minutes)
    if backfill_minutes > 0:
        log.info(f'Starting backfill for last {backfill_minutes} minutes...')
        total_backfilled = 0
        total_raw = 0
        for ch in CHANNELS:
            ch_strip = ch.strip()
            if not ch_strip:
                continue
            print(f"DEBUG: Processing backfill for channel: {ch_strip}")
            fetched = 0
            try:
                if not await ensure_connected():
                    log.warning('Disconnected during backfill; aborting backfill early.')
                    break
                async for msg in client.iter_messages(ch_strip, limit=400):  # cap to avoid huge history
                    if not msg.text:
                        continue
                    dt = msg.date.astimezone(tz)
                    if dt < backfill_cutoff:
                        break  # older than needed
                    if msg.id in processed:
                        continue
                    tracks = process_message(msg.text, msg.id, dt.strftime('%Y-%m-%d %H:%M:%S'), ch_strip)
                    if tracks:
                        print(f"DEBUG: Message {msg.id} generated {len(tracks)} tracks")
                        merged_any = False
                        merged_refs = []
                        for t in tracks:
                            if t.get('place'):
                                t['place'] = ensure_ua_place(t['place'])
                            merged, ref = maybe_merge_track(all_data, t)
                            if merged:
                                merged_any = True
                                merged_refs.append(ref)
                            else:
                                all_data.append(t)
                        processed.add(msg.id)
                        if merged_any:
                            log.info(f'Merged track(s) for {ch_strip} #{msg.id} into existing point(s).')
                        fetched += 1
                    else:
                        print(f"DEBUG: Message {msg.id} generated NO tracks (filtered or no matches)")
                        if ALWAYS_STORE_RAW:
                            all_data.append({
                                'id': str(msg.id),
                                'place': None,
                                'lat': None,
                                'lng': None,
                                'threat_type': None,
                                'text': msg.text[:500],
                                'date': dt.strftime('%Y-%m-%d %H:%M:%S'),
                                'channel': ch_strip,
                                'pending_geo': True
                            })
                            processed.add(msg.id)
                            total_raw += 1
                        print(f"DEBUG: Message {msg.id} - ALWAYS_STORE_RAW={ALWAYS_STORE_RAW}, stored as raw")
                        log.debug(f'Backfill skip (no geo): {ch_strip} #{msg.id} {msg.text[:80]!r}')
                if fetched:
                    total_backfilled += fetched
                    log.info(f'Backfilled {fetched} messages from {ch_strip}')
            except Exception as e:
                log.warning(f'Backfill error {ch_strip}: {e}')
    if backfill_minutes > 0:
        if total_backfilled or (ALWAYS_STORE_RAW and 'total_raw' in locals() and total_raw):
            save_messages(all_data)
            log.info(f'Backfill saved: {total_backfilled} geo, {locals().get("total_raw",0)} raw')
        log.info('Backfill completed.')
    while True:
        new_tracks = []
        for ch in CHANNELS:
            ch = ch.strip()
            if not ch:
                continue
            if ch in INVALID_CHANNELS:
                log.debug(f'Skip invalid channel {ch}')
                continue
            msgs_seen = 0
            msgs_recent_window = 0
            geo_added = 0
            try:
                if not await ensure_connected():
                    # If session invalid we stop loop gracefully
                    if not client.is_connected():
                        log.error('Stopping live loop due to lost/invalid session.')
                        AUTH_STATUS.update({'authorized': False, 'reason': 'lost_session'})
                        return
                log.debug(f'Polling channel {ch} (last processed count={len(processed)})')
                async for msg in client.iter_messages(ch, limit=20):
                    msgs_seen += 1
                    if not msg.text:
                        continue
                    if msg.id in processed:
                        continue
                    dt = msg.date.astimezone(tz)
                    if dt < datetime.now(tz) - timedelta(minutes=30):
                        # Older than live window
                        continue
                    msgs_recent_window += 1
                    tracks = process_message(msg.text, msg.id, dt.strftime('%Y-%m-%d %H:%M:%S'), ch)
                    if tracks:
                        merged_any = False
                        appended = []
                        for t in tracks:
                            if t.get('place'):
                                t['place'] = ensure_ua_place(t['place'])
                            merged, ref = maybe_merge_track(all_data, t)
                            if merged:
                                merged_any = True
                            else:
                                new_tracks.append(t)
                                appended.append(t)
                        geo_added += 1
                        processed.add(msg.id)
                        if merged_any and not appended:
                            log.info(f'Merged live track(s) {ch} #{msg.id} (no new marker).')
                        else:
                            log.info(f'Added track from {ch} #{msg.id} (+{len(appended)} new, merged={merged_any})')
                    else:
                        # Store raw if enabled to allow later reprocessing / debugging (e.g., napramok multi-line posts)
                        if ALWAYS_STORE_RAW:
                            all_data.append({
                                'id': str(msg.id), 'place': None, 'lat': None, 'lng': None,
                                'threat_type': None, 'text': msg.text[:800], 'date': dt.strftime('%Y-%m-%d %H:%M:%S'),
                                'channel': ch, 'pending_geo': True
                            })
                            processed.add(msg.id)
                        log.debug(f'Live skip (no geo): {ch} #{msg.id} {msg.text[:80]!r}')
            except AuthKeyDuplicatedError:
                log.error('AuthKeyDuplicatedError during live fetch. Ending loop until session replaced.')
                AUTH_STATUS.update({'authorized': False, 'reason': 'authkey_duplicated'})
                return
            except FloodWaitError as fe:
                wait = int(getattr(fe, 'seconds', 60))
                log.warning(f'FloodWait while reading {ch}: sleep {wait}s')
                await asyncio.sleep(wait)
            # Generic RPC errors will be caught by broad Exception if specific class not available
            except Exception as e:
                msg = str(e)
                log.warning(f'Error reading {ch}: {msg}')
                # Auto-mark invalid entity errors to skip future attempts this runtime
                markers = ['Cannot find any entity', 'CHANNEL_PRIVATE', 'USERNAME_NOT_OCCUPIED', 'TOPIC_DELETED']
                if any(mk in msg for mk in markers):
                    INVALID_CHANNELS.add(ch)
                    log.warning(f'Marking channel {ch} as invalid; will skip further reads this session.')
            finally:
                # Post-channel diagnostics to help debug silent channels like 'napramok'
                log.debug(
                    f'Channel diag {ch}: iter_messages_seen={msgs_seen}, recent_window={msgs_recent_window}, geo_added={geo_added}, invalid={ch in INVALID_CHANNELS}'
                )
                if msgs_seen == 0:
                    log.warning(f'Channel {ch} returned no messages this cycle (possible resolution/access issue).')
                elif msgs_recent_window == 0:
                    log.debug(f'Channel {ch} had messages but none within last 30m window.')
                elif geo_added == 0:
                    log.debug(f'Channel {ch} had {msgs_recent_window} recent messages but none produced geo tracks.')
        if new_tracks:
            # Append truly new tracks (merges already applied in-place)
            all_data.extend(new_tracks)
            save_messages(all_data)
            try:
                broadcast_new(new_tracks)
            except Exception as e:
                log.debug(f'SSE broadcast failed: {e}')
        else:
            # If only merges happened (no brand-new tracks), still persist periodically
            save_messages(all_data)
        await asyncio.sleep(60)

def start_fetch_thread():
    global FETCH_THREAD_STARTED
    log.info('start_fetch_thread() called')
    if not client:
        log.warning('start_fetch_thread: client is None')
        return
    if FETCH_THREAD_STARTED:
        log.info('start_fetch_thread: already started')
        return
    log.info('start_fetch_thread: starting new thread')
    FETCH_THREAD_STARTED = True
    loop = asyncio.new_event_loop()
    def runner():
        log.info('fetch_thread runner started')
        if FETCH_START_DELAY > 0:
            log.info(f'Delaying Telegram fetch start for {FETCH_START_DELAY}s (FETCH_START_DELAY).')
            time.sleep(FETCH_START_DELAY)
        asyncio.set_event_loop(loop)
        try:
            log.info('About to call fetch_loop()')
            loop.run_until_complete(fetch_loop())
        except AuthKeyDuplicatedError:
            AUTH_STATUS.update({'authorized': False, 'reason': 'authkey_duplicated_runner'})
            log.error('Fetch loop stopped: duplicated auth key.')
        except Exception as e:
            AUTH_STATUS.update({'authorized': False, 'reason': f'crash:{e.__class__.__name__}'})
            log.error(f'Fetch loop crashed: {e}')
        finally:
            FETCH_THREAD_STARTED = False
            log.info('fetch_thread runner finished')
    threading.Thread(target=runner, daemon=True).start()
    log.info('start_fetch_thread: thread started successfully')

def replace_client(new_session: str):
    global client, session_str
    session_str = new_session
    try:
        if client:
            try:
                # Telethon has disconnect
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                loop.run_until_complete(client.disconnect())
            except Exception:
                pass
    finally:
        client = TelegramClient(StringSession(new_session), API_ID, API_HASH)
        AUTH_STATUS.update({'authorized': True, 'reason': 'replaced_session'})
        start_fetch_thread()

# ----------------- Session watcher (auto reload new_session.txt) -----------------
SESSION_WATCH_FILE = os.getenv('SESSION_WATCH_FILE', 'new_session.txt')
SESSION_WATCH_INTERVAL = int(os.getenv('SESSION_WATCH_INTERVAL', '20'))
_watch_thread_started = False
_last_session_file_mtime = 0

def start_session_watcher():
    global _watch_thread_started, _last_session_file_mtime
    if _watch_thread_started:
        return
    _watch_thread_started = True
    def _watch():
        global _last_session_file_mtime, session_str
        while True:
            try:
                if os.path.exists(SESSION_WATCH_FILE):
                    mt = os.path.getmtime(SESSION_WATCH_FILE)
                    if mt != _last_session_file_mtime:
                        _last_session_file_mtime = mt
                        with open(SESSION_WATCH_FILE,'r',encoding='utf-8') as f:
                            new_s = f.read().strip()
                        if new_s and new_s != session_str:
                            log.info('Session watcher: detected updated session file, reloading...')
                            replace_client(new_s)
                # If we are unauthorized due to duplicate key, keep looking for replacement
                if AUTH_STATUS.get('reason','').startswith('authkey_duplicated') and not client.is_connected():
                    # just a hint in logs every few cycles
                    if int(time.time()) % (SESSION_WATCH_INTERVAL*3) == 0:
                        log.info('Waiting for new session (AuthKeyDuplicatedError). Generate via /auth endpoints.')
            except Exception as e:
                log.debug(f'Session watcher error: {e}')
            time.sleep(SESSION_WATCH_INTERVAL)
    threading.Thread(target=_watch, daemon=True).start()

@app.route('/google2848d36b38653ede.html')
def google_verification():
    """Google Search Console verification file"""
    return send_from_directory('static', 'google2848d36b38653ede.html')

@app.route('/')
def index():
    # BANDWIDTH OPTIMIZATION: Add caching headers for main page
    response = render_template('index.html')
    resp = app.response_class(response)
    resp.headers['Cache-Control'] = 'public, max-age=300'  # 5 minutes cache
    resp.headers['ETag'] = f'index-{int(time.time() // 300)}'
    return resp

@app.route('/map-only')
def map_only():
    """Map-only view for embedding in mobile apps (iOS/Android WebView)"""
    response = render_template('map_only.html')
    resp = app.response_class(response)
    resp.headers['Cache-Control'] = 'public, max-age=300'  # 5 minutes cache
    resp.headers['X-Frame-Options'] = 'ALLOWALL'  # Allow embedding in iframes/WebView
    resp.headers['Access-Control-Allow-Origin'] = '*'  # Allow cross-origin requests
    return resp

@app.route('/map-embed')
def map_embed():
    """Map with world mask (dimming) for mobile apps embedding"""
    response = render_template('map_embed.html')
    resp = app.response_class(response)
    resp.headers['Cache-Control'] = 'public, max-age=300'  # 5 minutes cache
    resp.headers['X-Frame-Options'] = 'ALLOWALL'  # Allow embedding in iframes/WebView
    resp.headers['Access-Control-Allow-Origin'] = '*'  # Allow cross-origin requests
    return resp

@app.route('/about')
def about():
    """About NEPTUN project page"""
    response = render_template('about.html')
    resp = app.response_class(response)
    resp.headers['Cache-Control'] = 'public, max-age=3600'  # 1 hour cache
    return resp

@app.route('/analytics')
def analytics():
    """Analytics and statistics page with original content analysis"""
    response = render_template('analytics.html')
    resp = app.response_class(response)
    resp.headers['Cache-Control'] = 'public, max-age=300'  # 5 minutes cache
    return resp

@app.route('/community')
@app.route('/telegram')
@app.route('/join')
def redirect_telegram():
    """Redirect to Telegram community"""
    page_name = request.path.lstrip('/')
    user_ip = request.headers.get('X-Forwarded-For', request.remote_addr)
    user_agent = request.headers.get('User-Agent', '')
    track_redirect_visit(page_name, user_ip, user_agent)
    return render_template('redirect.html')

@app.route('/channel')
@app.route('/group')
@app.route('/chat')
def redirect_telegram2():
    """Redirect to Telegram channel"""
    page_name = request.path.lstrip('/')
    user_ip = request.headers.get('X-Forwarded-For', request.remote_addr)
    user_agent = request.headers.get('User-Agent', '')
    track_redirect_visit(page_name, user_ip, user_agent)
    return render_template('redirect2.html')

@app.route('/news')
@app.route('/updates')
@app.route('/alerts')
def redirect_telegram3():
    """Redirect to Telegram alerts channel"""
    page_name = request.path.lstrip('/')
    user_ip = request.headers.get('X-Forwarded-For', request.remote_addr)
    user_agent = request.headers.get('User-Agent', '')
    track_redirect_visit(page_name, user_ip, user_agent)
    return render_template('redirect3.html')

@app.route('/track_redirect_click', methods=['POST'])
def track_redirect_click():
    """Track button click on redirect page"""
    try:
        data = request.get_json() or {}
        page_name = data.get('page', 'unknown')
        user_ip = request.headers.get('X-Forwarded-For', request.remote_addr)
        user_agent = request.headers.get('User-Agent', '')
        
        # Track as click (we'll add a suffix to differentiate)
        track_redirect_visit(f"{page_name}_click", user_ip, user_agent)
        
        return jsonify({'status': 'ok'})
    except Exception as e:
        log.warning(f"Failed to track redirect click: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/faq')
def faq():
    """Frequently Asked Questions page"""
    response = render_template('faq.html')
    resp = app.response_class(response)
    resp.headers['Cache-Control'] = 'public, max-age=3600'  # 1 hour cache
    return resp

@app.route('/privacy')
def privacy():
    """Privacy Policy page"""
    response = render_template('privacy.html')
    resp = app.response_class(response)
    resp.headers['Cache-Control'] = 'public, max-age=86400'  # 24 hours cache
    return resp

@app.route('/terms')
def terms():
    """Terms of Service page"""
    response = render_template('terms.html')
    resp = app.response_class(response)
    resp.headers['Cache-Control'] = 'public, max-age=86400'  # 24 hours cache
    return resp

@app.route('/contact')
def contact():
    """Contact page"""
    response = render_template('contact.html')
    resp = app.response_class(response)
    resp.headers['Cache-Control'] = 'public, max-age=86400'  # 24 hours cache
    return resp

# Address database for blackout schedules with subgroups
# Format: group can be "1.1", "1.2", "2.1", "2.2", "3.1", "3.2" etc.
# TODO: Replace with real database and API integration
BLACKOUT_ADDRESSES = {
    # Kyiv - all subgroups across different districts
    'київ хрещатик': {'group': '1.1', 'city': 'Київ', 'oblast': 'Київська', 'provider': 'ДТЕК Київські електромережі'},
    'київ вулиця хрещатик': {'group': '1.1', 'city': 'Київ', 'oblast': 'Київська', 'provider': 'ДТЕК Київські електромережі'},
    'київ майдан': {'group': '1.2', 'city': 'Київ', 'oblast': 'Київська', 'provider': 'ДТЕК Київські електромережі'},
    'київ печерськ': {'group': '2.1', 'city': 'Київ', 'oblast': 'Київська', 'provider': 'ДТЕК Київські електромережі'},
    'київ поділ': {'group': '2.2', 'city': 'Київ', 'oblast': 'Київська', 'provider': 'ДТЕК Київські електромережі'},
    'київ шевченківський': {'group': '3.1', 'city': 'Київ', 'oblast': 'Київська', 'provider': 'ДТЕК Київські електромережі'},
    'київ оболонь': {'group': '3.2', 'city': 'Київ', 'oblast': 'Київська', 'provider': 'ДТЕК Київські електромережі'},
    'київ троєщина': {'group': '1.1', 'city': 'Київ', 'oblast': 'Київська', 'provider': 'ДТЕК Київські електромережі'},
    'київ позняки': {'group': '2.1', 'city': 'Київ', 'oblast': 'Київська', 'provider': 'ДТЕК Київські електромережі'},
    'київ дарниця': {'group': '3.1', 'city': 'Київ', 'oblast': 'Київська', 'provider': 'ДТЕК Київські електромережі'},
    'київ лівобережна': {'group': '2.2', 'city': 'Київ', 'oblast': 'Київська', 'provider': 'ДТЕК Київські електромережі'},
    'київ академмістечко': {'group': '3.2', 'city': 'Київ', 'oblast': 'Київська', 'provider': 'ДТЕК Київські електромережі'},
    'київ теремки': {'group': '1.2', 'city': 'Київ', 'oblast': 'Київська', 'provider': 'ДТЕК Київські електромережі'},
    'київ вишневе': {'group': '2.1', 'city': 'Київ', 'oblast': 'Київська', 'provider': 'ДТЕК Київські електромережі'},
    'київ бориспіль': {'group': '1.1', 'city': 'Бориспіль', 'oblast': 'Київська', 'provider': 'ДТЕК Київські електромережі'},
    
    # Odesa - all subgroups
    'одеса дерибасівська': {'group': '1.1', 'city': 'Одеса', 'oblast': 'Одеська', 'provider': 'ДТЕК Одеські електромережі'},
    'одеса приморський': {'group': '1.2', 'city': 'Одеса', 'oblast': 'Одеська', 'provider': 'ДТЕК Одеські електромережі'},
    'одеса центр': {'group': '2.1', 'city': 'Одеса', 'oblast': 'Одеська', 'provider': 'ДТЕК Одеські електромережі'},
    'одеса аркадія': {'group': '2.2', 'city': 'Одеса', 'oblast': 'Одеська', 'provider': 'ДТЕК Одеські електромережі'},
    'одеса таїрова': {'group': '3.1', 'city': 'Одеса', 'oblast': 'Одеська', 'provider': 'ДТЕК Одеські електромережі'},
    'одеса котовського': {'group': '3.2', 'city': 'Одеса', 'oblast': 'Одеська', 'provider': 'ДТЕК Одеські електромережі'},
    'одеса молдаванка': {'group': '1.1', 'city': 'Одеса', 'oblast': 'Одеська', 'provider': 'ДТЕК Одеські електромережі'},
    'одеса пересипь': {'group': '2.1', 'city': 'Одеса', 'oblast': 'Одеська', 'provider': 'ДТЕК Одеські електромережі'},
    'одеса суворовський': {'group': '3.1', 'city': 'Одеса', 'oblast': 'Одеська', 'provider': 'ДТЕК Одеські електромережі'},
    'одеса чорноморка': {'group': '1.2', 'city': 'Одеса', 'oblast': 'Одеська', 'provider': 'ДТЕК Одеські електромережі'},
    
    # Kharkiv - all subgroups
    'харків сумська': {'group': '1.1', 'city': 'Харків', 'oblast': 'Харківська', 'provider': 'ДТЕК Східенерго'},
    'харків центр': {'group': '1.2', 'city': 'Харків', 'oblast': 'Харківська', 'provider': 'ДТЕК Східенерго'},
    'харків салтівка': {'group': '2.1', 'city': 'Харків', 'oblast': 'Харківська', 'provider': 'ДТЕК Східенерго'},
    'харків нагірний': {'group': '2.2', 'city': 'Харків', 'oblast': 'Харківська', 'provider': 'ДТЕК Східенерго'},
    'харків холодна гора': {'group': '3.1', 'city': 'Харків', 'oblast': 'Харківська', 'provider': 'ДТЕК Східенерго'},
    'харків павлове поле': {'group': '3.2', 'city': 'Харків', 'oblast': 'Харківська', 'provider': 'ДТЕК Східенерго'},
    'харків московський': {'group': '1.1', 'city': 'Харків', 'oblast': 'Харківська', 'provider': 'ДТЕК Східенерго'},
    'харків індустріальний': {'group': '2.1', 'city': 'Харків', 'oblast': 'Харківська', 'provider': 'ДТЕК Східенерго'},
    'харків київський': {'group': '1.2', 'city': 'Харків', 'oblast': 'Харківська', 'provider': 'ДТЕК Східенерго'},
    
    # Dnipro - all subgroups
    'дніпро центр': {'group': '1.1', 'city': 'Дніпро', 'oblast': 'Дніпропетровська', 'provider': 'ДТЕК Дніпровські електромережі'},
    'дніпро гагаріна': {'group': '1.2', 'city': 'Дніпро', 'oblast': 'Дніпропетровська', 'provider': 'ДТЕК Дніпровські електромережі'},
    'дніпро нагірний': {'group': '2.1', 'city': 'Дніпро', 'oblast': 'Дніпропетровська', 'provider': 'ДТЕК Дніпровські електромережі'},
    'дніпро проспект': {'group': '2.2', 'city': 'Дніпро', 'oblast': 'Дніпропетровська', 'provider': 'ДТЕК Дніпровські електромережі'},
    'дніпро придніпровськ': {'group': '3.1', 'city': 'Дніпро', 'oblast': 'Дніпропетровська', 'provider': 'ДТЕК Дніпровські електромережі'},
    'дніпро новокодацький': {'group': '3.2', 'city': 'Дніпро', 'oblast': 'Дніпропетровська', 'provider': 'ДТЕК Дніпровські електромережі'},
    'дніпро соборний': {'group': '1.1', 'city': 'Дніпро', 'oblast': 'Дніпропетровська', 'provider': 'ДТЕК Дніпровські електромережі'},
    'дніпро амур': {'group': '2.1', 'city': 'Дніпро', 'oblast': 'Дніпропетровська', 'provider': 'ДТЕК Дніпровські електромережі'},
    
    # Lviv - all subgroups
    'львів центр': {'group': '1.1', 'city': 'Львів', 'oblast': 'Львівська', 'provider': 'Львівобленерго'},
    'львів площа ринок': {'group': '1.2', 'city': 'Львів', 'oblast': 'Львівська', 'provider': 'Львівобленерго'},
    'львів франка': {'group': '2.1', 'city': 'Львів', 'oblast': 'Львівська', 'provider': 'Львівобленерго'},
    'львів сихів': {'group': '2.2', 'city': 'Львів', 'oblast': 'Львівська', 'provider': 'Львівобленерго'},
    'львів личаківська': {'group': '3.1', 'city': 'Львів', 'oblast': 'Львівська', 'provider': 'Львівобленерго'},
    'львів сихівська': {'group': '3.2', 'city': 'Львів', 'oblast': 'Львівська', 'provider': 'Львівобленерго'},
    'львів залізничний': {'group': '1.1', 'city': 'Львів', 'oblast': 'Львівська', 'provider': 'Львівобленерго'},
    'львів шевченківський': {'group': '2.1', 'city': 'Львів', 'oblast': 'Львівська', 'provider': 'Львівобленерго'},
    
    # Zaporizhzhia - all subgroups
    'запоріжжя центр': {'group': '1.1', 'city': 'Запоріжжя', 'oblast': 'Запорізька', 'provider': 'ДТЕК Запорізькі електромережі'},
    'запоріжжя проспект': {'group': '1.2', 'city': 'Запоріжжя', 'oblast': 'Запорізька', 'provider': 'ДТЕК Запорізькі електромережі'},
    'запоріжжя хортицький': {'group': '2.1', 'city': 'Запоріжжя', 'oblast': 'Запорізька', 'provider': 'ДТЕК Запорізькі електромережі'},
    'запоріжжя шевченківський': {'group': '2.2', 'city': 'Запоріжжя', 'oblast': 'Запорізька', 'provider': 'ДТЕК Запорізькі електромережі'},
    'запоріжжя заводський': {'group': '3.1', 'city': 'Запоріжжя', 'oblast': 'Запорізька', 'provider': 'ДТЕК Запорізькі електромережі'},
    'запоріжжя дніпровський': {'group': '3.2', 'city': 'Запоріжжя', 'oblast': 'Запорізька', 'provider': 'ДТЕК Запорізькі електромережі'},
    
    # Vinnytsia - all subgroups
    'вінниця центр': {'group': '1.1', 'city': 'Вінниця', 'oblast': 'Вінницька', 'provider': 'Вінницяобленерго'},
    'вінниця соборна': {'group': '1.2', 'city': 'Вінниця', 'oblast': 'Вінницька', 'provider': 'Вінницяобленерго'},
    'вінниця хмельницьке': {'group': '2.1', 'city': 'Вінниця', 'oblast': 'Вінницька', 'provider': 'Вінницяобленерго'},
    'вінниця вишенька': {'group': '2.2', 'city': 'Вінниця', 'oblast': 'Вінницька', 'provider': 'Вінницяобленерго'},
    'вінниця замостя': {'group': '3.1', 'city': 'Вінниця', 'oblast': 'Вінницька', 'provider': 'Вінницяобленерго'},
    
    # Poltava - all subgroups
    'полтава центр': {'group': '1.1', 'city': 'Полтава', 'oblast': 'Полтавська', 'provider': 'Полтаваобленерго'},
    'полтава соборності': {'group': '1.2', 'city': 'Полтава', 'oblast': 'Полтавська', 'provider': 'Полтаваобленерго'},
    'полтава київський': {'group': '2.1', 'city': 'Полтава', 'oblast': 'Полтавська', 'provider': 'Полтаваобленерго'},
    'полтава подільський': {'group': '2.2', 'city': 'Полтава', 'oblast': 'Полтавська', 'provider': 'Полтаваобленерго'},
    
    # Chernihiv - all subgroups
    'чернігів центр': {'group': '1.1', 'city': 'Чернігів', 'oblast': 'Чернігівська', 'provider': 'Чернігівобленерго'},
    'чернігів мира': {'group': '1.2', 'city': 'Чернігів', 'oblast': 'Чернігівська', 'provider': 'Чернігівобленерго'},
    'чернігів деснянський': {'group': '2.1', 'city': 'Чернігів', 'oblast': 'Чернігівська', 'provider': 'Чернігівобленерго'},
    
    # Zhytomyr - all subgroups
    'житомир центр': {'group': '1.1', 'city': 'Житомир', 'oblast': 'Житомирська', 'provider': 'Житомиробленерго'},
    'житомир київська': {'group': '1.2', 'city': 'Житомир', 'oblast': 'Житомирська', 'provider': 'Житомиробленерго'},
    'житомир богунія': {'group': '2.1', 'city': 'Житомир', 'oblast': 'Житомирська', 'provider': 'Житомиробленерго'},
    'житомир корольовський': {'group': '2.2', 'city': 'Житомир', 'oblast': 'Житомирська', 'provider': 'Житомиробленерго'},
    
    # Cherkasy - all subgroups
    'черкаси центр': {'group': '1.1', 'city': 'Черкаси', 'oblast': 'Черкаська', 'provider': 'Черкасиобленерго'},
    'черкаси соборна': {'group': '1.2', 'city': 'Черкаси', 'oblast': 'Черкаська', 'provider': 'Черкасиобленерgo'},
    'черкаси придніпровський': {'group': '2.1', 'city': 'Черкаси', 'oblast': 'Черкаська', 'provider': 'Черкасиобленерго'},
    
    # Sumy - all subgroups
    'суми центр': {'group': '1.1', 'city': 'Суми', 'oblast': 'Сумська', 'provider': 'Сумиобленерго'},
    'суми соборна': {'group': '1.2', 'city': 'Суми', 'oblast': 'Сумська', 'provider': 'Сумиобленерго'},
    'суми ковпаківський': {'group': '2.1', 'city': 'Суми', 'oblast': 'Сумська', 'provider': 'Сумиобленерго'},
    
    # Khmelnytskyi - all subgroups
    'хмельницький центр': {'group': '1.1', 'city': 'Хмельницький', 'oblast': 'Хмельницька', 'provider': 'Хмельницькобленерго'},
    'хмельницький проспект': {'group': '1.2', 'city': 'Хмельницький', 'oblast': 'Хмельницька', 'provider': 'Хмельницькобленерго'},
    'хмельницький загоцька': {'group': '2.1', 'city': 'Хмельницький', 'oblast': 'Хмельницька', 'provider': 'Хмельницькобленерго'},
    
    # Rivne - all subgroups
    'рівне центр': {'group': '1.1', 'city': 'Рівне', 'oblast': 'Рівненська', 'provider': 'Рівненобленерго'},
    'рівне соборна': {'group': '1.2', 'city': 'Рівне', 'oblast': 'Рівненська', 'provider': 'Рівненобленерго'},
    'рівне північний': {'group': '2.1', 'city': 'Рівне', 'oblast': 'Рівненська', 'provider': 'Рівненобленерго'},
    
    # Ivano-Frankivsk - all subgroups
    'івано-франківськ центр': {'group': '1.1', 'city': 'Івано-Франківськ', 'oblast': 'Івано-Франківська', 'provider': 'Прикарпаттяобленерго'},
    'івано-франківськ незалежності': {'group': '1.2', 'city': 'Івано-Франківськ', 'oblast': 'Івано-Франківська', 'provider': 'Прикарпаттяобленерго'},
    'івано-франківськ пасічна': {'group': '2.1', 'city': 'Івано-Франківськ', 'oblast': 'Івано-Франківська', 'provider': 'Прикарпаттяобленерго'},
    
    # Ternopil - all subgroups
    'тернопіль центр': {'group': '1.1', 'city': 'Тернопіль', 'oblast': 'Тернопільська', 'provider': 'Тернопільобленерго'},
    'тернопіль руська': {'group': '1.2', 'city': 'Тернопіль', 'oblast': 'Тернопільська', 'provider': 'Тернопільобленерго'},
    'тернопіль східний': {'group': '2.1', 'city': 'Тернопіль', 'oblast': 'Тернопільська', 'provider': 'Тернопільобленерго'},
    
    # Lutsk - all subgroups
    'луцьк центр': {'group': '1.1', 'city': 'Луцьк', 'oblast': 'Волинська', 'provider': 'Волиньобленерго'},
    'луцьк волі': {'group': '1.2', 'city': 'Луцьк', 'oblast': 'Волинська', 'provider': 'Волиньобленерго'},
    'луцьк вокзальна': {'group': '2.1', 'city': 'Луцьк', 'oblast': 'Волинська', 'provider': 'Волиньобленерго'},
    
    # Chernivtsi - all subgroups
    'чернівці центр': {'group': '1.1', 'city': 'Чернівці', 'oblast': 'Чернівецька', 'provider': 'Чернівціобленерго'},
    'чернівці головна': {'group': '1.2', 'city': 'Чернівці', 'oblast': 'Чернівецька', 'provider': 'Чернівціобленерго'},
    'чернівці садгора': {'group': '2.1', 'city': 'Чернівці', 'oblast': 'Чернівецька', 'provider': 'Чернівціобленерго'},
    
    # Uzhhorod - all subgroups
    'ужгород центр': {'group': '1.1', 'city': 'Ужгород', 'oblast': 'Закарпатська', 'provider': 'Закарпаттяобленерго'},
    'ужгород корзо': {'group': '1.2', 'city': 'Ужгород', 'oblast': 'Закарпатська', 'provider': 'Закарпаттяобленерго'},
    'ужгород боздош': {'group': '2.1', 'city': 'Ужгород', 'oblast': 'Закарпатська', 'provider': 'Закарпаттяобленерго'},
    
    # Kropyvnytskyi (Kirovohrad) - all subgroups
    'кропивницький центр': {'group': '1.1', 'city': 'Кропивницький', 'oblast': 'Кіровоградська', 'provider': 'Кіровоградобленерго'},
    'кропивницький велика перспективна': {'group': '1.2', 'city': 'Кропивницький', 'oblast': 'Кіровоградська', 'provider': 'Кіровоградобленерго'},
    'кропивницький фортечний': {'group': '2.1', 'city': 'Кропивницький', 'oblast': 'Кіровоградська', 'provider': 'Кіровоградобленерго'},
    
    # Mykolaiv - all subgroups
    'миколаїв центр': {'group': '1.1', 'city': 'Миколаїв', 'oblast': 'Миколаївська', 'provider': 'Миколаївобленерго'},
    'миколаїв соборна': {'group': '1.2', 'city': 'Миколаїв', 'oblast': 'Миколаївська', 'provider': 'Миколаївобленерго'},
    'миколаїв інгульський': {'group': '2.1', 'city': 'Миколаїв', 'oblast': 'Миколаївська', 'provider': 'Миколаївобленерго'},
    'миколаїв корабельний': {'group': '2.2', 'city': 'Миколаїв', 'oblast': 'Миколаївська', 'provider': 'Миколаївобленерго'},
    
    # Kherson - all subgroups
    'херсон центр': {'group': '1.1', 'city': 'Херсон', 'oblast': 'Херсонська', 'provider': 'Херсонобленерго'},
    'херсон ушакова': {'group': '1.2', 'city': 'Херсон', 'oblast': 'Херсонська', 'provider': 'Херсонобленерго'},
    'херсон дніпровський': {'group': '2.1', 'city': 'Херсон', 'oblast': 'Херсонська', 'provider': 'Херсонобленерго'},
    
    # Mariupol (DTEK Donetsk region)
    'маріуполь центр': {'group': '1.1', 'city': 'Маріуполь', 'oblast': 'Донецька', 'provider': 'ДТЕК Донецькі електромережі'},
    'маріуполь лівобережний': {'group': '2.1', 'city': 'Маріуполь', 'oblast': 'Донецька', 'provider': 'ДТЕК Донецькі електромережі'},
    
    # Kremenchuk - all subgroups
    'кременчук центр': {'group': '1.1', 'city': 'Кременчук', 'oblast': 'Полтавська', 'provider': 'Полтаваобленерго'},
    'кременчук київська': {'group': '1.2', 'city': 'Кременчук', 'oblast': 'Полтавська', 'provider': 'Полтаваобленерго'},
    'кременчук автозаводський': {'group': '2.1', 'city': 'Кременчук', 'oblast': 'Полтавська', 'provider': 'Полтаваобленерго'},
}

# Merge with extended database if available
if UKRAINE_ADDRESSES_DB:
    BLACKOUT_ADDRESSES.update(UKRAINE_ADDRESSES_DB)
    print(f"INFO: Merged addresses database, total: {len(BLACKOUT_ADDRESSES)} addresses")

# Blackout schedules by group and subgroup
# Format: group "1.1", "1.2", "2.1", "2.2", "3.1", "3.2"
# Each subgroup has different timing within main group
# TODO: Fetch from real APIs (DTEK, Ukrenergo)
BLACKOUT_SCHEDULES = {
    # Group 1 subgroups
    '1.1': [
        {'time': '00:00 - 04:00', 'label': 'Електропостачання', 'status': 'normal'},
        {'time': '04:00 - 08:00', 'label': 'Можливе відключення', 'status': 'normal'},
        {'time': '08:00 - 12:00', 'label': 'Електропостачання', 'status': 'normal'},
        {'time': '12:00 - 16:00', 'label': 'Активне відключення', 'status': 'active'},
        {'time': '16:00 - 20:00', 'label': 'Електропостачання', 'status': 'normal'},
        {'time': '20:00 - 24:00', 'label': 'Можливе відключення', 'status': 'upcoming'},
    ],
    '1.2': [
        {'time': '00:00 - 04:00', 'label': 'Можливе відключення', 'status': 'upcoming'},
        {'time': '04:00 - 08:00', 'label': 'Електропостачання', 'status': 'normal'},
        {'time': '08:00 - 12:00', 'label': 'Можливе відключення', 'status': 'normal'},
        {'time': '12:00 - 16:00', 'label': 'Електропостачання', 'status': 'normal'},
        {'time': '16:00 - 20:00', 'label': 'Активне відключення', 'status': 'active'},
        {'time': '20:00 - 24:00', 'label': 'Електропостачання', 'status': 'normal'},
    ],
    
    # Group 2 subgroups
    '2.1': [
        {'time': '00:00 - 04:00', 'label': 'Електропостачання', 'status': 'normal'},
        {'time': '04:00 - 08:00', 'label': 'Можливе відключення', 'status': 'normal'},
        {'time': '08:00 - 12:00', 'label': 'Електропостачання', 'status': 'normal'},
        {'time': '12:00 - 16:00', 'label': 'Можливе відключення', 'status': 'normal'},
        {'time': '16:00 - 20:00', 'label': 'Активне відключення', 'status': 'active'},
        {'time': '20:00 - 24:00', 'label': 'Електропостачання', 'status': 'normal'},
    ],
    '2.2': [
        {'time': '00:00 - 04:00', 'label': 'Можливе відключення', 'status': 'normal'},
        {'time': '04:00 - 08:00', 'label': 'Електропостачання', 'status': 'normal'},
        {'time': '08:00 - 12:00', 'label': 'Активне відключення', 'status': 'active'},
        {'time': '12:00 - 16:00', 'label': 'Електропостачання', 'status': 'normal'},
        {'time': '16:00 - 20:00', 'label': 'Можливе відключення', 'status': 'upcoming'},
        {'time': '20:00 - 24:00', 'label': 'Електропостачання', 'status': 'normal'},
    ],
    
    # Group 3 subgroups
    '3.1': [
        {'time': '00:00 - 04:00', 'label': 'Можливе відключення', 'status': 'upcoming'},
        {'time': '04:00 - 08:00', 'label': 'Електропостачання', 'status': 'normal'},
        {'time': '08:00 - 12:00', 'label': 'Можливе відключення', 'status': 'normal'},
        {'time': '12:00 - 16:00', 'label': 'Електропостачання', 'status': 'normal'},
        {'time': '16:00 - 20:00', 'label': 'Активне відключення', 'status': 'active'},
        {'time': '20:00 - 24:00', 'label': 'Електропостачання', 'status': 'normal'},
    ],
    '3.2': [
        {'time': '00:00 - 04:00', 'label': 'Електропостачання', 'status': 'normal'},
        {'time': '04:00 - 08:00', 'label': 'Можливе відключення', 'status': 'normal'},
        {'time': '08:00 - 12:00', 'label': 'Електропостачання', 'status': 'normal'},
        {'time': '12:00 - 16:00', 'label': 'Можливе відключення', 'status': 'upcoming'},
        {'time': '16:00 - 20:00', 'label': 'Електропостачання', 'status': 'normal'},
        {'time': '20:00 - 24:00', 'label': 'Активне відключення', 'status': 'active'},
    ],
    
    # Fallback for old integer groups (backward compatibility)
    1: [
        {'time': '06:00 - 10:00', 'label': 'Можливе відключення', 'status': 'normal'},
        {'time': '10:00 - 14:00', 'label': 'Електропостачання', 'status': 'normal'},
        {'time': '14:00 - 18:00', 'label': 'Активне відключення', 'status': 'active'},
        {'time': '18:00 - 22:00', 'label': 'Електропостачання', 'status': 'normal'},
        {'time': '22:00 - 02:00', 'label': 'Можливе відключення', 'status': 'upcoming'},
    ],
    2: [
        {'time': '08:00 - 12:00', 'label': 'Електропостачання', 'status': 'normal'},
        {'time': '12:00 - 16:00', 'label': 'Можливе відключення', 'status': 'upcoming'},
        {'time': '16:00 - 20:00', 'label': 'Активне відключення', 'status': 'active'},
        {'time': '20:00 - 00:00', 'label': 'Електропостачання', 'status': 'normal'},
        {'time': '00:00 - 04:00', 'label': 'Можливе відключення', 'status': 'normal'},
    ],
    3: [
        {'time': '04:00 - 08:00', 'label': 'Можливе відключення', 'status': 'normal'},
        {'time': '08:00 - 12:00', 'label': 'Активне відключення', 'status': 'active'},
        {'time': '12:00 - 16:00', 'label': 'Електропостачання', 'status': 'normal'},
        {'time': '16:00 - 20:00', 'label': 'Можливе відключення', 'status': 'upcoming'},
        {'time': '20:00 - 00:00', 'label': 'Електропостачання', 'status': 'normal'},
    ],
}

@app.route('/api/search_cities')
def search_cities():
    """Get all cities and addresses for autocomplete"""
    try:
        # Collect unique cities
        cities_set = set()
        addresses_list = []
        
        for address_key, data in BLACKOUT_ADDRESSES.items():
            city = data.get('city', '')
            if city:
                cities_set.add(city)
            
            # Parse address_key to extract street and building
            # Format: "city street" or "city street building"
            parts = address_key.split()
            if len(parts) >= 2:
                street = ' '.join(parts[1:])
                addresses_list.append({
                    'city': city,
                    'street': street,
                    'building': '',  # Can be extracted if needed
                    'group': data.get('group', ''),
                    'oblast': data.get('oblast', ''),
                    'provider': data.get('provider', '')
                })
        
        # Convert cities set to sorted list
        cities_list = sorted(list(cities_set))
        
        return jsonify({
            'cities': cities_list,
            'addresses': addresses_list[:200]  # Limit for performance
        })
        
    except Exception as e:
        print(f"ERROR in search_cities: {str(e)}")
        return jsonify({
            'cities': UKRAINE_CITIES if UKRAINE_CITIES else [],
            'addresses': []
        })


@app.route('/api/all_cities_with_queues')
def get_all_cities_with_queues():
    """Get all cities with their queues for the schedule grid"""
    try:
        # Group addresses by city and queue
        cities_data = {}
        
        for address_key, data in BLACKOUT_ADDRESSES.items():
            city = data.get('city', '')
            oblast = data.get('oblast', '')
            queue = data.get('group', '')
            provider = data.get('provider', '')
            
            if not city:
                continue
            
            # Create city key
            city_key = f"{city}, {oblast}"
            
            if city_key not in cities_data:
                cities_data[city_key] = {
                    'city': city,
                    'oblast': oblast,
                    'provider': provider,
                    'queues': set()
                }
            
            if queue:
                cities_data[city_key]['queues'].add(queue)
        
        # Convert to list and format
        result = []
        for city_key, data in cities_data.items():
            queues_list = sorted(list(data['queues']))
            
            # Determine current hour for status
            current_hour = datetime.now(pytz.timezone('Europe/Kiev')).hour
            
            # Check if any queue has active blackout now
            has_active_blackout = False
            active_queues = []
            
            for queue in queues_list:
                schedule = BLACKOUT_SCHEDULES.get(queue, [])
                for slot in schedule:
                    if slot.get('status') == 'active':
                        # Parse time range
                        time_range = slot.get('time', '')
                        if ' - ' in time_range:
                            start_time = time_range.split(' - ')[0]
                            start_hour = int(start_time.split(':')[0])
                            end_hour = (start_hour + 4) % 24
                            
                            if start_hour <= current_hour < end_hour or (end_hour < start_hour and (current_hour >= start_hour or current_hour < end_hour)):
                                has_active_blackout = True
                                active_queues.append(queue)
            
            # Determine status
            if has_active_blackout:
                status = 'active'
                status_text = f"Відключення черг: {', '.join(active_queues)}"
            elif len(queues_list) > 0:
                status = 'warning'
                status_text = f"Черги: {', '.join(queues_list)}"
            else:
                status = 'stable'
                status_text = "Стабільно"
            
            result.append({
                'city': data['city'],
                'oblast': data['oblast'],
                'provider': data['provider'],
                'queues': queues_list,
                'status': status,
                'statusText': status_text,
                'queuesCount': len(queues_list)
            })
        
        # Sort by city name
        result.sort(key=lambda x: x['city'])
        
        return jsonify({
            'success': True,
            'cities': result,
            'total': len(result)
        })
        
    except Exception as e:
        log.error(f"Error in get_all_cities_with_queues: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/get_schedule')
def get_schedule():
    """Get blackout schedule for a specific address using real geocoding and live DTEK updates"""
    city = request.args.get('city', '').strip()
    street = request.args.get('street', '').strip()
    building = request.args.get('building', '').strip()
    
    if not city:
        return jsonify({'error': 'Місто обов\'язкове для заповнення'}), 400
    
    # Try to use live schedule updater first
    if SCHEDULE_UPDATER_AVAILABLE:
        try:
            # Ensure cache is fresh
            if not schedule_updater.is_cache_valid(max_age_hours=1):
                schedule_updater.update_all_schedules()
            
            # Get schedule from live updater
            result = schedule_updater.get_schedule_for_address(city, street, building)
            
            if result and result.get('schedule'):
                return jsonify({
                    'found': True,
                    'address': f"{city}, {street} {building}".strip(),
                    'city': city,
                    'group': result.get('queue'),
                    'provider': result.get('provider'),
                    'schedule': result.get('schedule'),
                    'last_update': result.get('last_update'),
                    'source': 'live_dtek'
                })
        except Exception as e:
            log.warning(f"Live schedule failed, falling back: {e}")
    
    # Fallback to API client
    if not BLACKOUT_API_AVAILABLE:
        return get_schedule_fallback(city, street, building)
    
    try:
        # Use real API client to get schedule
        result = blackout_client.get_schedule_for_address(city, street, building)
        
        if not result['found']:
            return jsonify({
                'error': f'Адресу "{city}" не знайдено. Перевірте правильність написання міста.'
            }), 404
        
        # Add oblast info if available
        if 'київ' in city.lower():
            result['oblast'] = 'Київська'
        elif 'одес' in city.lower():
            result['oblast'] = 'Одеська'
        elif 'харків' in city.lower():
            result['oblast'] = 'Харківська'
        elif 'дніпр' in city.lower():
            result['oblast'] = 'Дніпропетровська'
        elif 'львів' in city.lower():
            result['oblast'] = 'Львівська'
        else:
            result['oblast'] = 'Україна'
        
        return jsonify(result)
        
    except Exception as e:
        logging.error(f"Error in get_schedule: {e}")
        return jsonify({
            'error': 'Помилка при отриманні графіку. Спробуйте ще раз.'
        }), 500


def get_schedule_fallback(city, street, building):
    """Fallback method using static data if API client is unavailable"""
    city_lower = city.lower()
    street_lower = street.lower() if street else ''
    
    # Try to find matching address in static database
    best_match = None
    best_match_data = None
    best_score = 0
    
    for address_key, data in BLACKOUT_ADDRESSES.items():
        key_parts = address_key.split()
        key_city = key_parts[0] if len(key_parts) > 0 else ''
        key_street = ' '.join(key_parts[1:]) if len(key_parts) > 1 else ''
        
        score = 0
        if city_lower in key_city or key_city in city_lower:
            score += 2
        if street_lower and (street_lower in key_street or key_street in street_lower):
            score += 2
        
        if score > best_score:
            best_score = score
            best_match = address_key
            best_match_data = data
    
    if not best_match_data or best_score < 2:
        return jsonify({'error': f'Адресу не знайдено для {city}. Спробуйте інше місто або вулицю.'}), 404
    
    # Reconstruct readable address
    parts = best_match.split()
    city_name = parts[0].capitalize()
    street_name = ' '.join(parts[1:]).capitalize() if len(parts) > 1 else ''
    readable_address = f'{city_name}'
    if street_name:
        readable_address += f', {street_name}'
    if building:
        readable_address += f', {building}'
    
    # Get schedule for the group
    group = best_match_data['group']
    schedule = BLACKOUT_SCHEDULES.get(group, [])
    
    return jsonify({
        'address': readable_address,
        'city': best_match_data['city'],
        'oblast': best_match_data['oblast'],
        'group': group,
        'provider': best_match_data['provider'],
        'schedule': schedule
    })


@app.route('/api/live_schedules')
def get_live_schedules():
    """Get live schedules from DTEK and Ukrenergo with automatic hourly updates"""
    try:
        if not SCHEDULE_UPDATER_AVAILABLE:
            return jsonify({
                'error': 'Автооновлення графіків недоступне',
                'fallback': True
            }), 503
        
        # Check if cache is still valid
        if not schedule_updater.is_cache_valid(max_age_hours=1):
            log.info("Cache expired, triggering update...")
            schedule_updater.update_all_schedules()
        
        # Get cached schedules
        schedules = schedule_updater.get_cached_schedules()
        
        if not schedules:
            return jsonify({
                'error': 'Графіки тимчасово недоступні',
                'retry_after': 60
            }), 503
        
        return jsonify({
            'success': True,
            'schedules': schedules,
            'last_update': schedules.get('last_update'),
            'next_update': 'через годину'
        })
        
    except Exception as e:
        log.error(f"Error in get_live_schedules: {e}")
        return jsonify({
            'error': 'Помилка отримання графіків'
        }), 500


@app.route('/api/schedule_status')
def get_schedule_status():
    """Get status of automatic schedule updates"""
    try:
        if not SCHEDULE_UPDATER_AVAILABLE:
            return jsonify({
                'available': False,
                'message': 'Автооновлення недоступне'
            })
        
        last_update = schedule_updater.last_update
        cache_valid = schedule_updater.is_cache_valid()
        
        return jsonify({
            'available': True,
            'last_update': last_update.isoformat() if last_update else None,
            'cache_valid': cache_valid,
            'next_update': 'через годину' if cache_valid else 'зараз',
            'scheduler_running': scheduler.running if scheduler_initialized else False,
            'scheduler_initialized': scheduler_initialized
        })
        
    except Exception as e:
        log.error(f"Error in get_schedule_status: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/api/force_update', methods=['POST'])
def force_schedule_update():
    """Force immediate schedule update (admin only)"""
    try:
        if not SCHEDULE_UPDATER_AVAILABLE:
            return jsonify({
                'success': False,
                'error': 'Schedule updater not available'
            }), 503
        
        log.info("🔄 Manual schedule update triggered")
        result = schedule_updater.update_all_schedules()
        
        return jsonify({
            'success': True,
            'message': 'Графіки успішно оновлено',
            'last_update': schedule_updater.last_update.isoformat() if schedule_updater.last_update else None,
            'data': result is not None
        })
        
    except Exception as e:
        log.error(f"Error in force_schedule_update: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@app.route('/locate')
def locate_place():
    """Search for a city/settlement and return coordinates or suggestions"""
    query = request.args.get('q', '').strip()
    
    if not query:
        return jsonify({'status': 'error', 'message': 'No query provided'})
    
    # Clean query from region suffixes before searching
    query_clean = query
    for suffix in [' область', ' Область', 'область', 'Область', 'ська область', 'цька область']:
        if suffix in query_clean:
            query_clean = query_clean.split(suffix)[0].strip()
            break
    
    query_lower = query_clean.lower()
    
    # First, try exact match in CITY_COORDS
    if query_lower in CITY_COORDS:
        lat, lng = CITY_COORDS[query_lower]
        return jsonify({
            'status': 'ok',
            'name': query.title(),
            'lat': lat,
            'lng': lng,
            'source': 'city_coords'
        })
    
    # Try exact match in SETTLEMENTS_INDEX
    if query_lower in SETTLEMENTS_INDEX:
        lat, lng = SETTLEMENTS_INDEX[query_lower]
        return jsonify({
            'status': 'ok',
            'name': query.title(),
            'lat': lat,
            'lng': lng,
            'source': 'settlements'
        })
    
    # Try exact match in UKRAINE_ADDRESSES_DB (extract city names)
    if UKRAINE_ADDRESSES_DB:
        for key, value in UKRAINE_ADDRESSES_DB.items():
            city_name = value.get('city', '').lower()
            if city_name == query_lower:
                # Use CITY_COORDS or SETTLEMENTS_INDEX for this city
                if city_name in CITY_COORDS:
                    lat, lng = CITY_COORDS[city_name]
                    return jsonify({
                        'status': 'ok',
                        'name': value.get('city'),
                        'lat': lat,
                        'lng': lng,
                        'source': 'addresses_db'
                    })
    
    # Try normalized version with UA_CITY_NORMALIZE
    if query_lower in UA_CITY_NORMALIZE:
        normalized = UA_CITY_NORMALIZE[query_lower]
        if normalized in CITY_COORDS:
            lat, lng = CITY_COORDS[normalized]
            return jsonify({
                'status': 'ok',
                'name': normalized.title(),
                'lat': lat,
                'lng': lng,
                'source': 'normalized'
            })
        if normalized in SETTLEMENTS_INDEX:
            lat, lng = SETTLEMENTS_INDEX[normalized]
            return jsonify({
                'status': 'ok',
                'name': normalized.title(),
                'lat': lat,
                'lng': lng,
                'source': 'normalized'
            })
    
    # Try API sources for exact match (используем 3 API параллельно)
    api_results = []
    
    # 1. Nominatim API (добавляем Ukraine в строку запроса)
    try:
        import requests
        nominatim_url = 'https://nominatim.openstreetmap.org/search'
        params = {
            'q': f'{query}, Ukraine',
            'format': 'json',
            'limit': 1,
            'accept-language': 'uk'
        }
        headers = {
            'User-Agent': 'NeptunAlarmMap/1.0 (https://neptun-alarm.onrender.com)'
        }
        
        response = requests.get(nominatim_url, params=params, headers=headers, timeout=3)
        if response.ok:
            results = response.json()
            if results and len(results) > 0:
                result = results[0]
                api_results.append({
                    'name': result.get('display_name', query).split(',')[0],
                    'lat': float(result['lat']),
                    'lng': float(result['lon']),
                    'source': 'nominatim'
                })
    except Exception as e:
        log.warning(f'Nominatim exact match error: {e}')
    
    # 2. Photon API (самый быстрый и надёжный для украинских сел)
    try:
        photon_url = 'https://photon.komoot.io/api/'
        params = {
            'q': query,
            'limit': 1
        }
        
        response = requests.get(photon_url, params=params, timeout=3)
        if response.ok:
            data = response.json()
            features = data.get('features', [])
            if features:
                feature = features[0]
                props = feature.get('properties', {})
                coords = feature.get('geometry', {}).get('coordinates', [])
                if coords and len(coords) >= 2 and (props.get('country') == 'Україна' or props.get('country') == 'Ukraine'):
                    api_results.append({
                        'name': props.get('name', query),
                        'lat': coords[1],
                        'lng': coords[0],
                        'source': 'photon'
                    })
    except Exception as e:
        log.warning(f'Photon exact match error: {e}')
    
    # 3. GeoNames API отключён (требует регистрацию, demo лимит исчерпан)
    # Photon + Nominatim дают полное покрытие всех украинских населённых пунктов
    
    # Если хотя бы один API вернул результат, используем его
    if api_results:
        # Приоритет: Photon (самый точный для украинских сел) > Nominatim
        for source_priority in ['photon', 'nominatim']:
            for result in api_results:
                if result['source'] == source_priority:
                    return jsonify({
                        'status': 'ok',
                        'name': result['name'],
                        'lat': result['lat'],
                        'lng': result['lng'],
                        'source': result['source']
                    })
    
    # If no exact match, return suggestions (prefix/substring match)
    suggestions = set()
    
    # Search in CITY_COORDS first (priority)
    for city_name in CITY_COORDS.keys():
        if query_lower in city_name:
            suggestions.add(city_name.title())
            if len(suggestions) >= 50:
                break
    
    # Then search in SETTLEMENTS_INDEX
    if len(suggestions) < 50:
        for settlement_name in SETTLEMENTS_INDEX.keys():
            city_title = settlement_name.title()
            if query_lower in settlement_name:
                suggestions.add(city_title)
                if len(suggestions) >= 100:
                    break
    
    # Also search in UKRAINE_ADDRESSES_DB cities
    if len(suggestions) < 100 and UKRAINE_ADDRESSES_DB:
        cities_from_db = set()
        for value in UKRAINE_ADDRESSES_DB.values():
            city_name = value.get('city', '').strip()
            if city_name and query_lower in city_name.lower():
                cities_from_db.add(city_name)
        suggestions.update(cities_from_db)
    
    # Add UKRAINE_CITIES if available
    if len(suggestions) < 100 and UKRAINE_CITIES:
        for city in UKRAINE_CITIES:
            if query_lower in city.lower():
                suggestions.add(city)
    
    # ВСЕГДА используем несколько API для максимальной полноты поиска
    api_suggestions = set()
    
    # 1. Photon API (быстрее чем Nominatim, использует OpenStreetMap данные)
    try:
        import requests
        photon_url = 'https://photon.komoot.io/api/'
        params = {
            'q': query,
            'limit': 20
        }
        
        response = requests.get(photon_url, params=params, timeout=3)
        if response.ok:
            data = response.json()
            for feature in data.get('features', []):
                props = feature.get('properties', {})
                name = props.get('name', '')
                country = props.get('country', '')
                if country == 'Україна' and name:
                    api_suggestions.add(name)
    except Exception as e:
        log.warning(f'Photon API error: {e}')
    
    # 2. Nominatim API (OpenStreetMap)
    try:
        import requests
        nominatim_url = 'https://nominatim.openstreetmap.org/search'
        params = {
            'q': f'{query}, Ukraine',
            'format': 'json',
            'limit': 30,
            'accept-language': 'uk',
            'addressdetails': 1
        }
        headers = {
            'User-Agent': 'NeptunAlarmMap/1.0 (https://neptun-alarm.onrender.com)'
        }
        
        response = requests.get(nominatim_url, params=params, headers=headers, timeout=4)
        if response.ok:
            results = response.json()
            for result in results:
                # Пробуем разные поля для названия
                name = None
                address = result.get('address', {})
                
                # Приоритет полям
                for field in ['village', 'town', 'city', 'hamlet', 'suburb', 'municipality']:
                    if field in address:
                        name = address[field]
                        break
                
                if not name:
                    display_name = result.get('display_name', '')
                    if display_name:
                        name = display_name.split(',')[0]
                
                if name:
                    api_suggestions.add(name)
    except Exception as e:
        log.warning(f'Nominatim API error: {e}')
    
    # 3. GeoNames API отключён (требует регистрацию, demo лимит 20к/день исчерпан)
    # Photon + Nominatim дают полное покрытие всех украинских населённых пунктов
    
    # Объединяем локальные и API результаты
    suggestions.update(api_suggestions)
    
    # Sort and limit
    suggestions_list = sorted(list(suggestions), key=lambda x: (len(x), x))[:50]
    
    if suggestions_list:
        return jsonify({
            'status': 'suggest',
            'matches': suggestions_list
        })
    
    # No matches found
    return jsonify({
        'status': 'not_found',
        'message': f'Не знайдено: {query}'
    })


def _prune_comments():
    # keep only last COMMENTS_MAX comments
    global COMMENTS
    if len(COMMENTS) > COMMENTS_MAX:
        COMMENTS = COMMENTS[-COMMENTS_MAX:]

@app.route('/comments', methods=['GET','POST'])
def comments_endpoint():
    """GET returns recent anonymous comments. POST inserts a new one persistently.

    Persistence strategy:
      - Store each comment into SQLite (comments table) with epoch for ordering.
      - Maintain small in-memory tail cache to avoid DB hit storms on rapid polling.
      - On GET always fetch from DB (limit) for durability across redeploys.
    """
    if request.method == 'POST':
        try:
            data = request.get_json(force=True, silent=True) or {}
        except Exception:
            data = {}
        text = (data.get('text') or '').strip()
        if not text:
            return jsonify({'ok': False, 'error': 'empty'}), 400
        reply_to = (data.get('reply_to') or '').strip() or None
        if reply_to and not re.fullmatch(r'[0-9a-fA-F]{6,20}', reply_to):
            reply_to = None  # sanitize unexpected format
        # rudimentary spam / flooding throttles (per-IP simple memory window)
        ip = request.headers.get('X-Forwarded-For', request.remote_addr) or 'unknown'
        now_ts = time.time()
        # simple rate tracker: store recent post times per IP in a module-level dict
        rt = getattr(app, '_comment_rate', None)
        if rt is None:
            rt = {}
            setattr(app, '_comment_rate', rt)
        arr = rt.get(ip, [])
        # drop entries older than 60s
        arr = [t for t in arr if now_ts - t < 60]
        if len(arr) >= 8:  # max 8 comments per minute per IP
            return jsonify({'ok': False, 'error': 'rate_limited'}), 429
        arr.append(now_ts)
        rt[ip] = arr
        # basic length clamp
        if len(text) > 800:
            text = text[:800]
        item = {
            'id': uuid.uuid4().hex[:10],
            'text': text,
            'ts': datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S'),
            'epoch': now_ts,
            'reply_to': reply_to
        }
        cache_item = {k: item[k] for k in ('id','text','ts')}
        if reply_to:
            cache_item['reply_to'] = reply_to
        COMMENTS.append(cache_item)  # store subset in memory cache
        _prune_comments()
        # persist
        save_comment_record(item)
        resp_item = {k: item[k] for k in ('id','text','ts')}
        if reply_to:
            resp_item['reply_to'] = reply_to
        return jsonify({'ok': True, 'item': resp_item})
    # GET
    limit = 80
    rows = load_recent_comments(limit=limit)
    if not rows and COMMENTS:  # fallback to cache if DB query unexpectedly empty
        rows = COMMENTS[-limit:]
    return jsonify({'ok': True, 'items': rows})

@app.route('/comments/react', methods=['POST'])
def comment_react_endpoint():
    """Toggle emoji reactions on comments."""
    try:
        data = request.get_json(force=True, silent=True) or {}
    except Exception:
        return jsonify({'ok': False, 'error': 'invalid_json'}), 400
    
    comment_id = (data.get('comment_id') or '').strip()
    emoji = (data.get('emoji') or '').strip()
    
    # Validation
    if not comment_id or not emoji:
        return jsonify({'ok': False, 'error': 'missing_params'}), 400
        
    # Validate emoji is in allowed list
    allowed_emojis = ['👍', '❤️', '🔥', '😢', '😡', '😂', '👎']
    if emoji not in allowed_emojis:
        return jsonify({'ok': False, 'error': 'invalid_emoji'}), 400
    
    # Get user IP for uniqueness
    ip = request.headers.get('X-Forwarded-For', request.remote_addr) or 'unknown'
    
    # Rate limiting: max 20 reactions per minute per IP
    now_ts = time.time()
    rt = getattr(app, '_reaction_rate', None)
    if rt is None:
        rt = {}
        setattr(app, '_reaction_rate', rt)
    
    arr = rt.get(ip, [])
    arr = [t for t in arr if now_ts - t < 60]  # Keep last 60 seconds
    if len(arr) >= 20:
        return jsonify({'ok': False, 'error': 'rate_limited'}), 429
    arr.append(now_ts)
    rt[ip] = arr
    
    # Toggle reaction
    result = toggle_comment_reaction(comment_id, emoji, ip)
    
    if result['action'] == 'error':
        return jsonify({'ok': False, 'error': 'server_error'}), 500
    
    return jsonify({
        'ok': True, 
        'action': result['action'],
        'reactions': result['reactions']
    })

@app.route('/active_alarms')
def active_alarms_endpoint():
    """Return current active oblast & raion air alarms (for polygon styling)."""
    
    # Rate limit отключен: все пользователи имеют свободный доступ
    
    try:
        now_ep = time.time()
        cutoff = now_ep - APP_ALARM_TTL_MINUTES*60
        for dct in (ACTIVE_OBLAST_ALARMS, ACTIVE_RAION_ALARMS):
            for k in list(dct.keys()):
                if dct[k]['last'] < cutoff:
                    dct.pop(k, None)
        obl_list = []
        for k,v in ACTIVE_OBLAST_ALARMS.items():
            base = k.lower()
            pcode = OBLAST_PCODE.get(base)
            obl_list.append({'name': k, 'since': v['since'], **({'pcode':pcode} if pcode else {})})
        return jsonify({
            'oblasts': obl_list,
            'raions': [{'name': k, 'since': v['since']} for k,v in ACTIVE_RAION_ALARMS.items()],
            'ttl_minutes': APP_ALARM_TTL_MINUTES
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/alarms_stats')
def alarms_stats():
    """Return recent alarm events history (start/cancel/expire) with optional query params:
    ?level=oblast|raion  ?name=<substring>  ?minutes=<window>  ?limit=N
    """
    level_f = request.args.get('level')
    name_sub = (request.args.get('name') or '').lower().strip()
    minutes = int(request.args.get('minutes', '720'))  # default 12h
    limit = int(request.args.get('limit','500'))
    if limit > 2000: limit = 2000
    cutoff = time.time() - minutes*60
    rows = []
    try:
        with _visits_db_conn() as conn:
            q = "SELECT level,name,event,ts FROM alarm_events WHERE ts >= ?"
            params = [cutoff]
            if level_f in ('oblast','raion'):
                q += " AND level = ?"; params.append(level_f)
            if name_sub:
                q += " AND LOWER(name) LIKE ?"; params.append(f"%{name_sub}%")
            q += " ORDER BY ts DESC LIMIT ?"; params.append(limit)
            cur = conn.execute(q, tuple(params))
            for level,name,event,tsv in cur.fetchall():
                rows.append({'level': level, 'name': name, 'event': event, 'ts': tsv})
    except Exception as e:
        return jsonify({'error': str(e)}), 500
    return jsonify({'items': rows, 'count': len(rows), 'window_minutes': minutes})

@app.route('/data')
def data():
    global FALLBACK_REPARSE_CACHE, MAX_REPARSE_CACHE_SIZE
    
    # Rate limit отключен: все пользователи имеют свободный доступ
    
    # BANDWIDTH OPTIMIZATION: Add aggressive caching headers  
    response_headers = {
        'Cache-Control': 'public, max-age=60, s-maxage=60',  # Increased cache to 60 seconds
        'ETag': f'data-{int(time.time() // 60)}',  # Cache for 60 seconds
        'Vary': 'Accept-Encoding'
    }
    
    # Check if client has cached version
    client_etag = request.headers.get('If-None-Match')
    if client_etag == response_headers['ETag']:
        return Response(status=304, headers=response_headers)
    
    # Use user-provided timeRange or fall back to global configured MONITOR_PERIOD_MINUTES
    try:
        time_range = int(request.args.get('timeRange', MONITOR_PERIOD_MINUTES))
        # Limit to reasonable values to prevent abuse and reduce bandwidth
        time_range = max(10, min(time_range, 100))  # Reduced from 200 to 100
    except (ValueError, TypeError):
        time_range = MONITOR_PERIOD_MINUTES
    
    print(f"[DEBUG] /data endpoint called with timeRange={request.args.get('timeRange')}, MONITOR_PERIOD_MINUTES={MONITOR_PERIOD_MINUTES}, using time_range={time_range}")
    messages = load_messages()
    print(f"[DEBUG] Loaded {len(messages)} total messages")
    tz = pytz.timezone('Europe/Kyiv')
    now = datetime.now(tz).replace(tzinfo=None)
    min_time = now - timedelta(minutes=time_range)
    print(f"[DEBUG] Filtering messages since {min_time} (last {time_range} minutes)")
    hidden = set(load_hidden())
    out = []  # geo tracks
    events = []  # list-only (alarms, cancellations, other non-geo informational)
    for m in messages:
        try:
            dt = datetime.strptime(m.get('date',''), '%Y-%m-%d %H:%M:%S')
        except Exception:
            continue
        if dt >= min_time:
            # Fallback reparse: if message lacks geo but contains course pattern, try to derive markers now
            txt_low = (m.get('text') or '').lower()
            msg_id = m.get('id')
            
            # Skip multi-regional UAV messages - they're already handled by immediate processing
            text_full = m.get('text') or ''
            text_lines = text_full.split('\n')
            region_count = sum(1 for line in text_lines if any(region in line.lower() for region in ['щина:', 'щина]', 'область:', 'край:']) or (
                'щина' in line.lower() and line.lower().strip().endswith(':')
            ))
            uav_count = sum(1 for line in text_lines if 'бпла' in line.lower() and ('курс' in line.lower() or 'на ' in line.lower()))
            
            if (not m.get('lat')) and (not m.get('lng')) and ('бпла' in txt_low and 'курс' in txt_low and ' на ' in txt_low):
                # Skip if this is a multi-regional UAV message (already processed immediately)
                if region_count >= 2 and uav_count >= 3:
                    add_debug_log(f"Skipping fallback reparse for multi-regional UAV message ID {msg_id}", "reparse")
                    continue
                    
                # Check if we've already reparsed this message to avoid duplicate processing
                if msg_id in FALLBACK_REPARSE_CACHE:
                    add_debug_log(f"Skipping fallback reparse for message ID {msg_id} - already processed", "reparse")
                    continue
                
                try:
                    # Add to cache to prevent future reprocessing
                    FALLBACK_REPARSE_CACHE.add(msg_id)
                    # Limit cache size to prevent memory growth
                    if len(FALLBACK_REPARSE_CACHE) > MAX_REPARSE_CACHE_SIZE:
                        # Remove oldest half of the cache (approximate LRU)
                        cache_list = list(FALLBACK_REPARSE_CACHE)
                        FALLBACK_REPARSE_CACHE = set(cache_list[len(cache_list)//2:])
                    
                    add_debug_log(f"Fallback reparse for message ID {msg_id} - first time processing", "reparse")
                    reparsed = process_message(m.get('text') or '', m.get('id'), m.get('date'), m.get('channel') or m.get('source') or '')
                    if isinstance(reparsed, list) and reparsed:
                        for t in reparsed:
                            try:
                                lat_r = round(float(t.get('lat')), 3)
                                lng_r = round(float(t.get('lng')), 3)
                            except Exception:
                                continue
                            text_r = (t.get('text') or '')
                            source_r = t.get('channel') or t.get('source') or ''
                            marker_key_r = f"{lat_r},{lng_r}|{text_r}|{source_r}"
                            if marker_key_r in hidden:
                                continue
                            out.append(t)
                        # Skip adding original as event if we produced tracks
                        if reparsed:
                            continue
                except Exception:
                    pass
            # list-only (no coordinates) -> push into events list if not suppressed
            if m.get('list_only'):
                if not m.get('suppress'):
                    events.append(m)
                continue  # skip trying to interpret as marker
            # build marker key similar to frontend hide logic (rounded lat/lng + text + source/channel)
            try:
                lat = round(float(m.get('lat')), 3)
                lng = round(float(m.get('lng')), 3)
            except Exception:
                continue  # not a proper geo marker
            text = (m.get('text') or '')
            source = m.get('source') or m.get('channel') or ''
            marker_key = f"{lat},{lng}|{text}|{source}"
            if marker_key in hidden:
                continue
            # Backward compatibility: allow prefix match (text truncated when stored) for same lat,lng,source
            base_prefix = f"{lat},{lng}|"
            if not any(h.startswith(base_prefix) for h in hidden if '|' in h):
                pass
            else:
                # iterate candidates with same coords and source, compare text prefix
                skip = False
                for h in hidden:
                    if not h.startswith(base_prefix):
                        continue
                    try:
                        _, htext, hsource = h.split('|',2)
                    except ValueError:
                        continue
                    if hsource == source and text.startswith(htext):
                        skip = True
                        break
                if skip:
                    continue
            # Фильтр: удаляем региональные метки без явных слов угроз (могли сохраниться старыми версиями логики)
            low_txt = text.lower()
            if m.get('source_match','').startswith('region') and not any(k in low_txt for k in ['бпла','дрон','шахед','shahed','geran','ракета','ракети','missile','iskander','s-300','s300','каб','артил','града','смерч','ураган','mlrs','avia','авіа','авиа','бомба']):
                continue
            out.append(m)
    # Sort events by time desc (latest first) like markers implicitly (messages stored chronological)
    try:
        events.sort(key=lambda x: x.get('date',''), reverse=True)
    except Exception:
        pass
    
    print(f"[DEBUG] Returning {len(out)} tracks and {len(events)} events")
    
    # Return all data without limits
    response_data = {
        'tracks': out,  # All tracks without limit
        'events': events,  # All events without limit
        'all_sources': CHANNELS,  # All sources
        'trajectories': []
    }
    
    resp = jsonify(response_data)
    # Add aggressive caching headers to reduce bandwidth
    resp.headers.update(response_headers)
    return resp

@app.route('/channels')
def list_channels():
    return jsonify({'channels': CHANNELS, 'invalid': list(INVALID_CHANNELS)})

@app.route('/debug_parse', methods=['POST'])
def debug_parse():
    """Ad-hoc debugging endpoint to inspect parser output for a stored message or raw text.

    POST JSON:
      {"id": <message_id>}  -> reparse stored message text
      or
      {"text": "raw message text", "channel": "optional", "date": "YYYY-MM-DD HH:MM:SS"}

    Response: { ok: bool, source: 'stored'|'raw', message: {...original message fields subset...}, tracks: [...], count: N }
    """
    try:
        payload = request.get_json(force=True, silent=True) or {}
    except Exception:
        try:
            payload = request.get_json(silent=True) or {}
        except Exception:
            payload = {}
    mid = payload.get('id')
    raw_text = payload.get('text')
    # Allow base64-encoded text to avoid client console encoding corruption
    if not raw_text:
        b64_txt = payload.get('b64') or payload.get('b64_text') or None
        if b64_txt:
            try:
                import base64
                raw_text = base64.b64decode(b64_txt).decode('utf-8', errors='replace')
            except Exception:
                raw_text = ''
    channel = payload.get('channel') or ''
    date_str = payload.get('date') or datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')
    src = 'raw'
    if mid and not raw_text:
        # look up stored messages
        try:
            for m in load_messages():
                if str(m.get('id')) == str(mid):
                    raw_text = m.get('text') or ''
                    channel = m.get('channel') or m.get('source') or channel
                    date_str = m.get('date') or date_str
                    src = 'stored'
                    break
        except Exception:
            pass
    if not raw_text:
        return jsonify({'ok': False, 'error': 'no_text_provided'}), 400
    try:
        tracks = process_message(raw_text, str(mid) if mid else 'debug', date_str, channel)
    except Exception as e:
        return jsonify({'ok': False, 'error': f'parse_error: {e}'}), 500
    return jsonify({
        'ok': True,
        'source': src,
        'message': {
            'id': mid,
            'channel': channel,
            'date': date_str,
            'text': raw_text[:2000]
        },
        'count': len(tracks) if isinstance(tracks, list) else 0,
        'tracks': tracks if isinstance(tracks, list) else []
    })

@app.route('/api/visitor_count')
def visitor_count():
    """API endpoint to get total visitor count from database."""
    try:
        import sqlite3
        conn = sqlite3.connect('visits.db')
        cursor = conn.cursor()
        
        # Get total unique visitors
        cursor.execute('SELECT COUNT(DISTINCT ip) FROM visits')
        total_visitors = cursor.fetchone()[0]
        
        conn.close()
        
        return str(total_visitors), 200, {
            'Content-Type': 'text/plain',
            'Cache-Control': 'public, max-age=10',
            'Access-Control-Allow-Origin': '*'
        }
    except Exception as e:
        print(f"[ERROR] Failed to get visitor count: {e}")
        return "0", 200, {'Content-Type': 'text/plain'}

@app.route('/api/android_visitor_count')
def android_visitor_count():
    """API endpoint to get Android app visitor count."""
    try:
        import sqlite3
        conn = sqlite3.connect('visits.db')
        cursor = conn.cursor()
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS app_visits (
                device_id TEXT PRIMARY KEY,
                platform TEXT,
                ip TEXT,
                last_seen DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        cursor.execute('SELECT COUNT(*) FROM app_visits WHERE platform = ?', ('android',))
        android_visitors = cursor.fetchone()[0] or 0
        
        conn.close()
        
        return str(android_visitors), 200, {
            'Content-Type': 'text/plain',
            'Cache-Control': 'public, max-age=10',
            'Access-Control-Allow-Origin': '*'
        }
    except Exception as e:
        print(f"[ERROR] Failed to get Android visitor count: {e}")
        return "0", 200, {'Content-Type': 'text/plain'}

@app.route('/api/track_android_visit', methods=['POST'])
def track_android_visit():
    """Track Android app visitor."""
    try:
        import sqlite3
        payload = request.get_json(silent=True) or {}
        client_ip = request.environ.get('HTTP_X_FORWARDED_FOR', request.remote_addr)
        device_id = str(payload.get('device_id') or '').strip() or client_ip
        platform_hint = payload.get('platform') or 'android'
        ua = request.headers.get('User-Agent', '')
        platform_label = _normalize_platform(platform_hint, ua)
        
        conn = sqlite3.connect('visits.db')
        cursor = conn.cursor()
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS app_visits (
                device_id TEXT PRIMARY KEY,
                platform TEXT,
                ip TEXT,
                last_seen DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        cursor.execute('''
            INSERT INTO app_visits (device_id, platform, ip, last_seen)
            VALUES (?, ?, ?, CURRENT_TIMESTAMP)
            ON CONFLICT(device_id) DO UPDATE SET
                platform=excluded.platform,
                ip=excluded.ip,
                last_seen=CURRENT_TIMESTAMP
        ''', (device_id, platform_label, client_ip))
        
        conn.commit()
        conn.close()
        
        return jsonify({'ok': True, 'platform': platform_label}), 200
    except Exception as e:
        print(f"[ERROR] Failed to track Android visit: {e}")
        return jsonify({'ok': False}), 500

@app.route('/api/events')
def get_events():
    """Get recent air alarm events from Telegram."""
    try:
        messages = load_messages()
        events = []
        
        # Process ALL messages, not just last 200
        for msg in messages:
            if not isinstance(msg, dict):
                continue
                
            text = msg.get('text', '').strip()
            channel = msg.get('channel', '')
            timestamp = msg.get('time', '')
            
            # Detect alarm type by emoji or text
            emoji = None
            status = None
            
            if '🚨' in text or 'Повітряна тривога' in text:
                emoji = '🚨'
                status = 'Повітряна тривога'
            elif '🟢' in text or 'Відбій тривоги' in text or 'відбій тривоги' in text:
                emoji = '🟢'
                status = 'Відбій тривоги'
            else:
                continue
            
            # Extract region from multiple formats:
            # Format 1: "**🚨 Дніпропетровська область**"
            # Format 2: "**🚨 Харківський район (Харківська обл.)**"
            region = ''
            
            if '**' in text:
                parts = text.split('**')
                for part in parts:
                    part = part.strip()
                    # Look for parts containing emoji
                    if '🚨' in part or '🟢' in part:
                        # Remove emoji and clean up
                        region = part.replace('🚨', '').replace('🟢', '').strip()
                        break
            
            # Fallback: extract from first line
            if not region and text:
                first_line = text.split('\n')[0].strip()
                # Remove markdown and emojis
                region = first_line.replace('**', '').replace('🚨', '').replace('🟢', '').strip()
                # Remove common phrases
                region = region.replace('Повітряна тривога.', '').replace('Прямуйте в укриття!', '').strip()
                region = region.replace('Відбій тривоги.', '').replace('Будьте обережні!', '').strip()
            
            # Skip if no region found
            if not region:
                continue
            
            events.append({
                'timestamp': timestamp,
                'channel': channel,
                'emoji': emoji,
                'region': region,
                'status': status,
                'text': text[:200]  # First 200 chars
            })
        
        # Sort by timestamp (newest first) and return last 100 events
        # This ensures stable results regardless of message order in file
        events.reverse()
        
        response = jsonify(events[:100])  # Return last 100 events
        response.headers['Cache-Control'] = 'public, max-age=30'
        response.headers['Access-Control-Allow-Origin'] = '*'
        return response
        
    except Exception as e:
        print(f"[ERROR] /api/events failed: {e}")
        return jsonify([]), 500

@app.route('/test_parse')
def test_parse():
    """Test endpoint to manually test message parsing without auth."""
    test_message = "Чернігівщина: 1 БпЛА на Козелець 1 БпЛА на Носівку 1 БпЛА неподалік Ічні 2 БпЛА на Куликівку 2 БпЛА між Корюківкою та Меною Сумщина: 3 БпЛА в районі Конотопу ㅤ ➡Підписатися"
    
    try:
        print("="*50)
        print("MANUAL TEST STARTED")
        print("="*50)
        tracks = process_message(test_message, 'TEST_1', '2025-09-05 17:20:00', 'test')
        print("="*50)
        print("MANUAL TEST COMPLETED")
        print("="*50)
        
        return jsonify({
            'success': True,
            'message': test_message,
            'tracks_count': len(tracks) if tracks else 0,
            'tracks': tracks,
            'test_time': datetime.now().isoformat()
        })
    except Exception as e:
        import traceback
        error_details = traceback.format_exc()
        print(f"ERROR in test_parse: {error_details}")
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': error_details
        }), 500
    """Locate a settlement or raion by name. Query param: q=<name>
    Returns: {status:'ok', name, lat, lng, source:'dict'|'geocode'|'fallback'} or {status:'not_found'}
    Lightweight normalization reusing UA_CITY_NORMALIZE and CITY_COORDS. Falls back to ensure_city_coords (may geocode if key allowed).
    """
    q = (request.args.get('q') or '').strip()
    if not q:
        return jsonify({'status':'empty'}), 400
    raw = q.lower()
    # Basic cleanup similar to parser's normalization
    raw = re.sub(r'["`ʼ’\'".,:;()]+','', raw)
    raw = re.sub(r'\s+',' ', raw)
    # Try direct dict match
    key = raw
    if key in UA_CITY_NORMALIZE:
        key = UA_CITY_NORMALIZE[key]
    # Heuristic accusative -> nominative (simple feminine endings) if still not found
    if key not in CITY_COORDS and len(key) > 4 and key.endswith(('у','ю')):
        alt = key[:-1] + 'а'
        if alt in CITY_COORDS:
            key = alt
    # Direct dictionary coordinate fetch
    if key in CITY_COORDS:
        lat,lng = CITY_COORDS[key]
        return jsonify({'status':'ok','name':key.title(),'lat':lat,'lng':lng,'source':'dict'})
    # Check full settlements index (all cities/villages loaded from external file)
    if 'SETTLEMENTS_INDEX' in globals() and key in SETTLEMENTS_INDEX:
        lat,lng = SETTLEMENTS_INDEX[key]
        return jsonify({'status':'ok','name':key.title(),'lat':lat,'lng':lng,'source':'settlement'})
    # If not exact, attempt prefix suggestions for UI autocomplete
    if 'SETTLEMENTS_INDEX' in globals() and len(key) >= 3:
        pref = key
        matches = [n for n in SETTLEMENTS_INDEX.keys() if n.startswith(pref)][:15]
        if not matches and pref.endswith(('у','ю')):
            pref2 = pref[:-1] + 'а'
            matches = [n for n in SETTLEMENTS_INDEX.keys() if n.startswith(pref2)][:15]
        if matches:
            return jsonify({'status':'suggest','query':q,'matches':matches})
    # Attempt dynamic ensure (geocode) unless negative cache prohibits
    coords = None
    try:
        coords = ensure_city_coords(key)
    except Exception:
        coords = None
    if coords:
        lat,lng = coords
        return jsonify({'status':'ok','name':key.title(),'lat':lat,'lng':lng,'source':'geocode'})
    return jsonify({'status':'not_found','query':q}), 404

@app.route('/add_channel', methods=['POST'])
def add_channel():
    """Add a channel username or numeric ID at runtime.
    Body JSON: {"id": "-1001234567890", "secret": "..."}
    Requires AUTH_SECRET match if set.
    Persists into channels_dynamic.json and updates global list.
    """
    if AUTH_SECRET and request.json.get('secret') != AUTH_SECRET:
        return jsonify({'status':'error','error':'unauthorized'}), 403
    cid = str(request.json.get('id','')).strip()
    if not cid:
        return jsonify({'status':'error','error':'empty_id'}), 400
    global CHANNELS
    # Normalize removing leading @ or https link wrappers
    cid = cid.replace('https://t.me/','').replace('t.me/','')
    # Remove joinchat pattern if present (cannot directly fetch by invite hash)
    if cid.startswith('+'):
        # Cannot use invite hash directly; require numeric ID user already joined from session
        return jsonify({'status':'error','error':'invite_link_not_supported_use_numeric_id'}), 400
    if cid not in CHANNELS:
        CHANNELS.append(cid)
        # Persist dynamic list excluding originals from env for clarity
        orig_env = os.getenv('TELEGRAM_CHANNELS', '').split(',') if os.getenv('TELEGRAM_CHANNELS') else []
        dynamic_part = [c for c in CHANNELS if c.strip() and c.strip() not in orig_env]
        save_dynamic_channels(dynamic_part)
        log.info(f'Added channel {cid}. Total now {len(CHANNELS)}')
        return jsonify({'status':'ok','added':cid,'total':len(CHANNELS)})
    return jsonify({'status':'ok','added':False,'message':'exists','total':len(CHANNELS)})

# ---------------- Manual marker management -----------------

def _normalize_admin_trajectory(raw_traj):
    """Sanitize trajectory payload coming from admin UI."""
    if not isinstance(raw_traj, dict):
        return None

    def _pt(val):
        if not isinstance(val, (list, tuple)) or len(val) != 2:
            return None
        try:
            lat = float(val[0])
            lng = float(val[1])
            return [round(lat, 6), round(lng, 6)]
        except (TypeError, ValueError):
            return None

    start = _pt(raw_traj.get('start'))
    end = _pt(raw_traj.get('end'))
    if not (start and end):
        return None

    traj = {'start': start, 'end': end}
    for key in ('source', 'target', 'kind'):
        value = raw_traj.get(key)
        if isinstance(value, str):
            value = value.strip()
            if value:
                traj[key] = value[:160]
    return traj
@app.route('/admin/add_manual_marker', methods=['POST'])
def admin_add_manual_marker():
    """Add a manual marker via admin panel.
    JSON body: {"lat":..., "lng":..., "text":"...", "place":"...", "threat_type":"shahed", "icon":"optional.png", "rotation":0}
    Requires secret if configured.
    """
    if not _require_secret(request):
        return jsonify({'status':'forbidden'}), 403
    payload = request.get_json(silent=True) or {}
    try:
        lat = float(payload.get('lat'))
        lng = float(payload.get('lng'))
        if not (43 <= lat <= 53.8 and 21 <= lng <= 41.5):
            raise ValueError('out_of_bounds')
        text = (payload.get('text') or '').strip()
        if not text:
            raise ValueError('empty_text')
        place = (payload.get('place') or '').strip()
        threat_type = (payload.get('threat_type') or '').strip().lower() or 'manual'
        allowed_types = {'shahed','raketa','avia','pvo','vibuh','alarm','alarm_cancel','mlrs','artillery','obstril','fpv','pusk','manual'}
        if threat_type not in allowed_types:
            threat_type = 'manual'
        icon = (payload.get('icon') or '').strip()
        rotation = payload.get('rotation', 0)
        try:
            rotation = float(rotation)
        except:
            rotation = 0
        trajectory = _normalize_admin_trajectory(payload.get('trajectory'))
        course_direction = (payload.get('course_direction') or '').strip() or None
        course_target = (payload.get('course_target') or '').strip() or None
        course_source = (payload.get('course_source') or '').strip() or (place or None)
        course_type = (payload.get('course_type') or '').strip() or None

        tz = pytz.timezone('Europe/Kyiv')
        now_dt = datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')
        mid = 'manual-' + uuid.uuid4().hex[:12]
        messages = load_messages()
        # Build message dict similar to parsed messages
        msg = {
            'id': mid,
            'date': now_dt,
            'text': text,
            'place': place,
            'lat': round(lat, 6),
            'lng': round(lng, 6),
            'threat_type': threat_type,
            'marker_icon': icon or None,
            'rotation': rotation,
            'manual': True,
            'channel': 'manual',
            'source': 'manual'
        }
        if trajectory:
            msg['trajectory'] = trajectory
        if course_direction:
            msg['course_direction'] = course_direction
        if course_target:
            msg['course_target'] = course_target
        if course_source:
            msg['course_source'] = course_source
        if course_type:
            msg['course_type'] = course_type
        messages.append(msg)
        save_messages(messages)
        return jsonify({'status':'ok','id':mid})
    except Exception as e:
        return jsonify({'status':'error','error':str(e)}), 400

@app.route('/admin/update_manual_marker', methods=['POST'])
def admin_update_manual_marker():
    """Update existing manual marker coordinates/text/type."""
    if not _require_secret(request):
        return jsonify({'status': 'forbidden'}), 403

    payload = request.get_json(silent=True) or {}
    marker_id = (payload.get('id') or '').strip()
    if not marker_id:
        return jsonify({'status': 'error', 'error': 'missing_id'}), 400

    try:
        lat = float(payload.get('lat'))
        lng = float(payload.get('lng'))
        if not (43 <= lat <= 53.8 and 21 <= lng <= 41.5):
            raise ValueError('out_of_bounds')
        place = (payload.get('place') or '').strip()
        text = (payload.get('text') or '').strip()
        if not text:
            raise ValueError('empty_text')
        threat_type = (payload.get('threat_type') or '').strip().lower() or 'manual'
        allowed_types = {'shahed','raketa','avia','pvo','vibuh','alarm','alarm_cancel','mlrs','artillery','obstril','fpv','pusk','manual'}
        if threat_type not in allowed_types:
            threat_type = 'manual'
        rotation = payload.get('rotation', 0)
        try:
            rotation = float(rotation)
        except Exception:
            rotation = 0

        trajectory = _normalize_admin_trajectory(payload.get('trajectory'))
        course_direction = (payload.get('course_direction') or '').strip()
        course_target = (payload.get('course_target') or '').strip()
        course_source = (payload.get('course_source') or '').strip()
        course_type = (payload.get('course_type') or '').strip()

        messages = load_messages()
        updated = False
        for msg in messages:
            if msg.get('id') != marker_id:
                continue
            msg['lat'] = round(lat, 6)
            msg['lng'] = round(lng, 6)
            msg['place'] = place
            msg['text'] = text
            msg['threat_type'] = threat_type
            msg['rotation'] = rotation
            msg['manual'] = msg.get('manual', True)

            if 'trajectory' in payload:
                if trajectory:
                    msg['trajectory'] = trajectory
                else:
                    msg.pop('trajectory', None)
            if 'course_direction' in payload:
                if course_direction:
                    msg['course_direction'] = course_direction
                else:
                    msg.pop('course_direction', None)
            if 'course_target' in payload:
                if course_target:
                    msg['course_target'] = course_target
                else:
                    msg.pop('course_target', None)
            if 'course_source' in payload:
                if course_source:
                    msg['course_source'] = course_source
                else:
                    msg.pop('course_source', None)
            if 'course_type' in payload:
                if course_type:
                    msg['course_type'] = course_type
                else:
                    msg.pop('course_type', None)
            updated = True
            break

        if not updated:
            return jsonify({'status': 'error', 'error': 'not_found'}), 404

        save_messages(messages)
        return jsonify({'status': 'ok', 'id': marker_id})
    except Exception as e:
        return jsonify({'status': 'error', 'error': str(e)}), 400

@app.route('/admin/markers')
def admin_markers():
    """API endpoint to get recent markers for admin map"""
    if not _require_secret(request):
        return jsonify({'status':'forbidden'}), 403
    
    all_msgs = load_messages()
    # Get recent markers (exclude pending geo)
    recent_markers = [m for m in reversed(all_msgs) if m.get('lat') and m.get('lng') and not m.get('pending_geo')][:120]
    
    return jsonify({
        'status': 'ok',
        'markers': recent_markers,
        'count': len(recent_markers)
    })

@app.route('/admin/raw_msgs')
def admin_raw_msgs():
    """API endpoint to get raw messages (pending geo) for admin panel"""
    if not _require_secret(request):
        return jsonify({'status':'forbidden'}), 403
    
    all_msgs = load_messages()
    raw_msgs = [m for m in reversed(all_msgs) if m.get('pending_geo')][:100]  # latest 100
    raw_count = len([m for m in all_msgs if m.get('pending_geo')])
    
    return jsonify({
        'status': 'ok',
        'raw_msgs': raw_msgs,
        'raw_count': raw_count
    })

@app.route('/admin/delete_manual_marker', methods=['POST'])
def admin_delete_manual_marker():
    if not _require_secret(request):
        return jsonify({'status':'forbidden'}), 403
    payload = request.get_json(silent=True) or {}
    mid = (payload.get('id') or '').strip()
    if not mid:
        return jsonify({'status':'error','error':'missing id'}), 400
    try:
        messages = load_messages()
        new_list = [m for m in messages if not (m.get('manual') and m.get('id') == mid)]
        if len(new_list) == len(messages):
            return jsonify({'status':'ok','deleted':False})
        save_messages(new_list)
        return jsonify({'status':'ok','deleted':True})
    except Exception as e:
        return jsonify({'status':'error','error':str(e)}), 500

@app.route('/hide_marker', methods=['POST'])
def hide_marker():
    """Store a marker key so it's excluded from subsequent /data responses."""
    try:
        payload = request.get_json(force=True) or {}
        lat = round(float(payload.get('lat')), 3)
        lng = round(float(payload.get('lng')), 3)
        text = (payload.get('text') or '').strip()
        source = (payload.get('source') or '').strip()
        marker_key = f"{lat},{lng}|{text}|{source}"
        hidden = load_hidden()
        if marker_key not in hidden:
            hidden.append(marker_key)
            save_hidden(hidden)
        return jsonify({'status':'ok','hidden_count':len(hidden)})
    except Exception as e:
        log.warning(f"hide_marker error: {e}")
        return jsonify({'status':'error','error':str(e)}), 400

@app.route('/unhide_marker', methods=['POST'])
def unhide_marker():
    """Remove previously hidden marker by key or by lat,lng plus text/source prefix match."""
    try:
        payload = request.get_json(force=True) or {}
        key = (payload.get('key') or '').strip()
        hidden = load_hidden()
        changed = False
        if key:
            if key.isdigit():
                idx = int(key)
                if 0 <= idx < len(hidden):
                    del hidden[idx]
                    changed = True
            elif key in hidden:
                hidden.remove(key)
                changed = True
        else:
            lat = payload.get('lat')
            lng = payload.get('lng')
            text = (payload.get('text') or '').strip()
            source = (payload.get('source') or '').strip()
            if lat is not None and lng is not None:
                try:
                    lat_r = round(float(lat), 3)
                    lng_r = round(float(lng), 3)
                except Exception:
                    lat_r = lng_r = None
                base_prefix = f"{lat_r},{lng_r}|" if lat_r is not None else None
                if base_prefix:
                    for h in list(hidden):
                        if not h.startswith(base_prefix):
                            continue
                        try:
                            _, htext, hsource = h.split('|', 2)
                        except ValueError:
                            continue
                        if source and hsource != source:
                            continue
                        if not text or htext.startswith(text) or text.startswith(htext):
                            hidden.remove(h)
                            changed = True
        if changed:
            save_hidden(hidden)
        else:
            log.info(f"unhide_marker: no change for key='{key}' payload={payload}")
        return jsonify({'status': 'ok', 'removed': changed, 'remaining': len(hidden)})
    except Exception as e:
        log.warning(f"unhide_marker error: {e}")
        return jsonify({'status': 'error', 'error': str(e)}), 400

# Guard against duplicate registration if this file is imported twice or a previous
# health endpoint already exists (avoids Flask AssertionError: overwriting endpoint)
if 'health' not in app.view_functions:
    @app.route('/health')
    def health():  # type: ignore
        now = time.time()
        
        # Basic stats + prune visitors
        with ACTIVE_LOCK:
            for vid, meta in list(ACTIVE_VISITORS.items()):
                ts = meta if isinstance(meta,(int,float)) else meta.get('ts',0)
                if now - ts > ACTIVE_TTL:
                    del ACTIVE_VISITORS[vid]
            visitors = len(ACTIVE_VISITORS)
        return jsonify({'status':'ok','messages':len(load_messages()), 'auth': AUTH_STATUS, 'visitors': visitors})

@app.route('/ads.txt')
def ads_txt():
    """Serve ads.txt for ad networks verification"""
    from flask import send_from_directory
    return send_from_directory('static', 'ads.txt', mimetype='text/plain')

@app.route('/robots.txt')
def robots_txt():
    """Serve robots.txt for search engines"""
    return send_from_directory('static', 'robots.txt', mimetype='text/plain')

@app.route('/sitemap.xml')
def sitemap_xml():
    """Serve sitemap.xml for search engines"""
    return send_from_directory('static', 'sitemap.xml', mimetype='application/xml')

@app.route('/presence', methods=['POST'])
def presence():
    """Register active viewers and return synchronized counts per platform."""
    client_ip = request.environ.get('HTTP_X_FORWARDED_FOR', request.remote_addr) or 'unknown'
    rate_key = f"{client_ip}_presence"
    now_time = time.time()
    recent = [ts for ts in request_counts[rate_key] if now_time - ts < PRESENCE_RATE_WINDOW]
    if len(recent) >= PRESENCE_RATE_LIMIT:
        return jsonify({'error': 'presence rate limited', 'retry_after': PRESENCE_RATE_WINDOW}), 429
    recent.append(now_time)
    request_counts[rate_key] = recent

    data = request.get_json(silent=True) or {}
    vid = str(data.get('id') or '').strip()
    if not vid:
        return jsonify({'status': 'error', 'error': 'id required'}), 400

    now = time.time()
    blocked = set(load_blocked())
    if vid in blocked:
        return jsonify({'status': 'blocked'})

    remote_ip = request.headers.get('X-Forwarded-For', request.remote_addr or '')
    ua = request.headers.get('User-Agent', '')[:300]
    platform_label = _normalize_platform(data.get('platform') or '', ua)

    stats = _load_visit_stats()
    if vid not in stats:
        stats[vid] = now
        if int(now) % 200 == 0:
            _prune_visit_stats()
        _save_visit_stats()

    try:
        _update_recent_visits(vid)
    except Exception as e:
        log.warning(f"recent visits update failed: {e}")

    try:
        record_visit_sql(vid, now, remote_ip)
    except Exception:
        pass

    db_first = None
    try:
        with _visits_db_conn() as conn:
            cur = conn.execute("SELECT first_seen FROM visits WHERE id=?", (vid,))
            row = cur.fetchone()
            if row and row[0]:
                try:
                    db_first = float(row[0])
                except Exception:
                    db_first = None
    except Exception:
        pass

    with ACTIVE_LOCK:
        prev = ACTIVE_VISITORS.get(vid) if isinstance(ACTIVE_VISITORS.get(vid), dict) else {}
        first_seen = prev.get('first') or db_first or stats.get(vid) or now
        ACTIVE_VISITORS[vid] = {
            'ts': now,
            'first': first_seen,
            'ip': remote_ip,
            'ua': prev.get('ua') or ua,
            'platform': platform_label
        }
        for key, meta in list(ACTIVE_VISITORS.items()):
            ts = meta if isinstance(meta, (int, float)) else meta.get('ts', 0)
            if now - ts > ACTIVE_TTL:
                del ACTIVE_VISITORS[key]

        platform_counts = {}
        for meta in ACTIVE_VISITORS.values():
            bucket = meta.get('platform') or 'web'
            platform_counts[bucket] = platform_counts.get(bucket, 0) + 1
        total = sum(platform_counts.values())

    apps_total = platform_counts.get('android', 0) + platform_counts.get('ios', 0)
    payload = {
        'status': 'ok',
        'visitors': total,
        'platforms': {
            'web': platform_counts.get('web', 0),
            'android': platform_counts.get('android', 0),
            'ios': platform_counts.get('ios', 0),
            'other': sum(v for k, v in platform_counts.items() if k not in VALID_PLATFORMS)
        },
        'apps': apps_total
    }
    return jsonify(payload)

@app.route('/raion_alarms')
def raion_alarms():
    # ...existing code...
    
    # Expose current active district air alarms
    out = []
    now = time.time()
    for key, info in list(RAION_ALARMS.items()):
        # Optional expiry cleanup (e.g., 3h stale auto-clear)
        if now - info.get('since', now) > 3*3600:
            RAION_ALARMS.pop(key, None)
            continue
        out.append({
            'raion': key,
            'place': info['place'],
            'lat': info['lat'],
            'lng': info['lng'],
            'since': info['since']
        })
    return jsonify({'alarms': out, 'count': len(out)})

# SSE stream endpoint
@app.route('/stream')
def stream():
    def gen():
        q = queue.Queue()
        SUBSCRIBERS.add(q)
        last_ping = time.time()
        try:
            while True:
                try:
                    item = q.get(timeout=5)
                    yield f'data: {item}\n\n'
                except Exception:
                    pass
                now_t = time.time()
                if now_t - last_ping > 25:
                    last_ping = now_t
                    yield ': ping\n\n'
        except GeneratorExit:
            pass
        finally:
            SUBSCRIBERS.discard(q)
    headers = {
        'Cache-Control': 'no-store',
        'Connection': 'keep-alive',
        'X-Accel-Buffering': 'no'
    }
    return Response(gen(), mimetype='text/event-stream', headers=headers)

def broadcast_new(tracks):
    """Send new geo tracks to all connected SSE subscribers."""
    if not tracks:
        return
    payload = json.dumps({'tracks': tracks}, ensure_ascii=False)
    dead = []
    for q in list(SUBSCRIBERS):
        try:
            q.put_nowait(payload)
        except Exception:
            dead.append(q)
    for d in dead:
        SUBSCRIBERS.discard(d)
def broadcast_control(event:dict):
    try:
        payload = json.dumps({'control': event}, ensure_ascii=False)
    except Exception:
        return
    dead = []
    for q in list(SUBSCRIBERS):
        try:
            q.put_nowait(payload)
        except Exception:
            dead.append(q)

# ---------------- Admin & blocking endpoints -----------------
def _require_secret(req):
    if not AUTH_SECRET:
        return True
    supplied = req.args.get('secret') or req.headers.get('X-Auth-Secret') or req.form.get('secret')
    return supplied and supplied == AUTH_SECRET

@app.route('/version')
def version_check():
    return {'version': '2024-12-06-oblast-raion-fix', 'timestamp': time.time()}

@app.route('/test_oblast_raion')
def test_oblast_raion():
    if not _require_secret(request):
        return Response('Forbidden', status=403)
    
    test_text = "Загроза застосування БПЛА. Перейдіть в укриття! | чернігівська область (чернігівський район), київська область (вишгородський район), сумська область (сумський, конотопський райони) - загроза ударних бпла!"
    result = process_message(test_text, 'test_99999', '2024-12-06', 'test_channel')
    
    return {
        'test_text': test_text,
        'result': result,
        'debug_logs': [log for log in DEBUG_LOGS if log.get('category') == 'oblast_raion'][-10:]
    }

@app.route('/test-pusk')
def test_pusk_icon():
    """Test route to debug pusk.png display issues"""
    with open('/Users/vladimirmalik/Desktop/render2/test_pusk_icon.html', 'r', encoding='utf-8') as f:
        return f.read()

@app.route('/admin')
def admin_panel():
    if not _require_secret(request):
        return Response('Forbidden', status=403)
    # Ensure rolling recent visits file is seeded from durable SQLite (survives redeploy)
    try:
        _seed_recent_from_sql()
    except Exception:
        pass
    now = time.time()
    # Merge ACTIVE_VISITORS volatile data with persistent DB to avoid session age resets on restart
    # Strategy: build dict from DB for active window; overlay runtime (for ip/ua freshness)
    db_active = {s['id']: s for s in _active_sessions_from_db(ACTIVE_TTL)}
    with ACTIVE_LOCK:
        visitors = []
        for vid, meta in ACTIVE_VISITORS.items():
            if isinstance(meta,(int,float)):
                mem_first = meta
                mem_last = meta
                db_sess = db_active.get(vid)
                if db_sess:
                    first_ts = db_sess.get('first') or mem_first
                    last_ts = db_sess.get('last') or mem_last
                else:
                    first_ts = mem_first
                    last_ts = mem_last
            else:
                mem_first = meta.get('first') or meta.get('ts', now)
                mem_last = meta.get('ts', mem_first)
                db_sess = db_active.get(vid)
                if db_sess:
                    # Use earlier first (older session start) and later last (most recent activity)
                    first_ts = min(mem_first, db_sess.get('first') or mem_first)
                    last_ts = max(mem_last, db_sess.get('last') or mem_last)
                else:
                    first_ts, last_ts = mem_first, mem_last
            if first_ts > last_ts:
                first_ts, last_ts = last_ts, first_ts
            sess_age = int(now - first_ts)
            idle_age = int(now - last_ts)
            ua = (meta.get('ua') if isinstance(meta, dict) else '') or ''
            ip = (meta.get('ip') if isinstance(meta, dict) else '') or ''
            visitors.append({
                'id': vid,
                'ip': ip,
                'age': sess_age,
                'age_fmt': _fmt_age(sess_age),
                'ua': ua,
                'ua_short': _ua_label(ua) if ua else '',
                'last_seen': _fmt_age(idle_age)
            })
    blocked = load_blocked()
    # Load raw (pending geo) messages
    all_msgs = load_messages()
    raw_msgs = [m for m in reversed(all_msgs) if m.get('pending_geo')][:100]  # latest 100
    # Collect last N geo markers (exclude pending geo) for hide management
    recent_markers = [m for m in reversed(all_msgs) if m.get('lat') and m.get('lng') and not m.get('pending_geo')][:120]
    # --- Visit stats aggregation (prefer durable SQLite to survive redeploy) ---
    daily_unique, week_unique = sql_unique_counts()
    if daily_unique is None:
        # fallback to rolling sets file if DB unavailable
        daily_unique, week_unique = _recent_counts()
    if daily_unique is None:  # final fallback to json stats
        stats = _load_visit_stats()
        tz = pytz.timezone('Europe/Kyiv')
        now_dt = datetime.now(tz)
        today_str = now_dt.strftime('%Y-%m-%d')
        week_cut = now_dt - timedelta(days=7)
        daily_unique = 0
        week_unique = 0
        for vid, ts in stats.items():
            try:
                tsf = float(ts)
            except Exception:
                continue
            dt = datetime.fromtimestamp(tsf, tz)
            if dt.strftime('%Y-%m-%d') == today_str:
                daily_unique += 1
            if dt >= week_cut:
                week_unique += 1
    hidden_keys = load_hidden()
    parsed_hidden = []
    for hk in hidden_keys:
        try:
            coord_part, text_part, source_part = hk.split('|',2)
            lat_str, lng_str = coord_part.split(',',1)
            parsed_hidden.append({'lat':lat_str,'lng':lng_str,'text':text_part,'source':source_part,'key':hk})
        except Exception:
            continue
    return render_template(
        'admin.html',
        visitors=visitors,
        blocked=blocked,
        raw_msgs=raw_msgs,
        raw_count=len([m for m in all_msgs if m.get('pending_geo')]),
        secret=(request.args.get('secret') or ''),
        monitor_period=MONITOR_PERIOD_MINUTES,
        markers=recent_markers,
        daily_unique=daily_unique,
        week_unique=week_unique,
        hidden_markers=parsed_hidden,
        neg_geocode=list(_load_neg_geocode_cache().items())[:150],
        debug_logs=DEBUG_LOGS,
        redirect_stats=get_redirect_stats()
    )

@app.route('/admin/clear_debug_logs', methods=['POST'])
def clear_debug_logs():
    if not _require_secret(request):
        return jsonify({'status': 'forbidden'}), 403
    global DEBUG_LOGS
    DEBUG_LOGS.clear()
    return jsonify({'status': 'ok', 'cleared': True})

@app.route('/admin/set_monitor_period', methods=['POST'])
def set_monitor_period():
    if not _require_secret(request):
        return jsonify({'status': 'forbidden'}), 403
    global MONITOR_PERIOD_MINUTES
    payload = request.get_json(silent=True) or request.form
    try:
        val = int(payload.get('value'))
        if not (1 <= val <= 360):
            raise ValueError('out of range')
        MONITOR_PERIOD_MINUTES = val
        save_config()
        print(f"[DEBUG] MONITOR_PERIOD_MINUTES updated to {MONITOR_PERIOD_MINUTES} minutes")
        return jsonify({'status':'ok','monitor_period':MONITOR_PERIOD_MINUTES})
    except Exception as e:
        return jsonify({'status':'error','error':str(e)}), 400

@app.route('/admin/neg_geocode_clear', methods=['POST'])
def admin_neg_geocode_clear():
    if not _require_secret(request):
        return jsonify({'status':'forbidden'}), 403
    global _neg_geocode_cache
    _neg_geocode_cache = {}
    _save_neg_geocode_cache()
    return jsonify({'status':'ok','cleared':True})

@app.route('/admin/neg_geocode_delete', methods=['POST'])
def admin_neg_geocode_delete():
    if not _require_secret(request):
        return jsonify({'status':'forbidden'}), 403
    payload = request.get_json(silent=True) or {}
    name = (payload.get('name') or '').strip().lower()
    if not name:
        return jsonify({'status':'error','error':'name required'}),400
    cache = _load_neg_geocode_cache()
    if name in cache:
        del cache[name]
        _save_neg_geocode_cache()
        return jsonify({'status':'ok','deleted':True})
    return jsonify({'status':'error','error':'not found'}),404

@app.route('/admin/stats', methods=['GET'])
def admin_stats():
    """Get comprehensive system statistics for admin dashboard"""
    if not _require_secret(request):
        return jsonify({'status':'forbidden'}), 403
    
    try:
        all_msgs = load_messages()
        now = time.time()
        tz = pytz.timezone('Europe/Kyiv')
        
        # Message statistics
        total_messages = len(all_msgs)
        pending_geo = len([m for m in all_msgs if m.get('pending_geo')])
        with_coordinates = len([m for m in all_msgs if m.get('lat') and m.get('lng')])
        
        # Recent activity (last 24h)
        cutoff_24h = now - 86400
        recent_msgs = [m for m in all_msgs if _msg_timestamp(m) > cutoff_24h]
        
        # Threat type breakdown
        threat_counts = {}
        for msg in all_msgs:
            if not msg.get('pending_geo') and msg.get('lat') and msg.get('lng'):
                threat_type = msg.get('threat_type', 'unknown')
                threat_counts[threat_type] = threat_counts.get(threat_type, 0) + 1
        
        # System health
        with ACTIVE_LOCK:
            active_users = len(ACTIVE_VISITORS)
        blocked_users = len(load_blocked())
        hidden_markers = len(load_hidden())
        neg_cache_size = len(_load_neg_geocode_cache())
        debug_logs_count = len(DEBUG_LOGS)
        
        return jsonify({
            'status': 'ok',
            'stats': {
                'messages': {
                    'total': total_messages,
                    'pending_geo': pending_geo,
                    'with_coordinates': with_coordinates,
                    'recent_24h': len(recent_msgs)
                },
                'threats': threat_counts,
                'system': {
                    'active_users': active_users,
                    'blocked_users': blocked_users,
                    'hidden_markers': hidden_markers,
                    'neg_cache_size': neg_cache_size,
                    'debug_logs': debug_logs_count,
                    'monitor_period': MONITOR_PERIOD_MINUTES
                },
                'timestamp': now
            }
        })
    except Exception as e:
        return jsonify({'status': 'error', 'error': str(e)}), 500

@app.route('/admin/cleanup', methods=['POST'])
def admin_cleanup():
    """Clean up old data to maintain performance"""
    if not _require_secret(request):
        return jsonify({'status':'forbidden'}), 403
    
    payload = request.get_json(silent=True) or {}
    days_to_keep = int(payload.get('days', 7))  # Keep last 7 days by default
    
    try:    
        cutoff_time = time.time() - (days_to_keep * 86400)
        
        # Clean old messages
        all_msgs = load_messages()
        old_count = len(all_msgs)
        new_msgs = [m for m in all_msgs if _msg_timestamp(m) > cutoff_time]
        
        # Always keep at least 100 most recent messages
        if len(new_msgs) < 100 and len(all_msgs) >= 100:
            new_msgs = sorted(all_msgs, key=_msg_timestamp, reverse=True)[:100]
        
        save_messages(new_msgs)
        
        # Clean old debug logs (keep last 500)
        global DEBUG_LOGS
        if len(DEBUG_LOGS) > 500:
            DEBUG_LOGS = DEBUG_LOGS[-500:]
        
        # Clean old visitor data from SQLite
        try:
            conn = sqlite3.connect(VISIT_DB_PATH)
            c = conn.cursor()
            c.execute("DELETE FROM visits WHERE first_seen < ?", (cutoff_time,))
            deleted_visits = c.rowcount
            conn.commit()
            conn.close()
        except Exception:
            deleted_visits = 0
        
        return jsonify({
            'status': 'ok',
            'cleaned': {
                'messages': old_count - len(new_msgs),
                'debug_logs': max(0, len(DEBUG_LOGS) - 500),
                'visitor_records': deleted_visits
            },
            'remaining': {
                'messages': len(new_msgs),
                'debug_logs': len(DEBUG_LOGS)
            }
        })
    except Exception as e:
        return jsonify({'status': 'error', 'error': str(e)}), 500

@app.route('/admin/export', methods=['GET'])
def admin_export():
    """Export data for backup/analysis"""
    if not _require_secret(request):
        return jsonify({'status':'forbidden'}), 403
    
    export_type = request.args.get('type', 'messages')
    
    try:
        if export_type == 'messages':
            all_msgs = load_messages()
            # Remove sensitive data
            clean_msgs = []
            for msg in all_msgs:
                clean_msg = {k: v for k, v in msg.items() if k not in ['id']}
                clean_msgs.append(clean_msg)
            return jsonify({'status': 'ok', 'data': clean_msgs, 'count': len(clean_msgs)})
        
        elif export_type == 'stats':
            with ACTIVE_LOCK:
                active_count = len(ACTIVE_VISITORS)
            
            return jsonify({
                'status': 'ok',
                'data': {
                    'active_users': active_count,
                    'blocked_users': len(load_blocked()),
                    'hidden_markers': len(load_hidden()),
                    'neg_cache_entries': len(_load_neg_geocode_cache()),
                    'debug_logs': len(DEBUG_LOGS),
                    'monitor_period': MONITOR_PERIOD_MINUTES,
                    'export_time': time.time()
                }
            })
        
        else:
            return jsonify({'status': 'error', 'error': 'Invalid export type'}), 400
    
    except Exception as e:
        return jsonify({'status': 'error', 'error': str(e)}), 500
        _save_neg_geocode_cache()
        return jsonify({'status':'ok','removed':name})
    return jsonify({'status':'ok','removed':None})

@app.route('/block', methods=['POST'])
def block_id():
    if not _require_secret(request):
        return jsonify({'status':'forbidden'}), 403
    payload = request.get_json(silent=True) or request.form
    vid = (payload or {}).get('id')
    if not vid:
        return jsonify({'status':'error','error':'id required'}), 400
    blocked = load_blocked()
    if vid not in blocked:
        blocked.append(vid)
        save_blocked(blocked)
    # push control event so client can self-block immediately
    broadcast_control({'type':'block','id':vid})
    return jsonify({'status':'ok','blocked':blocked})

@app.route('/unblock', methods=['POST'])
def unblock_id():
    if not _require_secret(request):
        return jsonify({'status':'forbidden'}), 403
    payload = request.get_json(silent=True) or request.form
    vid = (payload or {}).get('id')
    if not vid:
        return jsonify({'status':'error','error':'id required'}), 400
    blocked = load_blocked()
    if vid in blocked:
        blocked.remove(vid)
        save_blocked(blocked)
    return jsonify({'status':'ok','blocked':blocked})

@app.route('/admin/hidden_markers')
def admin_hidden_markers():
    """Return list of all hidden markers with metadata."""
    if not _require_secret(request):
        return jsonify({'status':'forbidden'}), 403
    hidden_keys = load_hidden()
    hidden_list = []
    for key in hidden_keys:
        try:
            parts = key.split('|', 2)
            if len(parts) >= 3:
                lat_lng, text, source = parts
                lat_str, lng_str = lat_lng.split(',')
                hidden_list.append({
                    'lat': float(lat_str),
                    'lng': float(lng_str),
                    'text': text,
                    'source': source,
                    'key': key
                })
        except Exception as e:
            log.warning(f"Failed to parse hidden marker key: {key}, error: {e}")
    return jsonify({'status':'ok', 'hidden': hidden_list, 'count': len(hidden_list)})

@app.route('/admin/unhide_marker', methods=['POST'])
def admin_unhide_marker():
    """Unhide a marker (alias for /unhide_marker with auth check)."""
    if not _require_secret(request):
        return jsonify({'status':'forbidden'}), 403
    return unhide_marker()

def _fmt_age(age_seconds:int)->str:
    # Format seconds to H:MM:SS (or M:SS if <1h)
    if age_seconds < 3600:
        m, s = divmod(age_seconds, 60)
        return f"{m}:{s:02d}"
    h, rem = divmod(age_seconds, 3600)
    m, s = divmod(rem, 60)
    return f"{h}:{m:02d}:{s:02d}"

def _ua_label(ua:str)->str:
    u = ua.lower()
    # Simple detection heuristics
    if 'android' in u:
        if 'wv' in u or 'version/' in u:
            base = 'Android WebView'
        else:
            base = 'Android'
    elif 'iphone' in u or 'ipad' in u or 'ipod' in u:
        base = 'iOS'
    elif 'mac os x' in u and 'mobile' not in u:
        base = 'macOS'
    elif 'windows nt' in u:
        base = 'Windows'
    elif 'linux' in u:
        base = 'Linux'
    else:
        base = 'Other'
    # Browser
    browser = 'Browser'
    if 'chrome/' in u and 'edg/' not in u and 'opr/' not in u:
        browser = 'Chrome'
    elif 'edg/' in u:
        browser = 'Edge'
    elif 'firefox/' in u:
        browser = 'Firefox'
    elif 'safari/' in u and 'chrome/' not in u:
        browser = 'Safari'
    elif 'opr/' in u or 'opera' in u:
        browser = 'Opera'
    return f"{base} {browser}"

def _load_opencage_cache():
    global _opencage_cache
    if _opencage_cache is not None:
        return _opencage_cache
    if os.path.exists(OPENCAGE_CACHE_FILE):
        try:
            with open(OPENCAGE_CACHE_FILE, 'r', encoding='utf-8') as f:
                _opencage_cache = json.load(f)
        except Exception:
            _opencage_cache = {}
    else:
        _opencage_cache = {}
    return _opencage_cache

def _save_opencage_cache():
    if _opencage_cache is None:
        return
    try:
        with open(OPENCAGE_CACHE_FILE, 'w', encoding='utf-8') as f:
            json.dump(_opencage_cache, f, ensure_ascii=False, indent=2)
    except Exception as e:
        log.warning(f"Failed saving OpenCage cache: {e}")


SETTLEMENTS_FILE = os.getenv('SETTLEMENTS_FILE', 'settlements_ua.json')
SETTLEMENTS_INDEX = {}
SETTLEMENTS_ORDERED = []  # (RAION_FALLBACK consolidated earlier; duplicate definition removed)

# --------------- Optional Git auto-commit settings ---------------
GIT_AUTO_COMMIT = os.getenv('GIT_AUTO_COMMIT', '0') not in ('0','false','False','')
GIT_REPO_SLUG = os.getenv('GIT_REPO_SLUG')  # e.g. 'vavaika22423232/neptun'
GIT_SYNC_TOKEN = os.getenv('GIT_SYNC_TOKEN')  # GitHub PAT (classic or fine-grained) with repo write
GIT_COMMIT_INTERVAL = int(os.getenv('GIT_COMMIT_INTERVAL', '180'))  # seconds between commits
_last_git_commit = 0

# Delay before first Telegram connect (helps избежать пересечения старого и нового инстанса при деплое)
FETCH_START_DELAY = int(os.getenv('FETCH_START_DELAY', '0'))  # seconds

def maybe_git_autocommit():
    """If enabled, commit & push updated messages.json back to GitHub.
    Requirements:
      - Set GIT_AUTO_COMMIT=1
      - Provide GIT_REPO_SLUG (owner/repo)
      - Provide GIT_SYNC_TOKEN (PAT with repo write)
    The container build must include git (Render base images do).
    Commits throttled by GIT_COMMIT_INTERVAL seconds.
    """
    global _last_git_commit
    if not GIT_AUTO_COMMIT or not GIT_REPO_SLUG or not GIT_SYNC_TOKEN:
        return
    now = time.time()
    if now - _last_git_commit < GIT_COMMIT_INTERVAL:
        return
    if not os.path.isdir('.git'):
        raise RuntimeError('Not a git repo')
    # Configure user (once)
    def run(cmd):
        return subprocess.run(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
    run('git config user.email "bot@local"')
    run('git config user.name "Auto Sync Bot"')
    # Set remote URL embedding token (avoid logging token!)
    safe_remote = f'https://x-access-token:{GIT_SYNC_TOKEN}@github.com/{GIT_REPO_SLUG}.git'
    # Do not print safe_remote (contains secret)
    # Update origin only if needed
    remotes = run('git remote -v').stdout
    if 'origin' not in remotes or GIT_REPO_SLUG not in remotes:
        run('git remote remove origin')
        run(f'git remote add origin "{safe_remote}"')
    # Stage & commit if there is a change
    run(f'git add {MESSAGES_FILE}')
    status = run('git status --porcelain').stdout
    if MESSAGES_FILE not in status:
        return  # no actual diff
    commit_msg = f'Update {MESSAGES_FILE} (auto)'  # no secrets
    run(f'git commit -m "{commit_msg}"')
    push_res = run('git push origin HEAD:main')
    if push_res.returncode == 0:
        _last_git_commit = now
    else:
        # If push fails (e.g., diverged), attempt pull+rebase then push
        run('git fetch origin')
        run('git rebase origin/main || git rebase --abort')
        push_res2 = run('git push origin HEAD:main')
        if push_res2.returncode == 0:
            _last_git_commit = now
        # else: give up silently to avoid spamming logs

def _load_settlements():
    global SETTLEMENTS_INDEX, SETTLEMENTS_ORDERED
    if not os.path.exists(SETTLEMENTS_FILE):
        return
    try:
        with open(SETTLEMENTS_FILE, 'r', encoding='utf-8') as f:
            data = json.load(f)
        # Expect list of dicts with keys: name, lat, lng (or lon)
        for item in data:
            try:
                name = item.get('name') or item.get('n')
                if not name:
                    continue
                lat = float(item.get('lat'))
                lng = float(item.get('lng') or item.get('lon'))
                key = name.strip().lower()
                if key and key not in SETTLEMENTS_INDEX:
                    SETTLEMENTS_INDEX[key] = (lat, lng)
            except Exception:
                continue
        # Order names by length descending to match longer first (avoids partial overshadowing)
        SETTLEMENTS_ORDERED = sorted(SETTLEMENTS_INDEX.keys(), key=len, reverse=True)[:50000]  # hard cap
        log.info(f'Loaded settlements: {len(SETTLEMENTS_INDEX)} (using top {len(SETTLEMENTS_ORDERED)})')
    except Exception as e:
        log.warning(f'Failed to load settlements file {SETTLEMENTS_FILE}: {e}')

_load_settlements()

def geocode_opencage(place: str):
    if not OPENCAGE_API_KEY:
        return None
    cache = _load_opencage_cache()
    key = place.strip().lower()
    now = int(datetime.utcnow().timestamp())
    if key in cache:
        entry = cache[key]
        if now - entry.get('ts', 0) < OPENCAGE_TTL:
            return tuple(entry['coords']) if entry['coords'] else None
    import requests
    try:
        resp = requests.get('https://api.opencagedata.com/geocode/v1/json', params={
            'q': place,
            'key': OPENCAGE_API_KEY,
            'language': 'uk',
            'limit': 1,
            'countrycode': 'ua'
        }, timeout=6)
        if resp.status_code == 200:
            data = resp.json()
            if data.get('results'):
                g = data['results'][0]['geometry']
                coords = (g['lat'], g['lng'])
                cache[key] = {'ts': now, 'coords': coords}
                _save_opencage_cache()
                return coords
        cache[key] = {'ts': now, 'coords': None}
        _save_opencage_cache()
        return None
    except Exception as e:
        log.warning(f"OpenCage error for '{place}': {e}")
        cache[key] = {'ts': now, 'coords': None}
        _save_opencage_cache()
        return None

"""(Removed duplicate legacy process_message; canonical version defined earlier.)"""

# ----------------------- Deferred initialization hooks -----------------------
@app.before_request
def _init_background():
    global INIT_ONCE
    if INIT_ONCE:
        return
    INIT_ONCE = True
    _startup_diagnostics()
    # Start background workers
    try:
        start_fetch_thread()
    except Exception as e:
        log.error(f'Failed to start fetch thread: {e}\n{traceback.format_exc()}')
    try:
        start_session_watcher()
    except Exception as e:
        log.error(f'Failed to start session watcher: {e}\n{traceback.format_exc()}')

@app.route('/startup_diag')
def startup_diag():
    """Expose current diagnostic snapshot (no secrets)."""
    try:
        info = {
            'pid': os.getpid(),
            'python': sys.version.split()[0],
            'platform': platform.platform(),
            'channels': CHANNELS,
            'authorized': AUTH_STATUS,
            'messages_file_exists': os.path.exists(MESSAGES_FILE),
            'messages_count': len(load_messages()),
            'fetch_thread_started': FETCH_THREAD_STARTED,
            'session_present': bool(session_str),
            'retention_minutes': MESSAGES_RETENTION_MINUTES,
            'retention_max_count': MESSAGES_MAX_COUNT,
            'subscribers': len(SUBSCRIBERS)
        }
        return jsonify(info)
    except Exception as e:
        return jsonify({'error': str(e)}), 500

# Manual trigger (idempotent) if needed before first page hit
@app.route('/startup_init', methods=['POST'])
def startup_init():
    _init_background()
    return jsonify({'status': 'ok'})

# BANDWIDTH PROTECTION: Custom static route will compete with Flask's built-in route
# Flask will prioritize our custom route due to specificity

# Graceful shutdown handler
import atexit
import signal

# Force reload endpoints for admin
@app.route('/api/force-reload-status')
def force_reload_status():
    """Check if force reload flag is active"""
    global FORCE_RELOAD_TIMESTAMP
    with FORCE_RELOAD_LOCK:
        current_time = time.time()
        # Check if force reload is still active (within duration window)
        should_reload = (FORCE_RELOAD_TIMESTAMP > 0 and 
                        (current_time - FORCE_RELOAD_TIMESTAMP) < FORCE_RELOAD_DURATION)
    return jsonify({'reload': should_reload})

@app.route('/admin/trigger-force-reload', methods=['POST'])
def trigger_force_reload():
    """Admin endpoint to trigger force reload for all users"""
    if not _require_secret(request):
        return Response('Forbidden', status=403)
    
    global FORCE_RELOAD_TIMESTAMP
    with FORCE_RELOAD_LOCK:
        FORCE_RELOAD_TIMESTAMP = time.time()
    
    log.info("🔄 ADMIN: Force reload triggered for all users (active for {} seconds)".format(FORCE_RELOAD_DURATION))
    return jsonify({'success': True, 'message': 'Force reload activated for {} seconds'.format(FORCE_RELOAD_DURATION)})

def shutdown_scheduler():
    """Shutdown scheduler gracefully"""
    if SCHEDULE_UPDATER_AVAILABLE and 'scheduler' in globals():
        try:
            if scheduler.running:
                log.info("Shutting down scheduler...")
                scheduler.shutdown(wait=False)
                log.info("✅ Scheduler shutdown complete")
        except Exception as e:
            log.error(f"Error shutting down scheduler: {e}")

# Register shutdown handlers
atexit.register(shutdown_scheduler)
signal.signal(signal.SIGTERM, lambda sig, frame: shutdown_scheduler())
signal.signal(signal.SIGINT, lambda sig, frame: shutdown_scheduler())

if __name__ == '__main__':
    # Local / container direct run (not needed if a WSGI server like gunicorn is used)
    port = int(os.getenv('PORT', '5000'))
    host = os.getenv('HOST', '0.0.0.0')
    log.info(f'Launching Flask app on {host}:{port}')
    # Eager start (still guarded) so that fetch begins even without first HTTP request locally
    try:
        _init_background()
    except Exception:
        pass
    app.run(host=host, port=port, debug=False)