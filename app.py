
# pyright: reportUnusedVariable=false, reportRedeclaration=false, reportGeneralTypeIssues=false
# pyright: reportUndefinedVariable=false, reportOptionalMemberAccess=false, reportAttributeAccessIssue=false
# type: ignore
# pylint: disable=all
# ---------------- Admin & blocking endpoints -----------------

# ...existing code...

import os, re, json, asyncio, threading, logging, pytz, time, subprocess, queue, sys, platform, traceback, uuid, gc
from collections import defaultdict
from datetime import datetime, timedelta
from flask import Flask, render_template, jsonify, request, Response, send_from_directory, g, redirect
from telethon import TelegramClient
from core.message_store import MessageStore, DeviceStore, FamilyStore
from functools import lru_cache
import hashlib

# MEMORY OPTIMIZATION: Force garbage collection on startup
gc.collect()

# ============================================================================
# HIGH-LOAD OPTIMIZATION: Response caching for API endpoints
# ============================================================================
class ResponseCache:
    """Thread-safe in-memory cache for API responses with TTL."""
    def __init__(self, default_ttl: int = 30):
        self._cache: dict = {}
        self._lock = threading.RLock()
        self.default_ttl = default_ttl
        self.hits = 0
        self.misses = 0
    
    def get(self, key: str):
        with self._lock:
            if key in self._cache:
                data, expires_at = self._cache[key]
                if time.time() < expires_at:
                    self.hits += 1
                    return data
                # Expired
                del self._cache[key]
            self.misses += 1
            return None
    
    def set(self, key: str, data, ttl: int = None):
        with self._lock:
            expires_at = time.time() + (ttl or self.default_ttl)
            self._cache[key] = (data, expires_at)
    
    def clear_expired(self):
        """Remove expired entries (call periodically)."""
        with self._lock:
            now = time.time()
            expired_keys = [k for k, (_, exp) in self._cache.items() if now >= exp]
            for k in expired_keys:
                del self._cache[k]
            return len(expired_keys)
    
    def stats(self) -> dict:
        with self._lock:
            total = self.hits + self.misses
            return {
                'hits': self.hits,
                'misses': self.misses,
                'hit_rate': f"{(self.hits / total * 100):.1f}%" if total > 0 else "0%",
                'cached_items': len(self._cache)
            }

# Global response cache
RESPONSE_CACHE = ResponseCache(default_ttl=30)

# Cached messages - avoid repeated file reads
_MESSAGES_CACHE = {'data': None, 'expires': 0}
_MESSAGES_CACHE_TTL = 5  # 5 second cache for messages

def load_messages_cached():
    """Load messages with caching to reduce disk I/O."""
    global _MESSAGES_CACHE
    now = time.time()
    if _MESSAGES_CACHE['data'] is not None and now < _MESSAGES_CACHE['expires']:
        return _MESSAGES_CACHE['data']
    # Load fresh
    data = MESSAGE_STORE.load()
    _MESSAGES_CACHE = {'data': data, 'expires': now + _MESSAGES_CACHE_TTL}
    return data

def invalidate_messages_cache():
    """Call this after saving new messages."""
    global _MESSAGES_CACHE
    _MESSAGES_CACHE = {'data': None, 'expires': 0}

# ============================================================================
# API PROTECTION - Production-grade hardening (prevents 23GB+ traffic spikes)
# ============================================================================
try:
    from api_protection import (
        init_protection,
        protected_endpoint,
        rate_limited,
        size_guarded,
        check_rate_limit,
        check_response_size,
        compute_etag,
        check_etag_match,
        get_pagination_params,
        paginate_list,
        record_response_size,
        get_since_timestamp,
        filter_by_since,
        supports_since_param,
        get_protection_stats,
        get_protection_status_endpoint,
        MAX_RESPONSE_SIZE_BYTES,
        MAX_PAGE_SIZE,
        DEFAULT_PAGE_SIZE,
        MAX_TOTAL_ITEMS,
    )
    API_PROTECTION_ENABLED = True
    print("INFO: API Protection module loaded - production hardening active")
except ImportError as e:
    API_PROTECTION_ENABLED = False
    print(f"WARNING: API Protection module not available: {e}")
    # Fallback stubs
    def protected_endpoint(*args, **kwargs):
        def decorator(f): return f
        return decorator
    def rate_limited(f): return f
    def size_guarded(*args, **kwargs):
        def decorator(f): return f
        return decorator
    def init_protection(app): return False
    MAX_RESPONSE_SIZE_BYTES = 5 * 1024 * 1024
    MAX_PAGE_SIZE = 100
    DEFAULT_PAGE_SIZE = 50
    MAX_TOTAL_ITEMS = 500
# ============================================================================

# Import expanded Ukraine addresses database
try:
    from ukraine_addresses_db import UKRAINE_ADDRESSES_DB, UKRAINE_CITIES
    print(f"INFO: Ukraine addresses database loaded: {len(UKRAINE_ADDRESSES_DB)} addresses")
except Exception as e:
    UKRAINE_ADDRESSES_DB = {}
    UKRAINE_CITIES = []
    print(f"WARNING: Ukraine addresses database not available: {e}")

# Import comprehensive Ukrainian settlements database (26000+ entries)
# MEMORY OPTIMIZATION: Load only if enough memory, otherwise use empty dict
# Default to loading the DB (needed for village-level geocoding)
MEMORY_OPTIMIZED = os.environ.get('MEMORY_OPTIMIZED', 'false').lower() == 'true'

if MEMORY_OPTIMIZED:
    # Don't load the huge settlements database - saves ~100MB RAM
    UKRAINE_ALL_SETTLEMENTS = {}
    UKRAINE_SETTLEMENTS_BY_OBLAST = {}
    print("INFO: MEMORY_OPTIMIZED=true - Large settlements database skipped to save RAM")
else:
    try:
        from ukraine_all_settlements import UKRAINE_ALL_SETTLEMENTS, UKRAINE_SETTLEMENTS_BY_OBLAST
        print(f"INFO: Ukraine ALL settlements loaded: {len(UKRAINE_ALL_SETTLEMENTS)} simple + {len(UKRAINE_SETTLEMENTS_BY_OBLAST)} oblast-aware entries")
    except Exception as e:
        UKRAINE_ALL_SETTLEMENTS = {}
        UKRAINE_SETTLEMENTS_BY_OBLAST = {}
        print(f"WARNING: Ukraine ALL settlements not available: {e}")

# SpaCy integration DISABLED to save memory (~150MB)
# Enable only if server has >1GB RAM
SPACY_AVAILABLE = False
nlp = None
print("INFO: SpaCy DISABLED to save memory")

# Nominatim geocoding integration - DISABLED (causes timeouts on Render)
# Was causing 30+ minute startup delays
NOMINATIM_AVAILABLE = False
def get_coordinates_nominatim(city_name, region=None):
    return None

# Groq AI integration for intelligent geocoding
GROQ_API_KEY = os.getenv('GROQ_API_KEY', '')
GROQ_MODEL = 'llama-3.3-70b-versatile'
GROQ_ENABLED = bool(GROQ_API_KEY)

# AI request caching and rate limiting
_groq_cache = {}  # Simple in-memory cache {hash: (result, timestamp)}
_groq_cache_ttl = 3600  # Cache TTL: 60 min (was 30 min) - reduce API calls significantly
_groq_last_request = 0  # Timestamp of last request
_groq_min_interval = 3.0  # Minimum 3 seconds between requests (was 2)
_groq_daily_cooldown_until = 0  # If set, skip ALL AI until this timestamp
_groq_429_backoff = 0  # Exponential backoff counter
_groq_requests_this_minute = 0  # Counter for requests in current minute
_groq_minute_start = 0  # Start of current minute window
_groq_max_per_minute = 5  # Max 5 requests per minute (cost optimization)

def _get_groq_cache_key(text):
    """Generate cache key for AI request"""
    import hashlib
    return hashlib.md5(text.encode()).hexdigest()[:16]

def _groq_is_available():
    """Check if Groq AI is currently available (not in cooldown)"""
    global _groq_daily_cooldown_until
    if not GROQ_ENABLED:
        return False
    if _groq_daily_cooldown_until > 0:
        import time as time_module
        if time_module.time() < _groq_daily_cooldown_until:
            return False
        else:
            # Cooldown expired, reset
            _groq_daily_cooldown_until = 0
            print("INFO: Groq AI cooldown expired, resuming")
    return True

def _groq_handle_429(error_message: str):
    """Handle 429 rate limit error - set global cooldown"""
    global _groq_daily_cooldown_until, _groq_429_backoff
    import time as time_module
    import re
    
    # Parse wait time from error message
    # Example: "Please try again in 4m56.352s"
    wait_match = re.search(r'try again in (\d+)m([\d.]+)s', error_message)
    if wait_match:
        minutes = int(wait_match.group(1))
        seconds = float(wait_match.group(2))
        wait_seconds = minutes * 60 + seconds + 60  # Add 1 min buffer
    else:
        # Default: 10 minutes cooldown with exponential backoff
        _groq_429_backoff = min(_groq_429_backoff + 1, 6)  # Max 6 = 640 seconds
        wait_seconds = 60 * (2 ** _groq_429_backoff)  # 2, 4, 8, 16, 32, 64 minutes
    
    _groq_daily_cooldown_until = time_module.time() + wait_seconds
    print(f"WARNING: Groq rate limit hit! Pausing ALL AI requests for {wait_seconds/60:.1f} minutes")

def _groq_rate_limit():
    """Smart rate limiter for Groq API"""
    global _groq_last_request, _groq_429_backoff, _groq_requests_this_minute, _groq_minute_start
    import time as time_module
    
    # Check if in cooldown
    if not _groq_is_available():
        raise Exception("Groq AI in cooldown mode")
    
    now = time_module.time()
    
    # Check per-minute limit
    if now - _groq_minute_start >= 60:
        # New minute, reset counter
        _groq_minute_start = now
        _groq_requests_this_minute = 0
    
    if _groq_requests_this_minute >= _groq_max_per_minute:
        # Too many requests this minute, skip
        remaining = 60 - (now - _groq_minute_start)
        print(f"RATE LIMIT: Groq max {_groq_max_per_minute}/min reached, skipping ({remaining:.0f}s until reset)")
        raise Exception(f"Groq rate limit: {_groq_max_per_minute}/min exceeded")
    
    elapsed = now - _groq_last_request
    if elapsed < _groq_min_interval:
        time_module.sleep(_groq_min_interval - elapsed)
    _groq_last_request = time_module.time()
    _groq_requests_this_minute += 1
    
    # Reset backoff on successful rate limit pass
    if _groq_429_backoff > 0:
        _groq_429_backoff = max(0, _groq_429_backoff - 1)

if GROQ_ENABLED:
    try:
        from groq import Groq
        groq_client = Groq(api_key=GROQ_API_KEY)
        print("INFO: Groq AI initialized successfully")
    except ImportError:
        GROQ_ENABLED = False
        groq_client = None
        print("WARNING: Groq library not installed. Run: pip install groq")
    except Exception as e:
        GROQ_ENABLED = False
        groq_client = None
        print(f"WARNING: Groq initialization failed: {e}")
else:
    groq_client = None
    print("INFO: Groq AI disabled (no API key)")

# Context-aware geocoding integration
try:
    from context_aware_geocoder import get_context_aware_geocoding
    CONTEXT_GEOCODER_AVAILABLE = True
except ImportError:
    CONTEXT_GEOCODER_AVAILABLE = False
    def get_context_aware_geocoding(text):
        return []
        return None
    nlp = None
    SPACY_AVAILABLE = False
    print("WARNING: SpaCy Ukrainian model not available. Using fallback geocoding methods.")
try:
    from telethon.errors import (
        AuthKeyDuplicatedError,
        AuthKeyUnregisteredError,
        FloodWaitError,
        SessionPasswordNeededError
    )
except ImportError:
    # Fallback dummies if some names not present in current Telethon version
    class AuthKeyDuplicatedError(Exception):
        pass
    class AuthKeyUnregisteredError(Exception):
        pass
    class FloodWaitError(Exception):
        def __init__(self, seconds=60): self.seconds = seconds
    class SessionPasswordNeededError(Exception):
        pass
from telethon.sessions import StringSession
import math

# === Kyiv Directional Enhancement Functions ===
def calculate_bearing(lat1, lon1, lat2, lon2):
    """Calculate bearing from point 1 to point 2 in degrees (0-360)"""
    lat1, lon1, lat2, lon2 = map(math.radians, [lat1, lon1, lat2, lon2])
    
    dlon = lon2 - lon1
    y = math.sin(dlon) * math.cos(lat2)
    x = math.cos(lat1) * math.sin(lat2) - math.sin(lat1) * math.cos(lat2) * math.cos(dlon)
    
    bearing = math.atan2(y, x)
    bearing = math.degrees(bearing)
    return (bearing + 360) % 360

def haversine(coord1, coord2):
    """
    Calculate the great-circle distance between two points on Earth.
    
    Args:
        coord1: tuple (lat, lng) in degrees
        coord2: tuple (lat, lng) in degrees
    
    Returns:
        Distance in kilometers
    """
    R = 6371  # Earth's radius in kilometers
    
    lat1, lon1 = math.radians(coord1[0]), math.radians(coord1[1])
    lat2, lon2 = math.radians(coord2[0]), math.radians(coord2[1])
    
    dlat = lat2 - lat1
    dlon = lon2 - lon1
    
    a = math.sin(dlat / 2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2)**2
    c = 2 * math.asin(math.sqrt(a))
    
    return R * c

def get_kyiv_directional_coordinates(threat_text, original_city="київ"):
    """
    For Kyiv threats, calculate directional coordinates based on threat patterns
    Returns modified coordinates showing approach direction instead of city center
    """
    kyiv_lat, kyiv_lng = 50.4501, 30.5234
    threat_lower = threat_text.lower()
    
    # Try to extract source city/direction from course patterns
    course_patterns = [
        r'бпла.*?курс.*?на.*?київ.*?з\s+([а-яіїєё\s\-\']+?)(?:\s|$|[,\.\!])',
        r'бпла.*?курс.*?на.*?київ.*?від\s+([а-яіїєё\s\-\']+?)(?:\s|$|[,\.\!])', 
        r'([а-яіїєё\s\-\']+?).*?курс.*?на.*?київ',
        r'z\s+([а-яіїєё\s\-\']+?).*?курс.*?на.*?київ'
    ]
    
    source_city = None
    for pattern in course_patterns:
        matches = re.findall(pattern, threat_lower)
        if matches:
            potential_city = matches[0].strip()
            if potential_city and len(potential_city) > 2:
                # Clean up common noise words
                noise_words = {'бпла', 'курсом', 'курс', 'на', 'над', 'області', 'область', 'обл', 'район'}
                clean_city = ' '.join([word for word in potential_city.split() if word not in noise_words])
                if clean_city:
                    source_city = clean_city
                    break
    
    if source_city:
        # Try to find coordinates for source city (we'll need to implement a simple lookup)
        # For now, use some common approach directions
        approach_directions = {
            'чернігів': (51.4982, 31.2893, "↘ Київ"),
            'суми': (50.9077, 34.7981, "↙ Київ"), 
            'харків': (49.9935, 36.2304, "← Київ"),
            'полтава': (49.5883, 34.5514, "↖ Київ"),
            'черкаси': (49.4444, 32.0598, "↑ Київ"),
            'житомир': (50.2547, 28.6587, "→ Київ"),
            'біла церква': (49.7939, 30.1014, "↗ Київ")
        }
        
        if source_city in approach_directions:
            source_lat, source_lng, direction_label = approach_directions[source_city]
            
            # Calculate bearing from source to Kyiv
            bearing = calculate_bearing(source_lat, source_lng, kyiv_lat, kyiv_lng)
            
            # Place marker on approach path (70% of the way from source to Kyiv)
            progress = 0.7  # 70% towards Kyiv
            approach_lat = source_lat + (kyiv_lat - source_lat) * progress
            approach_lng = source_lng + (kyiv_lng - source_lng) * progress
            
            return approach_lat, approach_lng, f"{direction_label} ({int(bearing)}°)", source_city
    
    # Fallback: use directional keywords to offset from center
    direction_offsets = {
        'півдн': (-0.08, 0, "↑ Київ (Пд)"),      # south
        'півден': (-0.08, 0, "↑ Київ (Пд)"), 
        'пн': (0.08, 0, "↓ Київ (Пн)"),          # north
        'північ': (0.08, 0, "↓ Київ (Пн)"),
        'сх': (0, 0.08, "← Київ (Сх)"),          # east  
        'схід': (0, 0.08, "← Київ (Сх)"),
        'зх': (0, -0.08, "→ Київ (Зх)"),         # west
        'захід': (0, -0.08, "→ Київ (Зх)"),
        'пд-сх': (-0.06, 0.06, "↖ Київ (ПдСх)"), # southeast
        'пн-зх': (0.06, -0.06, "↘ Київ (ПнЗх)"), # northwest
    }
    
    for direction, (lat_offset, lng_offset, label) in direction_offsets.items():
        if direction in threat_lower:
            return (kyiv_lat + lat_offset, kyiv_lng + lng_offset, 
                   label, direction)
    
    # Default: return regular Kyiv coordinates
    return kyiv_lat, kyiv_lng, "Київ", None

def extract_shahed_course_info(threat_text):
    """
    Extract course information from Shahed/UAV threat messages
    Returns: (source_city, target_city, direction, bearing, course_type)
    """
    text_lower = threat_text.lower()
    
    # Common course patterns for Shahed/UAV
    course_patterns = [
        # "БпЛА курсом з [source] на [target]"
        r'бпла\s+.*?курс(?:ом)?\s+з\s+([а-яіїєё\s\-\']+?)\s+на\s+([а-яіїєё\s\-\']+?)(?:\s|$|[,\.\!])',
        # "БпЛА курсом на [target] з [source]"  
        r'бпла\s+.*?курс(?:ом)?\s+на\s+([а-яіїєё\s\-\']+?)\s+з\s+([а-яіїєё\s\-\']+?)(?:\s|$|[,\.\!])',
        # "БпЛА з [source] курсом на [target]"
        r'бпла\s+з\s+([а-яіїєё\s\-\']+?)\s+курс(?:ом)?\s+на\s+([а-яіїєё\s\-\']+?)(?:\s|$|[,\.\!])',
        # "БпЛА з [source] у напрямку [target]"
        r'бпла\s+з\s+([а-яіїєё\s\-\']+?)\s+у\s+напрямк[уи]\s+([а-яіїєё\s\-\']+?)(?:\s|$|[,\.\!])',
        # "БпЛА курсом на [target]" (target only)
        r'бпла\s+.*?курс(?:ом)?\s+на\s+([а-яіїєё\s\-\']+?)(?=\s*(?:\n|$|[,\.\!\?;]))',
        # "[count]х БпЛА курс [source]-[target]"
        r'\d*х?\s*бпла\s+курс\s+([а-яіїєё\s\-\']+?)\s*[-–—]\s*([а-яіїєё\s\-\']+?)(?:\s|$|[,\.\!])',
    ]
    
    # Try to extract course information
    for pattern_idx, pattern in enumerate(course_patterns):
        matches = re.findall(pattern, text_lower)
        if matches:
            match = matches[0]
            
            if pattern_idx == 0:  # з source на target
                source = match[0].strip()
                target = match[1].strip()
            elif pattern_idx == 1:  # на target з source  
                target = match[0].strip()
                source = match[1].strip()
            elif pattern_idx == 2:  # з source курсом на target
                source = match[0].strip()
                target = match[1].strip()
            elif pattern_idx == 3:  # з source у напрямку target
                source = match[0].strip()
                target = match[1].strip()
            elif pattern_idx == 4:  # курсом на target (no source)
                source = None
                target = match.strip() if isinstance(match, str) else match[0].strip()
            elif pattern_idx == 5:  # курс source-target
                source = match[0].strip()
                target = match[1].strip()
            
            # Clean up noise words
            noise_words = {'область', 'обл', 'район', 'р-н', 'на', 'з', 'від', 'до'}
            if source:
                source = ' '.join([word for word in source.split() if word not in noise_words]).strip()
            if target:
                target = ' '.join([word for word in target.split() if word not in noise_words]).strip()
            
            # Determine course type
            if source and target:
                course_type = "full_course"  # Full trajectory
            elif target:
                course_type = "target_only"  # Only destination
            else:
                course_type = "unknown"
                
            return {
                'source_city': source,
                'target_city': target,
                'course_direction': f"на {target}" if target else None,
                'raw_direction': None,
                'course_type': course_type
            }
    
    # Try to extract directional information
    direction_patterns = {
        'північ': 'N', 'північний': 'N', 'пн': 'N',
        'південь': 'S', 'південний': 'S', 'пд': 'S', 
        'схід': 'E', 'східний': 'E', 'сх': 'E',
        'захід': 'W', 'західний': 'W', 'зх': 'W',
        'північно-східний': 'NE', 'пн-сх': 'NE',
        'північно-західний': 'NW', 'пн-зх': 'NW', 
        'південно-східний': 'SE', 'пд-сх': 'SE',
        'південно-західний': 'SW', 'пд-зх': 'SW'
    }
    
    for direction_ukr, direction_eng in direction_patterns.items():
        if direction_ukr in text_lower:
            return {
                'source_city': None,
                'target_city': None,
                'course_direction': direction_eng,
                'raw_direction': direction_ukr,
                'course_type': "directional"
            }
    
    return None

# Basic minimal subset for Render deployment. Heavy ML parts stripped for now.
# Load secrets from a local hidden .env file (key=value) if present (for local dev),
# then fall back to environment variables (for Render / production).

def _load_local_env(path: str = '.env'):
    if not os.path.exists(path):
        return
    try:
        with open(path, encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if not line or line.startswith('#'):
                    continue
                if '=' not in line:
                    continue
                k, v = line.split('=', 1)
                k = k.strip(); v = v.strip().strip('"').strip("'")
                # don't override already exported env vars
                if k and k not in os.environ:
                    os.environ[k] = v
    except Exception as e:
        logging.warning(f"Failed to load .env file: {e}")

_load_local_env()

API_ID = int(os.getenv('TELEGRAM_API_ID', '0') or '0')
API_HASH = os.getenv('TELEGRAM_API_HASH', '')
_DEFAULT_CHANNELS = 'mapstransler'
# SPEED FIX: Only use mapstransler to reduce backfill time (was 21 channels)
# To restore all channels, remove the override below
CHANNELS = ['mapstransler']  # HARDCODED for speed
# Original: CHANNELS = [c.strip() for c in os.getenv('TELEGRAM_CHANNELS', _DEFAULT_CHANNELS).split(',') if c.strip()]

# Channels which failed resolution (entity not found / access denied) to avoid repeated spam
INVALID_CHANNELS = set()
GOOGLE_MAPS_KEY = os.getenv('GOOGLE_MAPS_KEY', '')
OPENCAGE_API_KEY = os.getenv('OPENCAGE_API_KEY', '')  # optional geocoding
ALWAYS_STORE_RAW = os.getenv('ALWAYS_STORE_RAW', '1') not in ('0','false','False')

logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s %(message)s')
log = logging.getLogger(__name__)

app = Flask(__name__)

# ============= CLOUDFLARE CDN SUPPORT =============
# Cloudflare passes real client IP in CF-Connecting-IP header
def get_real_ip():
    """Get real client IP, supporting Cloudflare proxy."""
    # Cloudflare specific headers (most reliable)
    cf_ip = request.headers.get('CF-Connecting-IP')
    if cf_ip:
        return cf_ip
    # Standard proxy headers
    x_forwarded = request.headers.get('X-Forwarded-For')
    if x_forwarded:
        return x_forwarded.split(',')[0].strip()
    x_real_ip = request.headers.get('X-Real-IP')
    if x_real_ip:
        return x_real_ip
    return request.remote_addr or 'unknown'

# Cloudflare cache status header
@app.after_request
def add_cloudflare_headers(response):
    # Add headers for Cloudflare caching
    if 'Cache-Control' not in response.headers:
        # Default: no cache for dynamic content
        response.headers['Cache-Control'] = 'no-store'
    
    # Add Vary header for proper caching
    if 'Vary' not in response.headers:
        response.headers['Vary'] = 'Accept-Encoding'
    
    return response

# ============= API PROTECTION INITIALIZATION =============
# Initialize production-grade protection BEFORE other middleware
if API_PROTECTION_ENABLED:
    init_protection(app)
    print("INFO: API Protection hooks registered")
# =========================================================

# ============= PERFORMANCE OPTIMIZATION =============
# Enable gzip compression for faster response times
from flask_compress import Compress
compress = Compress()
compress.init_app(app)

# Cache control headers for static assets
@app.after_request
def add_cache_headers(response):
    # Cache static assets for 7 days
    if request.path.startswith('/static/'):
        if any(request.path.endswith(ext) for ext in ['.png', '.jpg', '.jpeg', '.gif', '.svg', '.ico', '.woff', '.woff2', '.ttf']):
            response.cache_control.max_age = 604800  # 7 days
            response.cache_control.public = True
        elif any(request.path.endswith(ext) for ext in ['.js', '.css']):
            response.cache_control.max_age = 86400  # 1 day
            response.cache_control.public = True
    # No cache for API endpoints
    elif request.path.startswith('/api/'):
        response.cache_control.no_cache = True
        response.cache_control.no_store = True
        response.cache_control.must_revalidate = True
    # Cache HTML for 5 minutes
    elif request.path == '/' or request.path == '/index.html':
        response.cache_control.max_age = 300
        response.cache_control.public = True
    return response

# ====================================================

# ============= PAYMENT & EMAIL CONFIGURATION =============

# WayForPay configuration
WAYFORPAY_MERCHANT_ACCOUNT = os.getenv('WAYFORPAY_MERCHANT_ACCOUNT', 'neptun_in_ua')
WAYFORPAY_MERCHANT_SECRET = os.getenv('WAYFORPAY_MERCHANT_SECRET', '')
WAYFORPAY_DOMAIN = 'neptun.in.ua'
WAYFORPAY_ENABLED = bool(WAYFORPAY_MERCHANT_SECRET)

if WAYFORPAY_ENABLED:
    print("INFO: WayForPay payment initialized")
else:
    print("WARNING: WayForPay disabled (missing WAYFORPAY_MERCHANT_SECRET)")

# Monobank Acquiring configuration (для ФОП/ТОВ - 1.4% комісія)
MONOBANK_TOKEN = os.getenv('MONOBANK_TOKEN', '')
MONOBANK_ENABLED = bool(MONOBANK_TOKEN)

if MONOBANK_ENABLED:
    print("INFO: Monobank Acquiring initialized")
    print("INFO: Commission: 1.4% | Instant payouts | Direct bank integration")
else:
    print("WARNING: Monobank Acquiring disabled (missing X-Token)")
    print("HINT: Register at https://fop.monobank.ua/ with your ФОП/ТОВ")

# Flask-Mail configuration
app.config['MAIL_SERVER'] = os.getenv('MAIL_SERVER', 'smtp.gmail.com')
app.config['MAIL_PORT'] = int(os.getenv('MAIL_PORT', 587))
app.config['MAIL_USE_TLS'] = os.getenv('MAIL_USE_TLS', 'True') == 'True'
app.config['MAIL_USERNAME'] = os.getenv('MAIL_USERNAME', '')
app.config['MAIL_PASSWORD'] = os.getenv('MAIL_PASSWORD', '')
app.config['MAIL_DEFAULT_SENDER'] = os.getenv('MAIL_DEFAULT_SENDER', 'noreply@neptun.in.ua')

MAIL_ENABLED = bool(app.config['MAIL_USERNAME'] and app.config['MAIL_PASSWORD'])

if MAIL_ENABLED:
    try:
        from flask_mail import Mail, Message
        mail = Mail(app)
        print("INFO: Flask-Mail initialized")
    except ImportError:
        MAIL_ENABLED = False
        mail = None
        print("WARNING: Flask-Mail not installed. Run: pip install flask-mail")
    except Exception as e:
        MAIL_ENABLED = False
        mail = None
        print(f"WARNING: Flask-Mail initialization failed: {e}")
else:
    mail = None
    print("WARNING: Email disabled (missing SMTP credentials)")

# Admin credentials
ADMIN_USERNAME = os.getenv('ADMIN_USERNAME', 'admin')
ADMIN_PASSWORD = os.getenv('ADMIN_PASSWORD', 'change_me_in_production')

# =========================================================

# Firebase Admin initialization
device_store = DeviceStore()
family_store = FamilyStore()
firebase_initialized = False

def init_firebase():
    """Initialize Firebase Admin SDK."""
    global firebase_initialized
    if firebase_initialized:
        return True
    
    try:
        import firebase_admin
        from firebase_admin import credentials, messaging
        
        # Try to load from environment variable (Render deployment)
        cred_json = os.environ.get('FIREBASE_CREDENTIALS')
        if cred_json:
            import base64
            cred_dict = json.loads(base64.b64decode(cred_json))
            cred = credentials.Certificate(cred_dict)
        else:
            # Try to load from file (local development)
            if os.path.exists('firebase-credentials.json'):
                cred = credentials.Certificate('firebase-credentials.json')
            else:
                print("WARNING: Firebase credentials not found")
                return False
        
        firebase_admin.initialize_app(cred)
        firebase_initialized = True
        print("INFO: Firebase Admin SDK initialized successfully")
        return True
    except Exception as e:
        print(f"ERROR: Failed to initialize Firebase: {e}")
        return False

# Initialize Firebase on startup
init_firebase()

# Shared rate tracking for lightweight bandwidth protection rules
request_counts = defaultdict(list)

# Presence counter configuration
VALID_PLATFORMS = {'web', 'android', 'ios'}
PRESENCE_RATE_WINDOW = 30  # seconds
PRESENCE_RATE_LIMIT = 3    # max requests per window per IP

# Scheduler removed - no longer needed for blackout schedules

# BANDWIDTH OPTIMIZATION: Rate limiting to prevent abuse
    # Rate limiting отключен: все пользователи имеют свободный доступ

# BANDWIDTH OPTIMIZATION: Enable gzip compression globally
import gzip
import io

# Add global response compression
@app.after_request
def compress_response(response):
    """Apply gzip compression to reduce bandwidth usage."""
    if (
        response.status_code == 200 and
        'gzip' in request.headers.get('Accept-Encoding', '').lower() and
        response.content_length and response.content_length > 500 and
        response.content_type.startswith(('application/json', 'text/html', 'text/css', 'application/javascript'))
    ):
        try:
            # Compress the response data
            buffer = io.BytesIO()
            with gzip.GzipFile(fileobj=buffer, mode='wb') as f:
                f.write(response.get_data())
            
            response.set_data(buffer.getvalue())
            response.headers['Content-Encoding'] = 'gzip'
            response.headers['Content-Length'] = len(response.get_data())
            response.headers['Vary'] = 'Accept-Encoding'
        except Exception:
            pass  # If compression fails, return original response
    
    # Add cache headers for static content
    if request.endpoint == 'static':
        response.headers['Cache-Control'] = 'public, max-age=86400'  # 24 hours
    
    return response

# ===== UKRAINE ALARM API PROXY =====
import requests as http_requests

# API key from environment variable (can be updated in Render without redeploy)
ALARM_API_KEY = os.getenv('ALARM_API_KEY', '57fe8a39:7698ad50f0f15d502b280a83019bab25')
ALARM_API_BASE = os.getenv('ALARM_API_BASE', 'https://api.ukrainealarm.com/api/v3')

# Mapping district names to oblast names (for oblast-level coloring)
DISTRICT_TO_OBLAST = {
    # Дніпропетровська
    "Синельниківський район": "Дніпропетровська область",
    "Новомосковський район": "Дніпропетровська область",
    "Дніпровський район": "Дніпропетровська область",
    "Криворізький район": "Дніпропетровська область",
    "Кам'янський район": "Дніпропетровська область",
    "Нікопольський район": "Дніпропетровська область",
    "Павлоградський район": "Дніпропетровська область",
    # Харківська
    "Куп'янський район": "Харківська область",
    "Ізюмський район": "Харківська область",
    "Чугуївський район": "Харківська область",
    "Харківський район": "Харківська область",
    "Богодухівський район": "Харківська область",
    "Красноградський район": "Харківська область",
    "Лозівський район": "Харківська область",
    # Сумська
    "Сумський район": "Сумська область",
    "Конотопський район": "Сумська область",
    "Шосткинський район": "Сумська область",
    "Охтирський район": "Сумська область",
    "Роменський район": "Сумська область",
    # Чернігівська
    "Новгород-Сіверський район": "Чернігівська область",
    "Чернігівський район": "Чернігівська область",
    "Ніжинський район": "Чернігівська область",
    "Прилуцький район": "Чернігівська область",
    "Корюківський район": "Чернігівська область",
    # Донецька
    "Краматорський район": "Донецька область",
    "Бахмутський район": "Донецька область",
    "Покровський район": "Донецька область",
    "Волноваський район": "Донецька область",
    "Кальміуський район": "Донецька область",
    "Маріупольський район": "Донецька область",
    "Донецький район": "Донецька область",
    "Горлівський район": "Донецька область",
    # Запорізька
    "Запорізький район": "Запорізька область",
    "Мелітопольський район": "Запорізька область",
    "Бердянський район": "Запорізька область",
    "Пологівський район": "Запорізька область",
    "Василівський район": "Запорізька область",
    # Луганська
    "Сєвєродонецький район": "Луганська область",
    "Старобільський район": "Луганська область",
    "Сватівський район": "Луганська область",
    "Щастинський район": "Луганська область",
    # Херсонська
    "Херсонський район": "Херсонська область",
    "Бериславський район": "Херсонська область",
    "Генічеський район": "Херсонська область",
    "Каховський район": "Херсонська область",
    "Скадовський район": "Херсонська область",
    # Миколаївська
    "Миколаївський район": "Миколаївська область",
    "Баштанський район": "Миколаївська область",
    "Вознесенський район": "Миколаївська область",
    "Первомайський район": "Миколаївська область",
    # Одеська
    "Одеський район": "Одеська область",
    "Білгород-Дністровський район": "Одеська область",
    "Болградський район": "Одеська область",
    "Ізмаїльський район": "Одеська область",
    "Подільський район": "Одеська область",
    "Березівський район": "Одеська область",
    "Роздільнянський район": "Одеська область",
    # Полтавська
    "Полтавський район": "Полтавська область",
    "Кременчуцький район": "Полтавська область",
    "Лубенський район": "Полтавська область",
    "Миргородський район": "Полтавська область",
    # Київська
    "Білоцерківський район": "Київська область",
    "Бориспільський район": "Київська область",
    "Броварський район": "Київська область",
    "Бучанський район": "Київська область",
    "Вишгородський район": "Київська область",
    "Обухівський район": "Київська область",
    "Фастівський район": "Київська область",
    # Черкаська
    "Черкаський район": "Черкаська область",
    "Золотоніський район": "Черкаська область",
    "Уманський район": "Черкаська область",
    "Звенигородський район": "Черкаська область",
    # Кіровоградська
    "Кропивницький район": "Кіровоградська область",
    "Олександрійський район": "Кіровоградська область",
    "Голованівський район": "Кіровоградська область",
    "Новоукраїнський район": "Кіровоградська область",
    # Вінницька
    "Вінницький район": "Вінницька область",
    "Гайсинський район": "Вінницька область",
    "Жмеринський район": "Вінницька область",
    "Могилів-Подільський район": "Вінницька область",
    "Тульчинський район": "Вінницька область",
    "Хмільницький район": "Вінницька область",
    # Житомирська
    "Житомирський район": "Житомирська область",
    "Бердичівський район": "Житомирська область",
    "Коростенський район": "Житомирська область",
    "Звягельський район": "Житомирська область",
    # Рівненська
    "Рівненський район": "Рівненська область",
    "Дубенський район": "Рівненська область",
    "Вараський район": "Рівненська область",
    "Сарненський район": "Рівненська область",
    # Волинська
    "Луцький район": "Волинська область",
    "Володимирський район": "Волинська область",
    "Ковельський район": "Волинська область",
    "Камінь-Каширський район": "Волинська область",
    # Тернопільська
    "Тернопільський район": "Тернопільська область",
    "Чортківський район": "Тернопільська область",
    "Кременецький район": "Тернопільська область",
    # Хмельницька
    "Хмельницький район": "Хмельницька область",
    "Шепетівський район": "Хмельницька область",
    "Кам'янець-Подільський район": "Хмельницька область",
    # Львівська
    "Львівський район": "Львівська область",
    "Стрийський район": "Львівська область",
    "Самбірський район": "Львівська область",
    "Дрогобицький район": "Львівська область",
    "Червоноградський район": "Львівська область",
    "Яворівський район": "Львівська область",
    "Золочівський район": "Львівська область",
    # Івано-Франківська
    "Івано-Франківський район": "Івано-Франківська область",
    "Калуський район": "Івано-Франківська область",
    "Коломийський район": "Івано-Франківська область",
    "Косівський район": "Івано-Франківська область",
    "Надвірнянський район": "Івано-Франківська область",
    "Верховинський район": "Івано-Франківська область",
    # Закарпатська
    "Ужгородський район": "Закарпатська область",
    "Мукачівський район": "Закарпатська область",
    "Берегівський район": "Закарпатська область",
    "Хустський район": "Закарпатська область",
    "Рахівський район": "Закарпатська область",
    "Тячівський район": "Закарпатська область",
    # Чернівецька
    "Чернівецький район": "Чернівецька область",
    "Вижницький район": "Чернівецька область",
    "Дністровський район": "Чернівецька область",
}

# Cache for alarm API responses
_alarm_cache = {'data': None, 'time': 0}
_alarm_all_cache = {'data': None, 'time': 0}  # Separate cache for /all endpoint
ALARM_CACHE_TTL = 30  # seconds
ALARM_CACHE_STALE_TTL = 300  # 5 minutes - serve stale data if API fails

@app.route('/api/alarms/proxy')
def alarm_proxy():
    """Proxy for ukrainealarm.com API - returns ALL active alerts with type info"""
    import time as _time
    now = _time.time()
    
    # Return cached data if fresh
    if _alarm_cache['data'] and (now - _alarm_cache['time']) < ALARM_CACHE_TTL:
        return jsonify(_alarm_cache['data'])
    
    # Try to fetch fresh data with retries
    for attempt in range(3):
        try:
            response = http_requests.get(
                f'{ALARM_API_BASE}/alerts',
                headers={'Authorization': ALARM_API_KEY},
                timeout=8
            )
            if response.ok:
                data = response.json()
                # Separate State (oblast) and District alerts
                states = []
                districts = []
                
                for region in data:
                    if region.get('activeAlerts') and len(region['activeAlerts']) > 0:
                        region_type = region.get('regionType', '')
                        region_name = region.get('regionName', '')
                        
                        alert_info = {
                            'regionName': region_name,
                            'regionType': region_type,
                            'activeAlerts': region.get('activeAlerts')
                        }
                        
                        if region_type == 'State':
                            states.append(alert_info)
                        elif region_type == 'District':
                            # For districts, also include parent oblast
                            oblast = DISTRICT_TO_OBLAST.get(region_name, '')
                            alert_info['oblast'] = oblast
                            districts.append(alert_info)
                
                result = {
                    'states': states,
                    'districts': districts,
                    'totalAlerts': len(states) + len(districts)
                }
                
                # Update cache
                _alarm_cache['data'] = result
                _alarm_cache['time'] = now
                
                return jsonify(result)
        except Exception as e:
            print(f"Alarm proxy attempt {attempt+1} failed: {e}")
            if attempt < 2:
                _time.sleep(1)  # Wait before retry
    
    # All retries failed - return cached data if available
    if _alarm_cache['data']:
        print("Returning cached alarm data after failures")
        return jsonify(_alarm_cache['data'])
    
    return jsonify({'states': [], 'districts': [], 'totalAlerts': 0, 'error': 'API unavailable'})

@app.route('/api/alarms/all')
@app.route('/api/alarms')  # Alias for compatibility
def alarm_all():
    """Returns ALL alerts (State, District, Community) for detailed view with caching"""
    import time as _time
    import hashlib
    now = _time.time()
    
    # Return fresh cached data if available
    if _alarm_all_cache['data'] and (now - _alarm_all_cache['time']) < ALARM_CACHE_TTL:
        # BANDWIDTH OPTIMIZATION: Support ETag for 304 responses
        cache_etag = _alarm_all_cache.get('etag')
        client_etag = request.headers.get('If-None-Match')
        if cache_etag and client_etag == cache_etag:
            return Response(status=304, headers={'ETag': cache_etag})
        
        resp = jsonify(_alarm_all_cache['data'])
        resp.headers['Cache-Control'] = 'public, max-age=30'
        if cache_etag:
            resp.headers['ETag'] = cache_etag
        return resp
    
    # Try to fetch with retries
    for attempt in range(3):
        try:
            response = http_requests.get(
                f'{ALARM_API_BASE}/alerts',
                headers={'Authorization': ALARM_API_KEY},
                timeout=8
            )
            if response.ok:
                data = response.json()
                # Return all active alerts with regionId for SVG matching
                result = []
                for region in data:
                    if region.get('activeAlerts') and len(region['activeAlerts']) > 0:
                        result.append({
                            'regionId': region.get('regionId'),
                            'regionName': region.get('regionName'),
                            'regionType': region.get('regionType'),
                            'activeAlerts': region.get('activeAlerts')
                        })
                
                # Generate ETag from content hash
                content_hash = hashlib.md5(json.dumps(result, sort_keys=True).encode()).hexdigest()[:16]
                etag = f'"{content_hash}"'
                
                # Update cache with ETag
                _alarm_all_cache['data'] = result
                _alarm_all_cache['time'] = now
                _alarm_all_cache['etag'] = etag
                
                # Check if client has same version
                client_etag = request.headers.get('If-None-Match')
                if client_etag == etag:
                    return Response(status=304, headers={'ETag': etag})
                
                resp = jsonify(result)
                resp.headers['Cache-Control'] = 'public, max-age=30'
                resp.headers['ETag'] = etag
                return resp
        except Exception as e:
            print(f"Alarm all attempt {attempt+1} failed: {e}")
            if attempt < 2:
                _time.sleep(0.5)  # Wait before retry
    
    # All retries failed - return stale cached data if available (within 5 min)
    if _alarm_all_cache['data'] and (now - _alarm_all_cache['time']) < ALARM_CACHE_STALE_TTL:
        print(f"Returning stale alarm data ({int(now - _alarm_all_cache['time'])}s old) after API failures")
        resp = jsonify(_alarm_all_cache['data'])
        resp.headers['Cache-Control'] = 'public, max-age=30'
        return resp
    
    # No cache available - return empty with error flag
    print("Alarm API failed and no cache available")
    resp = jsonify([])
    resp.headers['Cache-Control'] = 'public, max-age=10'
    return resp

# ==================== WAYFORPAY PAYMENT ====================
def generate_wayforpay_signature(params, secret_key):
    """Generate HMAC_MD5 signature for WayForPay"""
    import hmac
    import hashlib
    sign_string = ';'.join(str(p) for p in params)
    return hmac.new(
        secret_key.encode('utf-8'),
        sign_string.encode('utf-8'),
        hashlib.md5
    ).hexdigest()

@app.route('/api/wayforpay/create-invoice', methods=['POST'])
def wayforpay_create_invoice():
    """Create WayForPay invoice with unique order ID"""
    try:
        data = request.get_json() or {}
        
        # Generate unique order ID
        import time
        order_id = f"NEPTUN_{int(time.time())}_{uuid.uuid4().hex[:8]}"
        
        # Get client info
        client_name = data.get('name', 'Клієнт NEPTUN')
        client_telegram = data.get('telegram', '')
        client_type = data.get('type', 'Комерційна підписка')
        amount = int(data.get('amount', 1000))
        
        # Save subscription request
        subscription = {
            'id': order_id,
            'name': client_name,
            'telegram': client_telegram,
            'type': client_type,
            'amount': amount,
            'currency': 'UAH',
            'status': 'pending',
            'timestamp': datetime.now(pytz.timezone('Europe/Kiev')).isoformat(),
            'ip': request.remote_addr
        }
        
        # Save to file
        subscriptions = []
        if os.path.exists(COMMERCIAL_SUBSCRIPTIONS_FILE):
            try:
                with open(COMMERCIAL_SUBSCRIPTIONS_FILE, 'r', encoding='utf-8') as f:
                    subscriptions = json.load(f)
            except:
                pass
        subscriptions.append(subscription)
        with open(COMMERCIAL_SUBSCRIPTIONS_FILE, 'w', encoding='utf-8') as f:
            json.dump(subscriptions, f, ensure_ascii=False, indent=2)
        
        print(f"🔔 NEW WAYFORPAY ORDER: {order_id}")
        print(f"   Name: {client_name}, Telegram: {client_telegram}")
        print(f"   Amount: {amount} UAH")
        
        # If WayForPay secret is configured, create proper invoice
        if WAYFORPAY_ENABLED:
            import time as _time
            order_date = int(_time.time())
            
            # WayForPay API parameters
            product_name = 'Комерційна підписка NEPTUN (місяць)'
            product_count = 1
            product_price = amount
            
            # Signature for CREATE_INVOICE (specific order!)
            # merchantAccount;merchantDomainName;orderReference;orderDate;amount;currency;productName;productCount;productPrice
            sign_string = f"{WAYFORPAY_MERCHANT_ACCOUNT};{WAYFORPAY_DOMAIN};{order_id};{order_date};{amount};UAH;{product_name};{product_count};{product_price}"
            
            import hmac
            import hashlib
            signature = hmac.new(
                WAYFORPAY_MERCHANT_SECRET.encode('utf-8'),
                sign_string.encode('utf-8'),
                hashlib.md5
            ).hexdigest()
            
            print(f"   Sign string: {sign_string}")
            print(f"   Signature: {signature}")
            
            # Create invoice via WayForPay API
            invoice_data = {
                'transactionType': 'CREATE_INVOICE',
                'merchantAccount': WAYFORPAY_MERCHANT_ACCOUNT,
                'merchantDomainName': WAYFORPAY_DOMAIN,
                'merchantSignature': signature,
                'apiVersion': 1,
                'orderReference': order_id,
                'orderDate': order_date,
                'amount': amount,
                'currency': 'UAH',
                'productName': [product_name],
                'productCount': [product_count],
                'productPrice': [product_price],
                'returnUrl': 'https://neptun.in.ua/?payment=success',
                'serviceUrl': 'https://neptun.in.ua/api/wayforpay/callback',
                'language': 'UA'
            }
            
            try:
                import requests
                print(f"   Sending to WayForPay API...")
                response = requests.post(
                    'https://api.wayforpay.com/api',
                    json=invoice_data,
                    timeout=10
                )
                
                result = response.json()
                print(f"   WayForPay response: {result}")
                
                if result.get('reasonCode') == 1100:
                    invoice_url = result.get('invoiceUrl')
                    print(f"✅ WayForPay invoice created: {invoice_url}")
                    
                    return jsonify({
                        'success': True,
                        'order_id': order_id,
                        'payment_url': invoice_url,
                        'message': 'Рахунок створено'
                    })
                else:
                    error_msg = result.get('reason', 'Unknown error')
                    print(f"❌ WayForPay error: {error_msg}")
                    # Return error - no fallback to old invoice
                    return jsonify({
                        'success': False,
                        'order_id': order_id,
                        'error': f'WayForPay помилка: {error_msg}',
                        'error_detail': result
                    }), 400
                    
            except Exception as e:
                print(f"❌ WayForPay API error: {e}")
                traceback.print_exc()
                return jsonify({
                    'success': False,
                    'order_id': order_id,
                    'error': f'WayForPay API помилка: {str(e)}'
                }), 500
        
        # WayForPay not configured - return error
        return jsonify({
            'success': False,
            'error': 'WayForPay не налаштований на сервері'
        }), 500
        
    except Exception as e:
        print(f"❌ WayForPay create invoice error: {e}")
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500

@app.route('/api/wayforpay/callback', methods=['POST'])
def wayforpay_callback():
    """Handle WayForPay webhook after payment"""
    try:
        data = request.get_json() or {}
        
        order_id = data.get('orderReference', '')
        status = data.get('transactionStatus', '')
        
        print(f"💳 WayForPay callback: {order_id} - {status}")
        
        # Update subscription status
        if os.path.exists(COMMERCIAL_SUBSCRIPTIONS_FILE):
            try:
                with open(COMMERCIAL_SUBSCRIPTIONS_FILE, 'r', encoding='utf-8') as f:
                    subscriptions = json.load(f)
                
                for sub in subscriptions:
                    if sub.get('id') == order_id:
                        sub['status'] = 'paid' if status == 'Approved' else status
                        sub['payment_date'] = datetime.now(pytz.timezone('Europe/Kiev')).isoformat()
                        break
                
                with open(COMMERCIAL_SUBSCRIPTIONS_FILE, 'w', encoding='utf-8') as f:
                    json.dump(subscriptions, f, ensure_ascii=False, indent=2)
                    
                print(f"✅ Subscription {order_id} updated to: {status}")
                
            except Exception as e:
                print(f"❌ Error updating subscription: {e}")
        
        # Return response signature
        response_time = int(datetime.now().timestamp())
        sign_params = [order_id, status, response_time]
        
        if WAYFORPAY_ENABLED:
            signature = generate_wayforpay_signature(sign_params, WAYFORPAY_MERCHANT_SECRET)
        else:
            signature = ''
        
        return jsonify({
            'orderReference': order_id,
            'status': 'accept',
            'time': response_time,
            'signature': signature
        })
        
    except Exception as e:
        print(f"❌ WayForPay callback error: {e}")
        return jsonify({'error': str(e)}), 500

# ==================== COMMERCIAL SUBSCRIPTION ENDPOINT ====================
@app.route('/api/commercial_subscription', methods=['POST'])
def commercial_subscription():
    """Handle commercial subscription requests with Monobank payment"""
    try:
        data = request.get_json()
        
        # Validate required fields
        required_fields = ['name', 'telegram', 'type']
        missing_fields = [field for field in required_fields if not data.get(field)]
        
        if missing_fields:
            return jsonify({
                'error': f'Missing required fields: {", ".join(missing_fields)}'
            }), 400
        
        # Prepare subscription data
        subscription = {
            'id': str(uuid.uuid4()),
            'name': data.get('name'),
            'telegram': data.get('telegram'),
            'type': data.get('type'),
            'comment': data.get('comment', ''),
            'amount': data.get('amount', 1500),
            'currency': 'UAH',
            'status': 'pending',
            'timestamp': datetime.now(pytz.timezone('Europe/Kiev')).isoformat(),
            'ip': request.remote_addr,
            'user_agent': request.headers.get('User-Agent', '')
        }
        
        # Save to file (using persistent storage)
        subscriptions = []
        
        if os.path.exists(COMMERCIAL_SUBSCRIPTIONS_FILE):
            try:
                with open(COMMERCIAL_SUBSCRIPTIONS_FILE, 'r', encoding='utf-8') as f:
                    subscriptions = json.load(f)
            except:
                pass
        
        subscriptions.append(subscription)
        
        with open(COMMERCIAL_SUBSCRIPTIONS_FILE, 'w', encoding='utf-8') as f:
            json.dump(subscriptions, f, ensure_ascii=False, indent=2)
        
        print(f"🔔 NEW COMMERCIAL SUBSCRIPTION:")
        print(f"   ID: {subscription['id']}")
        print(f"   Name: {subscription['name']}")
        print(f"   Telegram: {subscription['telegram']}")
        print(f"   Type: {subscription['type']}")
        print(f"   Amount: {subscription['amount']} UAH")
        
        # Generate Monobank invoice if enabled
        payment_url = None
        payment_data = None
        invoice_id = None
        
        if MONOBANK_ENABLED:
            try:
                import requests
                
                # Monobank invoice parameters
                order_reference = subscription['id']
                amount = subscription['amount']
                
                invoice_payload = {
                    'amount': int(amount * 100),  # У копійках
                    'ccy': 980,  # UAH код
                    'merchantPaymInfo': {
                        'reference': order_reference,
                        'destination': f'Комерційна підписка NEPTUN для {subscription["name"]}',
                        'basketOrder': [{
                            'name': 'Комерційна підписка NEPTUN (місяць)',
                            'qty': 1,
                            'sum': int(amount * 100),
                            'icon': 'https://neptun.in.ua/static/favicon.ico',
                            'unit': 'шт'
                        }]
                    },
                    'redirectUrl': 'https://neptun.in.ua?payment=success',
                    'webHookUrl': 'https://neptun.in.ua/api/monobank_callback',
                    'validity': 3600,  # 1 година
                    'paymentType': 'debit'  # Оплата картою
                }
                
                # Відправка запиту до Monobank API
                headers = {
                    'X-Token': MONOBANK_TOKEN,
                    'Content-Type': 'application/json'
                }
                
                response = requests.post(
                    'https://api.monobank.ua/api/merchant/invoice/create',
                    json=invoice_payload,
                    headers=headers,
                    timeout=10
                )
                
                if response.status_code == 200:
                    invoice = response.json()
                    payment_url = invoice.get('pageUrl')
                    invoice_id = invoice.get('invoiceId')
                    
                    payment_data = {
                        'pageUrl': payment_url,
                        'invoiceId': invoice_id
                    }
                    
                    # Зберігаємо invoiceId до підписки
                    subscription['invoice_id'] = invoice_id
                    
                    # Перезаписуємо файл з новим invoiceId
                    with open(COMMERCIAL_SUBSCRIPTIONS_FILE, 'w', encoding='utf-8') as f:
                        json.dump(subscriptions, f, ensure_ascii=False, indent=2)
                    
                    print(f"✅ Monobank invoice created: {invoice_id}")
                    print(f"   Payment URL: {payment_url}")
                else:
                    print(f"❌ Monobank API error: {response.status_code}")
                    print(f"   Response: {response.text}")
                    
            except Exception as e:
                print(f"❌ Monobank invoice creation failed: {e}")
                traceback.print_exc()
        
        return jsonify({
            'success': True,
            'subscription_id': subscription['id'],
            'message': 'Дякуємо! Зараз ви будете перенаправлені на сторінку оплати Monobank.',
            'payment_url': payment_url,
            'payment_data': payment_data,
            'invoice_id': invoice_id
        }), 200
        
    except Exception as e:
        print(f"❌ Commercial subscription error: {e}")
        traceback.print_exc()
        return jsonify({'error': 'Internal server error'}), 500

# ==================== MONOBANK CALLBACK ENDPOINT ====================
@app.route('/api/monobank_callback', methods=['POST'])
def monobank_callback():
    """Handle Monobank webhook after payment"""
    try:
        if not MONOBANK_ENABLED:
            return jsonify({'error': 'Monobank not configured'}), 503
        
        # Get webhook data
        callback_data = request.get_json()
        
        if not callback_data:
            print("❌ Monobank webhook: missing data")
            return jsonify({'error': 'Invalid webhook'}), 400
        
        # TODO: Verify X-Sign header with Monobank public key (requires ecdsa library)
        # x_sign_base64 = request.headers.get('X-Sign', '')
        
        # Extract payment info
        invoice_id = callback_data.get('invoiceId', '')
        status = callback_data.get('status', '')  # 'success', 'failure', 'processing'
        amount = callback_data.get('amount', 0)  # У копійках
        final_amount = callback_data.get('finalAmount', 0)
        created_date = callback_data.get('createdDate', '')
        modified_date = callback_data.get('modifiedDate', '')
        reference = callback_data.get('reference', '')  # Наш order_reference
        fail_reason = callback_data.get('failureReason', '')
        
        print(f"💳 Monobank webhook received:")
        print(f"   Invoice ID: {invoice_id}")
        print(f"   Status: {status}")
        print(f"   Reference: {reference}")
        print(f"   Amount: {amount / 100} UAH")
        
        # Update subscription status (using persistent storage)
        
        if os.path.exists(COMMERCIAL_SUBSCRIPTIONS_FILE):
            try:
                with open(COMMERCIAL_SUBSCRIPTIONS_FILE, 'r', encoding='utf-8') as f:
                    subscriptions = json.load(f)
                
                # Find and update subscription by reference (наш UUID)
                for sub in subscriptions:
                    if sub['id'] == reference or sub.get('invoice_id') == invoice_id:
                        sub['payment_status'] = status
                        sub['payment_amount'] = final_amount / 100
                        sub['payment_time'] = modified_date or datetime.now(pytz.timezone('Europe/Kiev')).isoformat()
                        sub['monobank_invoice_id'] = invoice_id
                        
                        if status == 'success':
                            sub['status'] = 'paid'
                            print(f"✅ Subscription {reference} marked as PAID (Monobank)")
                            
                            # Send confirmation email
                            if MAIL_ENABLED:
                                try:
                                    send_subscription_email(sub)
                                except Exception as e:
                                    print(f"❌ Email sending failed: {e}")
                        elif status == 'failure':
                            sub['status'] = 'declined'
                            print(f"❌ Payment failed for {reference}: {fail_reason}")
                        
                        break
                
                # Save updated subscriptions
                with open(COMMERCIAL_SUBSCRIPTIONS_FILE, 'w', encoding='utf-8') as f:
                    json.dump(subscriptions, f, ensure_ascii=False, indent=2)
                    
            except Exception as e:
                print(f"❌ Failed to update subscription: {e}")
                traceback.print_exc()
        
        return jsonify({'status': 'ok'}), 200
        
    except Exception as e:
        print(f"❌ Monobank webhook error: {e}")
        traceback.print_exc()
        return jsonify({'error': 'Internal server error'}), 500

# ==================== EMAIL NOTIFICATION FUNCTION ====================
def send_subscription_email(subscription):
    """Send confirmation email for subscription"""
    if not MAIL_ENABLED:
        print("⚠️ Email disabled - skipping notification")
        return
    
    try:
        from flask_mail import Message
        
        subject = "✅ Підписка NEPTUN активована!"
        recipient = subscription['email']
        
        # HTML email body
        body_html = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <meta charset="utf-8">
            <style>
                body {{ font-family: Arial, sans-serif; line-height: 1.6; color: #333; }}
                .container {{ max-width: 600px; margin: 0 auto; padding: 20px; }}
                .header {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 30px; text-align: center; border-radius: 10px 10px 0 0; }}
                .content {{ background: #f9f9f9; padding: 30px; border-radius: 0 0 10px 10px; }}
                .info-block {{ background: white; padding: 20px; margin: 20px 0; border-radius: 8px; border-left: 4px solid #667eea; }}
                .footer {{ text-align: center; margin-top: 30px; color: #666; font-size: 12px; }}
                .btn {{ display: inline-block; padding: 12px 30px; background: #667eea; color: white; text-decoration: none; border-radius: 5px; margin-top: 20px; }}
            </style>
        </head>
        <body>
            <div class="container">
                <div class="header">
                    <h1>🎉 Вітаємо!</h1>
                    <p>Ваша комерційна підписка активована</p>
                </div>
                <div class="content">
                    <p>Привіт, <strong>{subscription['nickname']}</strong>!</p>
                    
                    <p>Дякуємо за оплату! Ваша місячна комерційна підписка на <strong>NEPTUN</strong> успішно активована.</p>
                    
                    <div class="info-block">
                        <h3>📋 Деталі підписки:</h3>
                        <p><strong>ID:</strong> {subscription['id']}</p>
                        <p><strong>Нікнейм:</strong> {subscription['nickname']}</p>
                        <p><strong>Сума:</strong> {subscription['amount']} {subscription['currency']}</p>
                        <p><strong>Статус:</strong> ✅ Оплачено</p>
                        <p><strong>Дата активації:</strong> {subscription.get('payment_time', subscription['timestamp'])}</p>
                    </div>
                    
                    <p><strong>Тепер ви можете використовувати карту NEPTUN у комерційних цілях!</strong></p>
                    
                    <ul>
                        <li>✅ Використання в стрімах (TikTok, YouTube, Twitch)</li>
                        <li>✅ Вбудовування на сторонні сайти</li>
                        <li>✅ Монетизація контенту з картою</li>
                        <li>✅ Пріоритетна підтримка</li>
                    </ul>
                    
                    <p>Підписка діє <strong>1 місяць</strong> з моменту оплати.</p>
                    
                    <a href="https://neptun.in.ua" class="btn">Відкрити NEPTUN карту</a>
                    
                    <p style="margin-top: 30px;">Якщо у вас виникнуть питання, відповідайте на цей email або пишіть нам у Telegram: {subscription.get('telegram', 'не вказано')}</p>
                </div>
                <div class="footer">
                    <p>NEPTUN - Карта тривог України 🇺🇦</p>
                    <p><a href="https://neptun.in.ua">neptun.in.ua</a></p>
                </div>
            </div>
        </body>
        </html>
        """
        
        msg = Message(
            subject=subject,
            recipients=[recipient],
            html=body_html
        )
        
        mail.send(msg)
        print(f"📧 Confirmation email sent to {recipient}")
        
    except Exception as e:
        print(f"❌ Failed to send email: {e}")
        traceback.print_exc()
        raise

# ==================== END COMMERCIAL SUBSCRIPTION ====================

# ===== UKRAINEALARM API MONITORING FOR PUSH NOTIFICATIONS =====
# This system monitors alarm state changes and triggers push notifications

# Store previous alarm states to detect changes
_alarm_states = {}  # {region_id: {'active': bool, 'types': [str], 'last_changed': timestamp, 'notified': bool}}
_monitoring_active = False
_first_run = True  # Don't send notifications on first run (existing alarms)

def get_region_display_name(region_data):
    """Get display name for region from API data."""
    region_name = region_data.get('regionName', '')
    region_type = region_data.get('regionType', '')
    
    # For State regions, return the oblast name
    if region_type == 'State':
        return region_name
    
    # For districts, return the DISTRICT name (not oblast!)
    # This is important for notification matching - users subscribe to districts
    if region_type == 'District':
        return region_name
    
    return region_name

def send_alarm_notification(region_data, alarm_started: bool):
    """Send FCM notification for alarm state change."""
    if not firebase_initialized:
        log.warning("Firebase not initialized, skipping alarm notifications")
        return

    try:
        from firebase_admin import messaging
        
        region_name = get_region_display_name(region_data)
        region_id = region_data.get('regionId', '')
        alert_types = region_data.get('activeAlerts', [])
        
        # Check if this region was recently notified via Telegram (suppress duplicate)
        # Only suppress if alarm is STARTING (not ending - відбій)
        if alarm_started:
            with _telegram_alert_lock:
                now = time.time()
                # Clean old entries (older than 5 minutes)
                for key in list(_telegram_region_notified.keys()):
                    if now - _telegram_region_notified[key] > 300:
                        del _telegram_region_notified[key]
                
                # Check if this region was recently notified
                region_lower = region_name.lower()
                # Extract root for matching (e.g., "херсонський район" -> "херсон")
                region_root = region_lower.replace('ський район', '').replace('ська область', '').replace('ський', '').replace('ська', '').replace(' район', '').replace(' область', '').strip()[:6]
                
                for notified_region, timestamp in _telegram_region_notified.items():
                    notified_root = notified_region.replace('ський район', '').replace('ська область', '').replace('ський', '').replace('ська', '').replace(' район', '').replace(' область', '').strip()[:6]
                    
                    # Match by root or full name
                    if (notified_region in region_lower or 
                        region_lower in notified_region or
                        (region_root and notified_root and region_root == notified_root)):
                        elapsed = now - timestamp
                        log.info(f"⏭️ Skipping alarm notification for {region_name} - already notified via Telegram {int(elapsed)}s ago (matched: {notified_region})")
                        return
        
        # Check recent Telegram messages for threat details (drones, rockets, KABs, etc.)
        threat_detail = None
        threat_text = None  # The actual text from Telegram message
        tts_location = None  # Specific city/location for TTS
        try:
            # Load all messages and filter recent ones (last 10 minutes)
            all_messages = MESSAGE_STORE.load()
            now = datetime.now(pytz.timezone('Europe/Kiev'))
            cutoff = now - timedelta(minutes=10)
            recent_messages = []
            for msg in all_messages:
                msg_time_str = msg.get('timestamp') or msg.get('time') or ''
                if msg_time_str:
                    try:
                        # Parse timestamp
                        if 'T' in msg_time_str:
                            msg_time = datetime.fromisoformat(msg_time_str.replace('Z', '+00:00'))
                        else:
                            msg_time = datetime.strptime(msg_time_str, '%Y-%m-%d %H:%M:%S')
                            msg_time = pytz.timezone('Europe/Kiev').localize(msg_time)
                        if msg_time > cutoff:
                            recent_messages.append(msg)
                    except:
                        # Include message if we can't parse time
                        recent_messages.append(msg)
                else:
                    recent_messages.append(msg)
            
            log.info(f"Checking {len(recent_messages)} recent messages for threat details for {region_name}")
            region_lower = region_name.lower()
            
            # Also get oblast for matching
            oblast = DISTRICT_TO_OBLAST.get(region_name, region_name)
            oblast_lower = oblast.lower().replace(' область', '').replace('ська', 'ськ')
            
            # Extract district name root for fuzzy matching (e.g., "Краматорський район" -> "краматор")
            district_root = region_lower.replace(' район', '').replace('ький', '').replace('ська', '').replace('ий', '')[:7]
            
            # Also extract city name (e.g., "Краматорський" -> "краматорськ")
            city_name = region_lower.replace(' район', '').replace('ький', 'ськ').replace('ий', '')
            
            # Extract oblast root for matching (e.g., "Харківська область" -> "харків")
            oblast_root = oblast_lower.replace('ська', '').replace('ський', '')[:6]
            
            for msg in recent_messages:
                msg_text = (msg.get('text', '') or '')
                msg_text_lower = msg_text.lower()
                msg_location = (msg.get('location', '') or '').lower()
                combined = msg_text_lower + ' ' + msg_location
                
                # Check if message relates to this region (fuzzy match)
                # Note: Telegram messages use "Харків (Харківська обл.)" format
                region_match = (
                    region_lower in combined or 
                    oblast_lower in combined or
                    district_root in combined or
                    city_name in combined or
                    oblast_root in combined  # "харків" in "харків (харківська обл.)"
                )
                
                if region_match:
                    # Витягуємо конкретну локацію (місто) з повідомлення
                    # Формат: "Харків (Харківська обл.)" або просто текст
                    msg_location_raw = msg.get('location', '') or ''
                    if msg_location_raw and '(' in msg_location_raw:
                        # Витягуємо місто до дужок
                        tts_location = msg_location_raw.split('(')[0].strip()
                    elif msg_location_raw:
                        tts_location = msg_location_raw.strip()
                    
                    # Use the FULL message text as threat_text for TTS
                    # This ensures "ЗМІ повідомляють про вибухи" is spoken as-is
                    threat_text = msg_text.strip()
                    # Remove location prefix if present (e.g., "Херсон (Херсонська обл.)")
                    # as we already announce the region separately
                    if '(' in threat_text and ')' in threat_text:
                        # Extract just the message part after the location
                        parts = threat_text.split(')', 1)
                        if len(parts) > 1 and parts[1].strip():
                            threat_text = parts[1].strip()
                    
                    if 'ракет' in msg_text_lower or 'балістичн' in msg_text_lower or 'крилат' in msg_text_lower:
                        threat_detail = 'ракети'
                        log.info(f"Found rocket threat for {region_name} at {tts_location}: {threat_text}")
                        break
                    elif 'бпла' in msg_text_lower or 'дрон' in msg_text_lower or 'шахед' in msg_text_lower:
                        threat_detail = 'дрони'
                        log.info(f"Found drone threat for {region_name} at {tts_location}: {threat_text}")
                        break
                    elif 'каб' in msg_text_lower:
                        threat_detail = 'каби'
                        log.info(f"Found KAB threat for {region_name} at {tts_location}: {threat_text}")
                        break
                    elif 'вибух' in msg_text_lower:
                        threat_detail = 'вибухи'
                        log.info(f"Found explosion report for {region_name} at {tts_location}: {threat_text}")
                        break
            
            # If no specific match found, just use generic alert type
            # DON'T use global messages - they may be for different regions
            if not threat_detail:
                log.info(f"No specific threat details found for {region_name}, using generic alert")
                        
        except Exception as e:
            log.warning(f"Error checking threat details: {e}")
        
        # Determine notification details based on state
        if alarm_started:
            # Alarm started
            threat_types = []
            for alert in alert_types:
                alert_type = alert.get('type', '')
                if alert_type == 'AIR':
                    threat_types.append('Повітряна тривога')
                elif alert_type == 'ARTILLERY':
                    threat_types.append('Артилерійська загроза')
                elif alert_type == 'URBAN_FIGHTS':
                    threat_types.append('Вуличні бої')
                elif alert_type == 'CHEMICAL':
                    threat_types.append('Хімічна загроза')
                elif alert_type == 'NUCLEAR':
                    threat_types.append('Ядерна загроза')
            
            if not threat_types:
                threat_types = ['Повітряна тривога']
            
            title = f"🚨 Тривога: {region_name}"
            
            # Use threat_text from Telegram if available, otherwise use generic descriptions
            if threat_text:
                body = threat_text  # e.g., "Загроза застосування БПЛА", "Загроза застосування КАБів"
                is_critical = True
            elif threat_detail == 'ракети':
                body = "Ракетна небезпека!"
                is_critical = True
            elif threat_detail == 'дрони':
                body = "Загроза застосування БПЛА"
                is_critical = True
            elif threat_detail == 'каби':
                body = "Загроза застосування КАБів"
                is_critical = True
            elif threat_detail == 'вибухи':
                body = "Повідомляють про вибухи"
                is_critical = True
            else:
                body = ", ".join(threat_types)
                is_critical = True
        else:
            # Alarm ended
            title = f"✅ Відбій: {region_name}"
            body = "Загрозу знято"
            is_critical = False
        
        log.info(f"=== ALARM FCM NOTIFICATION ===")
        log.info(f"Region: {region_name} ({region_id})")
        log.info(f"State: {'STARTED' if alarm_started else 'ENDED'}")
        log.info(f"Message: {title} - {body}")
        
        # Map region name to Firebase topic
        region_topic_map = {
            'Київ': 'region_kyiv_city',
            'Київська область': 'region_kyivska',
            'Дніпропетровська область': 'region_dnipropetrovska',
            'Харківська область': 'region_kharkivska',
            'Одеська область': 'region_odeska',
            'Львівська область': 'region_lvivska',
            'Донецька область': 'region_donetska',
            'Запорізька область': 'region_zaporizka',
            'Вінницька область': 'region_vinnytska',
            'Житомирська область': 'region_zhytomyrska',
            'Черкаська область': 'region_cherkaska',
            'Чернігівська область': 'region_chernihivska',
            'Полтавська область': 'region_poltavska',
            'Сумська область': 'region_sumska',
            'Миколаївська область': 'region_mykolaivska',
            'Херсонська область': 'region_khersonska',
            'Кіровоградська область': 'region_kirovohradska',
            'Хмельницька область': 'region_khmelnytska',
            'Рівненська область': 'region_rivnenska',
            'Волинська область': 'region_volynska',
            'Тернопільська область': 'region_ternopilska',
            'Івано-Франківська область': 'region_ivano_frankivska',
            'Закарпатська область': 'region_zakarpatska',
            'Чернівецька область': 'region_chernivetska',
            'Луганська область': 'region_luhanska',
        }
        
        # Get topic for this region
        topic = region_topic_map.get(region_name)
        
        # If district, also get oblast topic
        region_type = region_data.get('regionType', '')
        oblast_topic = None
        if region_type == 'District':
            oblast = DISTRICT_TO_OBLAST.get(region_name, '')
            if oblast:
                oblast_topic = region_topic_map.get(oblast)
                log.info(f"District {region_name} maps to oblast {oblast} (topic: {oblast_topic})")
        
        if not topic and not oblast_topic:
            log.info(f"No topic mapping for region: {region_name}")
            return

        # Send to topic (much more efficient than individual devices)
        success_count = 0
        
        # Send to region topic if available
        topics_to_send = []
        if topic:
            topics_to_send.append(topic)
        if oblast_topic and oblast_topic != topic:
            topics_to_send.append(oblast_topic)
        
        for target_topic in topics_to_send:
            try:
                # Визначаємо чіткий тип загрози для TTS
                if alarm_started:
                    if threat_detail == 'ракети':
                        tts_threat = 'Ракетна небезпека'
                    elif threat_detail == 'каби':
                        tts_threat = 'Загроза КАБів'
                    elif threat_detail == 'дрони':
                        tts_threat = 'Загроза БПЛА'
                    elif threat_detail == 'вибухи':
                        tts_threat = 'Повідомляють про вибухи'
                    else:
                        tts_threat = 'Повітряна тривога'
                else:
                    tts_threat = 'Відбій тривоги'
                
                # Визначаємо локацію для TTS: конкретне місто або область
                fcm_location = tts_location if tts_location else region_name
                
                # For Android: DATA-ONLY message so background handler can process TTS
                # For iOS: Include notification so system shows alert (TTS won't work in background on iOS)
                message = messaging.Message(
                    # NO notification block - Android needs data-only for background handler + TTS
                    data={
                        'type': 'alarm',
                        'title': title,
                        'body': body,
                        'location': fcm_location,  # Конкретне місто або область для TTS
                        'region': region_name,  # Область (для фільтрації)
                        'region_id': region_id,
                        'alarm_state': 'active' if alarm_started else 'ended',
                        'is_critical': 'true' if is_critical else 'false',
                        'threat_type': tts_threat,  # Чіткий тип загрози для TTS
                        'timestamp': datetime.now(pytz.timezone('Europe/Kiev')).isoformat(),
                        'click_action': 'FLUTTER_NOTIFICATION_CLICK',
                    },
                    android=messaging.AndroidConfig(
                        priority='high',
                        ttl=timedelta(seconds=300),
                    ),
                    apns=messaging.APNSConfig(
                        headers={
                            'apns-priority': '10',
                            'apns-push-type': 'alert',
                        },
                        payload=messaging.APNSPayload(
                            aps=messaging.Aps(
                                alert=messaging.ApsAlert(title=title, body=body),
                                sound='default',
                                badge=1,
                                content_available=True,
                            ),
                        ),
                    ),
                    topic=target_topic,  # Send to topic instead of individual token
                )
                
                response = messaging.send(message)
                success_count += 1
                log.info(f"✅ Alarm notification sent to topic {target_topic}: {response}")
            except Exception as e:
                log.error(f"Failed to send alarm to topic {target_topic}: {e}")
        
        log.info(f"Sent alarm notifications to {success_count} topics for region: {region_name}")
    except Exception as e:
        log.error(f"Error in send_alarm_notification: {e}")


# Track recently sent telegram alerts to avoid duplicates (message_id -> timestamp)
_telegram_alert_sent = {}
_telegram_alert_lock = threading.Lock()

# Track regions that received Telegram notifications recently to suppress duplicate alarm notifications
# region_name (normalized) -> timestamp
_telegram_region_notified = {}

def send_telegram_threat_notification(message_text: str, location: str, message_id: str):
    """Send FCM notification for threat messages from Telegram (КАБи, ракети, БПЛА etc.)."""
    if not firebase_initialized:
        return
    
    # Deduplicate - don't send same message within 5 minutes
    with _telegram_alert_lock:
        now = time.time()
        # Clean old entries
        _telegram_alert_sent.clear() if len(_telegram_alert_sent) > 1000 else None
        for mid in list(_telegram_alert_sent.keys()):
            if now - _telegram_alert_sent[mid] > 300:
                del _telegram_alert_sent[mid]
        
        if message_id in _telegram_alert_sent:
            return
        _telegram_alert_sent[message_id] = now
    
    try:
        from firebase_admin import messaging
        
        msg_lower = message_text.lower()
        
        # Try AI classification first for more accurate results
        ai_result = classify_threat_with_ai(message_text)
        
        if ai_result and ai_result.get('threat_type') not in ['unknown', None]:
            # Use AI classification
            threat_map = {
                'shahed': ('шахеди', '🛵'),
                'ballistic': ('балістика', '🚀'),
                'cruise': ('крилаті ракети', '🎯'),
                'kab': ('КАБи', '💣'),
                'drone': ('дрони', '🔭'),
                'explosion': ('вибухи', '💥'),
                'artillery': ('артилерія', '💨'),
            }
            threat_type, emoji = threat_map.get(ai_result['threat_type'], ('загроза', '⚠️'))
            if ai_result.get('emoji'):
                emoji = ai_result['emoji']
            is_critical = ai_result.get('priority', 3) >= 3
            
            # Use AI short description if available
            if ai_result.get('description_short'):
                ai_description = ai_result['description_short']
            else:
                ai_description = None
                
            print(f"AI threat classification: {threat_type} {emoji} (priority {ai_result.get('priority')})")
        else:
            # Fallback to regex-based classification
            ai_description = None
            if 'каб' in msg_lower:
                threat_type = 'каби'
                emoji = '💣'
                is_critical = True
            elif 'ракет' in msg_lower or 'балістичн' in msg_lower:
                threat_type = 'ракети'
                emoji = '🚀'
                is_critical = True
            elif 'бпла' in msg_lower or 'дрон' in msg_lower or 'шахед' in msg_lower:
                threat_type = 'дрони'
                emoji = '🛩️'
                is_critical = True
            elif 'вибух' in msg_lower:
                threat_type = 'вибухи'
                emoji = '💥'
                is_critical = True
            else:
                # Not a threat message, skip
                return
        
        # Extract region from location (e.g., "Харків (Харківська обл.)" -> "Харківська область")
        region_name = location
        city_name = ''  # Specific city for TTS
        if '(' in location and 'обл' in location:
            # Extract city (before parentheses) and oblast (in parentheses)
            import re
            city_match = re.match(r'^([^(]+)\s*\(', location)
            if city_match:
                city_name = city_match.group(1).strip()
            oblast_match = re.search(r'\(([^)]*обл[^)]*)\)', location)
            if oblast_match:
                region_name = oblast_match.group(1).replace('обл.', 'область').strip()
        
        title = f"{emoji} {region_name}"
        
        # For TTS: use city if available, otherwise region
        tts_location = city_name if city_name else region_name
        
        # Extract threat description from message (remove location prefix)
        body = message_text
        if ')' in body:
            parts = body.split(')', 1)
            if len(parts) > 1 and parts[1].strip():
                body = parts[1].strip()
        
        # Remove emoji from start if present
        if body and body[0] in '💣🚀🛩️💥🚨⚠️':
            body = body[1:].strip()
        
        log.info(f"=== TELEGRAM THREAT NOTIFICATION ===")
        log.info(f"Location: {location} -> {region_name}")
        log.info(f"Threat: {threat_type}")
        log.info(f"Message: {title} - {body}")
        
        # Map region name to Firebase topic
        region_topic_map = {
            'Київ': 'region_kyiv_city',
            'Київська область': 'region_kyivska',
            'Дніпропетровська область': 'region_dnipropetrovska',
            'Харківська область': 'region_kharkivska',
            'Одеська область': 'region_odeska',
            'Львівська область': 'region_lvivska',
            'Донецька область': 'region_donetska',
            'Запорізька область': 'region_zaporizka',
            'Вінницька область': 'region_vinnytska',
            'Житомирська область': 'region_zhytomyrska',
            'Черкаська область': 'region_cherkaska',
            'Чернігівська область': 'region_chernihivska',
            'Полтавська область': 'region_poltavska',
            'Сумська область': 'region_sumska',
            'Миколаївська область': 'region_mykolaivska',
            'Херсонська область': 'region_khersonska',
            'Кіровоградська область': 'region_kirovohradska',
            'Хмельницька область': 'region_khmelnytska',
            'Рівненська область': 'region_rivnenska',
            'Волинська область': 'region_volynska',
            'Тернопільська область': 'region_ternopilska',
            'Івано-Франківська область': 'region_ivano_frankivska',
            'Закарпатська область': 'region_zakarpatska',
            'Чернівецька область': 'region_chernivetska',
            'Луганська область': 'region_luhanska',
        }
        
        # Get topic for this region
        topic = region_topic_map.get(region_name)
        
        # Also try matching by city in parentheses -> extract oblast
        if not topic and '(' in location:
            city = location.split('(')[0].strip()
            # Try to find oblast from city
            for oblast_name in region_topic_map.keys():
                if oblast_name.replace(' область', '').lower() in location.lower():
                    topic = region_topic_map.get(oblast_name)
                    log.info(f"Matched city {city} to oblast {oblast_name}")
                    break
        
        if not topic:
            log.info(f"No topic mapping for region: {region_name}")
            return

        log.info(f"Sending telegram threat to topic: {topic}")
        
        # Map internal threat codes to human-readable Ukrainian for TTS
        threat_type_readable = {
            'каби': 'Загроза КАБів',
            'ракети': 'Ракетна небезпека',
            'дрони': 'Загроза БПЛА',
            'вибухи': 'Повідомляють про вибухи',
        }.get(threat_type, 'Повітряна тривога')  # Default to general alert
        
        # Send to topic
        success_count = 0
        try:
            message = messaging.Message(
                data={
                    'type': 'telegram_threat',
                    'title': title,
                    'body': body,
                    'location': tts_location,  # City or region for TTS
                    'region': region_name,
                    'alarm_state': 'active',
                    'is_critical': 'true' if is_critical else 'false',
                    'threat_type': threat_type_readable,  # Human-readable threat for TTS
                    'timestamp': datetime.now(pytz.timezone('Europe/Kiev')).isoformat(),
                    'click_action': 'FLUTTER_NOTIFICATION_CLICK',
                },
                android=messaging.AndroidConfig(
                    priority='high',
                    ttl=timedelta(seconds=300),
                ),
                apns=messaging.APNSConfig(
                    headers={
                        'apns-priority': '10',
                        'apns-push-type': 'alert',
                    },
                    payload=messaging.APNSPayload(
                        aps=messaging.Aps(
                            alert=messaging.ApsAlert(title=title, body=body),
                            sound='default',
                            badge=1,
                            content_available=True,
                        ),
                    ),
                ),
                topic=topic,  # Send to topic instead of individual token
            )
            
            response = messaging.send(message)
            success_count = 1
            log.info(f"✅ Telegram threat notification sent to topic {topic}: {response}")
        except Exception as e:
            log.error(f"Failed to send telegram threat to topic {topic}: {e}")
        
        log.info(f"Sent telegram threat notification to topic: {topic}")
        
        # Mark this region as notified to suppress duplicate alarm notifications
        if success_count > 0:
            with _telegram_alert_lock:
                # Normalize region name for matching
                region_key = region_name.lower()
                _telegram_region_notified[region_key] = time.time()
                # Also mark the city if different
                if '(' in location:
                    city = location.split('(')[0].strip().lower()
                    _telegram_region_notified[city] = time.time()
                log.info(f"Marked region '{region_key}' as telegram-notified (will suppress alarm notifications for 5 min)")
                
    except Exception as e:
        log.error(f"Error in send_telegram_threat_notification: {e}")

def monitor_alarms():
    """Background task to monitor ukrainealarm API and send notifications on state changes."""
    global _alarm_states, _first_run
    
    log.info("=== ALARM MONITORING STARTED ===")
    
    consecutive_failures = 0
    MAX_FAILURES_BEFORE_WARN = 5
    last_successful_fetch = 0
    
    while _monitoring_active:
        try:
            # Try multiple times before giving up this cycle
            data = None
            for attempt in range(3):
                try:
                    response = http_requests.get(
                        f'{ALARM_API_BASE}/alerts',
                        headers={'Authorization': ALARM_API_KEY},
                        timeout=15
                    )
                    if response.ok:
                        data = response.json()
                        consecutive_failures = 0
                        last_successful_fetch = time.time()
                        break
                    else:
                        log.warning(f"API attempt {attempt+1}/3 failed: HTTP {response.status_code}")
                except Exception as e:
                    log.warning(f"API attempt {attempt+1}/3 error: {e}")
                
                if attempt < 2:
                    time.sleep(2)  # Wait 2 sec between retries
            
            if data is None:
                consecutive_failures += 1
                if consecutive_failures >= MAX_FAILURES_BEFORE_WARN:
                    log.error(f"API unavailable for {consecutive_failures} consecutive cycles! Last success: {int(time.time() - last_successful_fetch)}s ago")
                else:
                    log.warning(f"API fetch failed (attempt {consecutive_failures}), keeping previous state")
                # DON'T clear _alarm_states - keep previous state!
                time.sleep(30)
                continue
            
            current_time = time.time()
            
            # Track which regions currently have alarms
            current_active_regions = set()
            
            # On first run, just store current states WITHOUT sending notifications
            # This prevents spam after server redeploy
            if _first_run:
                log.info("First run after deploy - storing initial alarm states WITHOUT notifications")
                for region in data:
                    region_id = region.get('regionId', '')
                    region_type = region.get('regionType', '')
                    active_alerts = region.get('activeAlerts', [])
                    has_alarm = len(active_alerts) > 0
                    
                    if has_alarm:
                        current_active_regions.add(region_id)
                        # Just store the state - NO notification on first run
                        log.info(f"📝 Stored existing alarm: {region.get('regionName')} (type: {region_type})")
                        _alarm_states[region_id] = {
                            'active': True,
                            'types': [alert.get('type') for alert in active_alerts],
                            'last_changed': current_time,
                            'notified': True  # Mark as notified to prevent duplicate on next change
                        }
                
                _first_run = False
                log.info(f"Initial state stored - {len(current_active_regions)} active alarms (no push sent)")
            else:
                # Normal monitoring - check for changes
                for region in data:
                    region_id = region.get('regionId', '')
                    region_type = region.get('regionType', '')
                    active_alerts = region.get('activeAlerts', [])
                    has_alarm = len(active_alerts) > 0
                    
                    if has_alarm:
                        current_active_regions.add(region_id)
                    
                    # Check if this is a state change
                    previous_state = _alarm_states.get(region_id, {})
                    was_active = previous_state.get('active', False)
                    was_notified = previous_state.get('notified', False)
                    
                    if has_alarm and not was_active:
                        # Alarm started - send notification ONLY for Districts
                        if not was_notified and region_type == 'District':
                            log.info(f"🚨 DISTRICT ALARM STARTED: {region.get('regionName')} (ID: {region_id})")
                            send_alarm_notification(region, alarm_started=True)
                        elif region_type == 'State':
                            log.info(f"ℹ️ Oblast alarm started (no push): {region.get('regionName')}")
                        _alarm_states[region_id] = {
                            'active': True,
                            'types': [alert.get('type') for alert in active_alerts],
                            'last_changed': current_time,
                            'notified': True
                        }
                    elif not has_alarm and was_active:
                        # Alarm ended - send відбій ONLY for Districts
                        if region_type == 'District':
                            log.info(f"✅ DISTRICT ALARM ENDED: {region.get('regionName')} (ID: {region_id})")
                            send_alarm_notification(region, alarm_started=False)
                        elif region_type == 'State':
                            log.info(f"ℹ️ Oblast alarm ended (no push): {region.get('regionName')}")
                        _alarm_states[region_id] = {
                            'active': False,
                            'types': [],
                            'last_changed': current_time,
                            'notified': False  # Reset for next alarm
                        }
                    elif has_alarm and was_active:
                        # Alarm still active - only log, don't resend notification
                        current_types = [alert.get('type') for alert in active_alerts]
                        previous_types = previous_state.get('types', [])
                        if set(current_types) != set(previous_types):
                            log.info(f"⚠️ ALARM TYPES CHANGED: {region.get('regionName')} - {current_types}")
                            _alarm_states[region_id]['types'] = current_types
                            # Keep notified=True to prevent resending
                
                # Check for regions that went from active to inactive (ended alarms)
                for region_id, state in list(_alarm_states.items()):
                    if state.get('active') and region_id not in current_active_regions:
                        # Find region data to send відбій notification
                        region_data = next((r for r in data if r.get('regionId') == region_id), None)
                        if region_data:
                            region_type = region_data.get('regionType', '')
                            # Send відбій ONLY for Districts
                            if region_type == 'District':
                                log.info(f"✅ DISTRICT ALARM ENDED (from tracking): {region_data.get('regionName')} (ID: {region_id})")
                                send_alarm_notification(region_data, alarm_started=False)
                            else:
                                log.info(f"ℹ️ Oblast alarm ended (from tracking, no push): {region_data.get('regionName')}")
                        _alarm_states[region_id] = {
                            'active': False,
                            'types': [],
                            'last_changed': current_time,
                            'notified': False
                        }
                
                log.info(f"Alarm monitoring cycle complete - {len(current_active_regions)} active alarms")
        
        except Exception as e:
            log.error(f"Error in alarm monitoring: {e}")
            consecutive_failures += 1
        
        # Wait before next check (45 seconds to reduce CPU load)
        time.sleep(45)
    
    log.info("=== ALARM MONITORING STOPPED ===")

def start_alarm_monitoring():
    """Start the alarm monitoring background thread."""
    global _monitoring_active
    
    if _monitoring_active:
        log.info("Alarm monitoring already active")
        return
    
    _monitoring_active = True
    monitor_thread = threading.Thread(target=monitor_alarms, daemon=True)
    monitor_thread.start()
    log.info("Alarm monitoring thread started")

# Start monitoring when app initializes
if firebase_initialized:
    start_alarm_monitoring()
else:
    log.warning("Firebase not initialized - alarm monitoring disabled")

@app.route('/api/monitoring-status')
def monitoring_status():
    """Check alarm monitoring status (for debugging)."""
    active_districts = []
    for region_id, state in _alarm_states.items():
        if state.get('active'):
            active_districts.append(region_id)
    
    return jsonify({
        'monitoring_active': _monitoring_active,
        'first_run': _first_run,
        'firebase_initialized': firebase_initialized,
        'alarm_states_count': len(_alarm_states),
        'active_alarms': len(active_districts),
        'active_region_ids': active_districts[:20],  # First 20 for debug
        'server_time': datetime.now(pytz.timezone('Europe/Kiev')).isoformat(),
    })

# ===== END UKRAINEALARM MONITORING =====


# Custom route for serving pre-compressed static files
@app.route('/static/<path:filename>')
def static_with_gzip(filename):
    """Serve static files with gzip compression support."""
    
    # SMART BANDWIDTH PROTECTION: Only rate limit large files, not icons
    client_ip = request.environ.get('HTTP_X_FORWARDED_FOR', request.remote_addr)
    
    # Skip rate limiting for small assets (icons, SVG, small images)
    is_small_asset = filename.endswith(('.svg', '.ico', '.woff', '.woff2')) or \
                     filename.startswith('icon_') or \
                     filename in ('manifest.json', 'sitemap.xml')
    
    if not is_small_asset:
        static_requests = request_counts.get(f"{client_ip}_static", [])
        now_time = time.time()
        
        # Clean old requests (last 60 seconds)
        static_requests = [req_time for req_time in static_requests if now_time - req_time < 60]
        
        # Allow 30 static file requests per minute per IP (increased from 5)
        if len(static_requests) >= 30:
            print(f"[BANDWIDTH] Rate limiting static file {filename} from {client_ip}")
            return jsonify({'error': 'Static files rate limited - wait 1 minute'}), 429
        
        static_requests.append(now_time)
        request_counts[f"{client_ip}_static"] = static_requests
    
    # SMART BANDWIDTH PROTECTION: Block only genuinely large files (>1MB)
    try:
        static_folder = os.path.join(os.path.dirname(__file__), 'static')
        file_path = os.path.join(static_folder, filename)
        
        if os.path.exists(file_path):
            file_size = os.path.getsize(file_path)
            
            # Block files larger than 1MB to save bandwidth
            if file_size > 1024 * 1024:  # 1MB limit 
                print(f"[BANDWIDTH PROTECTION] Blocking large file {filename} ({file_size//1024}KB) from {client_ip}")
                return jsonify({'error': f'Large file blocked - size {file_size//1024}KB exceeds 1MB limit'}), 503
                
            # Log access to files over 100KB for monitoring
            if file_size > 100 * 1024:
                print(f"[BANDWIDTH MONITOR] Serving large file {filename} ({file_size//1024}KB) to {client_ip}")
        else:
            print(f"[STATIC FILE] File not found: {filename}")
            return jsonify({'error': 'File not found'}), 404
            
    except Exception as e:
        print(f"[BANDWIDTH ERROR] Error checking file {filename}: {e}")
        return jsonify({'error': 'File access error'}), 500
    
    # Check if client accepts gzip and we have a gzipped version
    accepts_gzip = 'gzip' in request.headers.get('Accept-Encoding', '').lower()
    
    if accepts_gzip and filename.endswith('.js'):
        gzip_path = os.path.join(app.static_folder, filename + '.gz')
        if os.path.exists(gzip_path):
            response = send_from_directory(app.static_folder, filename + '.gz')
            response.headers['Content-Encoding'] = 'gzip'
            response.headers['Content-Type'] = 'application/javascript; charset=utf-8'
            
            # Add strong caching for JS files
            response.headers['Cache-Control'] = 'public, max-age=31536000, immutable'
            response.headers['Expires'] = (datetime.now() + timedelta(days=365)).strftime('%a, %d %b %Y %H:%M:%S GMT')
            
            return response
    
    # Fall back to regular static file serving
    response = send_from_directory(app.static_folder, filename)
    
    # CRITICAL BANDWIDTH PROTECTION: Check file size
    try:
        file_path = os.path.join(app.static_folder, filename)
        if os.path.exists(file_path):
            file_size = os.path.getsize(file_path)
            if file_size > 100 * 1024:  # 100KB limit
                print(f"[CRITICAL BANDWIDTH] Large static file {filename}: {file_size/1024:.1f}KB from {client_ip}")
    except Exception:
        pass
    
    return response

# Configure caching and compression for better performance on slow connections
app.config['SEND_FILE_MAX_AGE_DEFAULT'] = 31536000  # 1 year for static files
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16MB max file size

# Add cache headers for static files
@app.after_request
def add_cache_headers(response):
    if request.endpoint == 'static':
        # Check if this is a versioned resource (with ?v= parameter)
        if 'v=' in request.query_string.decode():
            # Cache versioned static files for 1 month (they won't change)
            response.headers['Cache-Control'] = 'public, max-age=2592000, immutable'
            response.headers['Expires'] = (datetime.now() + timedelta(days=30)).strftime('%a, %d %b %Y %H:%M:%S GMT')
        else:
            # Cache regular static files for 1 week
            response.headers['Cache-Control'] = 'public, max-age=604800, immutable'
            response.headers['Expires'] = (datetime.now() + timedelta(days=7)).strftime('%a, %d %b %Y %H:%M:%S GMT')
        
        # Add compression hints for images
        if request.path.endswith(('.png', '.jpg', '.jpeg', '.webp')):
            response.headers['Vary'] = 'Accept-Encoding'
            # Add ETag for better caching
            response.headers['ETag'] = f'"{hash(request.path + request.query_string.decode())}"'
            
    elif request.endpoint == 'index':
        # Cache main page for 5 minutes
        response.headers['Cache-Control'] = 'public, max-age=300'
        
    return response
COMMENTS = []  # retained as a small in-memory cache (recent) but now persisted to SQLite
COMMENTS_MAX = 500
ACTIVE_VISITORS = {}
ACTIVE_LOCK = threading.Lock()
ACTIVE_TTL = 70  # seconds of inactivity before a visitor is dropped
BLOCKED_FILE = 'blocked_ids.json'
# STATS_FILE and RECENT_VISITS_FILE are defined below in persistent storage section
VISIT_STATS = None  # lazy-loaded dict: {id: first_seen_epoch}
FORCE_RELOAD_TIMESTAMP = 0  # Timestamp when force reload was triggered
FORCE_RELOAD_DURATION = 120  # Duration in seconds to keep force reload active (2 minutes)
FORCE_RELOAD_LOCK = threading.Lock()
client = None
session_str = os.getenv('TELEGRAM_SESSION')  # Telethon string session (recommended for Render)
BOT_TOKEN = os.getenv('TELEGRAM_BOT_TOKEN')  # optional bot token fallback
AUTH_SECRET = os.getenv('AUTH_SECRET')  # simple shared secret to protect /auth endpoints
FETCH_THREAD_STARTED = False
AUTH_STATUS = {'authorized': False, 'reason': 'init'}
SUBSCRIBERS = set()  # queues for SSE clients
INIT_ONCE = False  # guard to ensure background startup once
# Persistent dynamic channels file
CHANNELS_FILE = 'channels_dynamic.json'

# Backfill progress tracking
BACKFILL_STATUS = {
    'in_progress': False,
    'started_at': None,
    'channels_done': 0,
    'channels_total': 0,
    'messages_processed': 0,
    'current_channel': None
}

# Global debug storage for admin panel
DEBUG_LOGS = []
MAX_DEBUG_LOGS = 20  # Reduced to save memory

# Cache for fallback reparse to avoid duplicate processing
FALLBACK_REPARSE_CACHE = set()  # message IDs that have been reparsed
MAX_REPARSE_CACHE_SIZE = 200  # Reduced to save memory


def _normalize_platform(platform_hint: str, ua: str) -> str:
    """Map arbitrary client hints to canonical platform buckets."""
    candidate = (platform_hint or '').strip().lower()
    if candidate in VALID_PLATFORMS:
        return candidate

    ua_lower = (ua or '').lower()
    if 'android' in ua_lower:
        return 'android'
    if any(token in ua_lower for token in ('iphone', 'ipad', 'ios', 'cfnetwork')):
        return 'ios'
    return 'web'

def add_debug_log(message, category="general"):
    """Add debug message to global debug storage for admin panel."""
    global DEBUG_LOGS
    DEBUG_LOGS.append({
        'timestamp': datetime.now().isoformat(),
        'category': category,
        'message': str(message)
    })
    # Keep only recent logs
    if len(DEBUG_LOGS) > MAX_DEBUG_LOGS:
        DEBUG_LOGS = DEBUG_LOGS[-MAX_DEBUG_LOGS:]

# -------- Air alarm tracking (oblast / raion) --------
APP_ALARM_TTL_MINUTES = 65  # auto-expire if no update ~1h
ACTIVE_OBLAST_ALARMS = {}   # canonical oblast key -> {'since': epoch, 'last': epoch}
ACTIVE_RAION_ALARMS = {}    # raion base (lowercase) -> {'since': epoch, 'last': epoch}

# P-code mapping for ADM1 (області + special status cities)
OBLAST_PCODE = {
    'автономна республіка крим': 'UA01',
    'вінницька область': 'UA05',
    'волинська область': 'UA07',
    'дніпропетровська область': 'UA12',
    'донецька область': 'UA14',
    'житомирська область': 'UA18',
    'закарпатська область': 'UA21',
    'запорізька область': 'UA23',
    'івано-франківська область': 'UA26',
    'київська область': 'UA32',
    'кіровоградська область': 'UA35',
    'луганська область': 'UA44',
    'львівська область': 'UA46',
    'миколаївська область': 'UA48',
    'одеська область': 'UA51',
    'полтавська область': 'UA53',
    'рівненська область': 'UA56',
    'сумська область': 'UA59',
    'тернопільська область': 'UA61',
    'харківська область': 'UA63',
    'херсонська область': 'UA65',
    'хмельницька область': 'UA68',
    'черкаська область': 'UA71',
    'чернівецька область': 'UA73',
    'чернігівська область': 'UA74',
    'київ': 'UA80',
    'севастополь': 'UA85'
}

# ---- Alarm persistence (SQLite) ----
def init_alarms_db():
    try:
        with _visits_db_conn() as conn:
            conn.execute("""
                CREATE TABLE IF NOT EXISTS alarms (
                    id TEXT PRIMARY KEY,
                    level TEXT,
                    name TEXT,
                    since REAL,
                    last REAL
                )
            """)
            conn.execute("CREATE INDEX IF NOT EXISTS idx_alarms_level ON alarms(level)")
    except Exception as e:
        log.warning(f"alarms db init failed: {e}")

def init_alarm_events_db():
    try:
        with _visits_db_conn() as conn:
            conn.execute("""
                CREATE TABLE IF NOT EXISTS alarm_events (
                    id TEXT PRIMARY KEY,
                    level TEXT,
                    name TEXT,
                    event TEXT,
                    ts REAL
                )
            """)
            conn.execute("CREATE INDEX IF NOT EXISTS idx_alarm_events_time ON alarm_events(ts)")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_alarm_events_name ON alarm_events(name)")
    except Exception as e:
        log.warning(f"alarm_events db init failed: {e}")

def log_alarm_event(level:str, name:str, event:str, ts=None):
    ts = ts or time.time()
    try:
        with _visits_db_conn() as conn:
            conn.execute("INSERT INTO alarm_events (id,level,name,event,ts) VALUES (?,?,?,?,?)",
                         (uuid.uuid4().hex[:12], level, name, event, ts))
    except Exception as e:
        log.debug(f"log_alarm_event failed: {e}")

def _alarm_key(level:str, name:str)->str:
    return f"{level}:{name}".lower()

def persist_alarm(level:str, name:str, since:float, last:float):
    try:
        with _visits_db_conn() as conn:
            conn.execute("INSERT OR REPLACE INTO alarms (id,level,name,since,last) VALUES (?,?,?,?,?)",
                         (_alarm_key(level,name), level, name, since, last))
    except Exception as e:
        log.debug(f"persist_alarm failed: {e}")

def remove_alarm(level:str, name:str):
    try:
        with _visits_db_conn() as conn:
            conn.execute("DELETE FROM alarms WHERE id=?", (_alarm_key(level,name),))
    except Exception as e:
        log.debug(f"remove_alarm failed: {e}")

def load_active_alarms(ttl_seconds:int):
    out_obl = {}
    out_raion = {}
    cutoff = time.time() - ttl_seconds
    try:
        with _visits_db_conn() as conn:
            cur = conn.execute("SELECT level,name,since,last FROM alarms WHERE last >= ?", (cutoff,))
            for level,name,since,last in cur.fetchall():
                if level == 'oblast': out_obl[name] = {'since': since, 'last': last}
                elif level == 'raion': out_raion[name] = {'since': since, 'last': last}
    except Exception as e:
        log.debug(f"load_active_alarms failed: {e}")
    return out_obl, out_raion

def load_dynamic_channels():
    try:
        if os.path.exists(CHANNELS_FILE):
            with open(CHANNELS_FILE,'r',encoding='utf-8') as f:
                dyn = json.load(f)
            if isinstance(dyn, list):
                return [str(x).strip() for x in dyn if x]
    except Exception as e:
        log.warning(f'Failed loading {CHANNELS_FILE}: {e}')
    return []

def save_dynamic_channels(extra):
    try:
        with open(CHANNELS_FILE,'w',encoding='utf-8') as f:
            json.dump(extra, f, ensure_ascii=False, indent=2)
    except Exception as e:
        log.warning(f'Failed saving {CHANNELS_FILE}: {e}')

_dyn = load_dynamic_channels()
if _dyn:
    # Merge without duplicates
    base = [c.strip() for c in CHANNELS if c.strip()]
    for d in _dyn:
        if d not in base:
            base.append(d)
    CHANNELS = base
# ---------------- Monitoring period global config (admin editable) ----------------
CONFIG_FILE = 'config.json'
MONITOR_PERIOD_MINUTES = 30  # default; editable only via admin panel
MANUAL_MARKER_WINDOW_MINUTES = int(os.getenv('MANUAL_MARKER_WINDOW_MINUTES', '720'))  # manual markers stay visible at least 12h

# ---------------- Ballistic threat state ----------------
BALLISTIC_THREAT_ACTIVE = False
BALLISTIC_THREAT_REGION = None
BALLISTIC_THREAT_TIMESTAMP = None

def add_system_chat_message(message_type, text, region=None, threat_type='ballistic'):
    """Add system message to chat about threats/alerts.
    
    message_type: 'threat_start' or 'threat_end'
    text: The alert message text
    region: Optional region name
    threat_type: 'ballistic', 'air', 'artillery', etc.
    """
    try:
        kyiv_tz = pytz.timezone('Europe/Kiev')
        now = datetime.now(kyiv_tz)
        
        # Create system message
        system_message = {
            'id': f'system_{uuid.uuid4()}',
            'userId': '⚠️ Система сповіщень',
            'deviceId': 'system',
            'message': text,
            'timestamp': now.timestamp(),
            'time': now.strftime('%H:%M'),
            'date': now.strftime('%d.%m.%Y'),
            'isSystem': True,  # Mark as system message
            'systemType': message_type,  # 'threat_start' or 'threat_end'
            'threatType': threat_type,
            'region': region
        }
        
        # Load, append, save
        messages = load_chat_messages()
        messages.append(system_message)
        save_chat_messages(messages)
        
        log.info(f'📢 Added system chat message: {message_type} - {text[:50]}...')
    except Exception as e:
        log.error(f'Error adding system chat message: {e}')

def update_ballistic_state(text, is_realtime=False):
    """Update ballistic threat state based on Telegram message text.
    
    Args:
        text: The message text to analyze
        is_realtime: If True, this is a live message (add to chat). If False, it's from backfill (don't add to chat)
    """
    global BALLISTIC_THREAT_ACTIVE, BALLISTIC_THREAT_REGION, BALLISTIC_THREAT_TIMESTAMP
    if not text:
        return
    text_lower = text.lower()
    
    # Detect ballistic threat activation
    if 'загроза балістики' in text_lower and 'відбій' not in text_lower:
        was_active = BALLISTIC_THREAT_ACTIVE
        BALLISTIC_THREAT_ACTIVE = True
        BALLISTIC_THREAT_TIMESTAMP = datetime.now().isoformat()
        # Try to extract region
        import re
        region_match = re.search(r'([\w\-]+(?:ська|ький|ка)\s*область)', text, re.IGNORECASE)
        if region_match:
            BALLISTIC_THREAT_REGION = region_match.group(1)
        else:
            BALLISTIC_THREAT_REGION = None
        log.info(f'🚀 BALLISTIC THREAT ACTIVATED: region={BALLISTIC_THREAT_REGION}, realtime={is_realtime}')
        
        # Add system message to chat ONLY for realtime (live) messages, not backfill
        if not was_active and is_realtime:
            region_text = f' ({BALLISTIC_THREAT_REGION})' if BALLISTIC_THREAT_REGION else ''
            add_system_chat_message(
                'threat_start',
                f'🚀 ЗАГРОЗА БАЛІСТИКИ{region_text}! Негайно в укриття!',
                BALLISTIC_THREAT_REGION,
                'ballistic'
            )
        return
    
    # Detect ballistic threat deactivation
    if 'відбій' in text_lower and ('балістик' in text_lower or 'загроз' in text_lower):
        was_active = BALLISTIC_THREAT_ACTIVE
        if BALLISTIC_THREAT_ACTIVE:
            log.info(f'✅ BALLISTIC THREAT DEACTIVATED, realtime={is_realtime}')
        BALLISTIC_THREAT_ACTIVE = False
        BALLISTIC_THREAT_REGION = None
        BALLISTIC_THREAT_TIMESTAMP = None
        
        # Add system message to chat ONLY for realtime (live) messages
        if was_active and is_realtime:
            add_system_chat_message(
                'threat_end',
                '✅ Відбій загрози балістики. Залишайтесь пильними.',
                None,
                'ballistic'
            )
        return

def add_telegram_message_to_chat(text, is_realtime=False):
    """Add important Telegram messages to chat as system notifications.
    
    Args:
        text: The message text from Telegram
        is_realtime: If True, add to chat. If False, skip (backfill)
    """
    if not text or not is_realtime:
        return
    
    text_lower = text.lower()
    
    # Skip if it's a ballistic message (handled separately by update_ballistic_state)
    if 'балістик' in text_lower:
        return
    
    # Detect threat type and format message
    message_type = None
    threat_type = None
    emoji = '⚠️'
    formatted_text = None
    region = None
    
    # Extract region from text
    import re
    region_match = re.search(r'([\w\-]+(?:ська|ький|ка)\s*(?:область|район))', text, re.IGNORECASE)
    if region_match:
        region = region_match.group(1)
    
    # КАБи (Керовані авіабомби)
    if 'каб' in text_lower and 'відбій' not in text_lower:
        message_type = 'threat_start'
        threat_type = 'kab'
        emoji = '💣'
        # Extract short version
        if len(text) > 100:
            formatted_text = f'{emoji} КАБи: {text[:100]}...'
        else:
            formatted_text = f'{emoji} {text}'
    
    # Ракети / крилаті ракети
    elif ('ракет' in text_lower or 'крилат' in text_lower) and 'відбій' not in text_lower:
        message_type = 'threat_start'
        threat_type = 'rocket'
        emoji = '🚀'
        if len(text) > 100:
            formatted_text = f'{emoji} Ракети: {text[:100]}...'
        else:
            formatted_text = f'{emoji} {text}'
    
    # БПЛА / Дрони / Шахеди
    elif any(kw in text_lower for kw in ['бпла', 'дрон', 'шахед', 'безпілотн']) and 'відбій' not in text_lower:
        message_type = 'threat_start'
        threat_type = 'drone'
        emoji = '🛩️'
        if len(text) > 100:
            formatted_text = f'{emoji} БПЛА: {text[:100]}...'
        else:
            formatted_text = f'{emoji} {text}'
    
    # Вибухи
    elif 'вибух' in text_lower:
        message_type = 'threat_start'
        threat_type = 'explosion'
        emoji = '💥'
        if len(text) > 100:
            formatted_text = f'{emoji} Вибухи: {text[:100]}...'
        else:
            formatted_text = f'{emoji} {text}'
    
    # Відбій тривоги (загальний)
    elif 'відбій' in text_lower and ('тривог' in text_lower or 'загроз' in text_lower):
        message_type = 'threat_end'
        threat_type = 'all_clear'
        emoji = '✅'
        formatted_text = f'{emoji} Відбій: {text[:80]}' if len(text) > 80 else f'{emoji} {text}'
    
    # Тривога (загальна повітряна)
    elif 'тривог' in text_lower and 'повітрян' in text_lower and 'відбій' not in text_lower:
        message_type = 'threat_start'
        threat_type = 'air_alarm'
        emoji = '🚨'
        formatted_text = f'{emoji} {text[:100]}' if len(text) > 100 else f'{emoji} {text}'
    
    # If we detected something, add to chat
    if message_type and formatted_text:
        add_system_chat_message(
            message_type,
            formatted_text,
            region,
            threat_type
        )
        log.info(f'📢 Added Telegram message to chat: {threat_type} - {formatted_text[:50]}...')

def load_config():
    """Load persisted configuration (currently only monitor period)."""
    global MONITOR_PERIOD_MINUTES
    try:
        if os.path.exists(CONFIG_FILE):
            with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
                cfg = json.load(f)
            # Validate range 1..360 else ignore
            mp = int(cfg.get('monitor_period', MONITOR_PERIOD_MINUTES))
            if 1 <= mp <= 360:
                MONITOR_PERIOD_MINUTES = mp
    except Exception as e:
        log.warning(f'Failed loading {CONFIG_FILE}: {e}')

def save_config():
    try:
        with open(CONFIG_FILE, 'w', encoding='utf-8') as f:
            json.dump({'monitor_period': MONITOR_PERIOD_MINUTES}, f, ensure_ascii=False, indent=2)
    except Exception as e:
        log.warning(f'Failed saving {CONFIG_FILE}: {e}')

load_config()
if API_ID and API_HASH:
    if session_str:
        log.info('Initializing Telegram client with TELEGRAM_SESSION string.')
        client = TelegramClient(StringSession(session_str), API_ID, API_HASH)
    elif BOT_TOKEN:
        log.info('Initializing Telegram client with BOT token (limited access).')
        # Bot sessions auto-authorize on start
        client = TelegramClient(StringSession(), API_ID, API_HASH)
    else:
        log.info('Initializing Telegram client with local session file (may not persist on Render).')
        client = TelegramClient('anon', API_ID, API_HASH)

# Use persistent disk on Render for data that should survive deploys
PERSISTENT_DATA_DIR = os.getenv('PERSISTENT_DATA_DIR', '/data')

# Log persistent storage status
log.info(f'PERSISTENT_DATA_DIR: {PERSISTENT_DATA_DIR}')
log.info(f'Directory exists: {os.path.isdir(PERSISTENT_DATA_DIR)}')

# Try to create the directory if it doesn't exist (Render disk should be mounted)
try:
    if PERSISTENT_DATA_DIR and not os.path.isdir(PERSISTENT_DATA_DIR):
        os.makedirs(PERSISTENT_DATA_DIR, exist_ok=True)
        log.info(f'Created directory: {PERSISTENT_DATA_DIR}')
except Exception as e:
    log.warning(f'Could not create persistent directory: {e}')

# Check again after attempting to create
if PERSISTENT_DATA_DIR and os.path.isdir(PERSISTENT_DATA_DIR):
    MESSAGES_FILE = os.path.join(PERSISTENT_DATA_DIR, 'messages.json')
    CHAT_MESSAGES_FILE = os.path.join(PERSISTENT_DATA_DIR, 'chat_messages.json')
    HIDDEN_FILE = os.path.join(PERSISTENT_DATA_DIR, 'hidden_markers.json')
    COMMERCIAL_SUBSCRIPTIONS_FILE = os.path.join(PERSISTENT_DATA_DIR, 'commercial_subscriptions.json')
    STATS_FILE = os.path.join(PERSISTENT_DATA_DIR, 'visits_stats.json')
    RECENT_VISITS_FILE = os.path.join(PERSISTENT_DATA_DIR, 'visits_recent.json')
    log.info(f'Using PERSISTENT storage: {CHAT_MESSAGES_FILE}')
else:
    # Fallback to local files (for development)
    MESSAGES_FILE = 'messages.json'
    CHAT_MESSAGES_FILE = 'chat_messages.json'  # Anonymous chat messages
    HIDDEN_FILE = 'hidden_markers.json'
    COMMERCIAL_SUBSCRIPTIONS_FILE = 'commercial_subscriptions.json'
    STATS_FILE = 'visits_stats.json'
    RECENT_VISITS_FILE = 'visits_recent.json'
    log.warning(f'Using LOCAL storage (will be lost on redeploy): {CHAT_MESSAGES_FILE}')
OPENCAGE_CACHE_FILE = 'opencage_cache.json'
OPENCAGE_TTL = 60 * 60 * 24 * 30  # 30 days
NEG_GEOCODE_FILE = 'negative_geocode_cache.json'
NEG_GEOCODE_TTL = 60 * 60 * 24 * 3  # 3 days for 'not found' entries
MESSAGES_RETENTION_MINUTES = int(os.getenv('MESSAGES_RETENTION_MINUTES', '1440'))  # 24 hours retention by default
MESSAGES_MAX_COUNT = int(os.getenv('MESSAGES_MAX_COUNT', '500'))  # Default limit 500 to prevent memory issues

def _startup_diagnostics():
    """Log one-time startup diagnostics to help investigate early exit issues on hosting platforms."""
    try:
        log.info('--- Startup diagnostics begin ---')
        log.info(f'Python: {sys.version.split()[0]} Platform: {platform.platform()} PID: {os.getpid()}')
        log.info(f'Flask version: {getattr(sys.modules.get("flask"), "__version__", "?")} Telethon version: {getattr(sys.modules.get("telethon"), "__version__", "?")}')
        log.info(f'Configured channels ({len(CHANNELS)}): {CHANNELS}')
        log.info(f'API_ID set: {bool(API_ID)} HASH set: {bool(API_HASH)} SESSION len: {len(session_str) if session_str else 0}')
        log.info(f'GOOGLE_MAPS_KEY set: {bool(GOOGLE_MAPS_KEY)} OPENCAGE_API_KEY set: {bool(OPENCAGE_API_KEY)}')
        if os.path.exists(MESSAGES_FILE):
            try:
                sz = os.path.getsize(MESSAGES_FILE)
                log.info(f'{MESSAGES_FILE} exists size={sz} bytes')
            except Exception:
                pass
        else:
            log.info(f'{MESSAGES_FILE} not present yet.')
        log.info(f'Retention minutes: {MESSAGES_RETENTION_MINUTES} Max count: {MESSAGES_MAX_COUNT}')
        log.info(f'FETCH_START_DELAY={os.getenv("FETCH_START_DELAY", "0")}')
        log.info('--- Startup diagnostics end ---')
    except Exception as e:
        log.warning(f'Diagnostics error: {e}')

def _prune_messages(data):
    """Apply retention policies (time / count). Mutates and returns list."""
    if not data:
        return data
    # Time based pruning
    if MESSAGES_RETENTION_MINUTES > 0:
        cutoff = datetime.utcnow() - timedelta(minutes=MESSAGES_RETENTION_MINUTES)
        pruned = []
        for m in data:
            if m.get('manual'):
                pruned.append(m)
                continue
            try:
                dt = datetime.strptime(m.get('date',''), '%Y-%m-%d %H:%M:%S')
            except Exception:
                # keep malformed to avoid data loss
                pruned.append(m)
                continue
            if dt.replace(tzinfo=None) >= cutoff:
                pruned.append(m)
        data = pruned
    # Count based pruning (keep newest by date)
    if MESSAGES_MAX_COUNT > 0 and len(data) > MESSAGES_MAX_COUNT:
        try:
            manual_items = [m for m in data if m.get('manual')]
            auto_items = [m for m in data if not m.get('manual')]
            allow_auto = max(0, MESSAGES_MAX_COUNT - len(manual_items))
            if len(auto_items) > allow_auto:
                auto_items = sorted(auto_items, key=lambda x: x.get('date',''))[-allow_auto:]
            combined = manual_items + auto_items
            data = sorted(combined, key=lambda x: x.get('date',''))
        except Exception:
            data = data[-MESSAGES_MAX_COUNT:]
    return data


MESSAGE_STORE = MessageStore(
    MESSAGES_FILE,
    prune_fn=_prune_messages,
    preserve_manual=True,
    backup_count=3,
)

# Cache for sent FCM notifications to prevent duplicates
# Format: {notification_hash: timestamp}
SENT_NOTIFICATIONS_CACHE = {}
NOTIFICATION_CACHE_TTL = 300  # 5 minutes - don't repeat same location+threat within this time

def _normalize_location_name(name: str) -> str:
    """Normalize location name for deduplication - remove common suffixes/prefixes."""
    if not name:
        return ''
    name = name.lower().strip()
    # Remove common suffixes
    suffixes = [' район', ' область', ' громада', ' міська', ' селищна', ' сільська', 
                ' (міська)', ' (районна)', ' (обласна)', 'ська', 'ський']
    for suffix in suffixes:
        if name.endswith(suffix):
            name = name[:-len(suffix)]
    return name.strip()

def _get_notification_hash(msg: dict) -> str:
    """Generate a unique hash for a notification based on content.
    Uses location name + threat type only (ignores coordinates) for better deduplication.
    """
    import hashlib
    # Use place + threat_type as unique key (ignore coordinates for better dedup)
    place = (msg.get('place', '') or msg.get('location', '') or '')[:100]
    place = _normalize_location_name(place)
    
    msg_type = (msg.get('threat_type', '') or msg.get('type', '') or '')[:50].lower()
    
    # Normalize threat type to category
    if 'бпла' in msg_type or 'дрон' in msg_type or 'шахед' in msg_type:
        msg_type = 'drone'
    elif 'ракет' in msg_type or 'балістичн' in msg_type or 'крилат' in msg_type:
        msg_type = 'rocket'
    elif 'каб' in msg_type or 'бомб' in msg_type:
        msg_type = 'kab'
    elif 'відбій' in msg_type or 'знято' in msg_type:
        msg_type = 'clear'
    else:
        msg_type = 'alert'
    
    content = f"{place}|{msg_type}"
    return hashlib.md5(content.encode()).hexdigest()

def _should_send_notification(msg: dict) -> bool:
    """Check if notification should be sent (not a duplicate)."""
    global SENT_NOTIFICATIONS_CACHE
    
    msg_hash = _get_notification_hash(msg)
    now = time.time()
    
    # Clean old entries from cache
    SENT_NOTIFICATIONS_CACHE = {
        h: t for h, t in SENT_NOTIFICATIONS_CACHE.items() 
        if now - t < NOTIFICATION_CACHE_TTL
    }
    
    if msg_hash in SENT_NOTIFICATIONS_CACHE:
        log.info(f"Skipping duplicate notification (hash: {msg_hash[:8]}...)")
        return False
    
    # Mark as sent
    SENT_NOTIFICATIONS_CACHE[msg_hash] = now
    return True

def load_messages():
    # HIGH-LOAD: Use cached version to reduce disk I/O
    return load_messages_cached()


def save_messages(data, send_notifications=True):
    try:
        # Invalidate cache on save
        invalidate_messages_cache()
        
        # Check for new messages to send notifications
        existing = MESSAGE_STORE.load()
        existing_ids = {msg.get('id') for msg in existing}
        new_messages = [msg for msg in data if msg.get('id') and msg.get('id') not in existing_ids]
        
        if new_messages:
            log.info(f"Found {len(new_messages)} new messages to process for notifications")
            
            # === MULTI-CHANNEL FUSION: Process new messages ===
            for msg in new_messages:
                try:
                    fusion_result = process_message_with_fusion(msg)
                    if fusion_result:
                        log.info(f"[FUSION] {fusion_result['action']} event {fusion_result['event_id']}")
                except Exception as e:
                    log.debug(f"Fusion system error: {e}")
            
            # === THREAT TRACKER: Process new messages ===
            for msg in new_messages:
                try:
                    result = process_message_for_threats(msg)
                    if result:
                        log.debug(f"Threat tracker: {result['action']} threat {result['threat_id']}")
                except Exception as e:
                    log.debug(f"Threat tracker error: {e}")
        
        saved = MESSAGE_STORE.save(data)
        
        # Send FCM notifications for new messages (with deduplication)
        if send_notifications:
            # Get current Kyiv time for freshness check
            kyiv_tz = pytz.timezone('Europe/Kyiv')
            now_kyiv = datetime.now(kyiv_tz)
            max_age_minutes = 5  # Only send notifications for messages less than 5 minutes old
            
            for msg in new_messages:
                # Skip messages that should NOT trigger notifications:
                # 1. Manual markers
                # 2. Messages without coordinates (pending_geo or no lat/lng)
                # 3. Messages without threat_type/type
                # 4. Old messages (more than 5 minutes old)
                if msg.get('manual'):
                    log.debug(f"Skipping FCM for manual marker: {msg.get('id')}")
                    continue
                    
                # Check for coordinates - field names may vary
                lat = msg.get('lat') or msg.get('latitude')
                lng = msg.get('lng') or msg.get('longitude')
                if msg.get('pending_geo') or not lat or not lng:
                    log.debug(f"Skipping FCM for message without coordinates: {msg.get('id')}")
                    continue
                    
                if not msg.get('threat_type') and not msg.get('type'):
                    log.debug(f"Skipping FCM for message without threat type: {msg.get('id')}")
                    continue
                
                # Check message age - skip old messages
                # Try multiple date formats: 'timestamp', 'date'
                msg_date = msg.get('timestamp') or msg.get('date', '')
                if msg_date:
                    try:
                        # Try different date formats
                        msg_time = None
                        for fmt in ['%Y-%m-%d %H:%M:%S', '%Y-%m-%d %H:%M', '%d.%m.%Y %H:%M:%S', '%d.%m.%Y %H:%M', '%d.%m.%Y']:
                            try:
                                msg_time = datetime.strptime(msg_date, fmt)
                                break
                            except ValueError:
                                continue
                        
                        if msg_time:
                            msg_time = kyiv_tz.localize(msg_time)
                            age_minutes = (now_kyiv - msg_time).total_seconds() / 60
                            
                            if age_minutes > max_age_minutes:
                                log.info(f"Skipping FCM for old message ({age_minutes:.1f} min old): {msg.get('location', 'unknown')}")
                                continue
                            log.info(f"Message is fresh ({age_minutes:.1f} min old), sending notification")
                        else:
                            log.warning(f"Could not parse message date '{msg_date}' with any format")
                            continue
                    except Exception as e:
                        log.warning(f"Error parsing message date '{msg_date}': {e}")
                        continue
                else:
                    log.debug(f"Message has no timestamp, skipping FCM")
                    continue
                    
                # Check if this notification was already sent recently
                if not _should_send_notification(msg):
                    log.info(f"Skipping duplicate FCM for: {msg.get('location', 'unknown')}")
                    continue
                try:
                    location = msg.get('place') or msg.get('location') or ''
                    threat = msg.get('threat_type') or msg.get('type') or 'загроза'
                    log.info(f"Sending FCM for message: {location} - {threat}")
                    send_fcm_notification(msg)
                except Exception as e:
                    log.error(f"Failed to send FCM notification: {e}")
    except Exception as exc:
        log.error('Failed to persist messages: %s', exc)
        saved = data
    else:
        print(f"DEBUG: Saving {len(saved)} messages to file")
    # After each save attempt optional git auto-commit
    try:
        maybe_git_autocommit()
    except Exception as e:
        log.debug(f'git auto-commit skipped: {e}')
    return saved

# ---------------- Deduplication / merge of near-duplicate geo events -----------------
# Two messages that refer to the same object coming almost back-to-back should not
# produce two separate points: instead we update the earlier one (increment count, merge text).
# Heuristics: same threat_type, within DEDUP_DIST_KM km, within DEDUP_TIME_MIN minutes.
# DISABLED: Now showing all messages as separate points with small offset
DEDUP_ENABLED = False  # Set to True to enable merging
DEDUP_TIME_MIN = int(os.getenv('DEDUP_TIME_MIN', '5'))
DEDUP_DIST_KM = float(os.getenv('DEDUP_DIST_KM', '7'))
DEDUP_SCAN_BACK = int(os.getenv('DEDUP_SCAN_BACK', '400'))  # how many recent messages to scan

def _parse_dt(s:str):
    try:
        return datetime.strptime(s, '%Y-%m-%d %H:%M:%S')
    except Exception:
        return None

def _haversine_km(lat1, lon1, lat2, lon2):
    try:
        from math import radians, sin, cos, asin, sqrt
        R = 6371.0
        dlat = radians(lat2-lat1)
        dlon = radians(lon2-lon1)
        a = sin(dlat/2)**2 + cos(radians(lat1))*cos(radians(lat2))*sin(dlon/2)**2
        c = 2*asin(sqrt(a))
        return R*c
    except Exception:
        return 999999

def maybe_merge_track(all_data:list, new_track:dict):
    """Try to merge new_track into an existing recent track.
    Returns tuple (merged: bool, track_ref: dict).
    
    If DEDUP_ENABLED is False, adds small random offset to prevent overlapping.
    """
    import random
    
    # If dedup disabled, add small offset and return as new track
    if not DEDUP_ENABLED:
        lat = new_track.get('lat')
        lng = new_track.get('lng')
        if isinstance(lat, (int, float)) and isinstance(lng, (int, float)):
            # Add small random offset (about 500m-1.5km)
            offset_lat = random.uniform(-0.012, 0.012)
            offset_lng = random.uniform(-0.015, 0.015)
            new_track['lat'] = lat + offset_lat
            new_track['lng'] = lng + offset_lng
        return False, new_track
    
    try:
        if not all_data:
            return False, new_track
        tt = (new_track.get('threat_type') or '').lower()
        if not tt:
            return False, new_track
        lat = new_track.get('lat'); lng = new_track.get('lng')
        if not isinstance(lat, (int,float)) or not isinstance(lng, (int,float)):
            return False, new_track
        new_dt = _parse_dt(new_track.get('date','')) or datetime.utcnow()
        # Scan recent slice only for performance
        scan_slice = all_data[-DEDUP_SCAN_BACK:]
        # Iterate reversed (newest first)
        for existing in reversed(scan_slice):
            if existing is new_track:  # shouldn't happen yet
                continue
            if (existing.get('threat_type') or '').lower() != tt:
                continue
            e_lat = existing.get('lat'); e_lng = existing.get('lng')
            if not isinstance(e_lat,(int,float)) or not isinstance(e_lng,(int,float)):
                continue
            dist = _haversine_km(lat,lng,e_lat,e_lng)
            if dist > DEDUP_DIST_KM:
                continue
            e_dt = _parse_dt(existing.get('date','')) or new_dt
            dt_min = abs((new_dt - e_dt).total_seconds())/60.0
            if dt_min > DEDUP_TIME_MIN:
                continue
            # Merge
            # Increment count
            existing['count'] = int(existing.get('count') or 1) + 1
            # Merge text (avoid duplication / uncontrolled growth)
            new_text = (new_track.get('text') or '').strip()
            if new_text:
                ex_text = existing.get('text') or ''
                if new_text not in ex_text:
                    combined = (ex_text + ' | ' + new_text).strip(' |') if ex_text else new_text
                    if len(combined) > 800:
                        combined = combined[:790] + '…'
                    existing['text'] = combined
            # Maintain list of merged ids
            if 'merged_ids' not in existing:
                existing['merged_ids'] = [existing.get('id')]
            nid = new_track.get('id')
            if nid and nid not in existing['merged_ids']:
                existing['merged_ids'].append(nid)
            # Update displayed date to the most recent
            if new_dt >= e_dt:
                existing['date'] = new_track.get('date') or existing.get('date')
            # Optionally capture first occurrence time
            if 'first_date' not in existing:
                existing['first_date'] = e_dt.strftime('%Y-%m-%d %H:%M:%S')
            existing['merged'] = True
            return True, existing
    except Exception as e:
        log.debug(f'dedup merge error: {e}')
    return False, new_track


def load_hidden():
    if os.path.exists(HIDDEN_FILE):
        try:
            with open(HIDDEN_FILE, encoding='utf-8') as f:
                return json.load(f)
        except Exception:
            return []
    return []

def save_hidden(data):
    with open(HIDDEN_FILE, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def load_blocked():
    if os.path.exists(BLOCKED_FILE):
        try:
            with open(BLOCKED_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception:
            return []
    return []

def save_blocked(blocked):
    try:
        with open(BLOCKED_FILE, 'w', encoding='utf-8') as f:
            json.dump(blocked, f, ensure_ascii=False, indent=2)
    except Exception as e:
        log.warning(f'Failed saving {BLOCKED_FILE}: {e}')

def _load_visit_stats():
    global VISIT_STATS
    if VISIT_STATS is not None:
        return VISIT_STATS
    if os.path.exists(STATS_FILE):
        try:
            with open(STATS_FILE,'r',encoding='utf-8') as f:
                VISIT_STATS = json.load(f)
        except Exception:
            VISIT_STATS = {}
    else:
        VISIT_STATS = {}
    return VISIT_STATS

def _save_visit_stats():
    if VISIT_STATS is None:
        return
    try:
        with open(STATS_FILE,'w',encoding='utf-8') as f:
            json.dump(VISIT_STATS, f, ensure_ascii=False, indent=2)
    except Exception as e:
        log.warning(f'Failed saving {STATS_FILE}: {e}')

def _prune_visit_stats(days:int=30):
    # remove entries older than N days to limit file growth - reduced from 45 to 30 days
    if VISIT_STATS is None:
        return
    cutoff = time.time() - days*86400
    removed = 0
    for vid, ts in list(VISIT_STATS.items()):
        try:
            if float(ts) < cutoff:
                del VISIT_STATS[vid]
                removed += 1
        except Exception:
            continue
    if removed:
        _save_visit_stats()

# ---- Rolling daily / weekly visit tracking (for persistence of counts across deploys) ----
def _load_recent_visits():
    try:
        if os.path.exists(RECENT_VISITS_FILE):
            # Guard against oversized/corrupted file (e.g. concurrent writes producing concatenated JSON objects)
            try:
                raw = open(RECENT_VISITS_FILE, 'r', encoding='utf-8').read()
            except Exception as e_read:
                log.warning(f"Failed reading {RECENT_VISITS_FILE}: {e_read}")
                return {}
            # Quick heuristic: if multiple top-level JSON objects concatenated, keep first valid
            data = None
            if raw.strip():
                try:
                    data = json.loads(raw)
                except json.JSONDecodeError as je:
                    # Try to split by newlines and stitch until first valid JSON object
                    fragments = raw.splitlines()
                    buf = ''
                    for line in fragments:
                        buf += line.strip() + '\n'
                        try:
                            data = json.loads(buf)
                            log.warning(f"Recovered first valid JSON segment from {RECENT_VISITS_FILE} after decode error: {je}")
                            break
                        except Exception:
                            continue
                    if data is None:
                        log.warning(f"Unable to repair {RECENT_VISITS_FILE}: {je}")
                        return {}
                except Exception as e_generic:
                    log.warning(f"Generic JSON load failure {RECENT_VISITS_FILE}: {e_generic}")
                    return {}
            else:
                return {}
            if not isinstance(data, dict):
                log.warning(f"Unexpected structure in {RECENT_VISITS_FILE}, resetting")
                return {}
            data.setdefault('day', '')
            data.setdefault('week_start', '')
            data.setdefault('today_ids', [])
            data.setdefault('week_ids', [])
            return data
    except Exception as e:
        log.warning(f"Failed loading {RECENT_VISITS_FILE}: {e}")
    return {}

def _save_recent_visits(data:dict):
    try:
        tmp = RECENT_VISITS_FILE + '.tmp'
        # Ensure directory exists (in case path was changed to subfolder later); here file in CWD so skip
        with open(tmp, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        try:
            os.replace(tmp, RECENT_VISITS_FILE)
        except FileNotFoundError:
            # Rare race on some FS / AV scanners: fall back to simple write
            try:
                with open(RECENT_VISITS_FILE, 'w', encoding='utf-8') as f2:
                    json.dump(data, f2, ensure_ascii=False, indent=2)
            except Exception as e2:
                log.warning(f"Fallback direct save failed {RECENT_VISITS_FILE}: {e2}")
    except Exception as e:
        log.warning(f"Failed saving {RECENT_VISITS_FILE}: {e}")

def _update_recent_visits(vid:str):
    """Update rolling daily/week sets with visitor id. Uses Europe/Kyiv timezone.
    This offers stable daily/week unique counts even if the broader first-seen file is lost on redeploy."""
    if not vid:
        return
    data = _load_recent_visits() or {}
    tz = pytz.timezone('Europe/Kyiv')
    now_dt = datetime.now(tz)
    today = now_dt.strftime('%Y-%m-%d')
    # ISO week (Monday start) anchor date for 7-day rolling window (not strictly calendar week) -> we store date 6 days prior cutoff
    # We'll implement simple 7-day rolling: if stored week_start older than 7 days, reset week_ids
    stored_week_start = data.get('week_start') or today
    try:
        sw_dt = datetime.strptime(stored_week_start, '%Y-%m-%d')
        # make tz-aware in same timezone
        sw_dt = tz.localize(sw_dt)
    except Exception:
        sw_dt = now_dt
    if (now_dt - sw_dt).days >= 7:
        # reset week window
        stored_week_start = today
        data['week_ids'] = []
    # day rollover
    if data.get('day') != today:
        data['day'] = today
        data['today_ids'] = []
    # ensure lists
    if 'today_ids' not in data or not isinstance(data['today_ids'], list):
        data['today_ids'] = []
    if 'week_ids' not in data or not isinstance(data['week_ids'], list):
        data['week_ids'] = []
    if vid not in data['today_ids']:
        data['today_ids'].append(vid)
    if vid not in data['week_ids']:
        data['week_ids'].append(vid)
    data['week_start'] = stored_week_start
    _save_recent_visits(data)

def _recent_counts():
    data = _load_recent_visits()
    if not data:
        return None, None
    return len(set(data.get('today_ids', []))), len(set(data.get('week_ids', [])))

# Simplified message processor placeholder
import math
import sqlite3

_opencage_cache = None
_neg_geocode_cache = None
_mapstransler_geocode_cache = {}  # In-memory cache for mapstransler geocoding

def _load_opencage_cache():
    global _opencage_cache
    if _opencage_cache is not None:
        return _opencage_cache
    if os.path.exists(OPENCAGE_CACHE_FILE):
        try:
            with open(OPENCAGE_CACHE_FILE, 'r', encoding='utf-8') as f:
                _opencage_cache = json.load(f)
        except Exception:
            _opencage_cache = {}
    else:
        _opencage_cache = {}
    return _opencage_cache

def _save_opencage_cache():
    if _opencage_cache is None:
        return
    try:
        # Limit cache size to prevent memory issues
        cache_to_save = _opencage_cache
        if len(_opencage_cache) > 1000:
            # Keep only the 1000 most recent entries (approximate)
            items = list(_opencage_cache.items())
            cache_to_save = dict(items[-1000:])
        with open(OPENCAGE_CACHE_FILE, 'w', encoding='utf-8') as f:
            json.dump(cache_to_save, f, ensure_ascii=False, indent=2)
    except Exception as e:
        log.warning(f"Failed saving OpenCage cache: {e}")

def _load_neg_geocode_cache():
    global _neg_geocode_cache
    if _neg_geocode_cache is not None:
        return _neg_geocode_cache
    if os.path.exists(NEG_GEOCODE_FILE):
        try:
            with open(NEG_GEOCODE_FILE,'r',encoding='utf-8') as f:
                _neg_geocode_cache = json.load(f)
        except Exception:
            _neg_geocode_cache = {}
    else:
        _neg_geocode_cache = {}
    return _neg_geocode_cache

def _save_neg_geocode_cache():
    if _neg_geocode_cache is None:
        return
    try:
        # Limit cache size to prevent memory issues
        cache_to_save = _neg_geocode_cache
        if len(_neg_geocode_cache) > 500:
            # Keep only the 500 most recent entries (approximate)
            items = list(_neg_geocode_cache.items())
            cache_to_save = dict(items[-500:])
        with open(NEG_GEOCODE_FILE,'w',encoding='utf-8') as f:
            json.dump(cache_to_save,f,ensure_ascii=False,indent=2)
    except Exception as e:
        log.warning(f"Failed saving negative geocode cache: {e}")

def _msg_timestamp(msg):
    """Extract timestamp from message for sorting and filtering"""
    if not msg:
        return 0
    
    # Try different timestamp fields
    date_str = msg.get('date') or msg.get('timestamp') or msg.get('time')
    if not date_str:
        return 0
    
    try:
        # Handle different date formats
        if isinstance(date_str, (int, float)):
            return float(date_str)
        
        # Parse datetime string
        if isinstance(date_str, str):
            # Try common formats
            for fmt in ['%Y-%m-%d %H:%M:%S', '%Y-%m-%d %H:%M', '%d.%m.%Y %H:%M:%S', '%d.%m.%Y %H:%M']:
                try:
                    dt = datetime.strptime(date_str, fmt)
                    return dt.timestamp()
                except ValueError:
                    continue
            
            # Try parsing with dateutil as fallback
            try:
                from dateutil import parser
                dt = parser.parse(date_str)
                return dt.timestamp()
            except:
                pass
    except Exception:
        pass
    
    return 0

def neg_geocode_check(name:str):
    if not name:
        return False
    cache = _load_neg_geocode_cache()
    key = name.strip().lower()
    entry = cache.get(key)
    if not entry:
        return False
    # expire
    if int(time.time()) - entry.get('ts',0) > NEG_GEOCODE_TTL:
        try: del cache[key]; _save_neg_geocode_cache()
        except Exception: pass
        return False
    return True

def neg_geocode_add(name:str, reason:str='not_found'):
    if not name:
        return
    cache = _load_neg_geocode_cache()
    key = name.strip().lower()
    cache[key] = {'ts': int(time.time()), 'reason': reason}
    _save_neg_geocode_cache()

UA_CITIES = [
    'київ','харків','одеса','одесса','дніпро','дніпропетровськ','львів','запоріжжя','запорожье','вінниця','миколаїв','николаев',
    'маріуполь','полтава','чернігів','чернигов','черкаси','житомир','суми','хмельницький','чернівці','рівне','івано-франківськ',
    'луцьк','тернопіль','ужгород','кропивницький','кіровоград','кременчук','краматорськ','біла церква','мелітополь','бердянськ',
    'павлоград','ніжин','шостка','короп','кролевець'
]
UA_CITY_NORMALIZE = {
    'одесса':'одеса','запорожье':'запоріжжя','запоріжжі':'запоріжжя','дніпропетровськ':'дніпро','кировоград':'кропивницький','кіровоград':'кропивницький',
    'николаев':'миколаїв','чернигов':'чернігів',
    # Accusative / variant forms
    'липову долину':'липова долина','липову долина':'липова долина',
    'великий багачку':'велика багачка','велику багачу':'велика багачка','велику багачку':'велика багачка','велику багачка':'велика багачка',
    'улянівку':'улянівка','уляновку':'улянівка',
    # Велика Димерка падежные формы
    'велику димерку':'велика димерка','велика димерку':'велика димерка','великої димерки':'велика димерка','великій димерці':'велика димерка',
    # Велика Виска падежные формы  
    'велику виску':'велика виска','великої виски':'велика виска','великій висці':'велика виска',
    # Мала дівиця
    'малу дівицю':'мала дівиця','мала дівицю':'мала дівиця',
    # Additional safety normalizations
    'олишівку':'олишівка','згурівку':'згурівка','ставищею':'ставище','кегичівку':'кегичівка','кегичевку':'кегичівка',
    # Voznesensk variants
    'вознесенська':'вознесенськ',
    # Mykolaiv variants  
    'миколаєва':'миколаїв',
    'корабел':'корабельний район херсон',
    'корабельний':'корабельний район херсон',
    'корабельному':'корабельний район херсон',
    'корабельному херсоні':'корабельний район херсон',
    # Novoukrainka variants
    'новоукраїнку':'новоукраїнка',
    'старому салтову':'старий салтів','старому салтові':'старий салтів','карлівку':'карлівка','магдалинівку':'магдалинівка',
    'балаклію':'балаклія','білу церкву':'біла церква','баришівку':'баришівка','сквиру':'сквира','сосницю':'сосниця',
    'васильківку':'васильківка','понорницю':'понорниця','куликівку':'куликівка','терни':'терни',
    'шостку':'шостка','березну':'березна','зачепилівку':'зачепилівка','нову водолагу':'нова водолага',
    'нову':'нова водолага',  # Fallback for partial regex matches
    'убни':'лубни','олми':'холми','летичів':'летичів','летичев':'летичів','летичеве':'летичів','деражню':'деражня',
    'деражне':'деражня','деражні':'деражня','корюківку':'корюківка','борзну':'борзна','жмеринку':'жмеринка','лосинівку':'лосинівка',
    'ніжину':'ніжин','ніжина':'ніжин','межову':'межова','межової':'межова','святогірську':'святогірськ'
}

# Add accusative / genitive / variant forms for reported missing settlements
UA_CITY_NORMALIZE.update({
    'городню':'городня','городні':'городня','городне':'городня','городни':'городня',
    'кролевця':'кролевець','кролевцу':'кролевець','кролевце':'кролевець',
    'дубовʼязівку':'дубовʼязівка','дубовязівку':'дубовʼязівка','дубовязовку':'дубовʼязівка','дубовязовка':'дубовʼязівка',
    'батурина':'батурин','батурині':'батурин','батурином':'батурин'
    ,'бердичев':'бердичів','бердичева':'бердичів','бердичеве':'бердичів','бердичеву':'бердичів','бердичеві':'бердичів','бердичевом':'бердичів','бердичеву':'бердичів','бердичіву':'бердичів','бердичіва':'бердичів'
    ,'гостомеля':'гостомель','гостомелю':'гостомель','гостомелі':'гостомель','гостомель':'гостомель'
    ,'боярки':'боярка','боярку':'боярка','боярці':'боярка','боярка':'боярка'
    # Черниговская область - дополнительные формы
    ,'седнів':'седнів','седніву':'седнів','седніва':'седнів'
    ,'новгороду':'новгород','новгороді':'новгород','новгородом':'новгород'
    ,'мену':'мена','мені':'мена','меною':'мена'
    ,'макарова':'макарів','макарові':'макарів','макаров':'макарів','макарову':'макарів','макарів':'макарів'
    ,'бородянки':'бородянка','бородянку':'бородянка','бородянці':'бородянка','бородянка':'бородянка'
    ,'кілії':'кілія','кілію':'кілія','кілією':'кілія','кілія':'кілія'
    ,'ізмаїльського':'ізмаїльський','ізмаїльському':'ізмаїльський','ізмаїльський':'ізмаїльський'
    ,'броварського':'броварський','броварському':'броварський','броварський':'броварський'
    ,'обухівського':'обухівський','обухівському':'обухівський','обухівський':'обухівський'
    ,'херсонського':'херсонський','херсонському':'херсонський','херсонський':'херсонський'
    ,'вінницького':'вінницький','вінницькому':'вінницький','вінницький':'вінницький'
    ,'куцуруба':'куцуруб','воскресенку':'воскресенка','воскресенки':'воскресенка'
    # Цибулів (Черкаська обл.) падежные / вариантные формы
    ,'цибулева':'цибулів','цибулеві':'цибулів','цибулеву':'цибулів','цибулевом':'цибулів','цибулів':'цибулів'
    # New accusative / variants for UAV course parsing batch
    ,'борзну':'борзна','царичанку':'царичанка','андріївку':'андріївка','ямполь':'ямпіль','ямполя':'ямпіль','ямпіль':'ямпіль','димеру':'димер','чорнобилю':'чорнобиль'
    ,'дмитрівку':'дмитрівка','дмитрівку чернігівська':'дмитрівка','берестин':'берестин'
    ,'семенівку':'семенівка','глобине':'глобине','глобину':'глобине','глобиному':'глобине','глобина':'глобине'
    ,'кринички':'кринички','криничок':'кринички','солоне':'солоне','солоного':'солоне','солоному':'солоне'
    ,'краснопалівку':'краснопавлівка','краснопалівку':'краснопавлівка','краснопалівка':'краснопавлівка'
    ,'велику димерку':'велика димерка','великій димерці':'велика димерка','великої димерки':'велика димерка'
    ,'брусилів':'брусилів','брусилова':'брусилів','брусилові':'брусилів'
    # New cities from napramok messages September 2025
    ,'десну':'десна','кіпті':'кіпті','ічню':'ічня','цвіткове':'цвіткове'
    ,'чоповичі':'чоповичі','звягель':'звягель','сахновщину':'сахновщина'
    ,'камʼянське':'камʼянське','піщаний брід':'піщаний брід','бобринець':'бобринець'
    ,'тендрівську косу':'тендрівська коса'
    # Одеська область
    ,'вилково':'вилкове','вилкову':'вилкове'
    # Common accusative forms for major cities  
    ,'одесу':'одеса','полтаву':'полтава','сумами':'суми','суму':'суми'
})
# Apostrophe-less fallback for Sloviansk
UA_CITY_NORMALIZE['словянськ'] = "слов'янськ"

# Donetsk front city normalization (latin/ukr vowel variants)
UA_CITY_NORMALIZE['лиман'] = 'ліман'

# ---------------- Dynamic settlement name → region map (from city_ukraine.json, no coords there) ---------------
NAME_REGION_MAP = {}

def _load_name_region_map():
    global NAME_REGION_MAP
    if NAME_REGION_MAP:
        return
    path = 'city_ukraine.json'
    if not os.path.exists(path):
        return
    try:
        with open(path,'r',encoding='utf-8') as f:
            data = json.load(f)
        added = 0
        for item in data:
            if not isinstance(item, dict):
                continue
            name = str(item.get('object_name') or '').strip().lower()
            region = str(item.get('region') or '').strip().title()
            if not name or len(name) < 2:
                continue
            # Skip obviously generic words
            if name in NAME_REGION_MAP:
                continue
            NAME_REGION_MAP[name] = region
            added += 1
        log.info(f"Loaded NAME_REGION_MAP entries: {added}")
    except Exception as e:
        log.warning(f"Failed load city_ukraine.json names: {e}")

_load_name_region_map()

# Fix problematic entries in NAME_REGION_MAP that cause wrong city resolution
# Remove incomplete city names that point to wrong regions
PROBLEMATIC_ENTRIES = [
    'кривий',     # Should be 'кривий ріг' not just 'кривий' -> causes wrong region lookup
    'старий',     # Too generic, causes conflicts
    'нова',       # Too generic
    'велика',     # Too generic
    'мала',       # Too generic
    'білозерка',  # Conflicts with Херсонська область when message clearly specifies region
]

for entry in PROBLEMATIC_ENTRIES:
    NAME_REGION_MAP.pop(entry, None)


# ==================== ENHANCED AI GEOCODING SYSTEM ====================
# Advanced intelligent geocoding with multi-strategy fallback, disambiguation, 
# context-aware resolution, and machine learning from corrections
# Version 2.0 - Maximum optimization

# Extended city aliases with common misspellings and transliterations
CITY_ALIASES = {
    # Major cities with common variants
    'київ': ['киев', 'kyiv', 'kiev', 'кіїв', 'кийів'],
    'харків': ['харьков', 'kharkiv', 'kharkov', 'харкiв'],
    'одеса': ['одесса', 'odessa', 'odesa', 'одэса'],
    'дніпро': ['днепр', 'dnipro', 'dnepr', 'днiпро', 'днiпропетровськ'],
    'львів': ['львов', 'lviv', 'lvov', 'львiв'],
    'запоріжжя': ['запорожье', 'zaporizhzhia', 'zaporozhye', 'запорiжжя'],
    'миколаїв': ['николаев', 'mykolaiv', 'nikolaev', 'миколаiв'],
    'херсон': ['kherson', 'herson', 'херсонь'],
    'полтава': ['poltava', 'полтаві'],
    'чернігів': ['чернигов', 'chernihiv', 'chernigov', 'чернiгiв'],
    'суми': ['сумы', 'sumy', 'сумi'],
    'кропивницький': ['кировоград', 'кропивницкий', 'kropyvnytskyi', 'кiровоград'],
    'вінниця': ['винница', 'vinnytsia', 'vinnitsa', 'вiнниця'],
    'житомир': ['zhytomyr', 'житомір'],
    'рівне': ['ровно', 'rivne', 'rovno', 'рiвне'],
    'луцьк': ['луцк', 'lutsk', 'луцьк'],
    'тернопіль': ['тернополь', 'ternopil', 'тернопiль'],
    'хмельницький': ['хмельницкий', 'khmelnytskyi', 'хмельницкій'],
    'чернівці': ['черновцы', 'chernivtsi', 'черновці', 'чернiвцi'],
    'івано-франківськ': ['ивано-франковск', 'ivano-frankivsk', 'франківськ', 'франковск'],
    'ужгород': ['uzhhorod', 'ужгороді'],
    'кривий ріг': ['кривой рог', 'kryvyi rih', 'кривий рiг'],
    'маріуполь': ['мариуполь', 'mariupol', 'марiуполь'],
    "слов'янськ": ['славянск', 'sloviansk', 'словянськ'],
    'краматорськ': ['краматорск', 'kramatorsk'],
    'бахмут': ['артемовск', 'bakhmut', 'артемівськ'],
    'мелітополь': ['мелитополь', 'melitopol'],
    'бердянськ': ['бердянск', 'berdiansk'],
    'нікополь': ['никополь', 'nikopol', 'нiкополь'],
    'павлоград': ['pavlohrad', 'павлоградь'],
    'кам\'янське': ['каменское', 'дніпродзержинськ', 'kamianske'],
}

# Reverse alias lookup
_ALIAS_TO_CANONICAL = {}
for canonical, aliases in CITY_ALIASES.items():
    for alias in aliases:
        _ALIAS_TO_CANONICAL[alias.lower()] = canonical

# Common OCR/typo corrections
TYPO_CORRECTIONS = {
    'кiiв': 'київ',
    'киiв': 'київ',
    'xapкiв': 'харків',
    'xapків': 'харків',
    'oдеса': 'одеса',  # Latin 'o'
    'oдесса': 'одеса',
    'днiпро': 'дніпро',
    'запорiжжя': 'запоріжжя',
    'миколаiв': 'миколаїв',
    'полтаві': 'полтава',
    'сумі': 'суми',
    'львiв': 'львів',
    'рiвне': 'рівне',
    'вiнниця': 'вінниця',
    'тернопiль': 'тернопіль',
    'чернiгiв': 'чернігів',
    'хмельницкий': 'хмельницький',
    'кіровоградщіні': 'кіровоградщина',
    'херсощіні': 'херсонщина',
}

# Disambiguation map for cities that exist in multiple oblasts
AMBIGUOUS_CITIES = {
    'михайлівка': ['запорізька', 'донецька', 'одеська', 'миколаївська'],
    'новоселівка': ['харківська', 'донецька', 'запорізька', 'дніпропетровська'],
    'петрівка': ['кіровоградська', 'донецька', 'харківська', 'одеська'],
    'олександрівка': ['донецька', 'кіровоградська', 'миколаївська', 'одеська'],
    'василівка': ['запорізька', 'дніпропетровська', 'київська'],
    'новогригорівка': ['дніпропетровська', 'херсонська', 'одеська'],
    'зеленівка': ['херсонська', 'одеська', 'миколаївська'],
    'кам\'янка': ['черкаська', 'дніпропетровська', 'запорізька'],
    'покровське': ['донецька', 'дніпропетровська', 'харківська'],
    'мар\'їнка': ['донецька', 'київська'],
    'юр\'ївка': ['дніпропетровська', 'донецька', 'кіровоградська'],
    'юріївка': ['дніпропетровська', 'донецька', 'кіровоградська'],
    'андріївка': ['харківська', 'донецька', 'запорізька', 'київська'],
    'семенівка': ['чернігівська', 'полтавська', 'сумська'],
    'білозерка': ['херсонська', 'запорізька'],
    'широке': ['дніпропетровська', 'запорізька', 'донецька'],
    'тернівка': ['дніпропетровська', 'донецька', 'кіровоградська'],
    'степове': ['дніпропетровська', 'запорізька', 'миколаївська'],
    'новопавлівка': ['донецька', 'запорізька', 'харківська'],
    'воскресенка': ['миколаївська', 'запорізька'],
    'першотравневе': ['донецька', 'харківська', 'дніпропетровська'],
    'веселе': ['запорізька', 'харківська', 'донецька'],
    'українка': ['київська', 'донецька', 'дніпропетровська'],
    'калинівка': ['вінницька', 'київська', 'чернігівська'],
    'красногорівка': ['донецька', 'дніпропетровська'],
    'лисичанськ': ['луганська'],
    'сєвєродонецьк': ['луганська'],
}

# Source region to oblast mapping for trajectory context
SOURCE_REGION_HINTS = {
    'чорне море': ['одеська', 'миколаївська', 'херсонська'],
    'азовське море': ['запорізька', 'донецька', 'херсонська'],
    'білорусь': ['чернігівська', 'київська', 'житомирська', 'волинська'],
    'крим': ['херсонська', 'запорізька', 'миколаївська', 'одеська'],
    'рф': ['харківська', 'сумська', 'чернігівська', 'луганська', 'донецька'],
    'росія': ['харківська', 'сумська', 'чернігівська', 'луганська', 'донецька'],
    'бєлгород': ['харківська', 'сумська'],
    'курськ': ['сумська', 'чернігівська'],
    'брянськ': ['чернігівська', 'сумська'],
}

# Geocoding learning storage
_GEOCODE_LEARNING_FILE = 'geocode_learning.json'
_geocode_learning_cache = None

def _load_geocode_learning():
    """Load learned geocoding corrections"""
    global _geocode_learning_cache
    if _geocode_learning_cache is not None:
        return _geocode_learning_cache
    
    try:
        if os.path.exists(_GEOCODE_LEARNING_FILE):
            with open(_GEOCODE_LEARNING_FILE, 'r', encoding='utf-8') as f:
                _geocode_learning_cache = json.load(f)
        else:
            _geocode_learning_cache = {
                'corrections': {},  # {normalized_query: {lat, lng, source}}
                'disambiguation': {},  # {city: preferred_oblast}
                'failed_queries': [],  # queries that consistently fail
                'stats': {'total_queries': 0, 'cache_hits': 0, 'api_calls': 0}
            }
    except Exception as e:
        print(f"WARNING: Failed to load geocode learning: {e}")
        _geocode_learning_cache = {'corrections': {}, 'disambiguation': {}, 'failed_queries': [], 'stats': {}}
    
    return _geocode_learning_cache

def _save_geocode_learning():
    """Save learned geocoding corrections"""
    global _geocode_learning_cache
    if _geocode_learning_cache is None:
        return
    
    try:
        with open(_GEOCODE_LEARNING_FILE, 'w', encoding='utf-8') as f:
            json.dump(_geocode_learning_cache, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"WARNING: Failed to save geocode learning: {e}")

def normalize_city_name(city: str) -> str:
    """
    Normalize city name using multiple strategies:
    1. Lowercase and strip
    2. Fix common typos/OCR errors
    3. Resolve aliases to canonical name
    4. Apply UA_CITY_NORMALIZE for case forms
    """
    if not city:
        return ''
    
    city = city.lower().strip()
    
    # Fix typos first
    if city in TYPO_CORRECTIONS:
        city = TYPO_CORRECTIONS[city]
    
    # Check aliases
    if city in _ALIAS_TO_CANONICAL:
        city = _ALIAS_TO_CANONICAL[city]
    
    # Apply accusative/genitive normalization
    if city in UA_CITY_NORMALIZE:
        city = UA_CITY_NORMALIZE[city]
    
    return city

def disambiguate_city(city: str, context_region: str = None, source_region: str = None, 
                      message_text: str = None) -> str:
    """
    Disambiguate city that exists in multiple oblasts.
    
    Uses multiple signals:
    1. Explicit region context from message
    2. Source region (trajectory source helps determine likely oblast)
    3. Learned preferences
    4. Statistical frequency
    """
    city_lower = normalize_city_name(city)
    
    if city_lower not in AMBIGUOUS_CITIES:
        return context_region  # Not ambiguous
    
    possible_oblasts = AMBIGUOUS_CITIES[city_lower]
    
    # Strategy 1: Explicit region context
    if context_region:
        context_lower = context_region.lower()
        for oblast in possible_oblasts:
            if oblast in context_lower or context_lower in oblast:
                return oblast + ' область'
    
    # Strategy 2: Source region hints
    if source_region and message_text:
        msg_lower = message_text.lower()
        for source, likely_oblasts in SOURCE_REGION_HINTS.items():
            if source in msg_lower or source in source_region.lower():
                # Find intersection with possible oblasts
                for oblast in likely_oblasts:
                    if oblast in possible_oblasts:
                        return oblast + ' область'
    
    # Strategy 3: Learned preferences
    learning = _load_geocode_learning()
    if city_lower in learning.get('disambiguation', {}):
        return learning['disambiguation'][city_lower]
    
    # Strategy 4: Return first (most common) option
    return possible_oblasts[0] + ' область' if possible_oblasts else context_region

def ai_geocode_with_context(city: str, message_text: str = None, 
                            source_region: str = None, target_hint: str = None) -> dict:
    """
    AI-powered geocoding with full context understanding.
    
    Uses Groq AI to:
    1. Parse complex location descriptions
    2. Resolve ambiguous names using context
    3. Extract oblast from surrounding text
    4. Handle compound location names
    
    Returns:
    {
        'city': normalized city name,
        'oblast': resolved oblast,
        'coords': (lat, lng) or None,
        'confidence': 0-1,
        'method': 'ai' | 'cache' | 'fallback'
    }
    """
    if not city:
        return None
    
    # Check learning cache first
    learning = _load_geocode_learning()
    cache_key = f"{normalize_city_name(city)}_{source_region or ''}"
    
    if cache_key in learning.get('corrections', {}):
        cached = learning['corrections'][cache_key]
        learning['stats']['cache_hits'] = learning['stats'].get('cache_hits', 0) + 1
        return {
            'city': city,
            'oblast': cached.get('oblast'),
            'coords': (cached['lat'], cached['lng']),
            'confidence': 0.95,
            'method': 'cache'
        }
    
    # Try AI if enabled
    if GROQ_ENABLED and message_text:
        try:
            ai_result = _ai_resolve_location(city, message_text, source_region, target_hint)
            if ai_result and ai_result.get('confidence', 0) >= 0.7:
                learning['stats']['api_calls'] = learning['stats'].get('api_calls', 0) + 1
                return ai_result
        except Exception as e:
            print(f"DEBUG: AI geocoding failed: {e}")
    
    # Fallback to disambiguation + standard geocoding
    resolved_oblast = disambiguate_city(city, None, source_region, message_text)
    
    return {
        'city': normalize_city_name(city),
        'oblast': resolved_oblast,
        'coords': None,  # Will be resolved by caller
        'confidence': 0.5,
        'method': 'fallback'
    }

def _ai_resolve_location(city: str, message_text: str, source_region: str = None, 
                         target_hint: str = None) -> dict:
    """
    Use Groq AI to resolve location with full context.
    """
    if not GROQ_ENABLED:
        return None
    
    # Rate limiting
    _groq_rate_limit()
    
    try:
        context_parts = []
        if source_region:
            context_parts.append(f"Джерело загрози: {source_region}")
        if target_hint:
            context_parts.append(f"Можливий напрямок: {target_hint}")
        
        context_str = "\n".join(context_parts) if context_parts else "Контекст відсутній"
        
        prompt = f"""Ти експерт з географії України. Визнач точне місцезнаходження населеного пункту.

ЗАВДАННЯ: Визначити область для міста/села "{city}"

КОНТЕКСТ:
{context_str}

ПОВІДОМЛЕННЯ:
{message_text}

ВАЖЛИВО:
1. Якщо в повідомленні згадується область явно - використай її
2. Якщо місто існує в кількох областях - визнач найбільш ймовірну за контекстом
3. Якщо джерело "Чорне море" або "Крим" - це південні області (Одеська, Миколаївська, Херсонська)
4. Якщо джерело "Білорусь" - це північні області (Київська, Чернігівська, Житомирська)
5. Якщо джерело "Росія"/"Бєлгород" - це східні області (Харківська, Сумська)

ВІДОМІ ОМОНІМИ:
- Михайлівка: є в Запорізькій, Донецькій, Одеській
- Петрівка: є в Кіровоградській, Донецькій, Харківській
- Олександрівка: є в багатьох областях
- Семенівка: є в Чернігівській, Полтавській, Сумській
- Юріївка: є в Дніпропетровській, Донецькій

Відповідь JSON:
{{"city": "назва в називному відмінку", "oblast": "повна назва області", "confidence": 0.95, "reasoning": "коротке пояснення"}}"""

        response = groq_client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[
                {"role": "system", "content": "Ти географ-експерт. Відповідай ТІЛЬКИ валідним JSON."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.1,
            max_tokens=200
        )
        
        result_text = response.choices[0].message.content.strip()
        
        # Clean JSON
        if result_text.startswith('```'):
            result_text = re.sub(r'^```(?:json)?\s*', '', result_text)
            result_text = re.sub(r'\s*```$', '', result_text)
        
        result = json.loads(result_text)
        
        print(f"DEBUG AI Geocode: {city} -> {result.get('oblast')} (conf={result.get('confidence')})")
        
        return {
            'city': result.get('city', city),
            'oblast': result.get('oblast'),
            'coords': None,  # Will be resolved separately
            'confidence': float(result.get('confidence', 0.5)),
            'method': 'ai',
            'reasoning': result.get('reasoning')
        }
        
    except json.JSONDecodeError as e:
        print(f"WARNING: AI geocode returned invalid JSON: {e}")
        return None
    except Exception as e:
        error_str = str(e)
        if '429' in error_str or 'rate_limit' in error_str.lower():
            _groq_handle_429(error_str)
        return None

def learn_geocode_correction(query: str, correct_coords: tuple, oblast: str = None, source: str = 'manual'):
    """
    Learn from a geocoding correction to improve future results.
    
    Args:
        query: Original query string
        correct_coords: (lat, lng) of correct location
        oblast: Oblast name if known
        source: 'manual' | 'user' | 'verified'
    """
    learning = _load_geocode_learning()
    
    normalized = normalize_city_name(query)
    
    learning['corrections'][normalized] = {
        'lat': correct_coords[0],
        'lng': correct_coords[1],
        'oblast': oblast,
        'source': source,
        'timestamp': datetime.now().isoformat()
    }
    
    # Update disambiguation if we learned oblast
    if oblast and normalized in AMBIGUOUS_CITIES:
        oblast_short = oblast.lower().replace(' область', '').replace('ська', 'ська')
        learning['disambiguation'][normalized] = oblast
    
    _geocode_learning_cache = learning
    _save_geocode_learning()
    
    print(f"INFO: Learned geocode correction: {query} -> {correct_coords}")

def get_geocode_stats() -> dict:
    """Get geocoding statistics"""
    learning = _load_geocode_learning()
    return {
        'total_corrections': len(learning.get('corrections', {})),
        'disambiguation_rules': len(learning.get('disambiguation', {})),
        'failed_queries': len(learning.get('failed_queries', [])),
        'stats': learning.get('stats', {})
    }

def smart_geocode(city: str, region: str = None, message_text: str = None,
                  source_region: str = None, use_ai: bool = True) -> tuple:
    """
    Smart geocoding with multi-strategy fallback.
    
    Strategies (in order):
    1. Learning cache (from corrections)
    2. Local CITY_COORDS database
    3. AI-powered resolution (if enabled)
    4. Nominatim API
    5. Disambiguation + region-based lookup
    
    Returns:
        (lat, lng) or None
    """
    if not city:
        return None
    
    normalized = normalize_city_name(city)
    
    # Strategy 1: Learning cache
    learning = _load_geocode_learning()
    learning['stats']['total_queries'] = learning['stats'].get('total_queries', 0) + 1
    
    cache_key = f"{normalized}_{region or ''}"
    if cache_key in learning.get('corrections', {}):
        cached = learning['corrections'][cache_key]
        learning['stats']['cache_hits'] = learning['stats'].get('cache_hits', 0) + 1
        return (cached['lat'], cached['lng'])
    
    # Also check without region
    if normalized in learning.get('corrections', {}):
        cached = learning['corrections'][normalized]
        return (cached['lat'], cached['lng'])
    
    # Strategy 2: Local CITY_COORDS
    if normalized in CITY_COORDS:
        return tuple(CITY_COORDS[normalized])
    
    # Strategy 3: AI resolution
    if use_ai and GROQ_ENABLED and message_text:
        try:
            ai_result = ai_geocode_with_context(city, message_text, source_region)
            if ai_result and ai_result.get('oblast'):
                # Try to find coords with resolved oblast
                resolved_region = ai_result['oblast']
                coords = geocode_with_context(normalized, resolved_region)
                if coords:
                    return coords
        except Exception as e:
            print(f"DEBUG: Smart geocode AI strategy failed: {e}")
    
    # Strategy 4: Nominatim
    if NOMINATIM_AVAILABLE:
        resolved_region = region
        if not resolved_region and normalized in AMBIGUOUS_CITIES:
            resolved_region = disambiguate_city(normalized, None, source_region, message_text)
        
        coords = get_coordinates_nominatim(normalized, resolved_region)
        if coords:
            return coords
    
    # Strategy 5: Standard geocode_with_context
    if region:
        coords = geocode_with_context(normalized, region)
        if coords:
            return coords
    
    # Strategy 6: Try without region
    coords = geocode_with_context(normalized, None)
    if coords:
        return coords
    
    # Mark as failed for future optimization
    if normalized not in learning.get('failed_queries', []):
        learning['failed_queries'] = learning.get('failed_queries', [])
        learning['failed_queries'].append(normalized)
        if len(learning['failed_queries']) > 500:
            learning['failed_queries'] = learning['failed_queries'][-500:]
        _save_geocode_learning()
    
    return None

def batch_geocode(locations: list, message_text: str = None, source_region: str = None) -> list:
    """
    Batch geocoding for multiple locations with optimization.
    
    Args:
        locations: List of dicts with 'city' and optional 'region' keys
        message_text: Context message for AI
        source_region: Source region for trajectory context
    
    Returns:
        List of dicts with added 'coords' key
    """
    results = []
    
    for loc in locations:
        city = loc.get('city', '')
        region = loc.get('region')
        
        coords = smart_geocode(city, region, message_text, source_region)
        
        results.append({
            **loc,
            'coords': coords,
            'resolved': coords is not None
        })
    
    return results

# ==================== END ENHANCED AI GEOCODING SYSTEM ====================


    """Use Groq AI (Llama 3.1 70B) to intelligently extract location from Ukrainian military message.
    
    Returns dict with:
    - city: settlement name (normalized to nominative case)
    - district: district name if mentioned (or None)
    - oblast: oblast name (or None)
    - confidence: AI confidence score 0-1
    
    Examples:
    - "Дніпропетровщина: БпЛА маневрує в районі Юріївки" 
      -> {city: "Юріївка", district: None, oblast: "Дніпропетровська область", confidence: 0.95}
    - "БпЛА в Павлоградському районі курсом на Тернівку"
      -> {city: "Тернівка", district: "Павлоградський", oblast: None, confidence: 0.9}
    """
    if not GROQ_ENABLED or not message_text:
        return None
    
    # Check cache first
    cache_key = _get_groq_cache_key('loc_' + message_text[:200])
    if cache_key in _groq_cache:
        cached = _groq_cache[cache_key]
        if time.time() - cached[1] < _groq_cache_ttl:
            return cached[0]
    
    # Apply rate limiting
    _groq_rate_limit()
    
    try:
        prompt = f"""Ти експерт з аналізу повідомлень про повітряні тривоги в Україні.

Витягни з повідомлення:
1. Назву населеного пункту (місто/село) - ОБОВ'ЯЗКОВО в називному відмінку (Юріївка, а не Юріївки)
2. Назву району (якщо вказано явно, наприклад "Павлоградський район")
3. Назву області

КРИТИЧНО ВАЖЛИВО:
- "курсом на X", "напрямок на X", "ціль на X" - X це МІСТО (city), а НЕ район!
- "в районі X" означає "біля X", а НЕ назву району
- "Павлоградський район" - це назва району
- "курсом на Павлоград" - Павлоград це МІСТО (city="Павлоград", district=null)
- Нормалізуй назви до називного відмінку (Юріївки → Юріївка, Тернівку → Тернівка)
- "Дніпропетровщина" → "Дніпропетровська область"

Повідомлення:
{message_text}

Відповідь ТІЛЬКИ у форматі JSON (без markdown, без пояснень):
{{"city": "назва або null", "district": "назва або null", "oblast": "назва або null", "confidence": 0.95}}"""

        response = groq_client.chat.completions.create(
            model="llama-3.3-70b-versatile",  # Updated model (llama-3.1 decommissioned)
            messages=[
                {"role": "system", "content": "Ти аналізуєш повідомлення про повітряні тривоги. Відповідай ТІЛЬКИ валідним JSON."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.1,
            max_tokens=300,
            top_p=0.9
        )
        
        result_text = response.choices[0].message.content.strip()
        
        # Remove markdown code blocks if present
        if result_text.startswith('```'):
            result_text = re.sub(r'^```(?:json)?\s*', '', result_text)
            result_text = re.sub(r'\s*```$', '', result_text)
        
        result = json.loads(result_text)
        
        # Validate and normalize result
        if not isinstance(result, dict):
            return None
        
        city = result.get('city')
        district = result.get('district')
        oblast = result.get('oblast')
        confidence = result.get('confidence', 0.5)
        
        # Skip if no useful info extracted
        if not city and not oblast:
            return None
        
        # Convert null strings to None
        if city in ['null', 'None', '']:
            city = None
        if district in ['null', 'None', '']:
            district = None
        if oblast in ['null', 'None', '']:
            oblast = None
        
        print(f"DEBUG Groq AI: city='{city}', district='{district}', oblast='{oblast}', confidence={confidence}")
        
        result = {
            'city': city.strip() if city else None,
            'district': district.strip() if district else None,
            'oblast': oblast.strip() if oblast else None,
            'confidence': float(confidence)
        }
        
        # Cache result
        _groq_cache[cache_key] = (result, time.time())
        
        return result
        
    except json.JSONDecodeError as e:
        print(f"WARNING: Groq AI returned invalid JSON: {e}")
        print(f"Response: {result_text[:200]}")
        return None
    except Exception as e:
        error_str = str(e)
        # Handle 429 rate limit - activate global cooldown
        if '429' in error_str or 'rate_limit' in error_str.lower():
            _groq_handle_429(error_str)
        else:
            print(f"WARNING: Groq AI extraction failed: {e}")
        return None

# AI-powered trajectory parsing cache to avoid repeated API calls
_trajectory_ai_cache = {}
_TRAJECTORY_AI_CACHE_TTL = 1800  # 30 minutes (was 5 min) - reduce API calls

def extract_trajectory_with_ai(message_text: str):
    """Use Groq AI to intelligently extract trajectory/course information from Ukrainian military messages.
    
    This is smarter than regex - it understands context and can handle various message formats.
    
    Returns dict with:
    - source_type: 'city' | 'region' | 'direction' | None
    - source_name: name of source location/direction
    - target_type: 'city' | 'region' | 'direction' | None  
    - target_name: name of target location/direction
    - confidence: AI confidence 0-1
    
    Examples:
    - "БпЛА з півночі на Суми" -> source_type='direction', source_name='північ', target_type='city', target_name='Суми'
    - "БпЛА з Херсонщини на Миколаївщину" -> source_type='region', source_name='Херсонщина', target_type='region', target_name='Миколаївщина'
    """
    if not GROQ_ENABLED or not message_text:
        return None
    
    # Check cache first
    cache_key = _get_groq_cache_key(message_text[:200])
    if cache_key in _trajectory_ai_cache:
        cached = _trajectory_ai_cache[cache_key]
        if time.time() - cached['ts'] < _TRAJECTORY_AI_CACHE_TTL:
            return cached['data']
    
    # Apply rate limiting
    _groq_rate_limit()
    
    try:
        prompt = f"""Ти експерт з аналізу повідомлень про рух дронів/БпЛА в Україні.

Витягни з повідомлення інформацію про ТРАЄКТОРІЮ руху:
1. ЗВІДКИ рухається (source) - місто, область, або напрямок (північ, південь, схід, захід, північно-східний і т.д.)
2. КУДИ рухається (target) - місто, область, або напрямок

ПРАВИЛА:
- "з півночі" = напрямок "північ" (source)
- "на Суми" = місто "Суми" (target)  
- "з Херсонщини" = область "Херсонщина" (source)
- "на Миколаївщину" = область "Миколаївщина" (target)
- "курсом на Дніпро" = місто "Дніпро" (target)
- "курс південний" = напрямок "південь" (target)
- "на сході Сумщини" = source область "Сумщина" + позиція "схід"
- Нормалізуй: Миколаївщину → Миколаївщина, Сум → Суми

Типи source/target:
- "city" = конкретне місто (Суми, Харків, Миколаїв)
- "region" = область (Херсонщина, Миколаївщина, Сумщина)  
- "direction" = напрямок (північ, південь, схід, захід, північно-східний і т.д.)

Повідомлення:
{message_text}

Відповідь ТІЛЬКИ JSON:
{{"source_type": "city|region|direction|null", "source_name": "назва або null", "target_type": "city|region|direction|null", "target_name": "назва або null", "source_position": "північ|південь|схід|захід|null", "confidence": 0.9}}"""

        response = groq_client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[
                {"role": "system", "content": "Ти аналізуєш траєкторії дронів. Відповідай ТІЛЬКИ валідним JSON без пояснень."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.1,
            max_tokens=200,
            top_p=0.9
        )
        
        result_text = response.choices[0].message.content.strip()
        
        # Remove markdown code blocks if present
        if result_text.startswith('```'):
            result_text = re.sub(r'^```(?:json)?\s*', '', result_text)
            result_text = re.sub(r'\s*```$', '', result_text)
        
        result = json.loads(result_text)
        
        # Validate result
        if not isinstance(result, dict):
            return None
        
        # Convert null strings to None
        for key in ['source_type', 'source_name', 'target_type', 'target_name', 'source_position']:
            if result.get(key) in ['null', 'None', '']:
                result[key] = None
        
        # Skip if no trajectory info
        if not result.get('target_name') and not result.get('target_type'):
            return None
        
        print(f"DEBUG Groq AI Trajectory: {result}")
        
        # Cache result
        _trajectory_ai_cache[cache_key] = {'ts': time.time(), 'data': result}
        
        return result
        
    except json.JSONDecodeError as e:
        print(f"WARNING: Groq AI trajectory returned invalid JSON: {e}")
        return None
    except Exception as e:
        error_str = str(e)
        # Handle 429 rate limit - activate global cooldown
        if '429' in error_str or 'rate_limit' in error_str.lower():
            _groq_handle_429(error_str)
        else:
            print(f"WARNING: Groq AI trajectory extraction failed: {e}")
        return None


# ==================== AI SMART ROUTE SYSTEM ====================
# System that learns from historical data and AI can modify predictions

# Use persistent storage if available (survives Render redeploys)
_ROUTE_PATTERNS_FILENAME = 'route_patterns.json'
if PERSISTENT_DATA_DIR and os.path.isdir(PERSISTENT_DATA_DIR):
    ROUTE_PATTERNS_FILE = os.path.join(PERSISTENT_DATA_DIR, _ROUTE_PATTERNS_FILENAME)
    print(f"INFO: Route patterns using PERSISTENT storage: {ROUTE_PATTERNS_FILE}")
else:
    ROUTE_PATTERNS_FILE = _ROUTE_PATTERNS_FILENAME
    print(f"WARNING: Route patterns using LOCAL storage (will be lost on redeploy): {ROUTE_PATTERNS_FILE}")

# Default patterns to initialize if file doesn't exist
_DEFAULT_ROUTE_PATTERNS = {
    "version": 1,
    "patterns": {
        "south_to_kyiv": {
            "name": "Південь → Київ",
            "description": "Типовий маршрут шахедів з Чорного моря на столицю",
            "source_regions": ["одеська", "миколаївська", "херсонська"],
            "waypoints": ["вінницька", "черкаська", "київська"],
            "target_regions": ["київська", "київ"],
            "frequency": 0,
            "confidence": 0.85
        },
        "east_to_kharkiv": {
            "name": "Схід → Харків",
            "description": "Атаки з РФ на Харківщину",
            "source_regions": ["білгородська", "курська"],
            "target_regions": ["харківська", "харків"],
            "frequency": 0,
            "confidence": 0.9
        },
        "crimea_to_central": {
            "name": "Крим → Центр",
            "description": "Атаки з Криму на центральну Україну",
            "source_regions": ["крим", "чорне море"],
            "waypoints": ["херсонська", "запорізька"],
            "target_regions": ["дніпропетровська", "полтавська", "київська"],
            "frequency": 0,
            "confidence": 0.75
        },
        "belarus_to_kyiv": {
            "name": "Білорусь → Київ",
            "description": "Атаки з півночі",
            "source_regions": ["білорусь", "гомельська"],
            "waypoints": ["чернігівська"],
            "target_regions": ["київська", "київ"],
            "frequency": 0,
            "confidence": 0.8
        }
    },
    "historical_routes": [],
    "ai_corrections": []
}

_route_patterns_cache = None
_route_patterns_modified = False

def _load_route_patterns():
    """Load route patterns from JSON file (persistent storage)"""
    global _route_patterns_cache
    if _route_patterns_cache is not None:
        return _route_patterns_cache
    
    try:
        if os.path.exists(ROUTE_PATTERNS_FILE):
            with open(ROUTE_PATTERNS_FILE, 'r', encoding='utf-8') as f:
                _route_patterns_cache = json.load(f)
                print(f"INFO: Loaded {len(_route_patterns_cache.get('historical_routes', []))} historical routes from {ROUTE_PATTERNS_FILE}")
        else:
            # Initialize with defaults
            _route_patterns_cache = _DEFAULT_ROUTE_PATTERNS.copy()
            _save_route_patterns()  # Save immediately to create file
            print(f"INFO: Created new route patterns file: {ROUTE_PATTERNS_FILE}")
    except Exception as e:
        print(f"WARNING: Failed to load route patterns: {e}")
        _route_patterns_cache = _DEFAULT_ROUTE_PATTERNS.copy()
    
    return _route_patterns_cache

def _save_route_patterns():
    """Save route patterns to JSON file (persistent storage)"""
    global _route_patterns_modified
    if not _route_patterns_cache:
        return
    
    try:
        _route_patterns_cache['last_updated'] = datetime.now().isoformat()
        with open(ROUTE_PATTERNS_FILE, 'w', encoding='utf-8') as f:
            json.dump(_route_patterns_cache, f, ensure_ascii=False, indent=2)
        _route_patterns_modified = False
        print(f"INFO: Route patterns saved to {ROUTE_PATTERNS_FILE} ({len(_route_patterns_cache.get('historical_routes', []))} routes)")
    except Exception as e:
        print(f"ERROR: Failed to save route patterns: {e}")

def predict_route_with_ai(source_region: str, current_position: tuple = None, message_text: str = None):
    """
    AI predicts most likely route based on:
    1. Source region
    2. Historical patterns
    3. Current message context
    
    Returns dict with:
    - predicted_targets: list of likely target regions
    - waypoints: list of intermediate points
    - confidence: 0-1
    - reasoning: AI explanation
    - pattern_used: name of matched pattern or 'ai_inference'
    """
    if not GROQ_ENABLED:
        # Fallback to pattern matching only
        return _predict_route_from_patterns(source_region)
    
    patterns = _load_route_patterns()
    
    # Check for exact pattern match first
    pattern_match = _find_matching_pattern(source_region, patterns)
    
    # Use AI to refine prediction
    _groq_rate_limit()
    
    try:
        historical_context = ""
        if patterns.get('historical_routes'):
            recent = patterns['historical_routes'][-10:]  # Last 10 routes
            historical_context = f"\nОстанні маршрути: {json.dumps(recent, ensure_ascii=False)}"
        
        pattern_context = ""
        if pattern_match:
            pattern_context = f"\nЗнайдений патерн: {json.dumps(pattern_match, ensure_ascii=False)}"
        
        prompt = f"""Ти експерт з аналізу траєкторій дронів/ракет над Україною.

ВХІДНІ ДАНІ:
- Регіон старту: {source_region}
- Поточна позиція: {current_position if current_position else 'невідома'}
- Повідомлення: {message_text[:300] if message_text else 'немає'}
{pattern_context}
{historical_context}

ЗАВДАННЯ: Спрогнозуй найбільш ймовірний маршрут.

ВАЖЛИВО:
- Враховуй типові маршрути (південь→Київ, схід→Харків)
- Шахеди зазвичай летять 100-150 км/год
- Ракети швидше - 300-900 км/год
- Якщо є патерн - використай його, але можеш скоригувати

Відповідай ТІЛЬКИ JSON:
{{"predicted_targets": ["регіон1", "регіон2"], "waypoints": ["місто1", "місто2"], "confidence": 0.85, "reasoning": "короткий опис", "suggested_correction": null}}"""

        response = groq_client.chat.completions.create(
            model=GROQ_MODEL,
            messages=[
                {"role": "system", "content": "Ти аналізуєш траєкторії атак. Відповідай ТІЛЬКИ JSON."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            max_tokens=300
        )
        
        result_text = response.choices[0].message.content.strip()
        if result_text.startswith('```'):
            result_text = re.sub(r'^```(?:json)?\s*', '', result_text)
            result_text = re.sub(r'\s*```$', '', result_text)
        
        result = json.loads(result_text)
        result['pattern_used'] = pattern_match['name'] if pattern_match else 'ai_inference'
        
        print(f"DEBUG AI Route Prediction: {source_region} -> {result.get('predicted_targets')}")
        return result
        
    except Exception as e:
        error_str = str(e)
        if '429' in error_str or 'rate_limit' in error_str.lower():
            _groq_handle_429(error_str)
        else:
            print(f"WARNING: AI route prediction failed: {e}")
        return _predict_route_from_patterns(source_region)

def _find_matching_pattern(source_region: str, patterns: dict):
    """Find pattern matching the source region"""
    source_lower = source_region.lower()
    for pattern_id, pattern in patterns.get('patterns', {}).items():
        for src in pattern.get('source_regions', []):
            if src.lower() in source_lower or source_lower in src.lower():
                return pattern
    return None

def _predict_route_from_patterns(source_region: str):
    """Fallback prediction using only stored patterns"""
    patterns = _load_route_patterns()
    match = _find_matching_pattern(source_region, patterns)
    
    if match:
        return {
            'predicted_targets': match.get('target_regions', []),
            'waypoints': match.get('waypoints', []),
            'confidence': match.get('confidence', 0.5),
            'reasoning': match.get('description', 'Pattern match'),
            'pattern_used': match.get('name', 'unknown')
        }
    
    return {
        'predicted_targets': [],
        'waypoints': [],
        'confidence': 0.1,
        'reasoning': 'No matching pattern',
        'pattern_used': None
    }

def update_route_pattern_with_ai(route_data: dict, actual_target: str = None):
    """
    AI updates/corrects route patterns based on actual observed routes.
    
    Args:
        route_data: {source_region, waypoints, target_region, timestamp}
        actual_target: The actual target that was reached (for correction)
    """
    patterns = _load_route_patterns()
    
    # Add to historical routes
    route_entry = {
        'timestamp': datetime.now().isoformat(),
        'source': route_data.get('source_region'),
        'target': actual_target or route_data.get('target_region'),
        'waypoints': route_data.get('waypoints', [])
    }
    
    if 'historical_routes' not in patterns:
        patterns['historical_routes'] = []
    patterns['historical_routes'].append(route_entry)
    
    # Keep only last 100 routes
    if len(patterns['historical_routes']) > 100:
        patterns['historical_routes'] = patterns['historical_routes'][-100:]
    
    # Update pattern frequency
    match = _find_matching_pattern(route_data.get('source_region', ''), patterns)
    if match:
        match['frequency'] = match.get('frequency', 0) + 1
    
    global _route_patterns_modified
    _route_patterns_modified = True
    _save_route_patterns()
    
    # Use AI to suggest pattern updates (async-friendly)
    if GROQ_ENABLED and len(patterns['historical_routes']) >= 10:
        _ai_analyze_patterns_for_update(patterns)

def _ai_analyze_patterns_for_update(patterns: dict):
    """AI analyzes historical data and suggests pattern updates"""
    try:
        _groq_rate_limit()
        
        recent_routes = patterns['historical_routes'][-20:]
        current_patterns = patterns.get('patterns', {})
        
        prompt = f"""Проаналізуй останні маршрути атак та запропонуй корекції до патернів.

ОСТАННІ МАРШРУТИ:
{json.dumps(recent_routes, ensure_ascii=False, indent=2)}

ПОТОЧНІ ПАТЕРНИ:
{json.dumps(current_patterns, ensure_ascii=False, indent=2)}

Чи бачиш нові закономірності? Чи потрібно скоригувати існуючі?

Відповідай JSON:
{{"corrections": [{{"pattern_id": "south_to_kyiv", "field": "confidence", "new_value": 0.9, "reason": "частіше підтверджується"}}], "new_patterns": [], "observations": "короткий опис"}}"""

        response = groq_client.chat.completions.create(
            model=GROQ_MODEL,
            messages=[
                {"role": "system", "content": "Ти аналітик військових патернів."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.2,
            max_tokens=500
        )
        
        result_text = response.choices[0].message.content.strip()
        if result_text.startswith('```'):
            result_text = re.sub(r'^```(?:json)?\s*', '', result_text)
            result_text = re.sub(r'\s*```$', '', result_text)
        
        suggestions = json.loads(result_text)
        
        # Store AI corrections for review (don't auto-apply)
        if 'ai_corrections' not in patterns:
            patterns['ai_corrections'] = []
        patterns['ai_corrections'].append({
            'timestamp': datetime.now().isoformat(),
            'suggestions': suggestions
        })
        
        # Keep last 10 suggestions
        patterns['ai_corrections'] = patterns['ai_corrections'][-10:]
        
        print(f"DEBUG AI Pattern Analysis: {suggestions.get('observations', 'No observations')}")
        
    except Exception as e:
        error_str = str(e)
        if '429' in error_str or 'rate_limit' in error_str.lower():
            _groq_handle_429(error_str)
        else:
            print(f"WARNING: AI pattern analysis failed: {e}")


# ==================== ENHANCED AI PREDICTION SYSTEM ====================
# Advanced trajectory prediction with ETA, multi-target probability, speed estimation
# Version 2.0 - Maximum optimization with Bayesian updates, ensemble prediction

import math
from datetime import timedelta

# Speed constants (km/h) based on threat type - REFINED
THREAT_SPEEDS = {
    'shahed': {'min': 120, 'avg': 150, 'max': 185, 'typical_altitude': 500},
    'drone': {'min': 80, 'avg': 130, 'max': 170, 'typical_altitude': 300},
    'cruise': {'min': 680, 'avg': 850, 'max': 1000, 'typical_altitude': 50},  # Low-flying
    'ballistic': {'min': 2000, 'avg': 4000, 'max': 7000, 'typical_altitude': 100000},
    'kab': {'min': 200, 'avg': 350, 'max': 550, 'typical_altitude': 5000},
    'rocket': {'min': 650, 'avg': 850, 'max': 1000, 'typical_altitude': 100},
    'x101': {'min': 700, 'avg': 850, 'max': 950, 'typical_altitude': 50},
    'kalibr': {'min': 700, 'avg': 880, 'max': 1000, 'typical_altitude': 20},
    'kinzhal': {'min': 3000, 'avg': 4500, 'max': 6000, 'typical_altitude': 20000},
    'iskander': {'min': 2100, 'avg': 3000, 'max': 4000, 'typical_altitude': 50000},
    'unknown': {'min': 150, 'avg': 300, 'max': 500, 'typical_altitude': 500}
}

# Seasonal attack patterns (month -> target type preferences)
SEASONAL_PATTERNS = {
    # Winter (heating season) - energy infrastructure
    1: {'industrial': 1.4, 'port': 0.9, 'capital': 1.2},
    2: {'industrial': 1.4, 'port': 0.9, 'capital': 1.2},
    12: {'industrial': 1.5, 'port': 0.8, 'capital': 1.3},
    # Spring - mixed
    3: {'industrial': 1.2, 'port': 1.0, 'capital': 1.1},
    4: {'industrial': 1.1, 'port': 1.1, 'capital': 1.0},
    5: {'industrial': 1.0, 'port': 1.2, 'capital': 1.0},
    # Summer - ports/grain
    6: {'industrial': 0.9, 'port': 1.4, 'capital': 0.95},
    7: {'industrial': 0.9, 'port': 1.5, 'capital': 0.9},
    8: {'industrial': 0.9, 'port': 1.4, 'capital': 0.95},
    # Fall - energy prep
    9: {'industrial': 1.1, 'port': 1.2, 'capital': 1.0},
    10: {'industrial': 1.3, 'port': 1.0, 'capital': 1.1},
    11: {'industrial': 1.4, 'port': 0.9, 'capital': 1.2},
}

# Special dates with increased attack probability
SPECIAL_DATES = {
    (1, 1): {'name': 'Новий рік', 'capital_boost': 1.5, 'overall_boost': 1.3},
    (1, 7): {'name': 'Різдво', 'capital_boost': 1.3, 'overall_boost': 1.2},
    (2, 24): {'name': 'Річниця вторгнення', 'capital_boost': 1.6, 'overall_boost': 1.4},
    (3, 8): {'name': '8 березня', 'capital_boost': 1.2, 'overall_boost': 1.1},
    (5, 9): {'name': 'День перемоги РФ', 'capital_boost': 1.4, 'overall_boost': 1.3},
    (6, 28): {'name': 'День Конституції', 'capital_boost': 1.3, 'overall_boost': 1.2},
    (8, 24): {'name': 'День Незалежності', 'capital_boost': 1.7, 'overall_boost': 1.5},
    (10, 14): {'name': 'День захисників', 'capital_boost': 1.3, 'overall_boost': 1.2},
    (12, 25): {'name': 'Католицьке Різдво', 'capital_boost': 1.2, 'overall_boost': 1.1},
    (12, 31): {'name': 'Переддень НР', 'capital_boost': 1.4, 'overall_boost': 1.3},
}

# Day of week patterns (0=Monday)
WEEKDAY_PATTERNS = {
    0: {'capital': 1.0, 'overall': 1.0},  # Monday - average
    1: {'capital': 1.0, 'overall': 1.0},  # Tuesday
    2: {'capital': 1.05, 'overall': 1.0}, # Wednesday
    3: {'capital': 1.05, 'overall': 1.0}, # Thursday
    4: {'capital': 1.1, 'overall': 1.05}, # Friday - slight increase
    5: {'capital': 1.2, 'overall': 1.15}, # Saturday - higher
    6: {'capital': 1.25, 'overall': 1.2}, # Sunday - highest
}

# Hour patterns for different threat types
HOURLY_PATTERNS = {
    'shahed': {
        # Night/early morning - peak shahed time
        0: 1.4, 1: 1.5, 2: 1.6, 3: 1.7, 4: 1.8, 5: 1.6,
        6: 1.2, 7: 0.8, 8: 0.6, 9: 0.5, 10: 0.4, 11: 0.4,
        12: 0.4, 13: 0.4, 14: 0.4, 15: 0.5, 16: 0.6, 17: 0.7,
        18: 0.8, 19: 0.9, 20: 1.0, 21: 1.1, 22: 1.2, 23: 1.3
    },
    'cruise': {
        # More evenly distributed, slight morning preference
        0: 0.9, 1: 0.9, 2: 0.9, 3: 1.0, 4: 1.1, 5: 1.2,
        6: 1.3, 7: 1.2, 8: 1.1, 9: 1.0, 10: 1.0, 11: 1.0,
        12: 1.0, 13: 1.0, 14: 1.0, 15: 1.0, 16: 1.0, 17: 1.0,
        18: 1.0, 19: 1.0, 20: 1.0, 21: 0.95, 22: 0.9, 23: 0.9
    },
    'ballistic': {
        # Unpredictable, slightly more daytime for KAB
        h: 1.0 for h in range(24)
    },
    'kab': {
        # Daytime operations (need visual)
        0: 0.3, 1: 0.2, 2: 0.2, 3: 0.2, 4: 0.3, 5: 0.5,
        6: 0.8, 7: 1.0, 8: 1.2, 9: 1.3, 10: 1.4, 11: 1.4,
        12: 1.4, 13: 1.4, 14: 1.3, 15: 1.2, 16: 1.1, 17: 1.0,
        18: 0.8, 19: 0.6, 20: 0.4, 21: 0.3, 22: 0.3, 23: 0.3
    }
}

# Flight corridors with waypoints
FLIGHT_CORRIDORS = {
    'south_to_kyiv': {
        'start_regions': ['одеська', 'миколаївська', 'херсонська'],
        'waypoints': [
            {'name': 'Вінниця', 'coords': [49.2331, 28.4682], 'probability': 0.3},
            {'name': 'Умань', 'coords': [48.7500, 30.2200], 'probability': 0.5},
            {'name': 'Черкаси', 'coords': [49.4444, 32.0598], 'probability': 0.4},
        ],
        'end_targets': ['київ', 'біла церква', 'васильків'],
        'typical_duration_hours': 4.5,
    },
    'east_to_kharkiv': {
        'start_regions': ['бєлгородська', 'курська'],
        'waypoints': [],
        'end_targets': ['харків', 'суми', 'полтава'],
        'typical_duration_hours': 0.5,
    },
    'crimea_to_odesa': {
        'start_regions': ['крим', 'чорне море'],
        'waypoints': [
            {'name': 'Херсон', 'coords': [46.6354, 32.6169], 'probability': 0.4},
        ],
        'end_targets': ['одеса', 'миколаїв', 'південний'],
        'typical_duration_hours': 1.5,
    },
    'belarus_to_kyiv': {
        'start_regions': ['білорусь', 'гомельська', 'мозирська'],
        'waypoints': [
            {'name': 'Чернігів', 'coords': [51.4982, 31.2893], 'probability': 0.3},
            {'name': 'Ніжин', 'coords': [51.0500, 31.8833], 'probability': 0.2},
        ],
        'end_targets': ['київ', 'бровари', 'бориспіль'],
        'typical_duration_hours': 3.0,
    },
    'caspian_to_west': {
        'start_regions': ['каспійське море', 'астрахань'],
        'waypoints': [
            {'name': 'Дніпро', 'coords': [48.4647, 35.0462], 'probability': 0.3},
            {'name': 'Київ', 'coords': [50.4501, 30.5234], 'probability': 0.5},
        ],
        'end_targets': ['київ', 'львів', 'хмельницький'],
        'typical_duration_hours': 2.0,  # Cruise missiles are fast
    },
}

# Important target cities with strategic value weights - EXPANDED
STRATEGIC_TARGETS = {
    # Capital - highest priority
    'київ': {'weight': 1.0, 'coords': [50.4501, 30.5234], 'type': 'capital', 'population': 2800000, 'air_defense': 'heavy'},
    
    # Major cities
    'харків': {'weight': 0.92, 'coords': [49.9935, 36.2304], 'type': 'city', 'population': 1400000, 'air_defense': 'medium'},
    'одеса': {'weight': 0.88, 'coords': [46.4825, 30.7233], 'type': 'port', 'population': 1000000, 'air_defense': 'medium'},
    'дніпро': {'weight': 0.85, 'coords': [48.4647, 35.0462], 'type': 'industrial', 'population': 980000, 'air_defense': 'medium'},
    'запоріжжя': {'weight': 0.82, 'coords': [47.8388, 35.1396], 'type': 'industrial', 'population': 750000, 'air_defense': 'light'},
    'львів': {'weight': 0.78, 'coords': [49.8397, 24.0297], 'type': 'city', 'population': 720000, 'air_defense': 'medium'},
    
    # Industrial/Energy hubs
    'кременчук': {'weight': 0.72, 'coords': [49.0689, 33.4202], 'type': 'industrial', 'population': 220000, 'air_defense': 'light'},
    'кривий ріг': {'weight': 0.70, 'coords': [47.9105, 33.3918], 'type': 'industrial', 'population': 620000, 'air_defense': 'light'},
    'маріуполь': {'weight': 0.65, 'coords': [47.0951, 37.5497], 'type': 'industrial', 'population': 430000, 'air_defense': 'none'},
    'павлоград': {'weight': 0.55, 'coords': [48.5333, 35.8708], 'type': 'industrial', 'population': 110000, 'air_defense': 'light'},
    'енергодар': {'weight': 0.60, 'coords': [47.4989, 34.6561], 'type': 'nuclear', 'population': 50000, 'air_defense': 'none'},
    'южноукраїнськ': {'weight': 0.55, 'coords': [47.8167, 31.2167], 'type': 'nuclear', 'population': 40000, 'air_defense': 'light'},
    
    # Ports
    'миколаїв': {'weight': 0.72, 'coords': [46.9750, 31.9946], 'type': 'port', 'population': 480000, 'air_defense': 'light'},
    'ізмаїл': {'weight': 0.58, 'coords': [45.3500, 28.8333], 'type': 'port', 'population': 70000, 'air_defense': 'light'},
    'рені': {'weight': 0.50, 'coords': [45.4500, 28.2833], 'type': 'port', 'population': 18000, 'air_defense': 'none'},
    'южний': {'weight': 0.55, 'coords': [46.6167, 31.1000], 'type': 'port', 'population': 32000, 'air_defense': 'light'},
    'чорноморськ': {'weight': 0.52, 'coords': [46.3000, 30.6500], 'type': 'port', 'population': 60000, 'air_defense': 'light'},
    
    # Regional centers
    'вінниця': {'weight': 0.68, 'coords': [49.2331, 28.4682], 'type': 'city', 'population': 370000, 'air_defense': 'light'},
    'полтава': {'weight': 0.62, 'coords': [49.5883, 34.5514], 'type': 'city', 'population': 290000, 'air_defense': 'light'},
    'черкаси': {'weight': 0.58, 'coords': [49.4444, 32.0598], 'type': 'city', 'population': 280000, 'air_defense': 'light'},
    'житомир': {'weight': 0.55, 'coords': [50.2547, 28.6587], 'type': 'city', 'population': 260000, 'air_defense': 'light'},
    'хмельницький': {'weight': 0.60, 'coords': [49.4230, 26.9871], 'type': 'military', 'population': 275000, 'air_defense': 'light'},
    'кропивницький': {'weight': 0.52, 'coords': [48.5079, 32.2623], 'type': 'city', 'population': 230000, 'air_defense': 'light'},
    'рівне': {'weight': 0.55, 'coords': [50.6199, 26.2516], 'type': 'city', 'population': 245000, 'air_defense': 'light'},
    'луцьк': {'weight': 0.52, 'coords': [50.7593, 25.3424], 'type': 'city', 'population': 215000, 'air_defense': 'light'},
    'тернопіль': {'weight': 0.50, 'coords': [49.5535, 25.5948], 'type': 'city', 'population': 225000, 'air_defense': 'light'},
    'івано-франківськ': {'weight': 0.52, 'coords': [48.9226, 24.7111], 'type': 'city', 'population': 235000, 'air_defense': 'light'},
    'ужгород': {'weight': 0.45, 'coords': [48.6208, 22.2879], 'type': 'city', 'population': 115000, 'air_defense': 'light'},
    'чернівці': {'weight': 0.48, 'coords': [48.2921, 25.9358], 'type': 'city', 'population': 265000, 'air_defense': 'light'},
    
    # Border cities (frequent targets)
    'суми': {'weight': 0.65, 'coords': [50.9077, 34.7981], 'type': 'border', 'population': 265000, 'air_defense': 'light'},
    'чернігів': {'weight': 0.62, 'coords': [51.4982, 31.2893], 'type': 'border', 'population': 285000, 'air_defense': 'light'},
    'херсон': {'weight': 0.60, 'coords': [46.6354, 32.6169], 'type': 'border', 'population': 280000, 'air_defense': 'light'},
    
    # Kyiv region targets
    'біла церква': {'weight': 0.50, 'coords': [49.8000, 30.1200], 'type': 'city', 'population': 210000, 'air_defense': 'light'},
    'бровари': {'weight': 0.48, 'coords': [50.5111, 30.7906], 'type': 'city', 'population': 110000, 'air_defense': 'medium'},
    'бориспіль': {'weight': 0.52, 'coords': [50.3500, 30.9500], 'type': 'airport', 'population': 60000, 'air_defense': 'medium'},
    'васильків': {'weight': 0.55, 'coords': [50.1833, 30.3167], 'type': 'military', 'population': 35000, 'air_defense': 'medium'},
    'гостомель': {'weight': 0.50, 'coords': [50.5667, 30.2167], 'type': 'airport', 'population': 15000, 'air_defense': 'medium'},
    
    # Strategic cities on common routes
    'умань': {'weight': 0.48, 'coords': [48.7500, 30.2200], 'type': 'city', 'population': 82000, 'air_defense': 'none'},
    'шепетівка': {'weight': 0.52, 'coords': [50.1833, 27.0667], 'type': 'military', 'population': 40000, 'air_defense': 'light'},
    'коростень': {'weight': 0.42, 'coords': [50.9500, 28.6333], 'type': 'city', 'population': 62000, 'air_defense': 'none'},
    'ніжин': {'weight': 0.42, 'coords': [51.0500, 31.8833], 'type': 'city', 'population': 70000, 'air_defense': 'none'},
    'конотоп': {'weight': 0.45, 'coords': [51.2333, 33.2000], 'type': 'city', 'population': 85000, 'air_defense': 'none'},
    'прилуки': {'weight': 0.42, 'coords': [50.5833, 32.3833], 'type': 'city', 'population': 56000, 'air_defense': 'none'},
    
    # Military/Strategic
    'старокостянтинів': {'weight': 0.60, 'coords': [49.7500, 27.2167], 'type': 'military', 'population': 35000, 'air_defense': 'medium'},
    'мелітополь': {'weight': 0.50, 'coords': [46.8500, 35.3667], 'type': 'city', 'population': 150000, 'air_defense': 'none'},
    'бердянськ': {'weight': 0.48, 'coords': [46.7500, 36.8000], 'type': 'port', 'population': 110000, 'air_defense': 'none'},
    'миргород': {'weight': 0.45, 'coords': [49.9667, 33.6000], 'type': 'military', 'population': 40000, 'air_defense': 'light'},
    'озерне': {'weight': 0.48, 'coords': [50.1500, 27.4667], 'type': 'military', 'population': 5000, 'air_defense': 'light'},
}

# Source regions with typical launch patterns - EXPANDED
SOURCE_REGIONS_INFO = {
    'чорне море': {
        'typical_targets': ['одеса', 'миколаїв', 'київ', 'вінниця'],
        'threat_types': ['cruise', 'shahed'],
        'launch_platforms': ['submarine', 'ship'],
        'typical_group_size': {'cruise': 8, 'shahed': 20}
    },
    'азовське море': {
        'typical_targets': ['запоріжжя', 'дніпро', 'харків', 'маріуполь'],
        'threat_types': ['cruise'],
        'launch_platforms': ['ship'],
        'typical_group_size': {'cruise': 4}
    },
    'білорусь': {
        'typical_targets': ['київ', 'чернігів', 'житомир', 'рівне'],
        'threat_types': ['shahed', 'drone'],
        'launch_platforms': ['ground'],
        'typical_group_size': {'shahed': 15, 'drone': 5}
    },
    'курська область': {
        'typical_targets': ['суми', 'харків', 'полтава', 'конотоп'],
        'threat_types': ['shahed', 'kab', 'drone'],
        'launch_platforms': ['aircraft', 'ground'],
        'typical_group_size': {'shahed': 10, 'kab': 5}
    },
    'бєлгородська область': {
        'typical_targets': ['харків'],
        'threat_types': ['kab', 'ballistic', 'drone'],
        'launch_platforms': ['aircraft', 'ground'],
        'typical_group_size': {'kab': 8, 'ballistic': 2}
    },
    'крим': {
        'typical_targets': ['одеса', 'миколаїв', 'херсон', 'київ', 'запоріжжя'],
        'threat_types': ['cruise', 'shahed', 'ballistic'],
        'launch_platforms': ['ground', 'aircraft'],
        'typical_group_size': {'cruise': 6, 'shahed': 25, 'ballistic': 3}
    },
    'каспійське море': {
        'typical_targets': ['київ', 'львів', 'харків', 'дніпро'],
        'threat_types': ['cruise'],
        'launch_platforms': ['ship', 'submarine'],
        'typical_group_size': {'cruise': 10}
    },
    'брянська область': {
        'typical_targets': ['чернігів', 'київ', 'суми', 'ніжин'],
        'threat_types': ['shahed', 'drone'],
        'launch_platforms': ['ground'],
        'typical_group_size': {'shahed': 12}
    },
    'ростовська область': {
        'typical_targets': ['харків', 'дніпро', 'запоріжжя'],
        'threat_types': ['cruise', 'ballistic'],
        'launch_platforms': ['aircraft', 'ground'],
        'typical_group_size': {'cruise': 6, 'ballistic': 2}
    },
    'воронезька область': {
        'typical_targets': ['харків', 'полтава', 'суми'],
        'threat_types': ['shahed', 'cruise'],
        'launch_platforms': ['ground', 'aircraft'],
        'typical_group_size': {'shahed': 8, 'cruise': 4}
    },
}

# Bayesian prior probabilities based on historical attacks (normalized)
PRIOR_TARGET_PROBABILITIES = {
    'київ': 0.25,
    'харків': 0.18,
    'одеса': 0.12,
    'дніпро': 0.10,
    'запоріжжя': 0.06,
    'миколаїв': 0.05,
    'львів': 0.04,
    'вінниця': 0.03,
    'полтава': 0.02,
    'суми': 0.02,
    'чернігів': 0.02,
    'херсон': 0.02,
    'кременчук': 0.02,
    'other': 0.07
}

def calculate_distance_km(lat1: float, lng1: float, lat2: float, lng2: float) -> float:
    """Calculate distance between two points in kilometers using Haversine formula"""
    R = 6371  # Earth's radius in km
    
    lat1_r, lat2_r = math.radians(lat1), math.radians(lat2)
    lng1_r, lng2_r = math.radians(lng1), math.radians(lng2)
    
    dlat = lat2_r - lat1_r
    dlng = lng2_r - lng1_r
    
    a = math.sin(dlat/2)**2 + math.cos(lat1_r) * math.cos(lat2_r) * math.sin(dlng/2)**2
    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))
    
    return R * c

def calculate_bearing(lat1: float, lng1: float, lat2: float, lng2: float) -> float:
    """Calculate bearing from point 1 to point 2 in degrees (0-360)"""
    lat1_r, lat2_r = math.radians(lat1), math.radians(lat2)
    lng1_r, lng2_r = math.radians(lng1), math.radians(lng2)
    dLng = lng2_r - lng1_r
    
    x = math.sin(dLng) * math.cos(lat2_r)
    y = math.cos(lat1_r) * math.sin(lat2_r) - math.sin(lat1_r) * math.cos(lat2_r) * math.cos(dLng)
    
    bearing = math.degrees(math.atan2(x, y))
    return (bearing + 360) % 360

def get_temporal_factors() -> dict:
    """Get all temporal factors for current time"""
    now = datetime.now()
    hour = now.hour
    weekday = now.weekday()
    month = now.month
    day = now.day
    
    factors = {
        'hour': hour,
        'weekday': weekday,
        'month': month,
        'is_night': 0 <= hour < 6,
        'is_weekend': weekday >= 5,
        'weekday_pattern': WEEKDAY_PATTERNS.get(weekday, {'capital': 1.0, 'overall': 1.0}),
        'seasonal_pattern': SEASONAL_PATTERNS.get(month, {}),
    }
    
    # Check special dates
    special = SPECIAL_DATES.get((month, day))
    if special:
        factors['special_date'] = special
        factors['capital_boost'] = special.get('capital_boost', 1.0)
        factors['overall_boost'] = special.get('overall_boost', 1.0)
    else:
        factors['capital_boost'] = 1.0
        factors['overall_boost'] = 1.0
    
    return factors

def softmax_normalize(probabilities: list) -> list:
    """Apply softmax normalization for better probability distribution"""
    if not probabilities:
        return []
    
    # Temperature parameter (lower = more confident, higher = more uniform)
    temperature = 0.5
    
    max_p = max(probabilities)
    exp_probs = [math.exp((p - max_p) / temperature) for p in probabilities]
    sum_exp = sum(exp_probs)
    
    if sum_exp == 0:
        return [1.0 / len(probabilities)] * len(probabilities)
    
    return [p / sum_exp for p in exp_probs]

def bayesian_update(prior: float, likelihood: float, evidence: float = 1.0) -> float:
    """Apply Bayesian update to probability"""
    if evidence == 0:
        return prior
    posterior = (likelihood * prior) / evidence
    return min(1.0, max(0.0, posterior))

def analyze_attack_pattern(active_threats: list, patterns: dict = None) -> dict:
    """
    Analyze current attack pattern to detect coordinated strikes.
    
    Returns:
    - attack_type: 'single' | 'wave' | 'diversionary' | 'saturation' | 'pinpoint'
    - coordination_score: 0-1 how coordinated the attack is
    - predicted_next_wave: estimated time until next wave
    - decoy_probability: chance some targets are decoys
    - primary_objective_guess: most likely strategic goal
    """
    if not active_threats:
        return {
            'attack_type': 'none',
            'coordination_score': 0,
            'predicted_next_wave': None,
            'decoy_probability': 0,
            'primary_objective_guess': None
        }
    
    num_threats = len(active_threats)
    threat_types = [t.get('type', 'unknown') for t in active_threats]
    unique_types = set(threat_types)
    
    # Analyze timing spread
    timestamps = []
    for t in active_threats:
        ts = t.get('first_seen') or t.get('timestamp')
        if ts:
            try:
                if isinstance(ts, str):
                    dt = datetime.fromisoformat(ts.replace('Z', '+00:00'))
                else:
                    dt = ts
                timestamps.append(dt)
            except:
                pass
    
    time_spread_minutes = 0
    if len(timestamps) >= 2:
        timestamps.sort()
        time_spread_minutes = (timestamps[-1] - timestamps[0]).total_seconds() / 60
    
    # Determine attack type
    attack_type = 'single'
    coordination_score = 0.3
    decoy_probability = 0
    
    if num_threats == 1:
        attack_type = 'single'
        coordination_score = 0.5
    elif num_threats <= 3:
        attack_type = 'small_group'
        coordination_score = 0.6
    elif num_threats <= 8:
        if len(unique_types) > 2:
            attack_type = 'combined'  # Multiple threat types
            coordination_score = 0.8
            decoy_probability = 0.3
        elif time_spread_minutes < 10:
            attack_type = 'wave'
            coordination_score = 0.75
        else:
            attack_type = 'dispersed'
            coordination_score = 0.5
    else:  # Large attack
        if 'ballistic' in unique_types or 'cruise' in unique_types:
            if 'shahed' in unique_types:
                attack_type = 'saturation'  # Mix to overwhelm air defense
                coordination_score = 0.9
                decoy_probability = 0.5  # Shaheds may be decoys
            else:
                attack_type = 'mass_strike'
                coordination_score = 0.85
        else:
            attack_type = 'drone_swarm'
            coordination_score = 0.7
    
    # Predict next wave based on historical patterns
    predicted_next_wave = None
    if patterns and 'attack_intervals' in patterns:
        intervals = patterns['attack_intervals']
        if intervals:
            avg_interval = sum(intervals) / len(intervals)
            predicted_next_wave = avg_interval
    
    # Guess primary objective
    targets = [t.get('target', t.get('heading', '')) for t in active_threats if t.get('target') or t.get('heading')]
    target_counts = {}
    for tgt in targets:
        tgt_lower = str(tgt).lower()
        target_counts[tgt_lower] = target_counts.get(tgt_lower, 0) + 1
    
    primary_objective = None
    if target_counts:
        primary_objective = max(target_counts, key=target_counts.get).title()
    
    return {
        'attack_type': attack_type,
        'coordination_score': round(coordination_score, 2),
        'predicted_next_wave': predicted_next_wave,
        'decoy_probability': round(decoy_probability, 2),
        'primary_objective_guess': primary_objective,
        'threat_diversity': len(unique_types),
        'total_threats': num_threats,
        'time_spread_minutes': round(time_spread_minutes, 1)
    }

def calculate_intercept_probability(threat_type: str, region: str, air_defense: str = 'unknown') -> float:
    """
    Estimate probability of interception based on threat and air defense.
    
    Args:
        threat_type: Type of threat (shahed, cruise, ballistic, etc.)
        region: Target region
        air_defense: 'heavy' | 'medium' | 'light' | 'unknown'
    
    Returns probability 0-1
    """
    # Base intercept rates by threat type (rough estimates)
    base_rates = {
        'shahed': 0.75,      # High intercept rate for slow drones
        'drone': 0.80,       # Other drones
        'cruise': 0.60,      # Cruise missiles harder to intercept
        'ballistic': 0.45,   # Ballistic very difficult
        'kab': 0.25,         # KABs almost impossible to intercept
        'rocket': 0.35,      # S-300 used as ground attack
        'unknown': 0.50
    }
    
    base_rate = base_rates.get(threat_type, 0.5)
    
    # Modify by air defense level
    defense_multipliers = {
        'heavy': 1.3,    # Kyiv, major cities
        'medium': 1.0,   # Regional centers
        'light': 0.7,    # Rural areas
        'unknown': 0.9
    }
    
    multiplier = defense_multipliers.get(air_defense, 0.9)
    
    # Cap at realistic levels
    return min(0.95, max(0.1, base_rate * multiplier))

def estimate_threat_altitude(threat_type: str, phase: str = 'cruise') -> dict:
    """
    Estimate threat altitude based on type and flight phase.
    
    Args:
        threat_type: Type of threat
        phase: 'launch' | 'cruise' | 'terminal' | 'unknown'
    
    Returns altitude info in meters
    """
    altitudes = THREAT_SPEEDS.get(threat_type, THREAT_SPEEDS['unknown'])
    typical_alt = altitudes.get('altitude', 1000)
    
    # Adjust by phase
    if phase == 'launch':
        alt_range = (typical_alt * 0.8, typical_alt * 1.5)
    elif phase == 'cruise':
        alt_range = (typical_alt * 0.7, typical_alt * 1.2)
    elif phase == 'terminal':
        alt_range = (50, typical_alt * 0.5)  # Diving to target
    else:
        alt_range = (typical_alt * 0.5, typical_alt * 1.5)
    
    return {
        'min_m': int(alt_range[0]),
        'max_m': int(alt_range[1]),
        'typical_m': typical_alt,
        'phase': phase
    }

def estimate_eta_minutes(distance_km: float, threat_type: str) -> dict:
    """
    Estimate time of arrival based on distance and threat type.
    
    Returns dict with:
    - min_minutes: fastest possible ETA
    - avg_minutes: expected ETA  
    - max_minutes: slowest ETA
    - formatted: human-readable string
    """
    speeds = THREAT_SPEEDS.get(threat_type, THREAT_SPEEDS['unknown'])
    
    # Convert to minutes (distance / speed * 60)
    min_eta = (distance_km / speeds['max']) * 60 if speeds['max'] > 0 else 999
    avg_eta = (distance_km / speeds['avg']) * 60 if speeds['avg'] > 0 else 999
    max_eta = (distance_km / speeds['min']) * 60 if speeds['min'] > 0 else 999
    
    # Format human-readable
    def format_time(minutes):
        if minutes < 1:
            return "< 1 хв"
        elif minutes < 60:
            return f"{int(minutes)} хв"
        else:
            hours = int(minutes // 60)
            mins = int(minutes % 60)
            if mins == 0:
                return f"{hours} год"
            return f"{hours} год {mins} хв"
    
    if min_eta == avg_eta == max_eta:
        formatted = format_time(avg_eta)
    elif max_eta - min_eta < 5:
        formatted = f"~{format_time(avg_eta)}"
    else:
        formatted = f"{format_time(min_eta)} - {format_time(max_eta)}"
    
    return {
        'min_minutes': round(min_eta, 1),
        'avg_minutes': round(avg_eta, 1),
        'max_minutes': round(max_eta, 1),
        'formatted': formatted
    }

def extract_attack_scale(message_text: str) -> dict:
    """
    Extract attack scale information from message text.
    
    Returns:
    - count: estimated number of threats
    - scale: 'single' | 'small_group' | 'large_group' | 'mass'
    - confidence: how confident we are in the count
    """
    if not message_text:
        return {'count': 1, 'scale': 'single', 'confidence': 0.3}
    
    msg_lower = message_text.lower()
    count = 1
    confidence = 0.5
    
    # Direct number extraction
    number_patterns = [
        (r'(\d+)\s*(?:бпла|шахед|дрон|ракет)', 1.0),
        (r'близько\s*(\d+)', 0.8),
        (r'до\s*(\d+)', 0.7),
        (r'понад\s*(\d+)', 0.8),
        (r'більше\s*(\d+)', 0.7),
        (r'(\d+)\s*одиниц', 1.0),
        (r'група\s*(?:з\s*)?(\d+)', 0.9),
    ]
    
    for pattern, conf in number_patterns:
        match = re.search(pattern, msg_lower)
        if match:
            try:
                count = int(match.group(1))
                confidence = conf
                break
            except:
                pass
    
    # Word-based count estimation
    if count == 1:
        word_counts = {
            'кілька': (3, 0.6),
            'декілька': (4, 0.6),
            'група': (5, 0.5),
            'групи': (8, 0.5),
            'багато': (10, 0.4),
            'масов': (15, 0.4),
            'велика група': (10, 0.5),
            'невелика група': (3, 0.6),
        }
        for word, (est_count, conf) in word_counts.items():
            if word in msg_lower:
                count = est_count
                confidence = conf
                break
    
    # Determine scale
    if count == 1:
        scale = 'single'
    elif count <= 3:
        scale = 'small_group'
    elif count <= 10:
        scale = 'large_group'
    else:
        scale = 'mass'
    
    return {
        'count': count,
        'scale': scale,
        'confidence': confidence
    }

def learn_from_attack_outcome(attack_id: str, actual_targets: list, predicted_targets: list, 
                               threat_type: str, source_region: str, timestamp: str = None):
    """
    Learn from actual attack outcomes to improve future predictions.
    Updates historical patterns and adjusts weights.
    
    Args:
        attack_id: Unique identifier for this attack
        actual_targets: List of targets that were actually hit/targeted
        predicted_targets: List of targets we predicted
        threat_type: Type of threat
        source_region: Where attack originated
        timestamp: When attack occurred
    """
    patterns = _load_route_patterns()
    
    if 'learning_history' not in patterns:
        patterns['learning_history'] = []
    
    # Calculate accuracy
    correct_predictions = 0
    for pred in predicted_targets:
        pred_name = pred if isinstance(pred, str) else pred.get('name', '').lower()
        for actual in actual_targets:
            actual_name = actual if isinstance(actual, str) else actual.get('name', '').lower()
            if pred_name.lower() == actual_name.lower():
                correct_predictions += 1
                break
    
    accuracy = correct_predictions / len(predicted_targets) if predicted_targets else 0
    
    # Store learning record
    record = {
        'attack_id': attack_id,
        'timestamp': timestamp or datetime.now().isoformat(),
        'threat_type': threat_type,
        'source_region': source_region,
        'predicted': [p if isinstance(p, str) else p.get('name') for p in predicted_targets[:5]],
        'actual': [a if isinstance(a, str) else a.get('name') for a in actual_targets],
        'accuracy': round(accuracy, 2)
    }
    patterns['learning_history'].append(record)
    
    # Keep last 500 records
    if len(patterns['learning_history']) > 500:
        patterns['learning_history'] = patterns['learning_history'][-500:]
    
    # Update source-target correlations
    if 'source_target_correlations' not in patterns:
        patterns['source_target_correlations'] = {}
    
    src_key = source_region.lower() if source_region else 'unknown'
    if src_key not in patterns['source_target_correlations']:
        patterns['source_target_correlations'][src_key] = {}
    
    for actual in actual_targets:
        actual_name = (actual if isinstance(actual, str) else actual.get('name', '')).lower()
        if actual_name:
            current = patterns['source_target_correlations'][src_key].get(actual_name, 0)
            patterns['source_target_correlations'][src_key][actual_name] = current + 1
    
    # Update temporal patterns
    if timestamp:
        try:
            dt = datetime.fromisoformat(timestamp.replace('Z', '+00:00'))
            hour = dt.hour
            weekday = dt.weekday()
            month = dt.month
            
            if 'temporal_attack_history' not in patterns:
                patterns['temporal_attack_history'] = {
                    'hourly': {str(h): 0 for h in range(24)},
                    'daily': {str(d): 0 for d in range(7)},
                    'monthly': {str(m): 0 for m in range(1, 13)}
                }
            
            patterns['temporal_attack_history']['hourly'][str(hour)] = \
                patterns['temporal_attack_history']['hourly'].get(str(hour), 0) + 1
            patterns['temporal_attack_history']['daily'][str(weekday)] = \
                patterns['temporal_attack_history']['daily'].get(str(weekday), 0) + 1
            patterns['temporal_attack_history']['monthly'][str(month)] = \
                patterns['temporal_attack_history']['monthly'].get(str(month), 0) + 1
        except:
            pass
    
    global _route_patterns_modified
    _route_patterns_modified = True
    _save_route_patterns()
    
    print(f"INFO: Learned from attack {attack_id}, accuracy={accuracy:.0%}")
    return {'status': 'ok', 'accuracy': accuracy}

def get_prediction_accuracy_stats() -> dict:
    """
    Get statistics on prediction accuracy over time.
    
    Returns accuracy metrics for evaluation.
    """
    patterns = _load_route_patterns()
    history = patterns.get('learning_history', [])
    
    if not history:
        return {
            'total_predictions': 0,
            'avg_accuracy': 0,
            'accuracy_trend': 'unknown',
            'best_threat_type': None,
            'worst_threat_type': None
        }
    
    # Overall accuracy
    accuracies = [h['accuracy'] for h in history if 'accuracy' in h]
    avg_accuracy = sum(accuracies) / len(accuracies) if accuracies else 0
    
    # Accuracy by threat type
    by_threat = {}
    for h in history:
        tt = h.get('threat_type', 'unknown')
        if tt not in by_threat:
            by_threat[tt] = []
        if 'accuracy' in h:
            by_threat[tt].append(h['accuracy'])
    
    threat_accuracies = {tt: sum(accs)/len(accs) for tt, accs in by_threat.items() if accs}
    
    best_threat = max(threat_accuracies, key=threat_accuracies.get) if threat_accuracies else None
    worst_threat = min(threat_accuracies, key=threat_accuracies.get) if threat_accuracies else None
    
    # Accuracy trend (last 50 vs previous 50)
    trend = 'stable'
    if len(accuracies) >= 100:
        recent = accuracies[-50:]
        older = accuracies[-100:-50]
        recent_avg = sum(recent) / len(recent)
        older_avg = sum(older) / len(older)
        if recent_avg > older_avg + 0.05:
            trend = 'improving'
        elif recent_avg < older_avg - 0.05:
            trend = 'declining'
    
    return {
        'total_predictions': len(history),
        'avg_accuracy': round(avg_accuracy, 3),
        'accuracy_trend': trend,
        'accuracy_by_threat': threat_accuracies,
        'best_threat_type': best_threat,
        'worst_threat_type': worst_threat
    }

def calculate_confidence_interval(probability: float, sample_size: int = 10) -> dict:
    """
    Calculate confidence interval for a probability estimate.
    
    Uses Wilson score interval for better accuracy with small samples.
    """
    import math
    
    z = 1.96  # 95% confidence
    n = max(1, sample_size)
    p = min(1.0, max(0.0, probability))
    
    # Wilson score interval
    denominator = 1 + z*z/n
    center = (p + z*z/(2*n)) / denominator
    spread = z * math.sqrt((p*(1-p) + z*z/(4*n)) / n) / denominator
    
    return {
        'lower': round(max(0, center - spread), 3),
        'upper': round(min(1, center + spread), 3),
        'center': round(center, 3),
        'width': round(spread * 2, 3)
    }

def detect_decoy_threats(threats: list) -> list:
    """
    Analyze a group of threats to identify potential decoys.
    
    In saturation attacks, slower drones (Shahed) may be decoys while
    faster missiles (cruise/ballistic) are the real targets.
    
    Returns threats with decoy_probability added.
    """
    if not threats or len(threats) < 2:
        return threats
    
    threat_types = {}
    for t in threats:
        tt = t.get('type', t.get('threat_type', 'unknown'))
        if tt not in threat_types:
            threat_types[tt] = []
        threat_types[tt].append(t)
    
    # Check for mixed attack pattern
    has_drones = 'shahed' in threat_types or 'drone' in threat_types
    has_missiles = 'cruise' in threat_types or 'ballistic' in threat_types
    
    for t in threats:
        tt = t.get('type', t.get('threat_type', 'unknown'))
        decoy_prob = 0
        
        if has_drones and has_missiles:
            # Mixed attack - drones more likely to be decoys
            if tt in ['shahed', 'drone']:
                # More drones = higher chance they're decoys
                drone_count = len(threat_types.get('shahed', [])) + len(threat_types.get('drone', []))
                missile_count = len(threat_types.get('cruise', [])) + len(threat_types.get('ballistic', []))
                
                if drone_count > missile_count * 2:
                    decoy_prob = 0.4  # Many drones vs few missiles
                elif drone_count > missile_count:
                    decoy_prob = 0.3
                else:
                    decoy_prob = 0.2
        
        # Shaheds from south heading north when missiles from east = probable decoy
        source = t.get('source_region', '').lower()
        heading = t.get('heading', t.get('target', '')).lower()
        
        if tt == 'shahed' and has_missiles:
            if 'одеськ' in source or 'миколаїв' in source:
                if 'київ' in heading:
                    decoy_prob = max(decoy_prob, 0.35)
        
        t['decoy_probability'] = round(decoy_prob, 2)
    
    return threats

def prioritize_threats(threats: list) -> list:
    """
    Prioritize threats based on multiple factors.
    
    Priority factors:
    1. Threat type (ballistic > cruise > KAB > shahed)
    2. Speed/ETA (faster = higher priority)
    3. Target value (capital > industrial > other)
    4. Not a likely decoy
    
    Returns threats sorted by priority score.
    """
    if not threats:
        return threats
    
    # Priority base scores by type
    type_priority = {
        'ballistic': 100,
        'cruise': 85,
        'kab': 80,
        'shahed': 60,
        'drone': 50,
        'rocket': 70,
        'unknown': 40
    }
    
    # Target priority modifiers
    target_priority = {
        'capital': 30,
        'industrial': 20,
        'port': 15,
        'military': 25,
        'civilian': 10
    }
    
    for t in threats:
        score = 0
        
        # Base type score
        tt = t.get('type', t.get('threat_type', 'unknown'))
        score += type_priority.get(tt, 40)
        
        # ETA factor - shorter ETA = higher priority
        eta = t.get('eta', {})
        if isinstance(eta, dict):
            eta_min = eta.get('min_minutes', 60)
        else:
            eta_min = 60
        
        if eta_min < 5:
            score += 50  # Very urgent
        elif eta_min < 15:
            score += 30
        elif eta_min < 30:
            score += 15
        
        # Target value
        target_type = t.get('target_type', 'civilian')
        score += target_priority.get(target_type, 10)
        
        # Reduce score if likely decoy
        decoy_prob = t.get('decoy_probability', 0)
        score *= (1 - decoy_prob * 0.5)
        
        # Boost if high confidence
        confidence = t.get('confidence', t.get('probability', 0.5))
        score *= (0.8 + confidence * 0.4)
        
        t['priority_score'] = round(score, 1)
    
    # Sort by priority (descending)
    threats.sort(key=lambda x: x.get('priority_score', 0), reverse=True)
    
    return threats

def get_regional_threat_assessment(region: str, active_threats: list = None) -> dict:
    """
    Get threat assessment for a specific region.
    
    Returns risk level and recommendations.
    """
    region_lower = region.lower()
    
    # Base risk by region position
    frontline_regions = ['харківська', 'запорізька', 'херсонська', 'донецька', 'луганська', 'сумська']
    high_value_regions = ['київ', 'київська', 'одеська', 'дніпропетровська']
    
    base_risk = 0.3
    if any(r in region_lower for r in frontline_regions):
        base_risk = 0.7
    elif any(r in region_lower for r in high_value_regions):
        base_risk = 0.5
    
    # Temporal risk adjustment
    temporal = get_temporal_factors()
    hour_pattern = HOURLY_PATTERNS.get('shahed', {}).get(temporal['hour'], 1.0)
    base_risk *= hour_pattern
    
    # Active threat adjustment
    threats_heading_to_region = []
    if active_threats:
        for t in active_threats:
            target = str(t.get('target', t.get('heading', ''))).lower()
            if region_lower in target or target in region_lower:
                threats_heading_to_region.append(t)
    
    if threats_heading_to_region:
        # Calculate ETA to region
        min_eta = min(
            t.get('eta', {}).get('min_minutes', 999) if isinstance(t.get('eta'), dict) else 999
            for t in threats_heading_to_region
        )
        threat_count = len(threats_heading_to_region)
        
        return {
            'region': region,
            'risk_level': 'critical' if base_risk > 0.7 else 'high' if base_risk > 0.5 else 'elevated',
            'risk_score': round(min(1.0, base_risk + 0.3), 2),
            'active_threats': threat_count,
            'min_eta_minutes': min_eta,
            'recommendation': 'Негайно в укриття!' if min_eta < 10 else 'Підготуватися до тривоги'
        }
    
    return {
        'region': region,
        'risk_level': 'elevated' if base_risk > 0.4 else 'low',
        'risk_score': round(base_risk, 2),
        'active_threats': 0,
        'min_eta_minutes': None,
        'recommendation': 'Слідкуйте за оновленнями' if base_risk > 0.4 else 'Нормальний стан'
    }


# ==================== AI SMART TTL SYSTEM ====================
# Intelligent marker lifetime calculation based on threat type, context, and status

# Base TTL in minutes - MINIMUM time, adjusted UP based on distance/ETA
THREAT_BASE_TTL = {
    'shahed': 15,       # Base 15 min, increases with distance
    'drone': 15,        # Other drones
    'cruise': 12,       # Cruise missiles
    'ballistic': 5,     # Ballistic - very fast
    'kab': 8,           # Guided bombs - fast
    'rocket': 8,        # Rockets
    'kinzhal': 3,       # Hypersonic - extremely fast
    'iskander': 5,      # Ballistic
    'kalibr': 15,       # Cruise missile
    'x101': 20,         # Long-range cruise
    'unknown': 20,      # Default
    'explosion': 10,    # Already happened
    'artillery': 8,     # Artillery
    'air': 15,          # Air alert general
}

# Maximum TTL by threat type (even with long distance)
THREAT_MAX_TTL = {
    'shahed': 180,      # 3 hours max for shaheds
    'drone': 120,       # 2 hours
    'cruise': 45,       # 45 min
    'ballistic': 15,    # 15 min max
    'kab': 20,          # 20 min
    'rocket': 15,       # 15 min
    'kinzhal': 8,       # 8 min
    'iskander': 12,     # 12 min
    'kalibr': 50,       # 50 min
    'x101': 60,         # 1 hour
    'unknown': 45,      # 45 min default
    'explosion': 15,    # 15 min
    'artillery': 12,    # 12 min
    'air': 30,          # 30 min
}

# Keywords indicating DISTANT threat (need more TTL)
DISTANT_KEYWORDS = [
    'чорне море', 'каспій', 'азовськ', 'білорусь', 'росія',
    'запуск', 'старт', 'пуск', 'зліт', 'виявлен', 'увійшл',
    'перетнув кордон', 'з території', 'від кордону',
]

# Keywords indicating CLOSE/ARRIVED threat (need less TTL)
CLOSE_KEYWORDS = [
    'над ', 'в районі', 'у районі', 'біля', 'поблизу',
    'наближається до', 'на підльоті', 'входить у',
    'вже в', 'досяг', 'прибув', 'летить над',
]

# Keywords that indicate threat is over/destroyed
THREAT_ENDED_KEYWORDS = [
    'збит', 'знищен', 'уражен', 'ліквідован', 'нейтралізован',
    'перехоплен', 'відбит', 'відведен', 'не загроз', 'пішов', 
    'покинув', 'вийшов', 'залишив', 'минув', 'пролетів',
    'завершен', 'закінч', 'скасуван', 'все чист', 'відбій',
    'влучан', 'вибух', 'впав', 'упав', 'приземлив',
]

# Keywords that indicate ongoing/active threat
THREAT_ACTIVE_KEYWORDS = [
    'курс', 'напрям', 'рухається', 'летить', 'прямує',
    'наближається', 'атак', 'загроз', 'небезпек', 'увага',
    'пуск', 'старт', 'виявлен', 'зафіксован', 'в повітр',
]

def calculate_ai_marker_ttl(message_text: str, threat_type: str = None, 
                            distance_km: float = None, eta_minutes: float = None,
                            source_region: str = None, target_region: str = None,
                            marker_data: dict = None) -> dict:
    """
    Calculate intelligent TTL (time-to-live) for a marker based on AI analysis.
    
    Instead of fixed 30-minute display time, calculates optimal TTL based on:
    1. Threat type (ballistic=fast, shahed=slow)
    2. Distance to target (further = longer TTL)
    3. ETA (adjust based on when it should arrive)
    4. Message context (destroyed? changed course? ongoing?)
    5. Historical patterns
    
    Returns:
    {
        'ttl_minutes': int,  # Recommended TTL
        'ttl_seconds': int,  # Same in seconds
        'expires_at': datetime,  # When marker should disappear
        'confidence': float,  # Confidence in TTL estimate
        'reason': str,  # Why this TTL was chosen
        'status': 'active' | 'ended' | 'uncertain'
    }
    """
    msg_lower = (message_text or '').lower()
    
    # Detect if threat is already over
    ended_count = sum(1 for kw in THREAT_ENDED_KEYWORDS if kw in msg_lower)
    active_count = sum(1 for kw in THREAT_ACTIVE_KEYWORDS if kw in msg_lower)
    
    # If threat is clearly ended
    if ended_count >= 2 or (ended_count > 0 and active_count == 0):
        return {
            'ttl_minutes': 5,
            'ttl_seconds': 300,
            'expires_at': datetime.now() + timedelta(minutes=5),
            'confidence': 0.9,
            'reason': 'Загроза знищена/завершена',
            'status': 'ended'
        }
    
    # Get base TTL from threat type
    if threat_type:
        tt_lower = threat_type.lower()
        # Handle variants
        if 'шахед' in tt_lower or 'герань' in tt_lower:
            threat_type = 'shahed'
        elif 'балістик' in tt_lower or 'іскандер' in tt_lower:
            threat_type = 'ballistic'
        elif 'крилат' in tt_lower or 'калібр' in tt_lower or 'х-' in tt_lower:
            threat_type = 'cruise'
        elif 'каб' in tt_lower or 'бомб' in tt_lower:
            threat_type = 'kab'
        elif 'кінжал' in tt_lower:
            threat_type = 'kinzhal'
    else:
        # Try to detect threat type from message
        if any(w in msg_lower for w in ['шахед', 'герань', 'бпла', 'дрон']):
            threat_type = 'shahed'
        elif any(w in msg_lower for w in ['балістик', 'іскандер', 'кн-23']):
            threat_type = 'ballistic'
        elif any(w in msg_lower for w in ['крилат', 'калібр', 'х-101', 'х-55', 'х-22']):
            threat_type = 'cruise'
        elif any(w in msg_lower for w in ['каб', 'керована бомба', 'авіабомб']):
            threat_type = 'kab'
        elif any(w in msg_lower for w in ['кінжал', 'гіперзвук']):
            threat_type = 'kinzhal'
        elif 'вибух' in msg_lower:
            threat_type = 'explosion'
        elif 'артилер' in msg_lower or 'обстріл' in msg_lower:
            threat_type = 'artillery'
        else:
            threat_type = 'unknown'
    
    base_ttl = THREAT_BASE_TTL.get(threat_type, 20)
    max_ttl = THREAT_MAX_TTL.get(threat_type, 45)
    reason = f"Базовий TTL для {threat_type}"
    confidence = 0.7
    
    # === ANALYZE DISTANCE FROM MESSAGE CONTEXT ===
    # Check if threat is distant (just launched, from far away)
    distant_count = sum(1 for kw in DISTANT_KEYWORDS if kw in msg_lower)
    # Check if threat is close (already over target area)
    close_count = sum(1 for kw in CLOSE_KEYWORDS if kw in msg_lower)
    
    distance_factor = 1.0
    if distant_count > close_count:
        # Distant threat - increase TTL significantly
        distance_factor = 2.5 if threat_type in ['shahed', 'drone'] else 1.8
        reason += " + далеко"
        confidence = 0.75
    elif close_count > distant_count:
        # Close threat - keep base TTL or reduce
        distance_factor = 0.8
        reason += " + близько"
        confidence = 0.8
    
    base_ttl = base_ttl * distance_factor
    
    # === ADJUST BY ETA IF KNOWN ===
    if eta_minutes is not None and eta_minutes > 0:
        # TTL should be at least ETA + buffer
        eta_buffer = eta_minutes * 1.3 + 5  # 1.3x ETA + 5 min buffer
        if eta_buffer > base_ttl:
            base_ttl = eta_buffer
            reason = f"ETA: {eta_minutes:.0f} хв"
            confidence = 0.85
    
    # === ADJUST BY DISTANCE IF KNOWN ===
    if distance_km is not None and distance_km > 0:
        # Estimate time based on threat speed
        speeds = THREAT_SPEEDS.get(threat_type, THREAT_SPEEDS['unknown'])
        avg_time = (distance_km / speeds['avg']) * 60  # in minutes
        
        # TTL should accommodate travel time + buffer
        travel_ttl = avg_time * 1.2 + 5  # 1.2x travel + 5 min buffer
        if travel_ttl > base_ttl:
            base_ttl = travel_ttl
            reason = f"Відстань: {distance_km:.0f} км"
            confidence = 0.8
    
    # === ADJUST FOR SOURCE REGION ===
    if source_region:
        src_lower = source_region.lower()
        if 'чорне море' in src_lower or 'каспій' in src_lower:
            if threat_type == 'shahed':
                base_ttl = max(base_ttl, 90)  # Shaheds from sea - at least 1.5 hours
            else:
                base_ttl = max(base_ttl, 40)
            reason += " (з моря)"
        elif 'білорусь' in src_lower:
            base_ttl = max(base_ttl, 30)
            reason += " (з Білорусі)"
    
    # === COURSE CHANGES ===
    if any(w in msg_lower for w in ['змінив курс', 'змінює напрям', 'маневрує', 'повернув']):
        base_ttl *= 1.2  # Add 20% for unpredictable path
        reason += " + маневри"
        confidence *= 0.9
    
    # === MULTIPLE THREATS ===
    quantity = 1
    qty_match = re.search(r'(\d+)\s*(?:бпла|шахед|дрон|ракет)', msg_lower)
    if qty_match:
        quantity = int(qty_match.group(1))
        if quantity > 5:
            base_ttl *= 1.15  # Large groups take slightly longer
            reason += f" ({quantity} шт)"
    
    # === APPLY MAX TTL LIMIT ===
    base_ttl = min(base_ttl, max_ttl)
    
    # Round to reasonable value
    base_ttl = int(round(base_ttl / 5) * 5)  # Round to nearest 5 minutes
    base_ttl = max(5, base_ttl)  # Minimum 5 minutes
    
    return {
        'ttl_minutes': base_ttl,
        'ttl_seconds': base_ttl * 60,
        'expires_at': datetime.now() + timedelta(minutes=base_ttl),
        'confidence': round(confidence, 2),
        'reason': reason,
        'status': 'active',
        'threat_type_detected': threat_type
    }

def get_marker_ttl_from_message(message: dict) -> dict:
    """
    Convenience function to get TTL for a marker from its message data.
    """
    text = message.get('text', '')
    threat_type = message.get('threat_type')
    
    # Extract coordinates for distance calculation
    lat = message.get('lat')
    lng = message.get('lng')
    distance_km = None
    eta_minutes = None
    
    # Get trajectory data if available
    trajectory = message.get('trajectory') or message.get('enhanced_trajectory')
    if trajectory:
        distance_km = trajectory.get('distance_km')
        eta = trajectory.get('eta', {})
        if isinstance(eta, dict):
            eta_minutes = eta.get('avg_minutes')
    
    # Get source region
    source_region = message.get('source') or message.get('course_source')
    
    return calculate_ai_marker_ttl(
        message_text=text,
        threat_type=threat_type,
        distance_km=distance_km,
        eta_minutes=eta_minutes,
        source_region=source_region,
        marker_data=message
    )

def should_marker_be_visible(message: dict, current_time: datetime = None) -> dict:
    """
    Determine if a marker should still be visible based on AI TTL.
    
    Returns:
    {
        'visible': bool,
        'reason': str,
        'remaining_minutes': int,  # If visible, minutes remaining
        'ttl_info': dict  # Full TTL calculation
    }
    """
    if current_time is None:
        current_time = datetime.now()
    
    # Get message timestamp
    try:
        msg_time = datetime.strptime(message.get('date', ''), '%Y-%m-%d %H:%M:%S')
    except:
        # Can't parse time, show by default
        return {
            'visible': True,
            'reason': 'Не вдалося визначити час',
            'remaining_minutes': 30,
            'ttl_info': None
        }
    
    # Calculate AI TTL
    ttl_info = get_marker_ttl_from_message(message)
    ttl_minutes = ttl_info['ttl_minutes']
    
    # Calculate age
    age_minutes = (current_time - msg_time).total_seconds() / 60
    
    if age_minutes > ttl_minutes:
        return {
            'visible': False,
            'reason': ttl_info['reason'],
            'remaining_minutes': 0,
            'age_minutes': int(age_minutes),
            'ttl_info': ttl_info
        }
    
    return {
        'visible': True,
        'reason': 'Активна загроза',
        'remaining_minutes': int(ttl_minutes - age_minutes),
        'age_minutes': int(age_minutes),
        'ttl_info': ttl_info
    }

# Global flag to enable/disable AI TTL (env override for deploys)
# Default is disabled unless explicitly enabled via env or admin API
AI_TTL_ENABLED = str(os.getenv('AI_TTL_ENABLED', 'false')).lower() in ('1', 'true', 'yes', 'y', 'on')

def set_ai_ttl_enabled(enabled: bool):
    """Enable or disable AI TTL system"""
    global AI_TTL_ENABLED
    AI_TTL_ENABLED = enabled
    print(f"INFO: AI TTL system {'enabled' if enabled else 'disabled'}")

# ==================== END AI SMART TTL SYSTEM ====================


# ==================== SMART THREAT TRACKING SYSTEM ====================
# Інтелектуальна система відстеження загроз:
# 1. Синхронізація з API тривог - коли тривога в регіоні закінчується, маркери зникають
# 2. Відстеження груп (шахедів) - лічильник збитих/активних
# 3. Оновлення позиції маркерів при нових повідомленнях
# 4. Автоматична зміна статусу (активний → збитий → пролетів)

import threading
import time as time_module

# Threat tracking storage
# threat_id -> { info about tracked threat }
ACTIVE_THREATS = {}
ACTIVE_THREATS_LOCK = threading.Lock()

# Mapping: region -> list of threat_ids in that region
REGION_THREATS = {}

# Cache for alarm states (to detect changes)
_LAST_ALARM_STATES = {}

class ThreatTracker:
    """
    Система відстеження загроз в реальному часі.
    
    Можливості:
    - Створення нових загроз з повідомлень
    - Оновлення позиції при нових даних
    - Відстеження груп (кількість в групі, кількість збитих)
    - Автоматичне видалення при зняття тривоги в регіоні
    - Зміна статусу (активний → збитий → минув)
    """
    
    def __init__(self):
        self.threats = {}  # threat_id -> ThreatInfo
        self.lock = threading.Lock()
        self.region_to_threats = {}  # region_name -> set of threat_ids
        self.message_to_threat = {}  # message_id -> threat_id (for linking)
        
    def generate_threat_id(self, msg_text: str, threat_type: str, region: str) -> str:
        """Generate unique ID for a threat based on key characteristics"""
        import hashlib
        # Create hash from characteristics that should be same for updates to same threat
        key = f"{threat_type}:{region}:{datetime.now().strftime('%Y%m%d%H')}"
        return hashlib.md5(key.encode()).hexdigest()[:12]
    
    def parse_threat_from_message(self, message: dict) -> dict:
        """
        Розбір повідомлення для витягування інформації про загрозу.
        
        Повертає:
        - threat_type: тип загрози
        - quantity: кількість в групі
        - regions: список регіонів де виявлено
        - status: активний/збитий/пролетів
        - direction: напрямок руху
        - coordinates: координати якщо є
        """
        text = message.get('text', '')
        msg_lower = text.lower()
        
        result = {
            'threat_type': None,
            'quantity': 1,
            'quantity_destroyed': 0,
            'regions': [],
            'status': 'active',
            'direction': None,
            'target': None,
            'coordinates': None,
            'original_message': message
        }
        
        # === DETERMINE THREAT TYPE ===
        if any(w in msg_lower for w in ['шахед', 'герань', 'shahed', 'geran']):
            result['threat_type'] = 'shahed'
        elif any(w in msg_lower for w in ['бпла', 'дрон', 'uav', 'безпілот']):
            result['threat_type'] = 'drone'
        elif any(w in msg_lower for w in ['балістик', 'іскандер', 'кн-23', 'ballistic']):
            result['threat_type'] = 'ballistic'
        elif any(w in msg_lower for w in ['крилат', 'калібр', 'х-101', 'х-55', 'cruise']):
            result['threat_type'] = 'cruise'
        elif any(w in msg_lower for w in ['каб', 'керована бомба', 'авіабомб', 'kab']):
            result['threat_type'] = 'kab'
        elif any(w in msg_lower for w in ['кінжал', 'kinzhal', 'гіперзвук']):
            result['threat_type'] = 'kinzhal'
        else:
            result['threat_type'] = 'unknown'
        
        # === EXTRACT QUANTITY ===
        # Patterns: "5 шахедів", "група з 10 БПЛА", "до 15 дронів"
        qty_patterns = [
            r'(\d+)\s*(?:шахед|shahed|герань|бпла|дрон|ракет)',
            r'група\s*(?:з\s*)?(\d+)',
            r'до\s*(\d+)\s*(?:шахед|бпла|дрон|ракет)',
            r'близько\s*(\d+)',
        ]
        for pattern in qty_patterns:
            match = re.search(pattern, msg_lower)
            if match:
                result['quantity'] = int(match.group(1))
                break
        
        # === EXTRACT DESTROYED COUNT ===
        # "збито 3 з 10", "знищено 5 шахедів"
        destroyed_patterns = [
            r'збит[оі]\s*(\d+)',
            r'знищен[оі]\s*(\d+)',
            r'уражен[оі]\s*(\d+)',
            r'(\d+)\s*збит',
            r'(\d+)\s*знищен',
        ]
        for pattern in destroyed_patterns:
            match = re.search(pattern, msg_lower)
            if match:
                result['quantity_destroyed'] = int(match.group(1))
                break
        
        # === DETERMINE STATUS ===
        if result['quantity_destroyed'] > 0:
            if result['quantity_destroyed'] >= result['quantity']:
                result['status'] = 'destroyed'
            else:
                result['status'] = 'partially_destroyed'
        
        # Check for "passed through" status
        passed_keywords = ['пролетів', 'минув', 'пройшов', 'покинув', 'вийшов', 'залишив']
        if any(kw in msg_lower for kw in passed_keywords):
            result['status'] = 'passed'
        
        # === EXTRACT REGIONS ===
        # List of Ukrainian regions
        ua_regions = [
            'київ', 'київська', 'харків', 'харківська', 'одес', 'одеська',
            'дніпро', 'дніпропетров', 'запоріж', 'львів', 'львівська',
            'полтав', 'вінниц', 'черкас', 'чернігів', 'суми', 'сумська',
            'миколаїв', 'херсон', 'донецьк', 'луганськ', 'житомир',
            'хмельниц', 'рівн', 'волин', 'тернопіл', 'івано-франків',
            'закарпат', 'чернівц', 'кіровоград', 'кропивниц'
        ]
        
        for region in ua_regions:
            if region in msg_lower:
                # Normalize region name
                region_normalized = region.title() + 'ська область'
                if region_normalized not in result['regions']:
                    result['regions'].append(region_normalized)
        
        # === EXTRACT DIRECTION/TARGET ===
        direction_patterns = [
            r'курс(?:ом)?\s*(?:на)?\s*([А-ЯІЇЄа-яіїє\-]+)',
            r'напрям(?:ок|ку)?\s*(?:на)?\s*([А-ЯІЇЄа-яіїє\-]+)',
            r'рухається\s*(?:до|на)\s*([А-ЯІЇЄа-яіїє\-]+)',
            r'летить\s*(?:до|на)\s*([А-ЯІЇЄа-яіїє\-]+)',
        ]
        for pattern in direction_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                result['direction'] = match.group(1).strip()
                result['target'] = result['direction']
                break
        
        # === GET COORDINATES ===
        if message.get('lat') and message.get('lng'):
            result['coordinates'] = {
                'lat': message['lat'],
                'lng': message['lng']
            }
        
        return result
    
    def find_existing_threat(self, parsed: dict) -> str:
        """
        Шукає існуючу загрозу яка може бути тією ж самою.
        
        Критерії співпадіння:
        - Той самий тип загрози
        - Той самий регіон або напрямок
        - Створено недавно (в межах 2 годин для шахедів, 30 хв для балістики)
        """
        threat_type = parsed.get('threat_type')
        regions = parsed.get('regions', [])
        direction = parsed.get('direction')
        
        # Time window for matching
        max_age_minutes = 120 if threat_type == 'shahed' else 30
        now = datetime.now()
        
        with self.lock:
            for threat_id, threat in self.threats.items():
                # Skip if different type
                if threat['threat_type'] != threat_type:
                    continue
                
                # Skip if too old
                age = (now - threat['created_at']).total_seconds() / 60
                if age > max_age_minutes:
                    continue
                
                # Check region match
                if regions and threat.get('regions'):
                    if any(r in threat['regions'] for r in regions):
                        return threat_id
                
                # Check direction match
                if direction and threat.get('direction'):
                    if direction.lower() in threat['direction'].lower() or threat['direction'].lower() in direction.lower():
                        return threat_id
        
        return None
    
    def create_or_update_threat(self, message: dict) -> dict:
        """
        Створює нову загрозу або оновлює існуючу.
        
        Повертає інформацію про загрозу та дію (created/updated).
        """
        parsed = self.parse_threat_from_message(message)
        
        # Try to find existing threat
        existing_id = self.find_existing_threat(parsed)
        
        if existing_id:
            # UPDATE existing threat
            return self._update_threat(existing_id, parsed, message)
        else:
            # CREATE new threat
            return self._create_threat(parsed, message)
    
    def _create_threat(self, parsed: dict, message: dict) -> dict:
        """Створює нову загрозу"""
        threat_id = self.generate_threat_id(
            message.get('text', ''),
            parsed['threat_type'],
            parsed['regions'][0] if parsed['regions'] else 'unknown'
        )
        
        threat = {
            'id': threat_id,
            'threat_type': parsed['threat_type'],
            'quantity': parsed['quantity'],
            'quantity_destroyed': parsed['quantity_destroyed'],
            'quantity_remaining': parsed['quantity'] - parsed['quantity_destroyed'],
            'regions': parsed['regions'],
            'current_region': parsed['regions'][0] if parsed['regions'] else None,
            'direction': parsed['direction'],
            'target': parsed['target'],
            'status': parsed['status'],
            'coordinates': parsed['coordinates'],
            'created_at': datetime.now(),
            'updated_at': datetime.now(),
            'message_ids': [message.get('id')],
            'history': [{
                'time': datetime.now().isoformat(),
                'event': 'created',
                'message_id': message.get('id'),
                'status': parsed['status'],
                'coordinates': parsed['coordinates']
            }]
        }
        
        with self.lock:
            self.threats[threat_id] = threat
            
            # Update region mapping
            for region in parsed['regions']:
                if region not in self.region_to_threats:
                    self.region_to_threats[region] = set()
                self.region_to_threats[region].add(threat_id)
            
            # Link message to threat
            self.message_to_threat[message.get('id')] = threat_id
        
        print(f"[THREAT TRACKER] Created threat {threat_id}: {parsed['threat_type']} x{parsed['quantity']} -> {parsed['direction']}")
        
        return {
            'action': 'created',
            'threat_id': threat_id,
            'threat': threat
        }
    
    def _update_threat(self, threat_id: str, parsed: dict, message: dict) -> dict:
        """Оновлює існуючу загрозу"""
        with self.lock:
            if threat_id not in self.threats:
                return self._create_threat(parsed, message)
            
            threat = self.threats[threat_id]
            changes = []
            
            # Update quantity if increased
            if parsed['quantity'] > threat['quantity']:
                changes.append(f"quantity: {threat['quantity']} -> {parsed['quantity']}")
                threat['quantity'] = parsed['quantity']
            
            # Update destroyed count
            if parsed['quantity_destroyed'] > threat['quantity_destroyed']:
                changes.append(f"destroyed: {threat['quantity_destroyed']} -> {parsed['quantity_destroyed']}")
                threat['quantity_destroyed'] = parsed['quantity_destroyed']
                threat['quantity_remaining'] = threat['quantity'] - threat['quantity_destroyed']
            
            # Update coordinates if provided (move marker)
            if parsed['coordinates']:
                old_coords = threat['coordinates']
                threat['coordinates'] = parsed['coordinates']
                if old_coords != parsed['coordinates']:
                    changes.append(f"moved to {parsed['coordinates']}")
            
            # Update regions (add new ones)
            for region in parsed['regions']:
                if region not in threat['regions']:
                    threat['regions'].append(region)
                    changes.append(f"entered {region}")
                    
                    # Update region mapping
                    if region not in self.region_to_threats:
                        self.region_to_threats[region] = set()
                    self.region_to_threats[region].add(threat_id)
            
            # Update current region
            if parsed['regions']:
                threat['current_region'] = parsed['regions'][-1]  # Latest region
            
            # Update direction
            if parsed['direction'] and parsed['direction'] != threat['direction']:
                changes.append(f"direction: {threat['direction']} -> {parsed['direction']}")
                threat['direction'] = parsed['direction']
                threat['target'] = parsed['target']
            
            # Update status
            if parsed['status'] != threat['status']:
                changes.append(f"status: {threat['status']} -> {parsed['status']}")
                threat['status'] = parsed['status']
            
            # Update timestamp
            threat['updated_at'] = datetime.now()
            
            # Link message
            if message.get('id') not in threat['message_ids']:
                threat['message_ids'].append(message.get('id'))
            self.message_to_threat[message.get('id')] = threat_id
            
            # Add to history
            threat['history'].append({
                'time': datetime.now().isoformat(),
                'event': 'updated',
                'message_id': message.get('id'),
                'changes': changes,
                'status': parsed['status'],
                'coordinates': parsed['coordinates']
            })
            
            if changes:
                print(f"[THREAT TRACKER] Updated threat {threat_id}: {', '.join(changes)}")
        
        return {
            'action': 'updated',
            'threat_id': threat_id,
            'threat': threat,
            'changes': changes
        }
    
    def update_from_alarms(self, active_alarms: dict) -> list:
        """
        Оновлює стан загроз на основі API тривог.
        
        Коли тривога в регіоні закінчується - всі загрози в цьому регіоні 
        переходять в статус 'passed' або 'cleared'.
        
        Повертає список threat_id які були змінені.
        """
        changed_threats = []
        
        # Get list of regions with active alarms
        active_regions = set()
        
        # Parse states
        for state in active_alarms.get('states', []):
            region_name = state.get('regionName', '')
            active_regions.add(region_name.lower())
        
        # Parse districts
        for district in active_alarms.get('districts', []):
            region_name = district.get('regionName', '')
            oblast = district.get('oblast', '')
            active_regions.add(region_name.lower())
            if oblast:
                active_regions.add(oblast.lower())
        
        with self.lock:
            # Check each region with threats
            for region, threat_ids in list(self.region_to_threats.items()):
                region_lower = region.lower()
                
                # Check if alarm is still active in this region
                alarm_active = any(
                    region_lower in ar or ar in region_lower 
                    for ar in active_regions
                )
                
                if not alarm_active:
                    # Alarm ended in this region - mark all threats as passed/cleared
                    for threat_id in list(threat_ids):
                        if threat_id in self.threats:
                            threat = self.threats[threat_id]
                            
                            # Only update if threat is still active
                            if threat['status'] in ['active', 'partially_destroyed']:
                                old_status = threat['status']
                                
                                # Determine new status
                                if threat['current_region'] == region:
                                    # This was the current region - threat passed through or was cleared
                                    if threat['quantity_destroyed'] >= threat['quantity']:
                                        threat['status'] = 'destroyed'
                                    else:
                                        threat['status'] = 'cleared_by_alarm'
                                    
                                    threat['history'].append({
                                        'time': datetime.now().isoformat(),
                                        'event': 'alarm_ended',
                                        'region': region,
                                        'old_status': old_status,
                                        'new_status': threat['status']
                                    })
                                    
                                    changed_threats.append(threat_id)
                                    print(f"[THREAT TRACKER] Alarm ended in {region}, threat {threat_id} status: {old_status} -> {threat['status']}")
        
        return changed_threats
    
    def get_threat_for_message(self, message_id: str) -> dict:
        """Отримує загрозу пов'язану з повідомленням"""
        with self.lock:
            threat_id = self.message_to_threat.get(message_id)
            if threat_id and threat_id in self.threats:
                return self.threats[threat_id].copy()
        return None
    
    def get_all_active_threats(self) -> list:
        """Отримує всі активні загрози"""
        with self.lock:
            return [
                t.copy() for t in self.threats.values()
                if t['status'] in ['active', 'partially_destroyed']
            ]
    
    def get_threats_in_region(self, region: str) -> list:
        """Отримує всі загрози в регіоні"""
        region_lower = region.lower()
        with self.lock:
            result = []
            for threat_id, threat in self.threats.items():
                if any(region_lower in r.lower() for r in threat.get('regions', [])):
                    result.append(threat.copy())
            return result
    
    def cleanup_old_threats(self, max_age_hours: int = 6):
        """Видаляє старі неактивні загрози"""
        now = datetime.now()
        removed = 0
        
        with self.lock:
            for threat_id in list(self.threats.keys()):
                threat = self.threats[threat_id]
                age_hours = (now - threat['created_at']).total_seconds() / 3600
                
                # Remove if too old or completed
                should_remove = False
                if age_hours > max_age_hours:
                    should_remove = True
                elif threat['status'] in ['destroyed', 'cleared_by_alarm', 'passed']:
                    # Keep completed threats for 30 minutes
                    if age_hours > 0.5:
                        should_remove = True
                
                if should_remove:
                    del self.threats[threat_id]
                    removed += 1
                    
                    # Clean up region mapping
                    for region, ids in self.region_to_threats.items():
                        ids.discard(threat_id)
        
        if removed > 0:
            print(f"[THREAT TRACKER] Cleaned up {removed} old threats")
        
        return removed
    
    def get_marker_for_threat(self, threat_id: str) -> dict:
        """
        Генерує дані маркера для відображення на карті.
        
        Включає:
        - Координати (останні відомі)
        - Іконку на основі типу та статусу
        - Підпис з кількістю та статусом
        - Колір на основі статусу
        """
        with self.lock:
            if threat_id not in self.threats:
                return None
            
            threat = self.threats[threat_id]
        
        # Generate marker data
        marker = {
            'threat_id': threat_id,
            'lat': threat['coordinates']['lat'] if threat['coordinates'] else None,
            'lng': threat['coordinates']['lng'] if threat['coordinates'] else None,
            'threat_type': threat['threat_type'],
            'status': threat['status'],
            'quantity': threat['quantity'],
            'quantity_destroyed': threat['quantity_destroyed'],
            'quantity_remaining': threat['quantity_remaining'],
            'direction': threat['direction'],
            'target': threat['target'],
            'current_region': threat['current_region'],
            'created_at': threat['created_at'].isoformat(),
            'updated_at': threat['updated_at'].isoformat(),
        }
        
        # Generate label
        if threat['quantity'] > 1:
            if threat['quantity_destroyed'] > 0:
                label = f"{threat['threat_type'].upper()} x{threat['quantity_remaining']}/{threat['quantity']} (збито: {threat['quantity_destroyed']})"
            else:
                label = f"{threat['threat_type'].upper()} x{threat['quantity']}"
        else:
            label = threat['threat_type'].upper()
        
        if threat['direction']:
            label += f" → {threat['direction']}"
        
        marker['label'] = label
        
        # Determine icon and color based on status
        status_icons = {
            'active': {'icon': 'icon_drone.svg', 'color': '#ff4444'},
            'partially_destroyed': {'icon': 'icon_drone.svg', 'color': '#ff8800'},
            'destroyed': {'icon': 'icon_explosion.svg', 'color': '#00ff00'},
            'passed': {'icon': 'icon_check.svg', 'color': '#888888'},
            'cleared_by_alarm': {'icon': 'icon_check.svg', 'color': '#44ff44'},
        }
        
        status_info = status_icons.get(threat['status'], status_icons['active'])
        marker['marker_icon'] = status_info['icon']
        marker['marker_color'] = status_info['color']
        
        return marker


# Global threat tracker instance
THREAT_TRACKER = ThreatTracker()

def check_alarms_and_update_threats():
    """
    Перевіряє стан тривог і оновлює загрози.
    Викликається періодично (кожні 30 сек).
    """
    try:
        # Get current alarms from cache
        alarm_data = _alarm_all_cache.get('data')
        if alarm_data:
            # Convert list format to dict format expected by update_from_alarms
            # _alarm_all_cache['data'] is a list of regions with active alarms
            if isinstance(alarm_data, list):
                # Convert to dict with states/districts
                states = []
                districts = []
                for region in alarm_data:
                    region_type = region.get('regionType', '')
                    if region_type == 'State':
                        states.append(region)
                    else:
                        districts.append(region)
                alarm_dict = {'states': states, 'districts': districts}
            else:
                alarm_dict = alarm_data
            
            changed = THREAT_TRACKER.update_from_alarms(alarm_dict)
            if changed:
                print(f"[THREAT TRACKER] Updated {len(changed)} threats based on alarm changes")
    except Exception as e:
        print(f"[THREAT TRACKER] Error checking alarms: {e}")

def process_message_for_threats(message: dict) -> dict:
    """
    Обробляє повідомлення для системи відстеження загроз.
    
    Повертає інформацію про створену/оновлену загрозу.
    """
    # Only process messages with threat indicators
    text = (message.get('text') or '').lower()
    
    threat_keywords = ['шахед', 'бпла', 'дрон', 'ракет', 'балістик', 'каб', 'крилат', 'кінжал']
    if not any(kw in text for kw in threat_keywords):
        return None
    
    try:
        result = THREAT_TRACKER.create_or_update_threat(message)
        return result
    except Exception as e:
        print(f"[THREAT TRACKER] Error processing message: {e}")
        return None

def get_smart_marker_visibility(message: dict, active_alarms: dict = None) -> dict:
    """
    Визначає чи повинен маркер бути видимим.
    
    Враховує:
    1. AI TTL для типу загрози
    2. Стан тривоги в регіоні
    3. Статус загрози (якщо відстежується)
    
    Повертає:
    {
        'visible': bool,
        'reason': str,
        'remaining_minutes': int,
        'threat_info': dict (якщо є)
    }
    """
    # First, check if there's a tracked threat
    msg_id = message.get('id')
    threat = THREAT_TRACKER.get_threat_for_message(msg_id) if msg_id else None
    
    if threat:
        # Use threat tracking info
        if threat['status'] in ['destroyed', 'cleared_by_alarm', 'passed']:
            # Threat is over - short visibility
            return {
                'visible': True,
                'reason': f"Загроза завершена: {threat['status']}",
                'remaining_minutes': 5,
                'auto_hide_at': (datetime.now() + timedelta(minutes=5)).isoformat(),
                'threat_info': threat
            }
        else:
            # Active threat - check TTL
            ttl_info = should_marker_be_visible(message)
            ttl_info['threat_info'] = threat
            return ttl_info
    
    # No tracked threat - use standard AI TTL
    return should_marker_be_visible(message)

# ==================== END SMART THREAT TRACKING SYSTEM ====================


# ==================== MULTI-CHANNEL INTELLIGENCE FUSION ====================
# Система злиття інформації з різних Telegram каналів
# Аналізує, комбінує, відстежує рух загроз
# AI FIRST APPROACH - кожне повідомлення проходить через AI

class ChannelIntelligenceFusion:
    """
    Інтелектуальна система злиття даних з різних каналів.
    AI-FIRST підхід - кожне повідомлення аналізується AI.
    
    Функції:
    1. AI аналіз кожного повідомлення (тип, кількість, координати, дія)
    2. Розпізнавання тієї ж загрози з різних джерел
    3. Комбінування інформації для точнішої картини
    4. Побудова траєкторій з послідовності повідомлень
    5. Визначення пріоритету джерел
    6. Автоматичне створення/оновлення/видалення/переміщення маркерів
    """
    
    # Пріоритет каналів (вищий = надійніший)
    CHANNEL_PRIORITY = {
        # === Офіційні/головні ===
        'kpszsu': 100,              # Офіційний канал ПС ЗСУ - найвища довіра
        'UkraineAlarmSignal': 95,   # Офіційні сигнали тривог
        'povitryanatrivogaaa': 90,  # Повітряна тривога
        
        # === Загальнонаціональні моніторинги ===
        'emonitor_ua': 85,          # E-Monitor Ukraine
        'monikppy': 85,             # Моніторинг ППО
        'war_monitor': 82,          # Військовий моніторинг
        'napramok': 80,             # Напрямок руху загроз
        'raketa_trevoga': 78,       # Ракетна тривога
        'sectorv666': 75,           # Sector V
        'ukrainsiypposhnik': 72,    # Українські повітряні сили
        
        # === Регіональні (південь) ===
        'korabely_media': 88,       # Південь: Херсон, Миколаїв, Одеса
        'vanek_nikolaev': 85,       # Миколаївська область
        'kherson_monitoring': 85,   # Херсонська область
        
        # === Регіональні (схід/центр) ===
        'gnilayachereha': 85,       # Запорізька область
        'timofii_kucher': 85,       # Дніпропетровська область
        'monitor1654': 85,          # Харківська область
        
        # === Наш канал ===
        'mapstransler': 60,         # Наш агрегований канал
    }
    
    # Часове вікно для злиття повідомлень (в секундах)
    FUSION_WINDOW_SECONDS = 600  # 10 хвилин
    
    # Мінімальна схожість для злиття
    MIN_SIMILARITY_SCORE = 0.35  # Знижено для кращого злиття
    
    # Максимальна відстань для злиття (км)
    MAX_FUSION_DISTANCE_KM = 150
    
    def __init__(self):
        self.pending_messages = []  # Повідомлення що очікують обробки
        self.fused_events = {}      # event_id -> FusedThreatEvent
        self.message_to_event = {}  # message_id -> event_id
        self.lock = threading.Lock()
        self.trajectory_builder = TrajectoryBuilder()
    
    def get_channel_priority(self, channel: str) -> int:
        """Отримує пріоритет каналу"""
        channel_clean = channel.lower().replace('@', '').strip()
        return self.CHANNEL_PRIORITY.get(channel_clean, 50)
    
    # Регіональна прив'язка каналів для точнішого геокодування
    CHANNEL_REGIONS = {
        'gnilayachereha': ['Запоріжжя'],
        'vanek_nikolaev': ['Миколаїв'],
        'timofii_kucher': ['Дніпро'],
        'korabely_media': ['Херсон', 'Миколаїв', 'Одеса'],
        'kherson_monitoring': ['Херсон'],
        'monitor1654': ['Харків'],
    }
    
    def get_channel_regions(self, channel: str) -> list:
        """Отримує регіони пов'язані з каналом"""
        channel_clean = channel.lower().replace('@', '').strip()
        return self.CHANNEL_REGIONS.get(channel_clean, [])
    
    def _find_city_coordinates_from_text(self, text: str) -> tuple:
        """
        Знаходить конкретне місто в тексті та повертає його координати.
        Також обробляє формати типу "на ПнСх Чернігівщини".
        """
        text_lower = text.lower()
        
        # === SPECIAL: Формат "на [напрямок] [області]" ===
        # Приклад: "на північний схід Чернігівщини"
        region_direction_pattern = r'на\s+(північн[а-яіїє\-]*\s*схід|північн[а-яіїє\-]*\s*захід|південн[а-яіїє\-]*\s*схід|південн[а-яіїє\-]*\s*захід|північ[а-яіїє]*|південь|півдня|півдні|схід|захід|сході|заході)\s+([А-ЯІЇЄа-яіїє]+(?:щини|івщини|ської|ської області)?)'
        match = re.search(region_direction_pattern, text, re.IGNORECASE)
        if match:
            direction_text = match.group(1).lower()
            region_text = match.group(2).lower()
            
            # Визначаємо регіон
            region_to_center = {
                'чернігівщини': (51.50, 31.29),  # Чернігів
                'чернігівської': (51.50, 31.29),
                'сумщини': (50.91, 34.80),  # Суми
                'сумської': (50.91, 34.80),
                'харківщини': (49.99, 36.23),  # Харків
                'харківської': (49.99, 36.23),
                'київщини': (50.45, 30.52),  # Київ
                'київської': (50.45, 30.52),
                'полтавщини': (49.59, 34.55),
                'полтавської': (49.59, 34.55),
                'дніпропетровщини': (48.46, 35.04),
                'дніпропетровської': (48.46, 35.04),
                'запоріжжя': (47.84, 35.14),
                'запорізької': (47.84, 35.14),
                'донеччини': (48.00, 37.80),
                'донецької': (48.00, 37.80),
                'луганщини': (48.57, 39.31),
                'луганської': (48.57, 39.31),
                'херсонщини': (46.64, 32.62),
                'херсонської': (46.64, 32.62),
                'миколаївщини': (46.97, 32.00),
                'миколаївської': (46.97, 32.00),
                'одещини': (46.48, 30.73),
                'одеської': (46.48, 30.73),
            }
            
            # Визначаємо напрямок (зсув від центру області)
            direction_offsets = {
                'північ': (0.5, 0), 'північн': (0.5, 0),
                'південь': (-0.5, 0), 'півдня': (-0.5, 0), 'півдні': (-0.5, 0),
                'схід': (0, 0.5), 'сході': (0, 0.5),
                'захід': (0, -0.5), 'заході': (0, -0.5),
                'північний схід': (0.4, 0.4), 'північно-схід': (0.4, 0.4),
                'північний захід': (0.4, -0.4), 'північно-захід': (0.4, -0.4),
                'південний схід': (-0.4, 0.4), 'південно-схід': (-0.4, 0.4),
                'південний захід': (-0.4, -0.4), 'південно-захід': (-0.4, -0.4),
            }
            
            center = None
            for key, coords in region_to_center.items():
                if key in region_text:
                    center = coords
                    break
            
            offset = (0, 0)
            for key, off in direction_offsets.items():
                if key in direction_text:
                    offset = off
                    break
            
            if center:
                final_coords = (center[0] + offset[0], center[1] + offset[1])
                logger.info(f"Parsed regional direction: '{direction_text}' + '{region_text}' -> {final_coords}")
                return final_coords
        
        # === Стандартний пошук міст ===
        city_patterns = [
            # Формат "Nх БПЛА Місто" - місто одразу після типу загрози
            r'\d+\s*х?\s*(?:бпла|дрон|шахед)\s+([А-ЯІЇЄа-яіїє\-]+)',
            # Формат "Місто (Область)"
            r'([А-ЯІЇЄа-яіїє\-]+)\s*\([А-ЯІЇЄа-яіїє\s]+обл',
            # Формат "курсом на Місто", "напрямок Місто"
            r'(?:курс(?:ом)?|напрям(?:ок)?)\s+(?:на\s+)?([А-ЯІЇЄа-яіїє\-]+)',
            # Формат "над Містом", "в районі Міста"
            r'(?:над|в районі|біля)\s+([А-ЯІЇЄа-яіїє\-]+)',
        ]
        
        found_cities = []
        for pattern in city_patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            for match in matches:
                city = match.strip().lower()
                # Фільтруємо службові слова
                if city in ['на', 'до', 'від', 'з', 'через', 'над', 'по', 'обл', 'області', 'район', 'уважно', 'західний', 'східний', 'північний', 'південний']:
                    continue
                if len(city) < 3:
                    continue
                found_cities.append(city)
        
        # Нормалізуємо знайдені міста (знімаємо закінчення)
        for city in found_cities:
            city_norm = city
            
            # Accusative -> Nominative
            if city_norm.endswith('у') and len(city_norm) > 3:
                city_norm = city_norm[:-1] + 'а'
            elif city_norm.endswith('ку') and len(city_norm) > 4:
                city_norm = city_norm[:-2] + 'ка'
            
            # Шукаємо в базах координат
            if city_norm in CITY_COORDS:
                coords = CITY_COORDS[city_norm]
                logger.info(f"Found city '{city}' -> '{city_norm}' in CITY_COORDS: {coords}")
                return coords
            
            # Пробуємо оригінальну форму
            if city in CITY_COORDS:
                coords = CITY_COORDS[city]
                logger.info(f"Found city '{city}' in CITY_COORDS: {coords}")
                return coords
        
        return None
    
    def extract_message_signature(self, message: dict) -> dict:
        """
        AI-FIRST: Витягує "підпис" повідомлення через AI.
        Fallback на regex якщо AI недоступний.
        
        AI визначає:
        - Тип загрози (shahed/drone/ballistic/cruise/kab)
        - Кількість
        - Регіони
        - Напрямок
        - Дію (create/move/update/remove)
        - Координати (якщо можна визначити)
        """
        text = (message.get('text') or '').lower()
        original_text = message.get('text', '')
        channel = message.get('channel') or message.get('source', '')
        
        signature = {
            'threat_type': None,
            'regions': set(),
            'direction': None,
            'course_direction': None,  # текст напрямку (західний, східний)
            'course_bearing': None,  # NEW: кут в градусах для обертання іконки
            'quantity': 1,
            'keywords': set(),
            'source_coords': None,
            'target_coords': None,
            'timestamp': None,
            'channel': channel,
            'action': 'create',  # create/move/update/remove
            'ai_analyzed': False,
            'confidence': 0.0,
        }
        
        # === PARSE SOURCE REGION ("із Сумщини", "з Херсонщини") ===
        source_region_pattern = r'(?:із|з|от)\s+([А-ЯІЇЄа-яіїє]+(?:щини|івщини|ської))'
        source_match = re.search(source_region_pattern, original_text, re.IGNORECASE)
        if source_match:
            source_region = source_match.group(1).lower()
            source_coords_map = {
                'сумщини': (50.91, 34.80),
                'чернігівщини': (51.50, 31.29),
                'харківщини': (49.99, 36.23),
                'київщини': (50.45, 30.52),
                'полтавщини': (49.59, 34.55),
                'дніпропетровщини': (48.46, 35.04),
                'запорізької': (47.84, 35.14),
                'херсонщини': (46.64, 32.62),
                'миколаївщини': (46.97, 32.00),
                'одещини': (46.48, 30.73),
                'донеччини': (48.00, 37.80),
                'луганщини': (48.57, 39.31),
            }
            for key, coords in source_coords_map.items():
                if key in source_region:
                    signature['source_coords'] = coords
                    logger.info(f"Parsed source region: '{source_region}' -> {coords}")
                    break
        
        # Parse timestamp
        try:
            signature['timestamp'] = datetime.strptime(
                message.get('date', ''), '%Y-%m-%d %H:%M:%S'
            )
        except:
            signature['timestamp'] = datetime.now()
        
        # === AI-FIRST ANALYSIS ===
        if GROQ_ENABLED:
            try:
                ai_result = self._ai_full_analysis(original_text, channel)
                if ai_result and ai_result.get('is_threat'):
                    signature['ai_analyzed'] = True
                    signature['confidence'] = ai_result.get('confidence', 0.8)
                    
                    # Apply AI results
                    if ai_result.get('threat_type'):
                        signature['threat_type'] = ai_result['threat_type']
                    if ai_result.get('regions'):
                        for r in ai_result['regions']:
                            signature['regions'].add(r)
                    if ai_result.get('quantity'):
                        signature['quantity'] = ai_result['quantity']
                    if ai_result.get('direction'):
                        signature['direction'] = ai_result['direction']
                    if ai_result.get('action'):
                        signature['action'] = ai_result['action']
                    
                    # NEW: Source coordinates від AI
                    if ai_result.get('source_coordinates'):
                        src = ai_result['source_coordinates']
                        if src.get('lat') and src.get('lng'):
                            signature['source_coords'] = (src['lat'], src['lng'])
                            logger.info(f"AI source_coords: {signature['source_coords']}")
                    
                    # NEW: Course bearing від AI (для обертання іконки)
                    if ai_result.get('course_bearing') is not None:
                        signature['course_bearing'] = ai_result['course_bearing']
                        logger.info(f"AI course_bearing: {signature['course_bearing']}°")
                    
                    # Координати від AI - довіряємо AI повністю
                    if ai_result.get('coordinates'):
                        coords = ai_result['coordinates']
                        if coords.get('lat') and coords.get('lng'):
                            signature['target_coords'] = (coords['lat'], coords['lng'])
                            logger.info(f"AI target_coords: {signature['target_coords']}")
                    
                    # Fallback на координати з повідомлення
                    if not signature['target_coords'] and message.get('lat') and message.get('lng'):
                        signature['target_coords'] = (message['lat'], message['lng'])
                    
                    return signature
                    
            except Exception as e:
                logger.error(f"AI analysis failed: {e}")
        
        # === FALLBACK: REGEX PARSING ===
        # (використовується якщо AI недоступний або не визначив загрозу)
        
        # === THREAT TYPE ===
        # Порядок важливий! Спочатку специфічні, потім загальні
        if any(w in text for w in ['шахед', 'герань', 'shahed', 'geran', 'шахедн']):
            signature['threat_type'] = 'shahed'
            signature['keywords'].add('shahed')
        elif any(w in text for w in ['балістик', 'балістич', 'іскандер', 'искандер']):
            signature['threat_type'] = 'ballistic'
            signature['keywords'].add('ballistic')
        elif any(w in text for w in ['крилат', 'калібр', 'калибр', 'х-101', 'х-55', 'х101', 'х55']):
            signature['threat_type'] = 'cruise'
            signature['keywords'].add('cruise')
        elif any(w in text for w in ['каб', 'авіабомб', 'авиабомб', 'кабів', 'кабов']):
            signature['threat_type'] = 'kab'
            signature['keywords'].add('kab')
        elif any(w in text for w in ['кінжал', 'кинжал']):
            signature['threat_type'] = 'kinzhal'
            signature['keywords'].add('kinzhal')
        elif any(w in text for w in ['бпла', 'дрон', 'безпілот', 'беспилот']):
            signature['threat_type'] = 'drone'
            signature['keywords'].add('drone')
        elif any(w in text for w in ['ракет', 'пуск', 'missile']):
            # Загальна категорія ракет якщо не визначено точніше
            signature['threat_type'] = 'cruise'
            signature['keywords'].add('cruise')
        
        # Контекстне визначення для коротких повідомлень (стиль Кучера)
        # Якщо є ознаки загрози але тип не визначено - припускаємо drone/shahed
        if not signature['threat_type']:
            # Формат "Nх" (1х, 2х, 5х) зазвичай означає БПЛА
            if re.search(r'\d+\s*х', text):
                signature['threat_type'] = 'drone'
                signature['keywords'].add('implicit_drone')
            # Загальні індикатори загрози
            elif any(ind in text for ind in ['загроза', 'уважно', 'воздух', '🚨', 
                                              'укриття', 'негайно', 'низько', 'йдуть', 
                                              'заходять', 'над містом', 'удар', 
                                              'атакув', 'прильот', 'кружля']):
                signature['threat_type'] = 'drone'
                signature['keywords'].add('implicit_threat')
        
        # === REGIONS ===
        ua_regions = {
            'київ': 'Київ', 'киев': 'Київ',
            'харків': 'Харків', 'харьков': 'Харків',
            'одес': 'Одеса',
            'дніпро': 'Дніпро', 'днепр': 'Дніпро', 'дніпр': 'Дніпро',
            'запоріж': 'Запоріжжя', 'запорож': 'Запоріжжя',
            'львів': 'Львів', 'львов': 'Львів',
            'полтав': 'Полтава',
            'вінниц': 'Вінниця', 'винниц': 'Вінниця',
            'черкас': 'Черкаси', 'черкащ': 'Черкаси',
            'чернігів': 'Чернігів', 'чернигов': 'Чернігів',
            'суми': 'Суми', 'сумщ': 'Суми',
            'миколаїв': 'Миколаїв', 'николаев': 'Миколаїв',
            'херсон': 'Херсон',
            'житомир': 'Житомир',
            'хмельниц': 'Хмельницький',
            'рівн': 'Рівне', 'ровн': 'Рівне',
            'волин': 'Волинь',
            'тернопіл': 'Тернопіль', 'тернопол': 'Тернопіль',
            'івано-франків': 'Івано-Франківськ', 'франков': 'Івано-Франківськ',
            'закарпат': 'Закарпаття',
            'чернівц': 'Чернівці', 'черновц': 'Чернівці',
            'кіровоград': 'Кропивницький', 'кировоград': 'Кропивницький', 'кропивниц': 'Кропивницький',
            'донецьк': 'Донецьк', 'донецк': 'Донецьк',
            'луганськ': 'Луганськ', 'луганск': 'Луганськ',
            'крив': 'Дніпро',  # Кривий Ріг -> Дніпро обл
        }
        for key, name in ua_regions.items():
            if key in text:
                signature['regions'].add(name)
        
        # Автоматичне визначення регіону по каналу (якщо не знайдено в тексті)
        if not signature['regions']:
            channel_regions = self.get_channel_regions(channel)
            for region in channel_regions:
                signature['regions'].add(region)
        
        # === DIRECTION ===
        # Спочатку шукаємо напрямок курсу (західний, східний тощо)
        course_direction_pattern = r'курс\s+(західн[а-яіїє]*|східн[а-яіїє]*|північн[а-яіїє]*|південн[а-яіїє]*|північно-західн[а-яіїє]*|північно-східн[а-яіїє]*|південно-західн[а-яіїє]*|південно-східн[а-яіїє]*)'
        course_match = re.search(course_direction_pattern, message.get('text', ''), re.IGNORECASE)
        if course_match:
            signature['direction'] = course_match.group(1).strip()
            signature['course_direction'] = course_match.group(1).strip()  # Зберігаємо для обертання іконки
        else:
            # Інші паттерни для напрямку на місто
            direction_patterns = [
                # Курс на Київ, курсом на Київ
                r'курс(?:ом)?\s*(?:на|-)?\s*([А-ЯІЇЄа-яіїє]{3,})',
                # Напрямок Київ, напрямок на Київ
                r'напрям(?:ок|ку)?\s*(?:на|-)?\s*([А-ЯІЇЄа-яіїє]{3,})',
                # рухається на/до Київ
                r'рухається\s*(?:на|до)\s*([А-ЯІЇЄа-яіїє]{3,})',
                # в напрямку Київ
                r'в\s*напрямку\s*([А-ЯІЇЄа-яіїє]{3,})',
                # → Київ, -> Київ
                r'[→\->]\s*([А-ЯІЇЄа-яіїє]{3,})',
            ]
            for pattern in direction_patterns:
                match = re.search(pattern, message.get('text', ''), re.IGNORECASE)
                if match:
                    direction = match.group(1).strip()
                    # Фільтруємо службові слова
                    if direction.lower() not in ['на', 'до', 'від', 'з', 'через', 'над', 'по', 'ку', 'ом', 'уважно', 'західний', 'східний', 'північний', 'південний']:
                        signature['direction'] = direction
                        break
        
        # === QUANTITY ===
        qty_patterns = [
            # Формат Кучера: "до 5х", "2х", "1х над містом"
            r'(?:до\s*)?(\d+)\s*х(?:\s|$|,|\.|!)',
            # 12 шахедів, 5 БПЛА, 10 дронів
            r'(\d+)\s*(?:шахед|бпла|дрон|ракет|од\.|одиниц)',
            # група з 5, група 10
            r'група\s*(?:з\s*)?(\d+)',
            # до 10, близько 10 (без х)
            r'(?:до|близько|біля|около|лишилось)\s*(\d+)(?!\s*х)',
            # кількість: 10, кількість 5
            r'кількість[:\s]*(\d+)',
            # (6 од.), [5 од]
            r'[\(\[]\s*(\d+)\s*(?:од|шт)',
            # Дніпро 2 БПЛА (число перед типом)
            r'(\d+)\s+(?:бпла|дрон)',
        ]
        for pattern in qty_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                qty = int(match.group(1))
                if 1 <= qty <= 100:  # Фільтр нереальних значень
                    signature['quantity'] = qty
                    break
        
        # === COORDINATES ===
        if message.get('lat') and message.get('lng'):
            signature['target_coords'] = (message['lat'], message['lng'])
        
        # === ADDITIONAL KEYWORDS ===
        status_keywords = {
            'збито': 'destroyed', 'збит': 'destroyed',
            'знищено': 'destroyed', 'знищен': 'destroyed',
            'пролетів': 'passed', 'минув': 'passed', 'пройшл': 'passed',
            'змінив курс': 'changed_course', 'повернув': 'changed_course',
            'розділ': 'split',  # група розділилась
        }
        for kw, status in status_keywords.items():
            if kw in text:
                signature['keywords'].add(status)
        
        return signature
    
    def _ai_full_analysis(self, text: str, channel: str = '') -> dict:
        """
        ПОВНИЙ AI-аналіз повідомлення через Groq LLM.
        AI сам визначає: тип, кількість, регіон, координати, дію.
        
        Це ГОЛОВНИЙ метод аналізу - викликається для кожного повідомлення.
        """
        if not GROQ_ENABLED or not groq_client:
            return None
        
        # Check cache first (коротший TTL для актуальності)
        cache_key = _get_groq_cache_key(f"full_threat:{text[:100]}")
        if cache_key in _groq_cache:
            cached, ts = _groq_cache[cache_key]
            if time.time() - ts < 300:  # 5 хвилин кеш
                return cached
        
        try:
            _groq_rate_limit()
            
            # Get channel context
            channel_context = ""
            channel_regions = self.get_channel_regions(channel)
            if channel_regions:
                channel_context = f"Канал '{channel}' моніторить регіони: {', '.join(channel_regions)}. "
            
            # Координати основних міст та областей для AI
            city_coords = """
КООРДИНАТИ МІСТ (lat, lng):
Київ: 50.45, 30.52 | Харків: 49.99, 36.23 | Одеса: 46.48, 30.73 | Дніпро: 48.46, 35.04
Запоріжжя: 47.84, 35.14 | Львів: 49.84, 24.03 | Миколаїв: 46.97, 32.00 | Херсон: 46.64, 32.62
Полтава: 49.59, 34.55 | Черкаси: 49.44, 32.06 | Вінниця: 49.23, 28.48 | Житомир: 50.25, 28.66
Суми: 50.91, 34.80 | Чернігів: 51.50, 31.29 | Хмельницький: 49.42, 26.98 | Кропивницький: 48.51, 32.26
Шостка: 51.87, 33.48 | Конотоп: 51.24, 33.20 | Ромни: 50.75, 33.47 | Охтирка: 50.31, 34.90
Глухів: 51.68, 33.92 | Новгород-Сіверський: 52.00, 33.27 | Прилуки: 50.59, 32.39 | Ніжин: 51.05, 31.89

НАПРЯМКИ (зсув від центру області):
- Північ: lat +0.5 | Південь: lat -0.5 | Схід: lng +0.5 | Захід: lng -0.5
- ПнСх: lat +0.4, lng +0.4 | ПнЗх: lat +0.4, lng -0.4
- ПдСх: lat -0.4, lng +0.4 | ПдЗх: lat -0.4, lng -0.4

КУРС (кут обертання іконки):
- північний: 0° | південний: 180° | східний: 90° | західний: -90°
- пн-сх: 45° | пн-зх: -45° | пд-сх: 135° | пд-зх: -135°
"""
            
            prompt = f"""Ти експерт з аналізу повідомлень про повітряну загрозу в Україні.
{channel_context}
{city_coords}

Повідомлення: "{text}"

ПРИКЛАДИ ПАРСИНГУ:
- "БпЛА із Сумщини на північний схід Чернігівщини, курс західний"
  → source: Суми (50.91, 34.80), coordinates: ПнСх Чернігівщини (51.90, 31.69), course_bearing: -90
- "2х БПЛА Шостка (Сумська обл.)" → coordinates: Шостка (51.87, 33.48), quantity: 2
- "Дрон курсом на Київ з Чернігова" → source: Чернігів, target: Київ

Проаналізуй повідомлення та визнач:

1. is_threat: true якщо активна загроза в повітрі, false якщо збито/минуло

2. threat_type: "shahed"|"drone"|"ballistic"|"cruise"|"kab"|"kinzhal"|null

3. quantity: кількість (1-50), "2х" = 2, "до 5х" = 5

4. regions: масив областей ["Чернігів", "Суми"]

5. source_coordinates: звідки летить {{"lat": N, "lng": N}} (із Сумщини = Суми)

6. coordinates: ДЕ ЗАРАЗ загроза {{"lat": N, "lng": N}}
   - "на ПнСх Чернігівщини" = Чернігів + зсув (lat+0.4, lng+0.4)
   - "Шостка" = координати Шостки
   - Якщо вказано місто - використай його координати!

7. course_bearing: кут курсу в градусах (для обертання іконки)
   - "курс західний" = -90, "курс північний" = 0, "курс східний" = 90
   - null якщо не вказано

8. direction: куди летить (назва міста/напрямок)

9. action: "create"|"move"|"update"|"remove"

10. confidence: 0.0-1.0

Відповідай ТІЛЬКИ JSON:
{{"is_threat":bool,"threat_type":"...","quantity":N,"regions":[...],"source_coordinates":{{"lat":N,"lng":N}},"coordinates":{{"lat":N,"lng":N}},"course_bearing":N,"direction":"...","action":"...","confidence":N}}"""

            response = groq_client.chat.completions.create(
                model=GROQ_MODEL,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.1,
                max_tokens=400,
            )
            
            result_text = response.choices[0].message.content.strip()
            
            # Parse JSON response
            import json
            # Clean up response
            if result_text.startswith('```'):
                result_text = result_text.split('```')[1]
                if result_text.startswith('json'):
                    result_text = result_text[4:]
            result_text = result_text.strip()
            
            result = json.loads(result_text)
            
            # Validate
            if not result.get('is_threat'):
                result = {'is_threat': False}
            else:
                # Normalize threat_type
                threat_map = {
                    'shahed': 'shahed', 'шахед': 'shahed', 'герань': 'shahed',
                    'drone': 'drone', 'бпла': 'drone', 'дрон': 'drone',
                    'ballistic': 'ballistic', 'балістика': 'ballistic',
                    'cruise': 'cruise', 'крилата': 'cruise',
                    'kab': 'kab', 'каб': 'kab',
                    'kinzhal': 'kinzhal', 'кинжал': 'kinzhal',
                }
                if result.get('threat_type'):
                    result['threat_type'] = threat_map.get(
                        str(result['threat_type']).lower(), 
                        result['threat_type']
                    )
                
                # Ensure quantity is int
                if result.get('quantity'):
                    try:
                        result['quantity'] = int(result['quantity'])
                    except:
                        result['quantity'] = 1
                
                # Validate action
                valid_actions = ['create', 'move', 'update', 'remove']
                if result.get('action') not in valid_actions:
                    result['action'] = 'create'
                
                # Log AI decision
                logger.info(f"AI Analysis: {result.get('threat_type')} x{result.get('quantity')} "
                           f"-> {result.get('regions')} action={result.get('action')} "
                           f"conf={result.get('confidence', 0):.0%}")
            
            # Cache result
            _groq_cache[cache_key] = (result, time.time())
            
            return result
            
        except Exception as e:
            if '429' in str(e):
                _groq_handle_429(str(e))
            logger.error(f"AI full analysis error: {e}")
            return None
    
    def _ai_analyze_message(self, text: str, channel: str = '') -> dict:
        """
        [DEPRECATED] Використовуй _ai_full_analysis замість цього.
        Залишено для сумісності.
        """
        return self._ai_full_analysis(text, channel)
    
    def calculate_similarity(self, sig1: dict, sig2: dict) -> float:
        """
        Розраховує схожість двох підписів повідомлень.
        
        Повертає score від 0.0 до 1.0
        """
        score = 0.0
        weights = {
            'threat_type': 0.30,
            'regions': 0.15,
            'direction': 0.15,
            'quantity': 0.10,
            'time': 0.15,
            'coordinates': 0.15,  # New: coordinate proximity
        }
        
        # Threat type match (most important)
        if sig1['threat_type'] and sig2['threat_type']:
            if sig1['threat_type'] == sig2['threat_type']:
                score += weights['threat_type']
            # Shahed and drone are similar
            elif {sig1['threat_type'], sig2['threat_type']} <= {'shahed', 'drone'}:
                score += weights['threat_type'] * 0.8
        
        # Region overlap
        if sig1['regions'] and sig2['regions']:
            overlap = sig1['regions'] & sig2['regions']
            union = sig1['regions'] | sig2['regions']
            if union:
                region_score = len(overlap) / len(union)
                score += weights['regions'] * region_score
            # Bonus for adjacent regions
            if overlap:
                score += 0.05  # Adjacent regions bonus
        elif sig1['regions'] or sig2['regions']:
            # One has regions, other doesn't - partial credit
            score += weights['regions'] * 0.3
        
        # Direction match
        if sig1['direction'] and sig2['direction']:
            # Fuzzy match for direction
            d1 = sig1['direction'].lower()
            d2 = sig2['direction'].lower()
            if d1 == d2:
                score += weights['direction']
            elif d1 in d2 or d2 in d1:
                score += weights['direction'] * 0.7
        elif sig1['direction'] or sig2['direction']:
            # Only one has direction - small credit
            score += weights['direction'] * 0.2
        
        # Quantity similarity
        q1, q2 = sig1['quantity'], sig2['quantity']
        if q1 and q2:
            qty_diff = abs(q1 - q2)
            max_qty = max(q1, q2)
            qty_score = 1.0 - (qty_diff / max_qty) if max_qty > 0 else 0
            score += weights['quantity'] * qty_score
        
        # Time proximity
        if sig1['timestamp'] and sig2['timestamp']:
            time_diff = abs((sig1['timestamp'] - sig2['timestamp']).total_seconds())
            # Score decreases as time difference increases
            time_score = max(0, 1.0 - (time_diff / self.FUSION_WINDOW_SECONDS))
            score += weights['time'] * time_score
        
        # Coordinate proximity (new)
        c1 = sig1.get('target_coords')
        c2 = sig2.get('target_coords')
        if c1 and c2:
            try:
                distance = haversine(c1, c2)
                if distance < self.MAX_FUSION_DISTANCE_KM:
                    coord_score = 1.0 - (distance / self.MAX_FUSION_DISTANCE_KM)
                    score += weights['coordinates'] * coord_score
                    # Bonus for very close positions
                    if distance < 50:
                        score += 0.1
            except:
                pass
        
        return score
    
    def find_matching_event(self, signature: dict) -> str:
        """
        Шукає існуючу подію що відповідає підпису.
        
        Повертає event_id або None.
        """
        best_match = None
        best_score = self.MIN_SIMILARITY_SCORE
        
        with self.lock:
            for event_id, event in self.fused_events.items():
                # Skip old events
                age = (datetime.now() - event['last_update']).total_seconds()
                if age > self.FUSION_WINDOW_SECONDS * 2:
                    continue
                
                # Compare with event's combined signature
                score = self.calculate_similarity(signature, event['signature'])
                
                if score > best_score:
                    best_score = score
                    best_match = event_id
        
        return best_match
    
    def create_event(self, message: dict, signature: dict) -> str:
        """
        Створює нову об'єднану подію загрози.
        """
        import hashlib
        
        # Generate event ID
        event_id = hashlib.md5(
            f"{signature['threat_type']}:{signature['timestamp']}:{signature['channel']}".encode()
        ).hexdigest()[:16]
        
        channel = signature['channel']
        priority = self.get_channel_priority(channel)
        
        # Initial trajectory with first position
        initial_trajectory = []
        if signature['target_coords']:
            initial_trajectory.append({
                'coords': signature['target_coords'],
                'timestamp': signature['timestamp'].isoformat() if signature['timestamp'] else datetime.now().isoformat(),
                'source': channel,
            })
        
        event = {
            'id': event_id,
            'created_at': datetime.now(),
            'last_update': datetime.now(),
            'signature': signature.copy(),  # Combined signature
            'messages': [{
                'id': message.get('id'),
                'channel': channel,
                'priority': priority,
                'text': message.get('text', ''),
                'timestamp': signature['timestamp'],
                'coordinates': signature['target_coords'],
            }],
            'threat_type': signature['threat_type'],
            'quantity': signature['quantity'],
            'quantity_destroyed': 0,
            'regions': list(signature['regions']),
            'direction': signature['direction'],
            'course_direction': signature.get('course_direction'),
            'course_bearing': signature.get('course_bearing'),  # NEW: кут від AI
            'source_coords': signature.get('source_coords'),
            'status': 'active',
            'best_coordinates': signature['target_coords'],
            'trajectory': initial_trajectory,  # Start with initial position
            'confidence': priority / 100.0,
        }
        
        with self.lock:
            self.fused_events[event_id] = event
            self.message_to_event[message.get('id')] = event_id
        
        print(f"[FUSION] Created event {event_id}: {signature['threat_type']} x{signature['quantity']} -> {signature['direction']}")
        
        return event_id
    
    def update_event(self, event_id: str, message: dict, signature: dict) -> dict:
        """
        Оновлює існуючу подію новою інформацією.
        
        Використовує пріоритет каналів для вирішення конфліктів.
        """
        with self.lock:
            if event_id not in self.fused_events:
                return None
            
            event = self.fused_events[event_id]
            channel = signature['channel']
            priority = self.get_channel_priority(channel)
            
            changes = []
            
            # Add message to event
            event['messages'].append({
                'id': message.get('id'),
                'channel': channel,
                'priority': priority,
                'text': message.get('text', ''),
                'timestamp': signature['timestamp'],
                'coordinates': signature['target_coords'],
            })
            self.message_to_event[message.get('id')] = event_id
            
            # Update with higher priority info
            best_priority = max(m['priority'] for m in event['messages'])
            
            # Update quantity (take max from high-priority sources)
            if signature['quantity'] > event['quantity']:
                high_priority_quantities = [
                    m for m in event['messages']
                    if m['priority'] >= best_priority - 10
                ]
                if priority >= best_priority - 10:
                    changes.append(f"quantity: {event['quantity']} -> {signature['quantity']}")
                    event['quantity'] = signature['quantity']
            
            # Update regions (merge)
            new_regions = signature['regions'] - set(event['regions'])
            if new_regions:
                event['regions'].extend(new_regions)
                changes.append(f"entered: {new_regions}")
            
            # Update direction (prefer higher priority)
            if signature['direction'] and priority >= best_priority - 10:
                if signature['direction'] != event['direction']:
                    changes.append(f"direction: {event['direction']} -> {signature['direction']}")
                    event['direction'] = signature['direction']
            
            # Update coordinates and trajectory
            if signature['target_coords']:
                # Always add to trajectory if coordinates are different from last point
                last_traj_coords = event['trajectory'][-1]['coords'] if event['trajectory'] else None
                coords_are_new = (
                    not last_traj_coords or 
                    abs(last_traj_coords[0] - signature['target_coords'][0]) > 0.01 or
                    abs(last_traj_coords[1] - signature['target_coords'][1]) > 0.01
                )
                
                if coords_are_new:
                    # Add to trajectory
                    event['trajectory'].append({
                        'coords': signature['target_coords'],
                        'timestamp': signature['timestamp'].isoformat() if signature['timestamp'] else datetime.now().isoformat(),
                        'source': channel,
                    })
                    changes.append(f"moved")
                
                # Update best_coordinates (prefer higher priority, more recent)
                if not event['best_coordinates'] or priority >= best_priority - 10:
                    event['best_coordinates'] = signature['target_coords']
            
            # Check for status updates
            if 'destroyed' in signature['keywords']:
                # Count destroyed
                destroyed_mentions = sum(
                    1 for m in event['messages']
                    if 'збит' in m['text'].lower() or 'знищен' in m['text'].lower()
                )
                if destroyed_mentions > event['quantity_destroyed']:
                    event['quantity_destroyed'] = min(destroyed_mentions, event['quantity'])
                    changes.append(f"destroyed: {event['quantity_destroyed']}")
                    
                    if event['quantity_destroyed'] >= event['quantity']:
                        event['status'] = 'destroyed'
            
            if 'passed' in signature['keywords']:
                if event['status'] == 'active':
                    event['status'] = 'passed'
                    changes.append(f"status: passed")
            
            if 'changed_course' in signature['keywords']:
                changes.append(f"changed course")
            
            # Update combined signature
            event['signature']['regions'].update(signature['regions'])
            if signature['direction']:
                event['signature']['direction'] = signature['direction']
            event['signature']['keywords'].update(signature['keywords'])
            
            # Update timestamps
            event['last_update'] = datetime.now()
            
            # Update confidence based on number of sources
            unique_channels = len(set(m['channel'] for m in event['messages']))
            event['confidence'] = min(1.0, (best_priority / 100.0) + (unique_channels - 1) * 0.1)
            
            if changes:
                print(f"[FUSION] Updated event {event_id}: {', '.join(changes)}")
        
        return event
    
    def process_message(self, message: dict) -> dict:
        """
        AI-FIRST: Обробляє нове повідомлення через AI систему.
        
        AI визначає:
        1. Чи це загроза
        2. Тип та кількість
        3. Координати
        4. Дію: create/move/update/remove
        """
        signature = self.extract_message_signature(message)
        
        # Skip if not a threat
        if not signature['threat_type']:
            return None
        
        # AI визначив дію
        action = signature.get('action', 'create')
        
        # Find matching event for move/update/remove actions
        event_id = None
        if action in ['move', 'update', 'remove']:
            event_id = self.find_matching_event(signature)
        
        # Execute action based on AI decision
        if action == 'remove':
            # AI каже що загрозу знищено/пройшла
            if event_id:
                with self.lock:
                    if event_id in self.fused_events:
                        self.fused_events[event_id]['status'] = 'destroyed'
                        print(f"[AI] Marked event {event_id} as destroyed")
                return {
                    'action': 'removed',
                    'event_id': event_id,
                    'event': self.fused_events.get(event_id),
                    'signature': signature,
                }
        
        elif action == 'move' and event_id:
            # AI каже що загроза перемістилась
            event = self.update_event(event_id, message, signature)
            if event and signature.get('target_coords'):
                # Оновити координати
                event['best_coordinates'] = signature['target_coords']
                print(f"[AI] Moved event {event_id} to {signature['target_coords']}")
            return {
                'action': 'moved',
                'event_id': event_id,
                'event': event,
                'signature': signature,
            }
        
        elif action == 'update' and event_id:
            # AI каже оновити існуючу загрозу
            event = self.update_event(event_id, message, signature)
            return {
                'action': 'updated',
                'event_id': event_id,
                'event': event,
                'signature': signature,
            }
        
        else:
            # Default: create or merge
            if not event_id:
                event_id = self.find_matching_event(signature)
            
            if event_id:
                # Merge with existing
                event = self.update_event(event_id, message, signature)
                return {
                    'action': 'merged',
                    'event_id': event_id,
                    'event': event,
                    'signature': signature,
                }
            else:
                # Create new
                event_id = self.create_event(message, signature)
                return {
                    'action': 'created',
                    'event_id': event_id,
                    'event': self.fused_events.get(event_id),
                    'signature': signature,
                }
    
    def get_active_events(self) -> list:
        """Отримує всі активні події"""
        now = datetime.now()
        active = []
        
        with self.lock:
            for event_id, event in self.fused_events.items():
                # Skip old events
                age = (now - event['last_update']).total_seconds()
                max_age = 7200  # 2 hours for shaheds
                if event['threat_type'] in ['ballistic', 'kinzhal', 'kab']:
                    max_age = 600  # 10 min for fast threats
                elif event['threat_type'] in ['cruise']:
                    max_age = 1800  # 30 min
                
                if age > max_age:
                    continue
                
                if event['status'] in ['active', 'partially_destroyed']:
                    active.append(event.copy())
        
        return active
    
    def generate_marker_from_event(self, event: dict) -> dict:
        """
        Генерує маркер для відображення на карті з об'єднаної події.
        """
        if not event['best_coordinates']:
            return None
        
        # Build place name from combined info
        place_parts = []
        if event['regions']:
            place_parts.append(event['regions'][-1])  # Latest region
        if event['direction']:
            place_parts.append(f"→ {event['direction']}")
        
        place = ' '.join(place_parts) if place_parts else 'Невідомо'
        
        # Build text with quantity info
        qty_text = ''
        if event['quantity'] > 1:
            remaining = event['quantity'] - event['quantity_destroyed']
            if event['quantity_destroyed'] > 0:
                qty_text = f" [{remaining}/{event['quantity']}, збито: {event['quantity_destroyed']}]"
            else:
                qty_text = f" [x{event['quantity']}]"
        
        # Sources info
        sources = list(set(m['channel'] for m in event['messages']))
        sources_text = f" ({len(sources)} джерел)" if len(sources) > 1 else ''
        
        # Icon based on threat type
        icon_map = {
            'shahed': 'icon_drone.svg',
            'drone': 'icon_drone.svg',
            'ballistic': 'icon_balistic.svg',
            'cruise': 'icon_rocket.svg',
            'kab': 'icon_balistic.svg',
            'kinzhal': 'icon_balistic.svg',
        }
        
        marker = {
            'id': f"fused_{event['id']}",
            'place': place,
            'lat': event['best_coordinates'][0],
            'lng': event['best_coordinates'][1],
            'threat_type': event['threat_type'],
            'text': f"{event['threat_type'].upper()}{qty_text}{sources_text}",
            'date': event['last_update'].strftime('%Y-%m-%d %H:%M:%S'),
            'channel': 'fusion',
            'marker_icon': icon_map.get(event['threat_type'], 'icon_drone.svg'),
            'source_match': 'fusion',
            # Direction for icon rotation
            'course_direction': event.get('course_direction'),
            'course_bearing': event.get('course_bearing'),  # NEW: кут в градусах від AI
            'direction': event.get('direction'),
            # Source coordinates for trajectory
            'source_lat': event['source_coords'][0] if event.get('source_coords') else None,
            'source_lng': event['source_coords'][1] if event.get('source_coords') else None,
            # Fusion metadata
            'fusion_event_id': event['id'],
            'fusion_confidence': event['confidence'],
            'fusion_sources': sources,
            'fusion_trajectory': event['trajectory'],
            'fusion_status': event['status'],
            'quantity': event['quantity'],
            'quantity_destroyed': event['quantity_destroyed'],
        }
        
        return marker
    
    def build_trajectory_from_event(self, event: dict) -> dict:
        """
        Будує траєкторію з послідовності позицій події.
        """
        if len(event['trajectory']) < 2:
            return None
        
        points = event['trajectory']
        
        # Sort by timestamp
        sorted_points = sorted(points, key=lambda p: p['timestamp'])
        
        # Build polyline
        coords = [p['coords'] for p in sorted_points if p['coords']]
        
        if len(coords) < 2:
            return None
        
        # Calculate distance and direction
        start = coords[0]
        end = coords[-1]
        
        total_distance = 0
        for i in range(1, len(coords)):
            total_distance += haversine(coords[i-1], coords[i])
        
        # Predict continuation
        if len(coords) >= 2:
            # Use last two points to predict direction
            lat_diff = end[0] - coords[-2][0]
            lng_diff = end[1] - coords[-2][1]
            
            # Project forward
            projection_factor = 0.5  # Project half the path forward
            predicted_end = (
                end[0] + lat_diff * projection_factor * len(coords),
                end[1] + lng_diff * projection_factor * len(coords),
            )
        else:
            predicted_end = end
        
        return {
            'event_id': event['id'],
            'actual_path': coords,
            'predicted_path': [end, predicted_end],
            'start': start,
            'end': end,
            'predicted_end': predicted_end,
            'total_distance_km': total_distance,
            'point_count': len(coords),
        }
    
    def cleanup_old_events(self, max_age_hours: float = 4):
        """Видаляє старі події"""
        now = datetime.now()
        removed = 0
        
        with self.lock:
            for event_id in list(self.fused_events.keys()):
                event = self.fused_events[event_id]
                age_hours = (now - event['created_at']).total_seconds() / 3600
                
                should_remove = False
                
                # Remove if too old
                if age_hours > max_age_hours:
                    should_remove = True
                
                # Remove completed events after 30 min
                if event['status'] in ['destroyed', 'passed'] and age_hours > 0.5:
                    should_remove = True
                
                if should_remove:
                    del self.fused_events[event_id]
                    removed += 1
        
        if removed > 0:
            print(f"[FUSION] Cleaned up {removed} old events")
        
        return removed


class TrajectoryBuilder:
    """
    Будівник траєкторій на основі послідовності повідомлень.
    """
    
    def __init__(self):
        self.active_trajectories = {}  # threat_id -> trajectory data
        self.lock = threading.Lock()
    
    def add_position(self, threat_id: str, lat: float, lng: float, 
                     timestamp: datetime, source: str):
        """Додає нову позицію до траєкторії"""
        with self.lock:
            if threat_id not in self.active_trajectories:
                self.active_trajectories[threat_id] = {
                    'positions': [],
                    'created_at': timestamp,
                    'last_update': timestamp,
                }
            
            traj = self.active_trajectories[threat_id]
            traj['positions'].append({
                'lat': lat,
                'lng': lng,
                'timestamp': timestamp.isoformat(),
                'source': source,
            })
            traj['last_update'] = timestamp
    
    def get_trajectory(self, threat_id: str) -> dict:
        """Отримує побудовану траєкторію"""
        with self.lock:
            if threat_id not in self.active_trajectories:
                return None
            
            traj = self.active_trajectories[threat_id]
            if len(traj['positions']) < 2:
                return None
            
            positions = sorted(traj['positions'], key=lambda p: p['timestamp'])
            
            return {
                'threat_id': threat_id,
                'positions': positions,
                'start': (positions[0]['lat'], positions[0]['lng']),
                'current': (positions[-1]['lat'], positions[-1]['lng']),
                'point_count': len(positions),
            }


# Global fusion system instance
CHANNEL_FUSION = ChannelIntelligenceFusion()

def process_message_with_fusion(message: dict) -> dict:
    """
    Обробляє повідомлення через систему злиття каналів.
    
    Це головна точка входу для обробки нових повідомлень.
    """
    result = CHANNEL_FUSION.process_message(message)
    
    if result and result['event']:
        # Also update threat tracker for alarm sync
        process_message_for_threats(message)
    
    return result

def get_fused_markers() -> list:
    """
    Отримує маркери з об'єднаних подій.
    """
    events = CHANNEL_FUSION.get_active_events()
    markers = []
    
    for event in events:
        marker = CHANNEL_FUSION.generate_marker_from_event(event)
        if marker:
            markers.append(marker)
    
    return markers

def get_fused_trajectories() -> list:
    """
    Отримує траєкторії з об'єднаних подій.
    """
    events = CHANNEL_FUSION.get_active_events()
    trajectories = []
    
    for event in events:
        traj = CHANNEL_FUSION.build_trajectory_from_event(event)
        if traj:
            trajectories.append(traj)
    
    return trajectories

# ==================== END MULTI-CHANNEL INTELLIGENCE FUSION ====================


def analyze_threat_context(message_text: str, threat_type: str) -> dict:
    """
    Analyze message context to improve prediction accuracy.
    
    Returns context clues for prediction adjustment.
    """
    if not message_text:
        return {}
    
    msg_lower = message_text.lower()
    context = {}
    
    # Attack scale
    context['scale'] = extract_attack_scale(message_text)
    
    # Target infrastructure hints
    if any(w in msg_lower for w in ['енерг', 'електр', 'тец', 'гес', 'підстанц', 'інфраструктур']):
        context['likely_target_type'] = 'energy_infrastructure'
    elif any(w in msg_lower for w in ['порт', 'морськ', 'судно', 'зерно', 'термінал']):
        context['likely_target_type'] = 'port'
    elif any(w in msg_lower for w in ['військов', 'аеродром', 'склад', 'база']):
        context['likely_target_type'] = 'military'
    elif any(w in msg_lower for w in ['житлов', 'цивільн', 'центр міста']):
        context['likely_target_type'] = 'civilian'
    
    # Urgency indicators
    urgent_words = ['терміново', 'увага', 'небезпека', 'загроза', 'швидко', 'негайно']
    context['urgency'] = any(w in msg_lower for w in urgent_words)
    
    # Direction certainty
    direction_certain = ['курсом на', 'напрямок на', 'рухається до', 'тримає курс']
    direction_uncertain = ['ймовірно', 'можливо', 'орієнтовно', 'приблизно']
    
    if any(d in msg_lower for d in direction_certain):
        context['direction_certainty'] = 'high'
    elif any(d in msg_lower for d in direction_uncertain):
        context['direction_certainty'] = 'low'
    else:
        context['direction_certainty'] = 'medium'
    
    # Speed/altitude indicators
    if any(w in msg_lower for w in ['малій висоті', 'низько', 'низьколетяч']):
        context['altitude'] = 'low'
    elif any(w in msg_lower for w in ['великій висоті', 'високо']):
        context['altitude'] = 'high'
    
    # Maneuvers
    if any(w in msg_lower for w in ['маневрує', 'змінює курс', 'змінив напрямок']):
        context['maneuvering'] = True
    
    return context

def predict_waypoints(source_coords: tuple, target_coords: tuple, threat_type: str, message_text: str = None) -> list:
    """
    Predict intermediate waypoints along the trajectory.
    
    Returns list of waypoints with:
    - name: waypoint name
    - coords: [lat, lng]
    - eta_minutes: estimated time to reach this point
    - probability: probability of passing through
    """
    if not source_coords or not target_coords:
        return []
    
    waypoints = []
    
    # Check known flight corridors
    msg_lower = (message_text or '').lower()
    
    for corridor_id, corridor in FLIGHT_CORRIDORS.items():
        # Check if source matches corridor
        source_match = any(region in msg_lower for region in corridor['start_regions'])
        
        if not source_match:
            continue
        
        # Check if any end target matches
        target_match = False
        for end_target in corridor['end_targets']:
            target_data = STRATEGIC_TARGETS.get(end_target)
            if target_data:
                target_dist = calculate_distance_km(
                    target_coords[0], target_coords[1],
                    target_data['coords'][0], target_data['coords'][1]
                )
                if target_dist < 50:  # Within 50km of a corridor end target
                    target_match = True
                    break
        
        if not target_match:
            continue
        
        # Found matching corridor - add waypoints
        total_distance = calculate_distance_km(
            source_coords[0], source_coords[1],
            target_coords[0], target_coords[1]
        )
        
        speeds = THREAT_SPEEDS.get(threat_type, THREAT_SPEEDS['unknown'])
        
        for wp in corridor['waypoints']:
            # Calculate distance to waypoint
            wp_distance = calculate_distance_km(
                source_coords[0], source_coords[1],
                wp['coords'][0], wp['coords'][1]
            )
            
            # Only include if waypoint is between source and target
            target_distance = calculate_distance_km(
                wp['coords'][0], wp['coords'][1],
                target_coords[0], target_coords[1]
            )
            
            if wp_distance < total_distance and target_distance < total_distance:
                eta_minutes = (wp_distance / speeds['avg']) * 60
                
                waypoints.append({
                    'name': wp['name'],
                    'coords': wp['coords'],
                    'eta_minutes': round(eta_minutes, 1),
                    'probability': wp['probability'],
                    'corridor': corridor_id
                })
        
        break  # Use first matching corridor
    
    # Sort by ETA
    waypoints.sort(key=lambda x: x['eta_minutes'])
    
    return waypoints

def ensemble_predict(source_coords: tuple, target_name: str, target_coords: tuple, 
                    threat_type: str, message_text: str = None, patterns: dict = None) -> dict:
    """
    Ensemble prediction combining multiple models:
    1. Statistical model (distance, strategic value)
    2. Temporal model (time of day, day of week, season)
    3. Historical model (past attack patterns)
    4. Bayesian model (prior probabilities)
    5. Corridor model (known flight paths)
    
    Returns combined probability with confidence intervals.
    """
    if not source_coords or not target_coords:
        return {'probability': 0.0, 'confidence': 0.0}
    
    temporal = get_temporal_factors()
    target_lower = target_name.lower()
    strategic = STRATEGIC_TARGETS.get(target_lower, {})
    target_type = strategic.get('type', 'city')
    
    # Model 1: Statistical (distance + strategic value)
    distance = calculate_distance_km(
        source_coords[0], source_coords[1],
        target_coords[0], target_coords[1]
    )
    
    max_range = {'shahed': 400, 'drone': 300, 'cruise': 1500, 'ballistic': 500, 'kab': 100}.get(threat_type, 400)
    stat_prob = max(0.05, 1.0 - (distance / max_range) ** 0.7) if distance <= max_range else 0.05
    stat_prob *= strategic.get('weight', 0.5)
    
    # Model 2: Temporal
    temporal_prob = 1.0
    
    # Hour pattern
    hour_patterns = HOURLY_PATTERNS.get(threat_type, HOURLY_PATTERNS.get('shahed', {}))
    hour_mult = hour_patterns.get(temporal['hour'], 1.0)
    temporal_prob *= hour_mult
    
    # Weekend/weekday
    temporal_prob *= temporal['weekday_pattern'].get('overall', 1.0)
    if target_lower == 'київ':
        temporal_prob *= temporal['weekday_pattern'].get('capital', 1.0)
    
    # Seasonal
    seasonal = temporal['seasonal_pattern'].get(target_type, 1.0)
    temporal_prob *= seasonal
    
    # Special date
    if target_lower == 'київ':
        temporal_prob *= temporal.get('capital_boost', 1.0)
    temporal_prob *= temporal.get('overall_boost', 1.0)
    
    # Model 3: Historical
    historical_prob = 1.0
    if patterns and patterns.get('historical_routes'):
        recent = patterns['historical_routes'][-50:]
        target_hits = sum(1 for r in recent if r.get('target', '').lower() == target_lower)
        if target_hits > 0:
            historical_prob = 1.0 + min(target_hits * 0.1, 0.5)
    
    # Model 4: Bayesian prior
    prior = PRIOR_TARGET_PROBABILITIES.get(target_lower, PRIOR_TARGET_PROBABILITIES.get('other', 0.05))
    
    # Model 5: Corridor
    corridor_prob = 1.0
    msg_lower = (message_text or '').lower()
    
    for corridor_id, corridor in FLIGHT_CORRIDORS.items():
        source_match = any(region in msg_lower for region in corridor['start_regions'])
        target_match = target_lower in corridor['end_targets']
        
        if source_match and target_match:
            corridor_prob = 1.5  # Strong boost for corridor match
            break
        elif source_match:
            # Partial match - check if target is a waypoint
            for wp in corridor.get('waypoints', []):
                if wp['name'].lower() == target_lower:
                    corridor_prob = 1.2 + wp['probability'] * 0.3
                    break
    
    # Combine models with weights
    weights = {
        'statistical': 0.25,
        'temporal': 0.20,
        'historical': 0.15,
        'bayesian': 0.20,
        'corridor': 0.20
    }
    
    # Normalize each model to 0-1 range
    models = {
        'statistical': min(1.0, stat_prob),
        'temporal': min(1.0, temporal_prob / 2.0),  # Divide by 2 since it can be > 1
        'historical': min(1.0, historical_prob / 1.5),
        'bayesian': prior,
        'corridor': min(1.0, corridor_prob / 1.5)
    }
    
    # Weighted average
    combined = sum(models[m] * weights[m] for m in models)
    
    # Calculate confidence based on model agreement
    model_values = list(models.values())
    variance = sum((v - combined) ** 2 for v in model_values) / len(model_values)
    confidence = max(0.3, 1.0 - math.sqrt(variance) * 2)
    
    return {
        'probability': round(combined, 4),
        'confidence': round(confidence, 3),
        'models': models,
        'weights': weights
    }

def calculate_target_probability(
    source_coords: tuple,
    target_name: str,
    target_coords: tuple,
    threat_type: str,
    message_text: str = None,
    patterns: dict = None
) -> float:
    """
    Calculate probability that trajectory ends at specific target.
    
    Factors:
    1. Distance (closer = higher probability)
    2. Strategic value (important cities get bonus)
    3. Direction alignment (if heading stated)
    4. Historical patterns (learned routes)
    5. Time of day (night attacks often target Kyiv)
    6. Attack scale (group attacks → Kyiv)
    7. Source region attack patterns
    8. Day of week patterns
    9. Recent attack correlation
    10. Geographic corridor analysis
    11. Seasonal patterns (NEW)
    12. Special dates (NEW)
    13. Air defense density (NEW)
    14. Population factor (NEW)
    15. Bayesian prior (NEW)
    """
    if not source_coords or not target_coords:
        return 0.0
    
    # Get ensemble prediction as base
    ensemble = ensemble_predict(
        source_coords, target_name, target_coords,
        threat_type, message_text, patterns
    )
    base_prob = ensemble['probability']
    
    # Additional refinements
    target_lower = target_name.lower()
    strategic = STRATEGIC_TARGETS.get(target_lower, {})
    temporal = get_temporal_factors()
    
    # Factor 1: Distance (max useful distance ~400km for drones)
    distance = calculate_distance_km(
        source_coords[0], source_coords[1],
        target_coords[0], target_coords[1]
    )
    
    # Distance penalty - further = less likely
    if threat_type in ['shahed', 'drone']:
        max_range = 400  # Shahed range ~400km
        if distance > max_range:
            distance_factor = 0.1
        else:
            # Non-linear: closer targets get exponentially higher probability
            distance_factor = (1.0 - (distance / max_range)) ** 0.7
    elif threat_type in ['ballistic']:
        max_range = 500  # Iskander ~500km
        distance_factor = 1.0 - (distance / max_range) * 0.3
    else:
        max_range = 1500  # Cruise missiles
        distance_factor = 1.0 - (distance / max_range) * 0.4
    
    base_prob *= max(0.1, distance_factor)
    
    # Factor 2: Strategic value
    target_lower = target_name.lower()
    strategic = STRATEGIC_TARGETS.get(target_lower)
    if strategic:
        base_prob *= (0.7 + strategic['weight'] * 0.5)  # 0.7-1.2 multiplier
    
    # Factor 3: Direction alignment (if message mentions direction)
    if message_text:
        msg_lower = message_text.lower()
        
        # Calculate actual direction from source to target
        lat_diff = target_coords[0] - source_coords[0]
        lng_diff = target_coords[1] - source_coords[1]
        
        # Check if message direction matches actual direction
        direction_match = False
        if 'північ' in msg_lower and lat_diff > 0:
            direction_match = True
            base_prob *= 1.3
        elif 'південь' in msg_lower and lat_diff < 0:
            direction_match = True
            base_prob *= 1.3
        elif 'схід' in msg_lower and lng_diff > 0:
            direction_match = True
            base_prob *= 1.3
        elif 'захід' in msg_lower and lng_diff < 0:
            direction_match = True
            base_prob *= 1.3
        
        # Compound directions (північно-західний, etc.)
        if 'північно-західн' in msg_lower and lat_diff > 0 and lng_diff < 0:
            base_prob *= 1.4
        elif 'північно-східн' in msg_lower and lat_diff > 0 and lng_diff > 0:
            base_prob *= 1.4
        elif 'південно-західн' in msg_lower and lat_diff < 0 and lng_diff < 0:
            base_prob *= 1.4
        elif 'південно-східн' in msg_lower and lat_diff < 0 and lng_diff > 0:
            base_prob *= 1.4
        
        # Explicit target mentions - STRONG signal
        if target_lower in msg_lower:
            base_prob *= 2.0
        
        # Explicit course mentions "курсом на Київ"
        if f'курс' in msg_lower and target_lower in msg_lower:
            base_prob *= 2.5
    
    # Factor 4: Historical patterns - weighted by recency
    if patterns and patterns.get('historical_routes'):
        recent_routes = patterns['historical_routes'][-100:]
        similar_routes = []
        for i, r in enumerate(recent_routes):
            if r.get('target', '').lower() == target_lower:
                # More recent routes have higher weight
                recency_weight = 1.0 + (i / len(recent_routes)) * 0.5
                similar_routes.append(recency_weight)
        
        if similar_routes:
            history_factor = 1.0 + min(sum(similar_routes) * 0.08, 0.6)
            base_prob *= history_factor
    
    # Factor 5: Time of day patterns
    try:
        current_hour = datetime.now().hour
        current_weekday = datetime.now().weekday()
        
        # Night attacks (00:00-06:00) - strategic targets
        if 0 <= current_hour < 6:
            if target_lower == 'київ':
                base_prob *= 1.5  # Night attacks strongly favor capital
            elif strategic and strategic['type'] in ['capital', 'industrial']:
                base_prob *= 1.2
        
        # Early morning (04:00-07:00) - common shahed arrival time
        if 4 <= current_hour < 7:
            if threat_type in ['shahed', 'drone']:
                if target_lower == 'київ':
                    base_prob *= 1.4  # Peak shahed arrival window
        
        # Weekend patterns (more mass attacks)
        if current_weekday >= 5:  # Saturday, Sunday
            if target_lower == 'київ':
                base_prob *= 1.15
                
    except:
        pass
    
    # Factor 6: Attack scale analysis (from message)
    if message_text:
        msg_lower = message_text.lower()
        
        # Group attacks → likely Kyiv
        group_indicators = ['група', 'групи', 'кілька', 'декілька', 'багато', 'масов']
        is_group_attack = any(ind in msg_lower for ind in group_indicators)
        
        # Count mentioned drones
        drone_count = 0
        count_patterns = [r'(\d+)\s*(?:бпла|шахед|дрон)', r'близько\s*(\d+)', r'до\s*(\d+)']
        for pattern in count_patterns:
            match = re.search(pattern, msg_lower)
            if match:
                try:
                    drone_count = max(drone_count, int(match.group(1)))
                except:
                    pass
        
        if is_group_attack or drone_count >= 3:
            if target_lower == 'київ':
                base_prob *= 1.4  # Group attacks usually target capital
            elif target_lower in ['харків', 'одеса', 'дніпро']:
                base_prob *= 1.2  # Or major cities
    
    # Factor 7: Source region → Target corridor patterns
    source_name_lower = (source_coords[2] if len(source_coords) > 2 else '').lower() if isinstance(source_coords, (list, tuple)) and len(source_coords) > 2 else ''
    
    # Known attack corridors
    ATTACK_CORRIDORS = {
        # South → Kyiv corridor
        ('одеська', 'миколаївська', 'херсонська'): {'київ': 1.5, 'вінниця': 1.3, 'черкаси': 1.2},
        # East → Kharkiv/Poltava
        ('харківська', 'сумська', 'луганська'): {'харків': 1.6, 'полтава': 1.3, 'суми': 1.4},
        # Crimea → South/Central
        ('крим', 'севастополь', 'чорне море'): {'одеса': 1.4, 'миколаїв': 1.5, 'херсон': 1.3, 'запоріжжя': 1.3},
        # Belarus → Kyiv/Chernihiv
        ('білорусь', 'гомель', 'мозир'): {'київ': 1.6, 'чернігів': 1.5, 'житомир': 1.3},
    }
    
    if message_text:
        msg_lower = message_text.lower()
        for sources, targets in ATTACK_CORRIDORS.items():
            if any(src in msg_lower for src in sources):
                if target_lower in targets:
                    base_prob *= targets[target_lower]
                    break
    
    # Factor 8: Geographic corridor (direct line of flight)
    # Bonus if target is roughly in line with source direction
    if message_text and source_coords and target_coords:
        # Calculate bearing from message-mentioned direction
        msg_lower = message_text.lower()
        expected_bearing = None
        
        if 'північ' in msg_lower and 'схід' not in msg_lower and 'захід' not in msg_lower:
            expected_bearing = 0
        elif 'північ' in msg_lower and 'схід' in msg_lower:
            expected_bearing = 45
        elif 'схід' in msg_lower and 'північ' not in msg_lower and 'південь' not in msg_lower:
            expected_bearing = 90
        elif 'південь' in msg_lower and 'схід' in msg_lower:
            expected_bearing = 135
        elif 'південь' in msg_lower and 'схід' not in msg_lower and 'захід' not in msg_lower:
            expected_bearing = 180
        elif 'південь' in msg_lower and 'захід' in msg_lower:
            expected_bearing = 225
        elif 'захід' in msg_lower and 'північ' not in msg_lower and 'південь' not in msg_lower:
            expected_bearing = 270
        elif 'північ' in msg_lower and 'захід' in msg_lower:
            expected_bearing = 315
        
        if expected_bearing is not None:
            # Calculate actual bearing to target
            import math
            lat1, lng1 = math.radians(source_coords[0]), math.radians(source_coords[1])
            lat2, lng2 = math.radians(target_coords[0]), math.radians(target_coords[1])
            dLng = lng2 - lng1
            x = math.sin(dLng) * math.cos(lat2)
            y = math.cos(lat1) * math.sin(lat2) - math.sin(lat1) * math.cos(lat2) * math.cos(dLng)
            actual_bearing = (math.degrees(math.atan2(x, y)) + 360) % 360
            
            # Calculate bearing difference (0-180)
            bearing_diff = abs(actual_bearing - expected_bearing)
            if bearing_diff > 180:
                bearing_diff = 360 - bearing_diff
            
            # Bonus for targets in the expected direction corridor (within 45°)
            if bearing_diff <= 30:
                base_prob *= 1.4  # Strong corridor match
            elif bearing_diff <= 60:
                base_prob *= 1.2  # Moderate match
            elif bearing_diff > 120:
                base_prob *= 0.6  # Wrong direction - penalty
    
    # Factor 9: Recent attack correlation (last 3 hours)
    # If same region was attacked recently, less likely to be hit again soon
    if patterns and patterns.get('historical_routes'):
        try:
            recent_3h = []
            cutoff_time = datetime.now() - timedelta(hours=3)
            for r in patterns['historical_routes'][-20:]:
                try:
                    ts = datetime.fromisoformat(r.get('timestamp', ''))
                    if ts > cutoff_time and r.get('target', '').lower() == target_lower:
                        recent_3h.append(r)
                except:
                    pass
            
            # If already hit in last 3 hours, slightly reduce probability
            # (attackers often switch targets)
            if recent_3h:
                base_prob *= max(0.7, 1.0 - len(recent_3h) * 0.1)
        except:
            pass
    
    # Factor 10: Infrastructure type matching
    if message_text and strategic:
        msg_lower = message_text.lower()
        target_type = strategic.get('type', '')
        
        # Energy infrastructure attacks
        if any(w in msg_lower for w in ['енерг', 'електр', 'тец', 'гес', 'підстанц']):
            if target_type == 'industrial':
                base_prob *= 1.3
            if target_lower in ['київ', 'харків', 'дніпро', 'запоріжжя']:
                base_prob *= 1.2
        
        # Port/shipping attacks
        if any(w in msg_lower for w in ['порт', 'морськ', 'судно', 'зерно']):
            if target_type == 'port':
                base_prob *= 1.5
    
    # Factor 11: Seasonal patterns (winter=energy, summer=ports)
    try:
        current_month = datetime.now().month
        seasonal = SEASONAL_PATTERNS.get(current_month, {})
        target_type_key = strategic.get('type', 'city')
        seasonal_mult = seasonal.get(target_type_key, 1.0)
        base_prob *= seasonal_mult
    except:
        pass
    
    # Factor 12: Special dates (holidays, anniversaries)
    try:
        current_month = datetime.now().month
        current_day = datetime.now().day
        special = SPECIAL_DATES.get((current_month, current_day))
        if special:
            if target_lower == 'київ':
                base_prob *= special.get('capital_boost', 1.0)
            else:
                base_prob *= special.get('overall_boost', 1.0)
    except:
        pass
    
    # Factor 13: Air defense density (harder to hit well-defended cities)
    air_defense = strategic.get('air_defense', 'none')
    if threat_type in ['shahed', 'drone', 'cruise']:
        # Drones/cruise more likely to target less defended areas
        defense_mult = {
            'heavy': 0.85,  # Heavy defense = attackers still try but less success
            'medium': 0.95,
            'light': 1.05,
            'none': 1.1
        }
        base_prob *= defense_mult.get(air_defense, 1.0)
    elif threat_type in ['ballistic', 'kinzhal']:
        # Ballistic missiles less affected by air defense
        pass
    
    # Factor 14: Population factor (bigger cities = more valuable targets)
    population = strategic.get('population', 100000)
    if population > 1000000:
        base_prob *= 1.15
    elif population > 500000:
        base_prob *= 1.08
    elif population < 50000:
        base_prob *= 0.9
    
    # Factor 15: Bayesian prior from historical data
    prior = PRIOR_TARGET_PROBABILITIES.get(target_lower, PRIOR_TARGET_PROBABILITIES.get('other', 0.05))
    # Blend with prior using 20% weight
    base_prob = base_prob * 0.8 + prior * 0.2
    
    # Clamp to 0-1 range
    return min(1.0, max(0.0, base_prob))

def predict_multiple_targets_with_ai(
    source_region: str,
    source_coords: tuple,
    threat_type: str,
    message_text: str = None,
    top_n: int = 3
) -> dict:
    """
    Advanced AI prediction returning multiple possible targets with probabilities.
    
    Returns:
    {
        'targets': [
            {'name': 'Київ', 'probability': 0.75, 'distance_km': 250, 'eta': {...}},
            {'name': 'Вінниця', 'probability': 0.15, 'distance_km': 150, 'eta': {...}},
            {'name': 'Черкаси', 'probability': 0.10, 'distance_km': 100, 'eta': {...}}
        ],
        'primary_target': 'Київ',
        'confidence': 0.75,
        'reasoning': 'AI explanation...',
        'speed_estimate_kmh': 150
    }
    """
    if not source_coords:
        return {'targets': [], 'primary_target': None, 'confidence': 0.0}
    
    patterns = _load_route_patterns()
    
    # Calculate probabilities for all strategic targets
    candidates = []
    for target_name, target_data in STRATEGIC_TARGETS.items():
        target_coords = target_data['coords']
        
        probability = calculate_target_probability(
            source_coords=source_coords,
            target_name=target_name,
            target_coords=target_coords,
            threat_type=threat_type,
            message_text=message_text,
            patterns=patterns
        )
        
        if probability > 0.05:  # Only include if >5% probability
            distance = calculate_distance_km(
                source_coords[0], source_coords[1],
                target_coords[0], target_coords[1]
            )
            eta = estimate_eta_minutes(distance, threat_type)
            
            # Get ensemble prediction for this target
            ensemble = ensemble_predict(
                source_coords, target_name, target_coords,
                threat_type, message_text, patterns
            )
            
            candidates.append({
                'name': target_name.title(),
                'probability': round(probability, 3),
                'distance_km': round(distance, 1),
                'eta': eta,
                'coords': target_coords,
                'type': target_data['type'],
                'ensemble_confidence': ensemble['confidence'],
                'air_defense': target_data.get('air_defense', 'unknown'),
                'population': target_data.get('population', 0)
            })
    
    # Apply softmax normalization for better distribution
    if candidates:
        probs = [c['probability'] for c in candidates]
        normalized = softmax_normalize(probs)
        for i, c in enumerate(candidates):
            c['probability'] = round(normalized[i], 3)
    
    # Sort by probability (descending)
    candidates.sort(key=lambda x: x['probability'], reverse=True)
    
    # Take top N
    top_targets = candidates[:top_n]
    
    # Predict waypoints for primary target
    waypoints = []
    if top_targets:
        primary_target = top_targets[0]
        waypoints = predict_waypoints(
            source_coords, 
            primary_target['coords'],
            threat_type,
            message_text
        )
    
    # Apply source region boost
    if message_text:
        msg_lower = message_text.lower()
        for src_name, src_info in SOURCE_REGIONS_INFO.items():
            if src_name in msg_lower:
                # Boost targets that are typical for this source
                for target in top_targets:
                    if target['name'].lower() in src_info.get('typical_targets', []):
                        target['probability'] *= 1.3
                        target['source_match'] = True
                break
    
    # Re-normalize after source boost
    total_prob = sum(c['probability'] for c in top_targets)
    if total_prob > 0:
        for c in top_targets:
            c['probability'] = round(c['probability'] / total_prob, 3)
    
    # Re-sort
    top_targets.sort(key=lambda x: x['probability'], reverse=True)
    
    # Use AI to refine and explain
    reasoning = f"На основі напрямку з {source_region}"
    
    # Get current attack context
    temporal = get_temporal_factors()
    current_hour = temporal['hour']
    current_weekday = temporal['weekday']
    time_context = "ніч" if 0 <= current_hour < 6 else "ранок" if 6 <= current_hour < 12 else "день" if 12 <= current_hour < 18 else "вечір"
    weekend = current_weekday >= 5
    special_date = temporal.get('special_date')
    
    if GROQ_ENABLED and top_targets:
        try:
            _groq_rate_limit()
            
            # Get historical context
            patterns = _load_route_patterns()
            recent_attacks = []
            if patterns.get('historical_routes'):
                for r in patterns['historical_routes'][-10:]:
                    recent_attacks.append(f"{r.get('source', '?')}→{r.get('target', '?')}")
            
            prompt = f"""Ти військовий аналітик з глибоким знанням тактики ворожих атак на Україну.

КОНТЕКСТ АТАКИ:
- Час: {time_context} ({current_hour}:00), {"вихідний" if weekend else "будній день"}
- Тип загрози: {threat_type}
- Регіон виявлення: {source_region}
- Повідомлення: {message_text[:300] if message_text else 'немає'}
- Останні атаки: {', '.join(recent_attacks[-5:]) if recent_attacks else 'немає даних'}

МОЇ РОЗРАХУНКИ (статистична модель):
{json.dumps([{'name': t['name'], 'prob': round(t['probability']*100), 'km': t['distance_km']} for t in top_targets], ensure_ascii=False)}

ТВОЄ ЗАВДАННЯ:
1. Оціни ймовірності моєї моделі
2. Скоригуй на основі реальних патернів:
   - Шахеди з півдня → 70% Київ
   - Групові атаки вночі → Київ/Харків
   - КАБи → прифронтові міста
   - Балістика з Криму → Одеса/Миколаїв
3. Поясни логіку коротко

JSON формат:
{{"adjusted": [{{"name": "Київ", "prob": 65}}, {{"name": "Вінниця", "prob": 20}}], "reason": "типовий нічний маршрут на столицю", "conf": 0.75}}"""

            response = groq_client.chat.completions.create(
                model=GROQ_MODEL,
                messages=[
                    {"role": "system", "content": "Ти експерт з аналізу траєкторій атак. Відповідай ТІЛЬКИ валідним JSON без markdown."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.15,
                max_tokens=300
            )
            
            result_text = response.choices[0].message.content.strip()
            if result_text.startswith('```'):
                result_text = re.sub(r'^```(?:json)?\s*', '', result_text)
                result_text = re.sub(r'\s*```$', '', result_text)
            
            ai_result = json.loads(result_text)
            
            # Apply AI adjustments (new format)
            if ai_result.get('adjusted'):
                for adj in ai_result['adjusted']:
                    for target in top_targets:
                        if target['name'].lower() == adj.get('name', '').lower():
                            # Convert percentage to decimal
                            new_prob = adj.get('prob', 0)
                            if isinstance(new_prob, (int, float)):
                                target['probability'] = new_prob / 100 if new_prob > 1 else new_prob
                            target['ai_adjusted'] = True
                
                # Re-sort after adjustments
                top_targets.sort(key=lambda x: x['probability'], reverse=True)
                
                # Re-normalize
                total_prob = sum(c['probability'] for c in top_targets)
                if total_prob > 0:
                    for c in top_targets:
                        c['probability'] = round(c['probability'] / total_prob, 3)
            
            # Legacy format support
            elif ai_result.get('adjusted_targets'):
                for adj in ai_result['adjusted_targets']:
                    for target in top_targets:
                        if target['name'].lower() == adj.get('name', '').lower():
                            target['probability'] = adj.get('probability', target['probability'])
                            target['ai_adjusted'] = True
                top_targets.sort(key=lambda x: x['probability'], reverse=True)
            
            reasoning = ai_result.get('reason') or ai_result.get('reasoning', reasoning)
            
            print(f"DEBUG AI Prediction refined: {[t['name'] + ':' + str(round(t['probability']*100)) + '%' for t in top_targets[:3]]}")
            
        except Exception as e:
            print(f"DEBUG: AI target refinement failed: {e}")
    
    # Get primary target
    primary = top_targets[0] if top_targets else None
    
    # Estimate speed based on threat type
    speed_estimate = THREAT_SPEEDS.get(threat_type, THREAT_SPEEDS['unknown'])['avg']
    
    # Calculate overall confidence
    confidence = 0.5
    if primary:
        # Higher probability = higher confidence
        confidence = min(0.95, primary['probability'] * 1.2)
        # Boost if AI adjusted
        if primary.get('ai_adjusted'):
            confidence = min(0.95, confidence * 1.1)
        # Boost if ensemble confidence is high
        if primary.get('ensemble_confidence', 0) > 0.7:
            confidence = min(0.95, confidence * 1.1)
    
    # Get temporal context for response
    temporal = get_temporal_factors()
    special_date_info = None
    if temporal.get('special_date'):
        special_date_info = {
            'name': temporal['special_date'],
            'is_attack_boost': temporal.get('special_date_boost', 1.0) > 1.0
        }
    
    return {
        'targets': top_targets,
        'primary_target': primary['name'] if primary else None,
        'primary_coords': primary['coords'] if primary else None,
        'confidence': round(confidence, 3),
        'reasoning': reasoning,
        'speed_estimate_kmh': speed_estimate,
        'threat_type': threat_type,
        'source_region': source_region,
        'time_context': time_context if 'time_context' in dir() else None,
        'waypoints': waypoints,  # Predicted intermediate points
        'temporal_context': {
            'hour': temporal['hour'],
            'weekday': temporal['weekday'],
            'month': temporal['month'],
            'is_night': 0 <= temporal['hour'] < 6,
            'is_weekend': temporal['weekday'] >= 5,
            'special_date': special_date_info
        }
    }

def get_enhanced_trajectory_prediction(trajectory_data: dict, message_text: str = None) -> dict:
    """
    Main function to get enhanced trajectory prediction with ETA and multi-targets.
    
    Takes existing trajectory_data from parse_trajectory_from_message() and enhances it.
    
    Returns enhanced trajectory with:
    - eta: {min_minutes, avg_minutes, max_minutes, formatted}
    - alternative_targets: [{name, probability, eta, distance_km}, ...]
    - confidence_level: 'high' | 'medium' | 'low'
    - speed_kmh: estimated speed
    """
    if not trajectory_data:
        return None
    
    start_coords = trajectory_data.get('start')
    end_coords = trajectory_data.get('end')
    source_name = trajectory_data.get('source_name', '')
    target_name = trajectory_data.get('target_name', '')
    
    # Determine threat type from message
    threat_type = 'shahed'  # Default
    if message_text:
        msg_lower = message_text.lower()
        if 'балістик' in msg_lower or 'искандер' in msg_lower or 'кінжал' in msg_lower:
            threat_type = 'ballistic'
        elif 'крилат' in msg_lower or 'калібр' in msg_lower or 'х-' in msg_lower:
            threat_type = 'cruise'
        elif 'каб' in msg_lower or 'керован' in msg_lower + 'бомб' in msg_lower:
            threat_type = 'kab'
        elif 'шахед' in msg_lower or 'герань' in msg_lower:
            threat_type = 'shahed'
        elif 'ракет' in msg_lower:
            threat_type = 'rocket'
    
    enhanced = {
        **trajectory_data,
        'threat_type': threat_type,
        'speed_kmh': THREAT_SPEEDS.get(threat_type, THREAT_SPEEDS['unknown'])['avg']
    }
    
    # Calculate ETA to primary target
    if start_coords and end_coords:
        distance = calculate_distance_km(
            start_coords[0], start_coords[1],
            end_coords[0], end_coords[1]
        )
        enhanced['distance_km'] = round(distance, 1)
        enhanced['eta'] = estimate_eta_minutes(distance, threat_type)
    
    # Get alternative targets
    multi_pred = predict_multiple_targets_with_ai(
        source_region=source_name,
        source_coords=tuple(start_coords) if start_coords else None,
        threat_type=threat_type,
        message_text=message_text,
        top_n=3
    )
    
    if multi_pred.get('targets'):
        enhanced['alternative_targets'] = multi_pred['targets']
        enhanced['ai_reasoning'] = multi_pred.get('reasoning', '')
        
        # Set confidence level
        confidence = multi_pred.get('confidence', 0.5)
        if confidence >= 0.7:
            enhanced['confidence_level'] = 'high'
        elif confidence >= 0.4:
            enhanced['confidence_level'] = 'medium'
        else:
            enhanced['confidence_level'] = 'low'
        enhanced['confidence'] = confidence
    
    print(f"DEBUG Enhanced Trajectory: {threat_type}, ETA={enhanced.get('eta', {}).get('formatted')}, confidence={enhanced.get('confidence_level')}")
    
    return enhanced

def ai_correct_route(route_id: str, correction_data: dict):
    """
    AI manually corrects a specific route prediction.
    Called when actual route differs from prediction.
    
    Args:
        route_id: ID of the route/marker
        correction_data: {actual_target, actual_waypoints, notes}
    """
    patterns = _load_route_patterns()
    
    correction_entry = {
        'timestamp': datetime.now().isoformat(),
        'route_id': route_id,
        'correction': correction_data
    }
    
    if 'ai_corrections' not in patterns:
        patterns['ai_corrections'] = []
    patterns['ai_corrections'].append(correction_entry)
    
    global _route_patterns_modified
    _route_patterns_modified = True
    _save_route_patterns()
    
    print(f"INFO: Route correction recorded: {route_id}")
    return {'status': 'ok', 'message': 'Correction recorded'}


# ==================== AI THREAT CLASSIFICATION ====================
_threat_ai_cache = {}
_THREAT_AI_CACHE_TTL = 1800  # 30 minutes (was 10 min) - reduce API calls

def classify_threat_with_ai(message_text: str):
    """Use Groq AI to intelligently classify threat type from Ukrainian military message.
    
    Returns dict with:
    - threat_type: 'shahed' | 'ballistic' | 'cruise' | 'kab' | 'drone' | 'explosion' | 'artillery' | 'unknown'
    - emoji: appropriate emoji for the threat
    - priority: 1-5 (5 = most critical)
    - quantity: number of objects if mentioned (None if not)
    - description_short: short summary in Ukrainian (max 50 chars)
    - regions_at_risk: list of regions that might be affected
    """
    if not GROQ_ENABLED or not message_text:
        return None
    
    # Check cache
    cache_key = hashlib.md5(message_text.encode()).hexdigest()
    cached = _threat_ai_cache.get(cache_key)
    if cached and time.time() - cached['ts'] < _THREAT_AI_CACHE_TTL:
        return cached['data']
    
    try:
        prompt = f"""Ти експерт з аналізу військових повідомлень про повітряні тривоги в Україні.

Проаналізуй повідомлення та визнач:
1. Тип загрози (threat_type):
   - "shahed" - Шахеди, ударні БПЛА, дрони-камікадзе
   - "ballistic" - Балістичні ракети (Іскандер, КН-23)
   - "cruise" - Крилаті ракети (Калібр, Х-101, Х-555)
   - "kab" - Керовані авіабомби (КАБ)
   - "drone" - Розвідувальні БПЛА (Орлан, Supercam)
   - "explosion" - Вибухи без уточнення типу
   - "artillery" - Артилерія, РСЗВ, С-300 по землі
   - "unknown" - Невизначено

2. Емодзі (emoji) для типу загрози:
   - 🛵 для Шахедів/БПЛА
   - 🚀 для балістики
   - 🎯 для крилатих ракет
   - 💣 для КАБів
   - 🔭 для розвідувальних дронів
   - 💥 для вибухів
   - 💨 для артилерії

3. Пріоритет (priority) від 1 до 5:
   - 5: Балістика, масований обстріл
   - 4: КАБи, крилаті ракети
   - 3: Шахеди, ударні БПЛА
   - 2: Розвідувальні дрони
   - 1: Невизначена загроза

4. Кількість (quantity): число об'єктів якщо вказано, інакше null

5. Короткий опис (description_short): до 50 символів українською

6. Регіони під загрозою (regions_at_risk): список областей куди може рухатися загроза

Повідомлення:
{message_text}

Відповідь ТІЛЬКИ у форматі JSON:
{{"threat_type": "shahed", "emoji": "🛵", "priority": 3, "quantity": 5, "description_short": "5 Шахедів на Київ", "regions_at_risk": ["Київська", "Черкаська"]}}"""

        response = groq_client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[
                {"role": "system", "content": "Ти військовий аналітик. Відповідай ТІЛЬКИ валідним JSON."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.1,
            max_tokens=400,
            top_p=0.9
        )
        
        result_text = response.choices[0].message.content.strip()
        
        # Remove markdown code blocks if present
        if result_text.startswith('```'):
            result_text = re.sub(r'^```(?:json)?\s*', '', result_text)
            result_text = re.sub(r'\s*```$', '', result_text)
        
        result = json.loads(result_text)
        
        if not isinstance(result, dict):
            return None
        
        # Normalize fields
        if result.get('quantity') in ['null', 'None', '', 0]:
            result['quantity'] = None
        if result.get('regions_at_risk') in ['null', 'None', '']:
            result['regions_at_risk'] = []
        
        print(f"DEBUG AI Threat Classification: {result.get('threat_type')} p{result.get('priority')} - {result.get('description_short')}")
        
        # Cache result
        _threat_ai_cache[cache_key] = {'ts': time.time(), 'data': result}
        
        return result
        
    except Exception as e:
        error_str = str(e)
        if '429' in error_str or 'rate_limit' in error_str.lower():
            _groq_handle_429(error_str)
        else:
            print(f"WARNING: AI threat classification failed: {e}")
        return None


# ==================== AI MESSAGE SUMMARIZATION ====================
_summary_ai_cache = {}
_SUMMARY_AI_CACHE_TTL = 1800  # 30 minutes

def summarize_message_with_ai(message_text: str, max_length: int = 100):
    """Use Groq AI to create a concise summary of a military message.
    
    Returns dict with:
    - summary: short summary in Ukrainian (max max_length chars)
    - key_info: list of key facts extracted
    - urgency: 'critical' | 'high' | 'medium' | 'low'
    """
    if not GROQ_ENABLED or not message_text or len(message_text) < 50:
        return None
    
    # Check cache
    cache_key = hashlib.md5(f"{message_text}_{max_length}".encode()).hexdigest()
    cached = _summary_ai_cache.get(cache_key)
    if cached and time.time() - cached['ts'] < _SUMMARY_AI_CACHE_TTL:
        return cached['data']
    
    try:
        prompt = f"""Ти експерт з аналізу військових повідомлень.

Створи КОРОТКИЙ підсумок повідомлення (до {max_length} символів) українською мовою.
Виділи ключові факти та визнач терміновість.

Повідомлення:
{message_text}

Відповідь у форматі JSON:
{{"summary": "короткий опис до {max_length} символів", "key_info": ["факт 1", "факт 2"], "urgency": "high"}}"""

        response = groq_client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[
                {"role": "system", "content": "Створюй короткі інформативні підсумки. Відповідай JSON."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.2,
            max_tokens=300,
            top_p=0.9
        )
        
        result_text = response.choices[0].message.content.strip()
        if result_text.startswith('```'):
            result_text = re.sub(r'^```(?:json)?\s*', '', result_text)
            result_text = re.sub(r'\s*```$', '', result_text)
        
        result = json.loads(result_text)
        
        # Truncate summary if too long
        if result.get('summary') and len(result['summary']) > max_length:
            result['summary'] = result['summary'][:max_length-3] + '...'
        
        _summary_ai_cache[cache_key] = {'ts': time.time(), 'data': result}
        return result
        
    except Exception as e:
        error_str = str(e)
        if '429' in error_str or 'rate_limit' in error_str.lower():
            _groq_handle_429(error_str)
        else:
            print(f"WARNING: AI summarization failed: {e}")
        return None


# ==================== AI CHAT MODERATION ====================
_moderation_ai_cache = {}
_MODERATION_AI_CACHE_TTL = 3600  # 1 hour

def moderate_chat_message_with_ai(message_text: str, nickname: str = None):
    """Use Groq AI to moderate chat messages - detect spam, profanity, threats.
    
    Returns dict with:
    - is_safe: True if message is OK to post
    - reason: reason if blocked (None if safe)
    - category: 'spam' | 'profanity' | 'threat' | 'flood' | 'advertising' | None
    - severity: 1-5 (5 = most severe)
    - suggestion: suggested edit if minor issue (None otherwise)
    """
    if not GROQ_ENABLED or not message_text:
        return {'is_safe': True, 'reason': None, 'category': None, 'severity': 0}
    
    # Skip very short messages - probably safe
    if len(message_text.strip()) < 3:
        return {'is_safe': True, 'reason': None, 'category': None, 'severity': 0}
    
    # Check cache
    cache_key = hashlib.md5(message_text.encode()).hexdigest()
    cached = _moderation_ai_cache.get(cache_key)
    if cached and time.time() - cached['ts'] < _MODERATION_AI_CACHE_TTL:
        return cached['data']
    
    try:
        prompt = f"""Ти модератор українського чату про повітряні тривоги.

Перевір повідомлення на порушення:
1. Нецензурна лексика (мат, образи) - category: "profanity"
2. Спам (реклама, посилання) - category: "spam"  
3. Погрози насильства - category: "threat"
4. Фейки/дезінформація - category: "fake"

Нікнейм: "{nickname or 'Анонім'}"
Повідомлення: "{message_text}"

ВАЖЛИВО: Відповідай ТІЛЬКИ валідним JSON об'єктом!
Якщо повідомлення НОРМАЛЬНЕ (без порушень):
{{"is_safe": true, "reason": null, "category": null, "severity": 0}}

Якщо є ПОРУШЕННЯ:
{{"is_safe": false, "reason": "опис порушення", "category": "profanity", "severity": 3}}

Відповідь:"""

        response = groq_client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[
                {"role": "system", "content": "Ти модератор чату. Відповідай ВИКЛЮЧНО валідним JSON. Блокуй тільки явні порушення - мат, спам, погрози. Звичайні питання та побажання - is_safe: true."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.1,
            max_tokens=150,
            top_p=0.9
        )
        
        result_text = response.choices[0].message.content.strip()
        
        # Remove markdown code blocks if present
        if result_text.startswith('```'):
            result_text = re.sub(r'^```(?:json)?\s*', '', result_text)
            result_text = re.sub(r'\s*```$', '', result_text)
        
        # Try to extract JSON from response
        json_match = re.search(r'\{[^{}]*\}', result_text)
        if json_match:
            result_text = json_match.group()
        
        result = json.loads(result_text)
        
        # Ensure required fields
        result.setdefault('is_safe', True)
        result.setdefault('reason', None)
        result.setdefault('category', None)
        result.setdefault('severity', 0)
        
        if not result['is_safe']:
            print(f"AI MODERATION: Blocked message - {result.get('reason')} [{result.get('category')}]")
        
        _moderation_ai_cache[cache_key] = {'ts': time.time(), 'data': result}
        return result
        
    except Exception as e:
        error_str = str(e)
        if '429' in error_str or 'rate_limit' in error_str.lower():
            _groq_handle_429(error_str)
        else:
            print(f"WARNING: AI moderation failed: {e}")
        return {'is_safe': True, 'reason': None, 'category': None, 'severity': 0}


# ==================== AI COMPREHENSIVE ANALYSIS ====================
def analyze_message_comprehensive_ai(message_text: str):
    """Single AI call to extract ALL information from a military message.
    
    Combines: location extraction, trajectory parsing, threat classification, summarization.
    More efficient than multiple separate AI calls.
    
    Returns dict with all extracted data or None on failure.
    """
    if not GROQ_ENABLED or not message_text:
        return None
    
    # Check combined cache
    cache_key = hashlib.md5(f"comprehensive_{message_text}".encode()).hexdigest()
    cached = _threat_ai_cache.get(cache_key)
    if cached and time.time() - cached['ts'] < _THREAT_AI_CACHE_TTL:
        return cached['data']
    
    try:
        prompt = f"""Ти експерт з аналізу військових повідомлень про повітряні тривоги в Україні.

Проаналізуй повідомлення та витягни ВСЮ інформацію одним запитом:

1. ЛОКАЦІЯ:
   - city: назва міста/села в називному відмінку
   - district: район (якщо вказано)
   - oblast: область

2. ТРАЄКТОРІЯ (якщо є курс/напрямок):
   - source_type: 'city'|'region'|'direction'|null
   - source_name: звідки
   - target_type: 'city'|'region'|'direction'|null  
   - target_name: куди

3. ЗАГРОЗА:
   - threat_type: 'shahed'|'ballistic'|'cruise'|'kab'|'drone'|'explosion'|'artillery'|'unknown'
   - emoji: 🛵|🚀|🎯|💣|🔭|💥|💨
   - priority: 1-5 (5 найвища)
   - quantity: кількість або null

4. ПІДСУМОК:
   - summary: короткий опис до 80 символів
   - urgency: 'critical'|'high'|'medium'|'low'

Повідомлення:
{message_text}

Відповідь ТІЛЬКИ валідний JSON:
{{
  "location": {{"city": null, "district": null, "oblast": null}},
  "trajectory": {{"source_type": null, "source_name": null, "target_type": null, "target_name": null}},
  "threat": {{"threat_type": "unknown", "emoji": "⚠️", "priority": 1, "quantity": null}},
  "summary": {{"text": "опис", "urgency": "medium"}}
}}"""

        response = groq_client.chat.completions.create(
            model="llama-3.3-70b-versatile",
            messages=[
                {"role": "system", "content": "Ти військовий аналітик. Відповідай ТІЛЬКИ валідним JSON без markdown."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.1,
            max_tokens=600,
            top_p=0.9
        )
        
        result_text = response.choices[0].message.content.strip()
        if result_text.startswith('```'):
            result_text = re.sub(r'^```(?:json)?\s*', '', result_text)
            result_text = re.sub(r'\s*```$', '', result_text)
        
        result = json.loads(result_text)
        
        if not isinstance(result, dict):
            return None
        
        # Normalize null values
        def normalize_nulls(obj):
            if isinstance(obj, dict):
                return {k: normalize_nulls(v) for k, v in obj.items()}
            if obj in ['null', 'None', '']:
                return None
            return obj
        
        result = normalize_nulls(result)
        
        print(f"DEBUG AI Comprehensive: threat={result.get('threat',{}).get('threat_type')}, "
              f"city={result.get('location',{}).get('city')}, "
              f"target={result.get('trajectory',{}).get('target_name')}")
        
        _threat_ai_cache[cache_key] = {'ts': time.time(), 'data': result}
        return result
        
    except Exception as e:
        error_str = str(e)
        if '429' in error_str or 'rate_limit' in error_str.lower():
            _groq_handle_429(error_str)
        else:
            print(f"WARNING: AI comprehensive analysis failed: {e}")
        return None


def safe_float(value, default=None):
    """Safely convert value to float, returning default on failure."""
    if value is None:
        return default
    try:
        result = float(value)
        # Check for NaN and Inf
        if result != result or result == float('inf') or result == float('-inf'):
            return default
        return result
    except (ValueError, TypeError):
        return default

def validate_ukraine_coords(lat, lng):
    """Validate that coordinates are within Ukraine bounds.
    Returns True if valid, False otherwise."""
    if lat is None or lng is None:
        return False
    try:
        lat_f = float(lat)
        lng_f = float(lng)
        # Ukraine bounding box (approximate)
        # Lat: 44.0 - 52.5, Lng: 22.0 - 40.5
        if not (44.0 <= lat_f <= 52.5):
            return False
        if not (22.0 <= lng_f <= 40.5):
            return False
        return True
    except (ValueError, TypeError):
        return False

def geocode_with_context(city: str, oblast_key: str, district: str = None):
    """Geocode city using Photon API with oblast and optional district context.
    Returns (lat, lng, is_approx) or None."""
    if not city:
        return None
    
    try:
        import requests
        
        # Normalize oblast key to standard form for matching
        oblast_lower = oblast_key.lower().strip() if oblast_key else ''
        
        # Map various oblast formats to standardized name for API matching
        oblast_normalize = {
            # Full forms
            'дніпропетровська область': 'Дніпропетровська',
            'харківська область': 'Харківська',
            'полтавська область': 'Полтавська',
            'сумська область': 'Сумська',
            'чернігівська область': 'Чернігівська',
            'миколаївська область': 'Миколаївська',
            'одеська область': 'Одеська',
            'запорізька область': 'Запорізька',
            'херсонська область': 'Херсонська',
            'київська область': 'Київська',
            'донецька область': 'Донецька',
            'луганська область': 'Луганська',
            'вінницька область': 'Вінницька',
            'волинська область': 'Волинська',
            'житомирська область': 'Житомирська',
            'закарпатська область': 'Закарпатська',
            'івано-франківська область': 'Івано-Франківська',
            'кіровоградська область': 'Кіровоградська',
            'львівська область': 'Львівська',
            'рівненська область': 'Рівненська',
            'тернопільська область': 'Тернопільська',
            'хмельницька область': 'Хмельницька',
            'черкаська область': 'Черкаська',
            'чернівецька область': 'Чернів��цька',
            # Short forms with обл.
            'харківська обл.': 'Харківська',
            'чернігівська обл.': 'Чернігівська',
            'миколаївська обл.': 'Миколаївська',
            'одеська обл.': 'Одеська',
            'херсонська обл.': 'Херсонська',
            'київська обл.': 'Київська',
            # Colloquial forms
            'харківщина': 'Харківська',
            'полтавщина': 'Полтавська',
            'сумщина': 'Сумська',
            'дніпропетровщина': 'Дніпропетровська',
            'миколаївщина': 'Миколаївська',
            'херсонщина': 'Херсонська',
            'одещина': 'Одеська',
            'чернігівщина': 'Чернігівська',
            'київщина': 'Київська',
            'кіровоградщина': 'Кіровоградська',
            'вінниччина': 'Вінницька',
            'запоріжжя': 'Запорізька',
        }
        
        region_name = oblast_normalize.get(oblast_lower)
        if not region_name:
            # Try partial match
            for key, val in oblast_normalize.items():
                if key in oblast_lower or oblast_lower in key:
                    region_name = val
                    break
        if not region_name:
            region_name = oblast_key  # Use as-is
        
        print(f"DEBUG geocode_with_context: city='{city}', oblast='{oblast_key}' -> region='{region_name}'")
        
        photon_url = 'https://photon.komoot.io/api/'
        params = {'q': city, 'limit': 15}
        
        response = requests.get(photon_url, params=params, timeout=3)
        if response.ok:
            data = response.json()
            
            for feature in data.get('features', []):
                props = feature.get('properties', {})
                state = props.get('state', '')
                county = props.get('county', '')
                country = props.get('country', '')
                osm_key = props.get('osm_key', '')
                osm_value = props.get('osm_value', '')
                
                # Filter out POIs
                if osm_key not in ['place', 'boundary']:
                    continue
                valid_place_types = ['city', 'town', 'village', 'hamlet', 'suburb', 'neighbourhood', 'administrative', 'borough', 'quarter', 'district']
                if osm_key == 'place' and osm_value not in valid_place_types:
                    continue
                
                # Filter by Ukraine and oblast
                if (country == 'Україна' or country == 'Ukraine'):
                    # Check if state matches region_name
                    if region_name.lower() in state.lower() or state.lower() in region_name.lower():
                        coords_arr = feature.get('geometry', {}).get('coordinates', [])
                        if coords_arr and len(coords_arr) >= 2:
                            lng_val = safe_float(coords_arr[0])
                            lat_val = safe_float(coords_arr[1])
                            if lat_val is None or lng_val is None:
                                continue
                            if not validate_ukraine_coords(lat_val, lng_val):
                                continue
                            lat, lng = lat_val, lng_val
                            
                            # If district provided, prefer district match
                            if district:
                                county_lower = county.lower()
                                district_lower = district.lower()
                                
                                if district_lower in county_lower or county_lower.startswith(district_lower):
                                    print(f"DEBUG Groq+Photon: '{city}' in {county}, {state} (district match!) -> ({lat}, {lng})")
                                    return (lat, lng, False)
                                else:
                                    continue  # Keep looking for district match
                            
                            # No district filter or found oblast match
                            print(f"DEBUG Groq+Photon: '{city}' in {state} -> ({lat}, {lng})")
                            return (lat, lng, False)
        
    except Exception as e:
        print(f"DEBUG: geocode_with_context error: {e}")
    
    # FALLBACK: Try Nominatim if Photon failed
    if NOMINATIM_AVAILABLE and region_name:
        print(f"DEBUG geocode_with_context: Photon failed, trying Nominatim for '{city}' in {region_name}")
        nominatim_coords = get_coordinates_nominatim(city, region_name)
        if nominatim_coords:
            print(f"DEBUG Nominatim fallback: '{city}' in {region_name} -> {nominatim_coords}")
            return (nominatim_coords[0], nominatim_coords[1], False)
    
    return None

def extract_district_and_oblast_context(message_text: str):
    """Extract district (район) and oblast context from message.
    Returns dict with 'district', 'oblast_key', 'excluded_oblast'.
    
    Examples:
    - "БпЛА маневрує в районі Юріївки" -> Павлоградський район (from context)
    - "БпЛА в Покровському районі" -> Покровський район
    - "Дніпропетровщина: БпЛА..." -> Дніпропетровська область
    """
    if not message_text:
        return {'district': None, 'oblast_key': None, 'excluded_oblast': None}
    
    message_lower = message_text.lower()
    result = {'district': None, 'oblast_key': None, 'excluded_oblast': None}
    
    # Extract explicit district mentions
    # Pattern: "[назва] район", "в [назва] районі", "[назва]ський район"
    # BUT NOT: "в районі [село]" - this means "near [village]", not district name
    district_patterns = [
        r'([а-яїієґ]{3,}ськ(?:ий|ому|ого))\s+район',  # "павлоградський район" (min 3 chars before "ськ")
        r'([а-яїієґ]{3,})\s+район(?:і)?(?:\s|$)',      # "покровський район" (min 3 chars)
    ]
    
    # Don't extract "в районі X" as district - this means "near X"
    # Only extract explicit district names like "павлоградський район"
    
    for pattern in district_patterns:
        match = re.search(pattern, message_lower)
        if match:
            district = match.group(1).strip()
            
            # Skip common prepositions and short words
            skip_words = ['в', 'на', 'за', 'до', 'від', 'при', 'під', 'над', 'між', 'про', 'для']
            if district in skip_words or len(district) < 3:
                continue
            
            # Normalize district name
            if district.endswith('ому') or district.endswith('ого'):
                district = district[:-3] + 'ий'
            result['district'] = district
            print(f"DEBUG: Extracted district: '{district}'")
            break
    
    # Extract oblast (same logic as before)
    # Check for "з [область]" pattern - city is NOT in that oblast
    from_oblast_pattern = r'з\s+([а-яїіє]+щини|[а-яїіє]+ської\s+обл)'
    from_match = re.search(from_oblast_pattern, message_lower)
    if from_match:
        excluded = from_match.group(1).strip()
        result['excluded_oblast'] = excluded
    
    # Look for oblast mention in header or text
    oblast_patterns = [
        r'^([а-яїіє]+(?:ч)?чина|[а-яїіє]+щина|волинь):',  # "Хмельниччина:", "Вінниччина:", "Дніпропетровщина:", "Волинь:"
        r'([а-яїіє]+ська\s+обл\.?)',  # "Харківська обл."
        r'([а-яїіє]+ська\s+область)',  # "Полтавська область"
    ]
    
    for pattern in oblast_patterns:
        match = re.search(pattern, message_lower, re.MULTILINE)
        if match:
            oblast_mention = match.group(1).strip()
            
            # Normalize oblast names
            oblast_normalizations = {
                'харківщина': 'харківська обл.',
                'чернігівщина': 'чернігівська обл.',
                'полтавщина': 'полтавська область',
                'дніпропетровщина': 'дніпропетровська область',
                'сумщина': 'сумська область',
                'миколаївщина': 'миколаївська обл.',
                'одещина': 'одеська обл.',
                'запоріжжя': 'запорізька область',
                'херсонщина': 'херсонська обл.',
                'київщина': 'київська обл.',
                'черкащина': 'черкаська область',
                'вінниччина': 'вінницька область',
                'хмельниччина': 'хмельницька область',
                'тернопільщина': 'тернопільська область',
                'житомирщина': 'житомирська область',
                'волинь': 'волинська область',
                'донеччина': 'донецька область',
                'луганщина': 'луганська область',
            }
            
            if oblast_mention in oblast_normalizations:
                result['oblast_key'] = oblast_normalizations[oblast_mention]
            elif oblast_mention in OBLAST_CENTERS:
                result['oblast_key'] = oblast_mention
            
            break
    
    return result

def ensure_city_coords(name: str, region_hint: str = None):
    """Return (lat,lng,approx_bool) for settlement using Photon/Nominatim APIs.
    approx_bool True means we used oblast center fallback (low precision)."""
    if not name:
        return None
    n = name.strip().lower()
    
    # PRIORITY 0: Check UKRAINE_ALL_SETTLEMENTS first (26000+ entries, BEST coverage)
    if n in UKRAINE_ALL_SETTLEMENTS:
        coords = UKRAINE_ALL_SETTLEMENTS[n]
        return (coords[0], coords[1], False)
    
    # Apply UA_CITY_NORMALIZE before any lookups
    if n in UA_CITY_NORMALIZE:
        n = UA_CITY_NORMALIZE[n]
        print(f"DEBUG: Normalized '{name.lower()}' -> '{n}'")
        # Check again after normalization
        if n in UKRAINE_ALL_SETTLEMENTS:
            coords = UKRAINE_ALL_SETTLEMENTS[n]
            return (coords[0], coords[1], False)
    
    # Normalize Ukrainian city name declensions to nominative case
    # This fixes issues like "Тернівку" (accusative) -> "Тернівка" (nominative)
    # for consistent API geocoding results
    original_n = n
    if n.endswith('ку') and len(n) > 4:
        # Accusative ending: Тернівку -> Тернівка
        n = n[:-2] + 'ка'
    elif n.endswith('цю') and len(n) > 4:
        # Accusative ending: Вінницю -> Вінниця
        n = n[:-2] + 'ця'
    elif n.endswith('у') and len(n) > 3:
        # Check if it's likely accusative (not ending in consonant+у)
        if n[-2] in 'аеиоуяюєї':
            pass  # Likely nominative already (e.g., "Суму")
        else:
            # Try: Київу -> Київ, but preserve: Суму, Ромну (already nominative)
            test_form = n[:-1]
            # Only convert if it looks like a valid city name
            if test_form and test_form[-1] in 'вгджзклмнпрстфхцчшщ':
                n = test_form
    elif n.endswith('ові') and len(n) > 5:
        # Dative ending: Києву -> Київ
        n = n[:-3]
    elif n.endswith('ом') and len(n) > 4:
        # Instrumental ending: Київом -> Київ
        n = n[:-2]
    
    if n != original_n:
        print(f"DEBUG: Declension normalized '{original_n}' -> '{n}'")
    
    # PRIORITY FIX: Check for "City + Oblast" pattern (e.g., "Вилково Одещини")
    # Split on space and check if we have both a city and oblast
    words = n.split()
    region_context = None
    if len(words) >= 2:
        # Try first word as city (with normalization)
        potential_city = words[0]
        if potential_city in UA_CITY_NORMALIZE:
            potential_city = UA_CITY_NORMALIZE[potential_city]
        
        potential_oblast = ' '.join(words[1:])
        
        # Check if remaining words match an oblast
        if potential_oblast in OBLAST_CENTERS or any(potential_oblast in oblast_key for oblast_key in OBLAST_CENTERS.keys()):
            # This is "City+Oblast" pattern - extract region for API query
            n = potential_city
            region_context = potential_oblast
            print(f"DEBUG: Found 'City+Oblast' pattern: '{potential_city}' + '{potential_oblast}' -> will search API with region filter")
    
    # Check if it's a direct oblast/region name
    if n in OBLAST_CENTERS:
        lat,lng = OBLAST_CENTERS[n]; return (lat,lng,True)
    if 'SETTLEMENTS_INDEX' in globals() and n in (globals().get('SETTLEMENTS_INDEX') or {}):
        lat,lng = globals()['SETTLEMENTS_INDEX'][n]; return (lat,lng,False)
    
    # Use Photon API (supports Cyrillic, fast, finds villages)
    try:
        import requests
        
        # Get region hint from explicit parameter, extracted context, or NAME_REGION_MAP
        region_hint = region_hint or region_context or NAME_REGION_MAP.get(n)
        if isinstance(region_hint, str):
            region_hint = region_hint.lower()
        
        # Try Photon first (supports Cyrillic)
        photon_url = 'https://photon.komoot.io/api/'
        photon_params = {'q': n, 'limit': 10}
        
        photon_response = requests.get(photon_url, params=photon_params, timeout=3)
        if photon_response.ok:
            photon_data = photon_response.json()
            for feature in photon_data.get('features', []):
                props = feature.get('properties', {})
                state = props.get('state', '')
                country = props.get('country', '')
                osm_key = props.get('osm_key', '')
                osm_value = props.get('osm_value', '')
                
                # Filter out POIs and tourism - only settlements
                if osm_key not in ['place', 'boundary']:
                    continue
                valid_place_types = ['city', 'town', 'village', 'hamlet', 'suburb', 'neighbourhood', 'administrative']
                if osm_key == 'place' and osm_value not in valid_place_types:
                    continue
                
                # Filter by Ukraine
                if country in ['Україна', 'Ukraine']:
                    # If we have region hint, filter by it
                    if region_hint:
                        if region_hint in state.lower() or state.lower() in region_hint:
                            coords_arr = feature.get('geometry', {}).get('coordinates', [])
                            if coords_arr and len(coords_arr) >= 2:
                                lng_val = safe_float(coords_arr[0])
                                lat_val = safe_float(coords_arr[1])
                                if lat_val is not None and lng_val is not None and validate_ukraine_coords(lat_val, lng_val):
                                    print(f"DEBUG Photon: Found '{n}' in {state} -> ({lat_val}, {lng_val})")
                                    return (lat_val, lng_val, False)
                    else:
                        # No region hint, use first Ukraine result
                        coords_arr = feature.get('geometry', {}).get('coordinates', [])
                        if coords_arr and len(coords_arr) >= 2:
                            lng_val = safe_float(coords_arr[0])
                            lat_val = safe_float(coords_arr[1])
                            if lat_val is not None and lng_val is not None and validate_ukraine_coords(lat_val, lng_val):
                                print(f"DEBUG Photon: Found '{n}' in {state} -> ({lat_val}, {lng_val})")
                                return (lat_val, lng_val, False)
        
        # Fallback to Nominatim with transliteration
        def transliterate_ua_to_latin(text):
            translit_map = {
                'а': 'a', 'б': 'b', 'в': 'v', 'г': 'h', 'ґ': 'g', 'д': 'd', 'е': 'e', 'є': 'ye',
                'ж': 'zh', 'з': 'z', 'и': 'y', 'і': 'i', 'ї': 'yi', 'й': 'y', 'к': 'k', 'л': 'l',
                'м': 'm', 'н': 'n', 'о': 'o', 'п': 'p', 'р': 'r', 'с': 's', 'т': 't', 'у': 'u',
                'ф': 'f', 'х': 'kh', 'ц': 'ts', 'ч': 'ch', 'ш': 'sh', 'щ': 'shch', 'ь': '', 'ю': 'yu', 'я': 'ya',
                'А': 'A', 'Б': 'B', 'В': 'V', 'Г': 'H', 'Ґ': 'G', 'Д': 'D', 'Е': 'E', 'Є': 'Ye',
                'Ж': 'Zh', 'З': 'Z', 'И': 'Y', 'І': 'I', 'Ї': 'Yi', 'Й': 'Y', 'К': 'K', 'Л': 'L',
                'М': 'M', 'Н': 'N', 'О': 'O', 'П': 'P', 'Р': 'R', 'С': 'S', 'Т': 'T', 'У': 'U',
                'Ф': 'F', 'Х': 'Kh', 'Ц': 'Ts', 'Ч': 'Ch', 'Ш': 'Sh', 'Щ': 'Shch', 'Ь': '', 'Ю': 'Yu', 'Я': 'Ya'
            }
            return ''.join(translit_map.get(c, c) for c in text)
        
        name_latin = transliterate_ua_to_latin(n)
        nominatim_url = 'https://nominatim.openstreetmap.org/search'
        params = {'q': f'{name_latin}, Ukraine', 'format': 'json', 'limit': 5, 'addressdetails': 1}
        headers = {'User-Agent': 'NeptunAlarmMap/1.0 (https://neptun.in.ua)'}
        
        response = requests.get(nominatim_url, params=params, headers=headers, timeout=4)
        if response.ok:
            results = response.json()
            if not isinstance(results, list):
                results = []
            for result in results:
                if not isinstance(result, dict):
                    continue
                if region_hint:
                    address = result.get('address', {})
                    result_state = address.get('state', '')
                    if region_hint in result_state.lower() or result_state.lower() in region_hint:
                        lat_val = safe_float(result.get('lat'))
                        lng_val = safe_float(result.get('lon'))
                        if lat_val is not None and lng_val is not None and validate_ukraine_coords(lat_val, lng_val):
                            print(f"DEBUG Nominatim: Found '{n}' -> '{name_latin}' in {result_state} -> ({lat_val}, {lng_val})")
                            return (lat_val, lng_val, False)
                else:
                    # No region hint, use first valid result
                    lat_val = safe_float(result.get('lat'))
                    lng_val = safe_float(result.get('lon'))
                    if lat_val is not None and lng_val is not None and validate_ukraine_coords(lat_val, lng_val):
                        print(f"DEBUG Nominatim: Found '{n}' -> '{name_latin}' -> ({lat_val}, {lng_val})")
                        return (lat_val, lng_val, False)
    except Exception as e:
        print(f"DEBUG: Geocoding error for '{name}': {e}")
    
    # Approximate fallback: oblast center (if region hint matches an oblast name substring)
    if region_hint:
        reg_low = region_hint.lower()
        for oblast_key, (olat, olng) in OBLAST_CENTERS.items():
            if oblast_key in reg_low:
                return (olat, olng, True)
    return None

def ensure_city_coords_with_message_context(name: str, message_text: str = ""):
    """Enhanced version that tries to extract oblast from message if city not found.
    Returns (lat,lng,approx_bool) - approx_bool True means used oblast fallback."""
    
    # Normalize name for lookup
    name_lower = name.strip().lower()
    
    # PRIORITY 0: If message contains explicit oblast, try Nominatim API FIRST
    # This prevents returning wrong coordinates from local dictionaries for cities
    # with duplicate names in different oblasts (e.g., Радушне in Миколаївська vs Дніпропетровська)
    if message_text:
        message_lower = message_text.lower()
        
        # Direct oblast name patterns - maps text patterns to nominatim region names
        direct_oblast_patterns = {
            'київська область': 'Київська',
            'київська обл': 'Київська',
            'харківська область': 'Харківська',
            'харківська обл': 'Харківська',
            'чернігівська область': 'Чернігівська',
            'чернігівська обл': 'Чернігівська',
            'сумська область': 'Сумська',
            'сумська обл': 'Сумська',
            'полтавська область': 'Полтавська',
            'полтавська обл': 'Полтавська',
            'дніпропетровська область': 'Дніпропетровська',
            'дніпропетровська обл': 'Дніпропетровська',
            'миколаївська область': 'Миколаївська',
            'миколаївська обл': 'Миколаївська',
            'одеська область': 'Одеська',
            'одеська обл': 'Одеська',
            'херсонська область': 'Херсонська',
            'херсонська обл': 'Херсонська',
            'запорізька область': 'Запорізька',
            'запорізька обл': 'Запорізька',
            'черкаська область': 'Черкаська',
            'черкаська обл': 'Черкаська',
            'житомирська область': 'Житомирська',
            'житомирська обл': 'Житомирська',
            'вінницька область': 'Вінницька',
            'вінницька обл': 'Вінницька',
            'донецька область': 'Донецька',
            'донецька обл': 'Донецька',
            'луганська область': 'Луганська',
            'луганська обл': 'Луганська',
            'кіровоградська область': 'Кіровоградська',
            'кіровоградська обл': 'Кіровоградська',
            'рівненська область': 'Рівненська',
            'рівненська обл': 'Рівненська',
            'волинська область': 'Волинська',
            'волинська обл': 'Волинська',
            'львівська область': 'Львівська',
            'львівська обл': 'Львівська',
            'тернопільська область': 'Тернопільська',
            'тернопільська обл': 'Тернопільська',
            'хмельницька область': 'Хмельницька',
            'хмельницька обл': 'Хмельницька',
            'івано-франківська область': 'Івано-Франківська',
            'івано-франківська обл': 'Івано-Франківська',
            'закарпатська область': 'Закарпатська',
            'закарпатська обл': 'Закарпатська',
            'чернівецька область': 'Чернівецька',
            'чернівецька обл': 'Чернівецька',
        }
        
        explicit_oblast = None
        for pattern, oblast_key in direct_oblast_patterns.items():
            if pattern in message_lower:
                explicit_oblast = oblast_key
                print(f"DEBUG GEOLOOKUP: Found explicit oblast '{pattern}' -> '{oblast_key}' for city '{name}'")
                break
        
        if explicit_oblast and NOMINATIM_AVAILABLE:
            # Try Nominatim API with explicit oblast filtering FIRST
            print(f"DEBUG GEOLOOKUP: Trying Nominatim for '{name}' in {explicit_oblast} oblast")
            coords = get_coordinates_nominatim(name_lower, explicit_oblast)
            if coords:
                print(f"DEBUG GEOLOOKUP: Nominatim found '{name}' in {explicit_oblast} -> {coords}")
                return (coords[0], coords[1], False)
            else:
                print(f"DEBUG GEOLOOKUP: Nominatim could not find '{name}' in {explicit_oblast}")
    
    # PRIORITY 1: Check UKRAINE_ALL_SETTLEMENTS (26000+ entries, BEST coverage)
    # Only if no explicit oblast in message or API failed
    if name_lower in UKRAINE_ALL_SETTLEMENTS:
        coords = UKRAINE_ALL_SETTLEMENTS[name_lower]
        return (coords[0], coords[1], False)
    
    # Also check CITY_COORDS for legacy entries
    if name_lower in CITY_COORDS:
        coords = CITY_COORDS[name_lower]
        if len(coords) >= 2:
            return (coords[0], coords[1], False)
    
    # PRIORITY 2: If message_text contains explicit oblast name, try Photon API
    # This handles cases like "Київська область: БпЛА курсом на Димер"
    if message_text:
        # Re-use message_lower from above
        message_lower = message_text.lower()
        
        # Direct oblast name patterns for Photon
        direct_oblast_patterns_photon = {
            'київська область': 'київська обл.',
            'київська обл': 'київська обл.',
            'харківська область': 'харківська обл.',
            'харківська обл': 'харківська обл.',
            'чернігівська область': 'чернігівська обл.',
            'чернігівська обл': 'чернігівська обл.',
            'сумська область': 'сумська область',
            'сумська обл': 'сумська область',
            'полтавська область': 'полтавська область',
            'полтавська обл': 'полтавська область',
            'дніпропетровська область': 'дніпропетровська область',
            'дніпропетровська обл': 'дніпропетровська область',
            'миколаївська область': 'миколаївська обл.',
            'миколаївська обл': 'миколаївська обл.',
            'одеська область': 'одеська обл.',
            'одеська обл': 'одеська обл.',
            'херсонська область': 'херсонська обл.',
            'херсонська обл': 'херсонська обл.',
            'запорізька область': 'запорізька область',
            'запорізька обл': 'запорізька область',
            'черкаська область': 'черкаська область',
            'черкаська обл': 'черкаська область',
            'житомирська область': 'житомирська область',
            'житомирська обл': 'житомирська область',
            'вінницька область': 'вінницька область',
            'вінницька обл': 'вінницька область',
            'донецька область': 'донецька область',
            'донецька обл': 'донецька область',
            'луганська область': 'луганська область',
            'луганська обл': 'луганська область',
        }
        
        explicit_oblast_photon = None
        for pattern, oblast_key in direct_oblast_patterns_photon.items():
            if pattern in message_lower:
                explicit_oblast_photon = oblast_key
                break
        
        if explicit_oblast_photon:
            # Try Photon API with explicit oblast filtering
            try:
                import requests
                
                oblast_to_region_map = {
                    'харківська обл.': 'Харківська область',
                    'чернігівська обл.': 'Чернігівська область',
                    'полтавська область': 'Полтавська область',
                    'дніпропетровська область': 'Дніпропетровська область',
                    'сумська область': 'Сумська область',
                    'миколаївська обл.': 'Миколаївська область',
                    'одеська обл.': 'Одеська область',
                    'запорізька область': 'Запорізька область',
                    'херсонська обл.': 'Херсонська область',
                    'київська обл.': 'Київська область',
                    'черкаська область': 'Черкаська область',
                    'вінницька область': 'Вінницька область',
                    'житомирська область': 'Житомирська область',
                    'донецька область': 'Донецька область',
                    'луганська область': 'Луганська область',
                }
                
                region_name = oblast_to_region_map.get(explicit_oblast)
                
                if region_name:
                    # Normalize city name first
                    name_normalized = name.strip().lower()
                    if name_normalized.endswith('ку') and len(name_normalized) > 4:
                        name_normalized = name_normalized[:-2] + 'ка'
                    elif name_normalized.endswith('у') and len(name_normalized) > 3:
                        name_normalized = name_normalized[:-1] + 'а'
                    
                    photon_url = 'https://photon.komoot.io/api/'
                    params = {'q': name_normalized, 'limit': 10}
                    
                    response = requests.get(photon_url, params=params, timeout=3)
                    if response.ok:
                        data = response.json()
                        
                        for feature in data.get('features', []):
                            props = feature.get('properties', {})
                            state = props.get('state', '')
                            country = props.get('country', '')
                            osm_key = props.get('osm_key', '')
                            osm_value = props.get('osm_value', '')
                            
                            # Filter: only settlements in Ukraine
                            if osm_key not in ['place', 'boundary']:
                                continue
                            valid_types = ['city', 'town', 'village', 'hamlet', 'suburb', 'neighbourhood', 'administrative']
                            if osm_key == 'place' and osm_value not in valid_types:
                                continue
                            
                            if (country == 'Україна' or country == 'Ukraine') and region_name in state:
                                coords_arr = feature.get('geometry', {}).get('coordinates', [])
                                if coords_arr and len(coords_arr) >= 2:
                                    lng_val = safe_float(coords_arr[0])
                                    lat_val = safe_float(coords_arr[1])
                                    if lat_val is not None and lng_val is not None and validate_ukraine_coords(lat_val, lng_val):
                                        print(f"DEBUG: Photon EXPLICIT OBLAST: '{name}' in {state} -> ({lat_val}, {lng_val})")
                                        return (lat_val, lng_val, False)
            except Exception as e:
                print(f"DEBUG: Explicit oblast geocoding error: {e}")
    
    # PRIORITY 1: Try Groq AI for intelligent context understanding
    if GROQ_ENABLED and message_text:
        try:
            ai_result = extract_location_with_groq_ai(message_text)
            if ai_result and ai_result.get('confidence', 0) > 0.7:
                ai_city = ai_result.get('city')
                ai_district = ai_result.get('district')
                ai_oblast = ai_result.get('oblast')
                
                # Use AI-extracted city name if provided and confident
                if ai_city:
                    target_city = ai_city.lower()
                    print(f"DEBUG Groq: Using AI-extracted city '{target_city}' (confidence: {ai_result['confidence']})")
                    
                    # Try geocoding with AI-provided context (oblast as-is, geocode_with_context normalizes it)
                    if ai_oblast:
                        coords = geocode_with_context(target_city, ai_oblast, ai_district)
                        if coords:
                            return coords
                    
                    # Fallback to basic geocoding with AI city name and oblast hint
                    oblast_hint = ai_oblast.lower() if ai_oblast else None
                    coords = ensure_city_coords(target_city, oblast_hint)
                    if coords:
                        return coords
                        
        except Exception as e:
            print(f"DEBUG: Groq AI geocoding attempt failed: {e}")
            # Continue to fallback methods
    
    # PRIORITY 2: Original declension normalization and processing
    # Normalize Ukrainian city name declensions FIRST
    original_name = name
    name_lower = name.strip().lower()
    
    # Normalize declensions to nominative case for consistent API results
    if name_lower.endswith('ку') and len(name_lower) > 4:
        name_lower = name_lower[:-2] + 'ка'
    elif name_lower.endswith('цю') and len(name_lower) > 4:
        name_lower = name_lower[:-2] + 'ця'
    elif name_lower.endswith('у') and len(name_lower) > 3:
        if name_lower[-2] not in 'аеиоуяюєї' and name_lower[-2] in 'вгджзклмнпрстфхцчшщ':
            name_lower = name_lower[:-1]
    elif name_lower.endswith('ові') and len(name_lower) > 5:
        name_lower = name_lower[:-3]
    elif name_lower.endswith('ом') and len(name_lower) > 4:
        name_lower = name_lower[:-2]
    
    if name_lower != original_name.lower():
        print(f"DEBUG: Declension '{original_name}' -> '{name_lower}'")
        name = name_lower  # Update name for further processing
    
    # PRIORITY: Try SpaCy first if available
    if SPACY_AVAILABLE and message_text:
        try:
            spacy_results = spacy_enhanced_geocoding(message_text)
            
            # Look for the specific city we're searching for
            name_lower = name.lower()
            for result in spacy_results:
                if (result['normalized'] == name_lower or 
                    result['name'].lower() == name_lower):
                    if result['coords']:
                        lat, lng = result['coords']
                        print(f"DEBUG SpaCy: Found {name} via SpaCy -> ({lat}, {lng})")
                        return (lat, lng, False)  # Not approximate since SpaCy found exact match
            
        except Exception as e:
            print(f"DEBUG SpaCy fallback error: {e}")
            # Continue to regex-based processing
    
    # FALLBACK: Original regex-based processing
    
    # SMART CONTEXT EXTRACTION: Extract district and oblast from message
    context = extract_district_and_oblast_context(message_text)
    district_hint = context.get('district')
    detected_oblast_key = context.get('oblast_key')
    excluded_oblast = context.get('excluded_oblast')
    
    # Legacy oblast detection (kept for backward compatibility)
    # Initialize detected_oblast_key at function scope
    detected_oblast_key = None
    from_region_hint = None  # Additional region hint from "з [область]" pattern
    
    # First, if we have message text, try to extract oblast info and build specific city keys
    if message_text:
        message_lower = message_text.lower()
        
        # Check for "з [область]" pattern - use as ADDITIONAL region hint (not exclusion)
        # Example: "БпЛА на Юріївку з Харківщини" - Yuriivka is likely IN Kharkiv region
        from_oblast_pattern = r'з\s+([а-яїіє]+щини|[а-яїіє]+ської\s+обл)'
        from_match = re.search(from_oblast_pattern, message_lower)
        if from_match:
            from_region = from_match.group(1).strip()
            # Normalize to oblast name
            if from_region.endswith('щини'):
                from_region = from_region[:-1]  # миколаївщини -> миколаївщин
            if from_region.endswith('н'):
                from_region = from_region[:-1] + 'на'  # миколаївщин -> миколаївщина
            
            # Map to oblast key
            from_region_map = {
                'миколаївщина': 'миколаївська',
                'одещина': 'одеська', 
                'херсонщина': 'херсонська',
                'дніпропетровщина': 'дніпропетровська',
                'харківщина': 'харківська',
                'сумщина': 'сумська',
                'чернігівщина': 'чернігівська',
                'полтавщина': 'полтавська',
            }
            from_region_hint = from_region_map.get(from_region)
            if from_region_hint:
                print(f"DEBUG: Found 'з {from_region}' pattern - using {from_region_hint} oblast as region hint for '{name}'")
        
        # ENHANCED: Find the closest oblast to the specific city name
        city_pos = message_lower.find(name.lower())
        if city_pos != -1:
            # Look for oblast in close proximity to the city (within 100 characters before/after)
            start_pos = max(0, city_pos - 100)
            end_pos = min(len(message_lower), city_pos + len(name) + 100)
            context = message_lower[start_pos:end_pos]
            
            # PRIORITY: Check for oblast at the START of the line with colon (e.g., "Дніпропетровщина: БпЛА...")
            # This is most reliable indicator in multi-region messages
            line_start_oblast = re.match(r'^([а-яїіє]+щина|[а-яїіє]+ська\s+обл(?:\.|асть)?):?\s+', context.lstrip())
            if line_start_oblast:
                match = line_start_oblast.group(1).strip().lower()
                add_debug_log(f"OBLAST CONTEXT: Found line-start oblast '{match}' for city '{name}'", "oblast_line_start")
            else:
                # Enhanced regional context detection - try parenthetical oblast first
                oblast_patterns = [
                    # Parenthetical oblast: "(Oblast обл.)" - most specific
                    r'\(([^)]+)\s+обл\.\)',
                    r'\(([^)]+)\s+область\)',
                    # Oblast adjective forms: "харківська обл."
                    r'\b([а-яїіє]+ська)\s+обл(?:\.|асть)?\b',
                    r'\b([а-яїіє]+цька)\s+обл(?:\.|асть)?\b', 
                    # Regional names: "харківщина", "полтавщина", etc.
                    r'\b([а-яїіє]+щина)\b',
                    r'\b([а-яїіє]+щині)\b',
                    r'\b([а-яїіє]+щину)\b',
                    # Additional patterns for regional context
                    r'\bна\s+([а-яїіє]+щині)\b',  # "на Сумщині"
                    r'\bу\s+([а-яїіє]+щині)\b',   # "у Сумщині"
                    r'\bв\s+([а-яїіє]+щині)\b',   # "в Сумщині"
                ]
                
                match = None
                for pattern in oblast_patterns:
                    matches = re.findall(pattern, context)  # Search in context, not full message
                    if matches:
                        match = matches[0].strip().lower()
                        break
            
            if match:
                # Normalize regional names to nominative case AND adjective form
                if match.endswith('щині'):
                    match = match[:-2] + 'на'  # сумщині -> сумщина
                elif match.endswith('щину'):
                    match = match[:-2] + 'на'  # сумщину -> сумщина
                
                # Convert regional names to adjective forms for city lookup
                regional_to_adjective = {
                    'сумщина': 'сумська',
                    'харківщина': 'харківська',
                    'чернігівщина': 'чернігівська',
                    'полтавщина': 'полтавська',
                    'дніпропетровщина': 'дніпропетровська',
                    'херсонщина': 'херсонська',
                    'миколаївщина': 'миколаївська',
                    'одещина': 'одеська',
                    'київщина': 'київська',
                    'житомирщина': 'житомирська',
                    'рівненщина': 'рівненська',
                }
                
                if match in regional_to_adjective:
                    match = regional_to_adjective[match]
                
                # Priority: use from_region_hint if present (from "з [область]" pattern)
                if from_region_hint:
                    print(f"DEBUG: Prioritizing 'з [область]' hint: {from_region_hint} for city '{name}'")
                    match = from_region_hint
                
                if match:  # Only process if we have a valid match
                    # Create possible city+oblast combinations to search
                    city_variants = [
                        f"{name.lower()}({match})",  # миколаївка(сумська)
                        f"{name.lower()} ({match})",  # миколаївка (сумська)
                        f"{name.lower()} {match}",
                        f"{name.lower()} {match} обл.",
                        f"{name.lower()} {match} область",
                    ]
                    
                    print(f"DEBUG: Checking variants for {name} with oblast {match}: trying API with region filter")
                    
                    # Store oblast key for potential fallback
                    oblast_normalizations = {
                        'харківська': 'харківська обл.',
                        'чернігівська': 'чернігівська обл.',
                        'полтавська': 'полтавська область',
                        'дніпропетровська': 'дніпропетровська область',
                        'сумська': 'сумська область',
                        'миколаївська': 'миколаївська обл.',
                        'одеська': 'одеська обл.',
                        'запорізька': 'запорізька область',
                        'херсонська': 'херсонська обл.',
                        'київська': 'київська обл.',
                        'черкаська': 'черкаська область',
                        'вінницька': 'вінницька область',
                        'харківщина': 'харківська обл.',
                        'чернігівщина': 'чернігівська обл.',
                        'полтавщина': 'полтавська область',
                        'дніпропетровщина': 'дніпропетровська область',
                        'сумщина': 'сумська область',
                        'миколаївщина': 'миколаївська обл.',
                        'одещина': 'одеська обл.',
                        'запоріжжя': 'запорізька область',
                        'херсонщина': 'херсонська обл.',
                        'київщина': 'київська обл.',
                        'черкащина': 'черкаська область',
                        'вінниччина': 'вінницька область',
                    }
                    
                    if match in oblast_normalizations:
                        detected_oblast_key = oblast_normalizations[match]
                    elif match in OBLAST_CENTERS:
                        detected_oblast_key = match
    
    # CRITICAL: Try Photon API with region filtering for multi-regional cities
    # This handles cases like "Ольшанське" which exists in multiple oblasts
    if detected_oblast_key and message_text:
        try:
            import requests
            
            # Map oblast key to region name for API filtering
            oblast_to_region_map = {
                'харківська обл.': 'Харківська область',
                'чернігівська обл.': 'Чернігівська область',
                'полтавська область': 'Полтавська область',
                'дніпропетровська область': 'Дніпропетровська область',
                'сумська область': 'Сумська область',
                'миколаївська обл.': 'Миколаївська область',
                'одеська обл.': 'Одеська область',
                'запорізька область': 'Запорізька область',
                'херсонська обл.': 'Херсонська область',
                'київська обл.': 'Київська область',
                'черкаська область': 'Черкаська область',
                'вінницька область': 'Вінницька область',
                'хмельницька область': 'Хмельницька область',
                'житомирська область': 'Житомирська область',
                'рівненська область': 'Рівненська область',
                'волинська область': 'Волинська область',
                'львівська область': 'Львівська область',
                'тернопільська область': 'Тернопільська область',
                'івано-франківська область': 'Івано-Франківська область',
                'закарпатська область': 'Закарпатська область',
                'чернівецька область': 'Чернівецька область',
            }
            
            region_name = oblast_to_region_map.get(detected_oblast_key)
            
            # Try Photon API first (fastest and most reliable for Ukrainian cities)
            photon_url = 'https://photon.komoot.io/api/'
            params = {
                'q': name,
                'limit': 10  # Get multiple results to filter by region
            }
            
            response = requests.get(photon_url, params=params, timeout=3)
            if response.ok:
                data = response.json()
                best_match = None
                district_match = None
                
                for feature in data.get('features', []):
                    props = feature.get('properties', {})
                    state = props.get('state', '')
                    county = props.get('county', '')  # district/район
                    country = props.get('country', '')
                    osm_key = props.get('osm_key', '')
                    osm_value = props.get('osm_value', '')
                    
                    # Filter out POIs - only settlements
                    if osm_key not in ['place', 'boundary']:
                        continue
                    valid_place_types = ['city', 'town', 'village', 'hamlet', 'suburb', 'neighbourhood', 'administrative']
                    if osm_key == 'place' and osm_value not in valid_place_types:
                        continue
                    
                    # Filter by Ukraine and detected region
                    if (country == 'Україна' or country == 'Ukraine'):
                        # Check if state matches detected oblast
                        if region_name and region_name in state:
                            coords_arr = feature.get('geometry', {}).get('coordinates', [])
                            if coords_arr and len(coords_arr) >= 2:
                                lng_val = safe_float(coords_arr[0])
                                lat_val = safe_float(coords_arr[1])
                                if lat_val is None or lng_val is None:
                                    continue
                                if not validate_ukraine_coords(lat_val, lng_val):
                                    continue
                                lat, lng = lat_val, lng_val
                                
                                # PRIORITY: If district hint exists, check if it matches
                                if district_hint:
                                    county_lower = county.lower()
                                    district_lower = district_hint.lower()
                                    
                                    # Normalize both for comparison
                                    # "Павлоградський район" should match "павлоградський"
                                    if district_lower in county_lower or county_lower.startswith(district_lower):
                                        print(f"DEBUG: Photon API found '{name}' in {county}, {state} (district match!) -> ({lat}, {lng})")
                                        return (lat, lng, False)
                                    else:
                                        # Store as potential match but keep looking for district match
                                        if not district_match:
                                            district_match = (lat, lng)
                                        continue
                                
                                # No district hint or no match yet - use this result
                                if not best_match:
                                    best_match = (lat, lng)
                                    print(f"DEBUG: Photon API found '{name}' in {state} -> ({lat}, {lng})")
                
                # Return best match (district match preferred, then first oblast match)
                if district_match:
                    return (district_match[0], district_match[1], False)
                if best_match:
                    return (best_match[0], best_match[1], False)
            
            # Fallback to Nominatim API if Photon didn't find the city
            # NOTE: Nominatim doesn't support Cyrillic in query, need transliteration
            if region_name:
                # Transliterate to Latin for Nominatim (it rejects Cyrillic with HTTP 400)
                def transliterate_ua_to_latin(text):
                    """Ukrainian to Latin transliteration for Nominatim API"""
                    translit_map = {
                        'а': 'a', 'б': 'b', 'в': 'v', 'г': 'h', 'ґ': 'g', 'д': 'd', 'е': 'e', 'є': 'ye',
                        'ж': 'zh', 'з': 'z', 'и': 'y', 'і': 'i', 'ї': 'yi', 'й': 'y', 'к': 'k', 'л': 'l',
                        'м': 'm', 'н': 'n', 'о': 'o', 'п': 'p', 'р': 'r', 'с': 's', 'т': 't', 'у': 'u',
                        'ф': 'f', 'х': 'kh', 'ц': 'ts', 'ч': 'ch', 'ш': 'sh', 'щ': 'shch', 'ь': '', 'ю': 'yu', 'я': 'ya',
                        'А': 'A', 'Б': 'B', 'В': 'V', 'Г': 'H', 'Ґ': 'G', 'Д': 'D', 'Е': 'E', 'Є': 'Ye',
                        'Ж': 'Zh', 'З': 'Z', 'И': 'Y', 'І': 'I', 'Ї': 'Yi', 'Й': 'Y', 'К': 'K', 'Л': 'L',
                        'М': 'M', 'Н': 'N', 'О': 'O', 'П': 'P', 'Р': 'R', 'С': 'S', 'Т': 'T', 'У': 'U',
                        'Ф': 'F', 'Х': 'Kh', 'Ц': 'Ts', 'Ч': 'Ch', 'Ш': 'Sh', 'Щ': 'Shch', 'Ь': '', 'Ю': 'Yu', 'Я': 'Ya'
                    }
                    return ''.join(translit_map.get(c, c) for c in text)
                
                name_latin = transliterate_ua_to_latin(name)
                
                nominatim_url = 'https://nominatim.openstreetmap.org/search'
                params = {
                    'q': f'{name_latin}, Ukraine',
                    'format': 'json',
                    'limit': 5,
                    'addressdetails': 1
                }
                headers = {
                    'User-Agent': 'NeptunAlarmMap/1.0 (https://neptun-alarm.onrender.com)'
                }
                
                response = requests.get(nominatim_url, params=params, headers=headers, timeout=4)
                if response.ok:
                    results = response.json()
                    if not isinstance(results, list):
                        results = []
                    for result in results:
                        if not isinstance(result, dict):
                            continue
                        # Verify it's in the correct oblast
                        address = result.get('address', {})
                        result_state = address.get('state', '')
                        
                        if region_name in result_state or result_state in region_name:
                            lat_val = safe_float(result.get('lat'))
                            lng_val = safe_float(result.get('lon'))
                            if lat_val is None or lng_val is None:
                                continue
                            if not validate_ukraine_coords(lat_val, lng_val):
                                continue
                            display_name = result.get('display_name', '')
                            print(f"DEBUG: Nominatim API found '{name}' -> '{name_latin}' in {result_state} -> ({lat_val}, {lng_val})")
                            return (lat_val, lng_val, False)
        except Exception as e:
            print(f"DEBUG: Multi-regional API lookup error: {e}")
    
    # Second try: standard city lookup via API (without oblast context but with excluded_oblast filter)
    try:
        import requests
        
        # Try Photon API (supports Cyrillic)
        photon_url = 'https://photon.komoot.io/api/'
        photon_params = {'q': name, 'limit': 10}
        
        photon_response = requests.get(photon_url, params=photon_params, timeout=3)
        if photon_response.ok:
            photon_data = photon_response.json()
            
            # Military context priority: if message contains UAV/shahed keywords,
            # prioritize oblasts closer to frontline (Dnipropetrovska, Donetska, Zaporizka, Khersonska)
            military_keywords = ['бпла', 'шахед', 'shahed', 'дрон', 'курс', 'напрямок']
            is_military_context = any(kw in message_text.lower() for kw in military_keywords) if message_text else False
            frontline_oblasts = ['дніпропетровська', 'донецька', 'запорізька', 'херсонська', 'миколаївська', 'харківська', 'луганська']
            
            # Collect all results
            ukraine_results = []
            for feature in photon_data.get('features', []):
                props = feature.get('properties', {})
                state = props.get('state', '')
                country = props.get('country', '')
                osm_key = props.get('osm_key', '')
                osm_value = props.get('osm_value', '')
                
                # CRITICAL: Filter out POIs and tourism objects - only accept actual settlements
                # This fixes issue where "Тернівка" matched tourism POI "Красивый вид на Терновку" in Crimea
                if osm_key not in ['place', 'boundary']:
                    continue  # Skip tourism, amenity, etc.
                
                # Only accept settlement types
                valid_place_types = ['city', 'town', 'village', 'hamlet', 'suburb', 'neighbourhood', 'administrative']
                if osm_key == 'place' and osm_value not in valid_place_types:
                    continue
                
                if country in ['Україна', 'Ukraine']:
                    # If we have excluded_oblast, skip results from that oblast
                    if excluded_oblast and excluded_oblast in state.lower():
                        print(f"DEBUG: Skipping Photon result in excluded oblast: {state}")
                        continue
                    
                    coords_arr = feature.get('geometry', {}).get('coordinates', [])
                    if coords_arr and len(coords_arr) >= 2:
                        lng_val = safe_float(coords_arr[0])
                        lat_val = safe_float(coords_arr[1])
                        if lat_val is None or lng_val is None:
                            continue
                        if not validate_ukraine_coords(lat_val, lng_val):
                            continue
                        
                        # Check if this is a frontline oblast
                        is_frontline = any(oblast in state.lower() for oblast in frontline_oblasts)
                        
                        ukraine_results.append({
                            'lat': lat_val,
                            'lng': lng_val,
                            'state': state,
                            'is_frontline': is_frontline
                        })
            
            # Select best result based on context
            if ukraine_results:
                # If military context, prioritize frontline oblasts
                if is_military_context:
                    frontline_results = [r for r in ukraine_results if r['is_frontline']]
                    if frontline_results:
                        best = frontline_results[0]
                        print(f"DEBUG Photon (military priority): Found '{name}' in {best['state']} -> ({best['lat']}, {best['lng']})")
                        return (best['lat'], best['lng'], False)
                
                # Otherwise use first result
                best = ukraine_results[0]
                print(f"DEBUG Photon: Found '{name}' in {best['state']} (excluded={excluded_oblast}) -> ({best['lat']}, {best['lng']})")
                return (best['lat'], best['lng'], False)
    except Exception as e:
        print(f"DEBUG: Photon fallback error: {e}")
    
    # Try ensure_city_coords as final fallback
    result = ensure_city_coords(name, detected_oblast_key.lower() if isinstance(detected_oblast_key, str) else None)
    if result:
        return result
    

    
    # Third try: if we have oblast key, return oblast center as fallback
    if message_text and detected_oblast_key and detected_oblast_key in OBLAST_CENTERS:
        lat, lng = OBLAST_CENTERS[detected_oblast_key]
        print(f"DEBUG: Using oblast center fallback for {name}: {detected_oblast_key} -> ({lat}, {lng})")
        return (lat, lng, True)  # True indicates this is an oblast fallback
    
    return None

def normalize_ukrainian_toponym(lemmatized_name: str, original_text: str, grammatical_case: str = None) -> str:
    """
    Universal normalization for Ukrainian place names using linguistic patterns
    
    Args:
        lemmatized_name: SpaCy lemmatized form
        original_text: Original text from message
        grammatical_case: Grammatical case detected by SpaCy (Nom, Gen, Acc, etc.)
        
    Returns:
        Properly normalized toponym
    """
    
    # Rule 1: Special exceptions that need manual handling
    special_exceptions = {
        'чкаловський': 'чкаловське',    # "Чкаловське" wrongly lemmatized as adjective
        'чкаловського': 'чкаловське',   # Genitive case of Чкаловське
        'чкаловському': 'чкаловське',   # Locative case of Чкаловське
        'чкаловськом': 'чкаловське',    # Instrumental case of Чкаловське
        'олексадрія': 'олександрія',    # Common typo/variant
    }
    
    if lemmatized_name in special_exceptions:
        fixed = special_exceptions[lemmatized_name]
        print(f"DEBUG normalize_toponym: Special exception '{lemmatized_name}' → '{fixed}'")
        return fixed
    
    # Rule 2: Adjective endings → City names (most common SpaCy error)
    adjective_to_city_patterns = [
        (r'(.+)ський$', r'\1ськ'),      # покровський → покровськ
        (r'(.+)цький$', r'\1цьк'),      # краматорський → краматорськ  
        (r'(.+)рський$', r'\1рськ'),    # examples like "петрівський" → "петрівськ"
        (r'(.+)нський$', r'\1нськ'),    # examples like "український" → "українськ"
        (r'(.+)льський$', r'\1льськ'),  # examples like "кривський" → "кривськ"
    ]
    
    for pattern, replacement in adjective_to_city_patterns:
        import re
        if re.match(pattern, lemmatized_name):
            normalized = re.sub(pattern, replacement, lemmatized_name)
            print(f"DEBUG normalize_toponym: Adjective pattern '{lemmatized_name}' → '{normalized}'")
            return normalized
    
    # Rule 3: Handle specific case forms that need different normalization
    case_specific_fixes = {
        # Genitive forms that should be nominative
        'зарічний': 'зарічне',          # "Зарічного" (Gen) → "зарічне" (Nom)
        
        # Instrumental case normalization
        'новоукраїнськом': 'новоукраїнськ',  # "над Новоукраїнськом" (Ins) → base form
        'краматорськом': 'краматорськ',      # "над Краматорськом" (Ins) → base form
        'покровськом': 'покровськ',          # "над Покровськом" (Ins) → base form
    }
    
    if lemmatized_name in case_specific_fixes:
        fixed = case_specific_fixes[lemmatized_name]
        print(f"DEBUG normalize_toponym: Case fix '{lemmatized_name}' → '{fixed}'")
        return fixed
    
    # Rule 4: Handle endings that indicate feminine places
    feminine_place_patterns = [
        (r'(.+)івка$', r'\1івка'),      # Keep as is: миколаївка, гусарівка
        (r'(.+)енка$', r'\1енка'),      # Keep as is: савинка (but handle special cases)
    ]
    
    # Special feminine cases that need fixing
    feminine_special_cases = {
        'савинка': 'савинці',  # This is actually "Савинці" wrongly lemmatized
    }
    
    if lemmatized_name in feminine_special_cases:
        fixed = feminine_special_cases[lemmatized_name]
        print(f"DEBUG normalize_toponym: Feminine fix '{lemmatized_name}' → '{fixed}'")
        return fixed
    
    # Rule 5: Use original text pattern if lemmatization looks wrong
    original_lower = original_text.lower()
    
    # If original ends with typical city suffixes but lemma doesn't, prefer original pattern
    city_ending_patterns = [r'(.+)ськ$', r'(.+)цьк$', r'(.+)ів$', r'(.+)ине$', r'(.+)не$']
    lemma_is_adjective = any(lemmatized_name.endswith(ending) for ending in ['ський', 'цький', 'рський', 'нський'])
    
    import re
    for pattern in city_ending_patterns:
        if re.match(pattern, original_lower) and lemma_is_adjective:
            print(f"DEBUG normalize_toponym: Using original pattern '{original_lower}' over lemma '{lemmatized_name}'")
            return original_lower
    
    # Rule 6: Default - return the lemmatized form if no patterns match
    return lemmatized_name


def determine_regional_context(entity, doc, detected_regions, message_text):
    """
    Determine the correct regional context for a geographical entity
    based on its position in the text relative to regional headers
    
    Args:
        entity: SpaCy entity or PseudoEntity
        doc: SpaCy Doc object
        detected_regions: List of detected region names
        message_text: Original message text
        
    Returns:
        str: Most appropriate region name or None
    """
    if not detected_regions:
        return None
    
    if len(detected_regions) == 1:
        return detected_regions[0]
    
    # For multiple regions, find the closest preceding region header
    entity_start_char = entity.start_char if hasattr(entity, 'start_char') else 0
    
    # If entity doesn't have char positions, estimate from token positions
    if not hasattr(entity, 'start_char'):
        try:
            # Find token in doc by text matching
            for token in doc:
                if token.text == entity.text and token.i >= entity.start:
                    entity_start_char = token.idx
                    break
        except:
            entity_start_char = 0
    
    # Find all region positions in text
    region_positions = []
    message_lower = message_text.lower()
    
    region_patterns = {
        'сумщина': ['сумщин'],
        'чернігівщина': ['чернігівщин'],
        'харківщина': ['харківщин'],
        'полтавщина': ['полтавщин'],
        'херсонщина': ['херсонщин'],
        'миколаївщина': ['миколаївщин'],
        'дніпропетровщина': ['дніпропетровщин'],
        'київщина': ['київщин'],
        'донеччина': ['донеччин'],
        'луганщина': ['луганщин'],
        'одесщина': ['одесщин', 'одещин'],
        'запорізька': ['запорізьк'],
        'львівщина': ['львівщин'],
        'волинщина': ['волинщин', 'волинь'],
        'житомирщина': ['житомирщин'],
        'черкащина': ['черкащин'],
        'вінниччина': ['вінниччин', 'вінничин'],
    }
    
    for region_name in detected_regions:
        patterns = region_patterns.get(region_name, [region_name])
        for pattern in patterns:
            pos = message_lower.find(pattern)
            if pos != -1:
                region_positions.append((pos, region_name))
                break
    
    # Sort by position
    region_positions.sort(key=lambda x: x[0])
    
    # Find the closest preceding region
    closest_region = None
    closest_distance = float('inf')
    
    for pos, region_name in region_positions:
        if pos <= entity_start_char:
            distance = entity_start_char - pos
            if distance < closest_distance:
                closest_distance = distance
                closest_region = region_name
    
    # If no preceding region found, use the first one
    result = closest_region if closest_region else detected_regions[0]
    
    print(f"DEBUG Regional context: Entity '{entity.text}' at char {entity_start_char} -> region '{result}'")
    print(f"DEBUG Region positions: {region_positions}")
    
    return result


def spacy_enhanced_geocoding(message_text: str, existing_city_coords: dict = None, 
                           existing_normalizer: dict = None) -> list:
    """
    Enhanced city extraction using SpaCy NLP for Ukrainian text with proper entity recognition
    
    Args:
        message_text: Original message text
        existing_city_coords: deprecated parameter (now uses API instead of local dict)
        existing_normalizer: UA_CITY_NORMALIZE dict (defaults to global UA_CITY_NORMALIZE)
        
    Returns:
        List of dicts with city information:
        {
            'name': str,           # Original city name from message
            'normalized': str,     # Normalized city name for lookup
            'coords': tuple,       # (lat, lng) coordinates if found
            'region': str,         # Detected region if any
            'confidence': float,   # Confidence score 0.0-1.0
            'source': str,         # Detection method used
            'case': str           # Grammatical case if detected
        }
    """
    if not SPACY_AVAILABLE:
        return []
    
    # existing_city_coords is deprecated - we use API now
    if existing_normalizer is None:
        existing_normalizer = UA_CITY_NORMALIZE
        
    results = []
    
    try:
        doc = nlp(message_text)
        
        # Extract regions first for context
        detected_regions = []
        region_patterns = {
            'сумщина': ['сумщин', 'сумська область', 'сумська обл'],
            'чернігівщина': ['чернігівщин', 'чернігівська область', 'чернігівська обл'],
            'харківщина': ['харківщин', 'харківська область', 'харківська обл'],
            'полтавщина': ['полтавщин', 'полтавська область', 'полтавська обл'],
            'херсонщина': ['херсонщин', 'херсонська область', 'херсонська обл'],
            'миколаївщина': ['миколаївщин', 'миколаївська область', 'миколаївська обл'],
            'дніпропетровщина': ['дніпропетровщин', 'дніпропетровська область', 'дніпропетровська обл'],
            'київщина': ['київщин', 'київська область', 'київська обл'],
            'донеччина': ['донеччин', 'донецька область', 'донецька обл'],
            'луганщина': ['луганщин', 'луганська область', 'луганська обл'],
            'одесщина': ['одесщин', 'одеська область', 'одеська обл', 'одещин', 'одещина'],
            'запорізька': ['запорізьк', 'запорізька область', 'запорізька обл'],
            'львівщина': ['львівщин', 'львівська область', 'львівська обл'],
            'волинщина': ['волинщин', 'волинська область', 'волинська обл', 'волинь'],
            'житомирщина': ['житомирщин', 'житомирська область', 'житомирська обл'],
            'черкащина': ['черкащин', 'черкаська область', 'черкаська обл'],
            'вінниччина': ['вінниччин', 'вінницька область', 'вінницька обл', 'вінничин'],
        }
        
        message_lower = message_text.lower()
        for region_name, patterns in region_patterns.items():
            if any(pattern in message_lower for pattern in patterns):
                detected_regions.append(region_name)
        
        print(f"DEBUG SpaCy NLP: Processing text: '{message_text}'")
        print(f"DEBUG SpaCy NLP: Detected regions: {detected_regions}")
        
        # Process named entities from SpaCy NER - this is the proper NLP approach
        geographical_entities = []
        for ent in doc.ents:
            if ent.label_ in ['LOC', 'GPE']:  # Location, Geopolitical entity
                print(f"DEBUG SpaCy NLP: Found entity '{ent.text}' with label '{ent.label_}' confidence: {ent._.score if hasattr(ent, '_') and hasattr(ent._, 'score') else 'N/A'}")
                geographical_entities.append(ent)
        
        # Also look for proper nouns that might be geographical names
        for token in doc:
            if (token.pos_ == 'PROPN' and 
                not any(ent.start <= token.i < ent.end for ent in geographical_entities) and
                len(token.text) > 2):  # Skip short tokens
                print(f"DEBUG SpaCy NLP: Found additional PROPN candidate: '{token.text}'")
                # Create a pseudo-entity for processing
                class PseudoEntity:
                    def __init__(self, token):
                        self.text = token.text
                        self.start = token.i
                        self.end = token.i + 1  # Add missing end attribute
                        self.label_ = 'PROPN_CANDIDATE'
                geographical_entities.append(PseudoEntity(token))
        
        for ent in geographical_entities:
            entity_text = ent.text.lower()
            
            # Skip if this is a region (already processed)
            is_region = False
            for region_name, patterns in region_patterns.items():
                if any(pattern in entity_text for pattern in patterns):
                    is_region = True
                    break
            
            if not is_region:
                # Get morphological info
                if hasattr(ent, 'start'):
                    token = doc[ent.start]
                else:
                    # For pseudo-entities, find the token
                    token = next((t for t in doc if t.text.lower() == entity_text), None)
                    if not token:
                        continue
                
                case_info = None
                if hasattr(token, 'morph') and token.morph:
                    morph_dict = token.morph.to_dict()
                    case_info = morph_dict.get('Case', None)
                
                # Normalize city name using lemma - this is proper NLP morphological analysis
                normalized_name = token.lemma_.lower() if token.lemma_ and token.lemma_ != '-PRON-' else entity_text
                
                # For multi-word geographical entities, handle them specially
                if len(ent.text.split()) > 1:
                    # For multi-word entities, use custom normalization
                    entity_lower = ent.text.lower()
                    multi_word_fixes = {
                        'кривому рогу': 'кривий ріг',
                        'кривий ріг': 'кривий ріг',
                        'кривого рогу': 'кривий ріг',
                        'новий буг': 'новий буг',
                        'білий камінь': 'білий камінь',
                        'покровськ': 'покровськ',  # formerly красноармейск
                    }
                    for pattern, canonical in multi_word_fixes.items():
                        if pattern in entity_lower:
                            normalized_name = canonical
                            break
                    else:
                        # If no special case, try to reconstruct from lemmas
                        words = []
                        for i in range(ent.start, ent.end):
                            word_token = doc[i]
                            word_lemma = word_token.lemma_.lower() if word_token.lemma_ and word_token.lemma_ != '-PRON-' else word_token.text.lower()
                            words.append(word_lemma)
                        normalized_name = ' '.join(words)
                
                print(f"DEBUG SpaCy NLP: Entity '{ent.text}' -> normalized: '{normalized_name}', case: {case_info}")
                
                # Apply intelligent normalization for Ukrainian place names
                normalized_name = normalize_ukrainian_toponym(normalized_name, ent.text, case_info)
                
                # Apply existing normalization rules
                if normalized_name in existing_normalizer:
                    normalized_name = existing_normalizer[normalized_name]
                
                # Determine the most appropriate regional context for this entity
                region_context = determine_regional_context(ent, doc, detected_regions, message_text)
                
                # Look up coordinates using enhanced lookup with Nominatim fallback
                coords = get_coordinates_enhanced(normalized_name, region_context, message_text)
                
                # Determine confidence based on source
                confidence = 0.9 if ent.label_ in ['LOC', 'GPE'] else 0.7  # Higher for NER entities
                source = 'spacy_ner' if ent.label_ in ['LOC', 'GPE'] else 'spacy_propn'
                
                result = {
                    'name': ent.text,
                    'normalized': normalized_name,
                    'coords': coords,
                    'region': region_context,
                    'confidence': confidence,
                    'source': source,
                    'case': case_info
                }
                results.append(result)
                print(f"DEBUG SpaCy NLP: Added result: {result}")
        
        # Additional pattern-based extraction for missed entities (as fallback)
        preposition_patterns = ['на', 'повз', 'через', 'у напрямку', 'в напрямку']
        
        for i, token in enumerate(doc):
            # Simple prepositions
            if token.text.lower() in preposition_patterns[:3]:  # на, повз, через
                city_info = _extract_city_after_preposition_spacy(doc, i, detected_regions, 
                                                                existing_city_coords, existing_normalizer)
                if city_info:
                    results.append(city_info)
            
            # Direction patterns
            elif (token.text.lower() == 'у' and i + 1 < len(doc) and 
                  doc[i + 1].text.lower() == 'напрямку'):
                city_info = _extract_city_after_preposition_spacy(doc, i + 1, detected_regions,
                                                                existing_city_coords, existing_normalizer)
                if city_info:
                    results.append(city_info)
        
        # Remove duplicates while preserving order
        unique_results = []
        seen_cities = set()
        for result in results:
            city_key = result['normalized']
            if city_key not in seen_cities:
                seen_cities.add(city_key)
                unique_results.append(result)
        
        print(f"DEBUG SpaCy NLP: Final results: {unique_results}")
        return unique_results
        
    except Exception as e:
        print(f"SpaCy processing error: {e}")
        return []

def _find_coordinates_multiple_formats(city_name: str, detected_regions: list, existing_city_coords: dict) -> tuple:
    """
    Try to find coordinates using API with regional filtering
    Returns coordinates tuple (lat, lng) or None
    
    Note: existing_city_coords parameter is deprecated but kept for backward compatibility
    """
    try:
        import requests
        
        # Build region context from detected_regions
        region_context = None
        if detected_regions:
            # Convert region names to adjective forms
            region_adj_map = {
                'сумщина': 'сумська',
                'чернігівщина': 'чернігівська', 
                'харківщина': 'харківська',
                'полтавщина': 'полтавська',
                'дніпропетровщина': 'дніпропетровська',
                'херсонщина': 'херсонська',
                'миколаївщина': 'миколаївська',
                'київщина': 'київська',
                'донеччина': 'донецька',
                'луганщина': 'луганська'
            }
            
            for region in detected_regions:
                region_adj = region_adj_map.get(region, region)
                region_context = region_adj + ' область'
                break
        
        # Try Photon API (supports Cyrillic)
        photon_url = 'https://photon.komoot.io/api/'
        photon_params = {'q': city_name, 'limit': 10}
        
        photon_response = requests.get(photon_url, params=photon_params, timeout=3)
        if photon_response.ok:
            photon_data = photon_response.json()
            for feature in photon_data.get('features', []):
                props = feature.get('properties', {})
                state = props.get('state', '')
                country = props.get('country', '')
                osm_key = props.get('osm_key', '')
                osm_value = props.get('osm_value', '')
                
                # Filter out POIs - only settlements
                if osm_key not in ['place', 'boundary']:
                    continue
                valid_place_types = ['city', 'town', 'village', 'hamlet', 'suburb', 'neighbourhood', 'administrative']
                if osm_key == 'place' and osm_value not in valid_place_types:
                    continue
                
                if country in ['Україна', 'Ukraine']:
                    # Filter by region if available
                    if region_context and region_context in state:
                        coords_arr = feature.get('geometry', {}).get('coordinates', [])
                        if coords_arr and len(coords_arr) >= 2:
                            lng_val = safe_float(coords_arr[0])
                            lat_val = safe_float(coords_arr[1])
                            if lat_val is not None and lng_val is not None and validate_ukraine_coords(lat_val, lng_val):
                                print(f"DEBUG SpaCy Photon: Found '{city_name}' in {state} -> ({lat_val}, {lng_val})")
                                return (lat_val, lng_val)
                    elif not region_context:
                        # No region filter, use first Ukraine result
                        coords_arr = feature.get('geometry', {}).get('coordinates', [])
                        if coords_arr and len(coords_arr) >= 2:
                            lng_val = safe_float(coords_arr[0])
                            lat_val = safe_float(coords_arr[1])
                            if lat_val is not None and lng_val is not None and validate_ukraine_coords(lat_val, lng_val):
                                print(f"DEBUG SpaCy Photon: Found '{city_name}' in {state} -> ({lat_val}, {lng_val})")
                                return (lat_val, lng_val)
    
    except Exception as e:
        print(f"DEBUG SpaCy API lookup error: {e}")
    
    print(f"DEBUG SpaCy coord lookup: No coordinates found via API for '{city_name}'")
    return None

def get_coordinates_enhanced(city_name: str, region: str = None, context: str = "") -> tuple:
    """
    Enhanced coordinate lookup with Nominatim API fallback
    
    Args:
        city_name: Name of the settlement
        region: Optional region specification
        context: Context for military priority (e.g., "БпЛА курсом на")
        
    Returns:
        Tuple of (latitude, longitude) or None if not found
    """
    
    # First try local database with regional context prioritization
    context_lower = context.lower()
    
    # Handle Зарічне disambiguation based on context
    if city_name == 'зарічне':
        if any(keyword in context_lower for keyword in ['дніпропетровщина', 'дніпро', 'покровський', 'бпла']):
            # For Dnipropetrovska oblast contexts
            coords = DNIPRO_CITY_COORDS.get('зарічне дніпропетровська')
            if coords:
                print(f"DEBUG Enhanced coord lookup: Found '{city_name}' using Dnipropetrovska context -> {coords}")
                return coords
        elif any(keyword in context_lower for keyword in ['рівненщина', 'рівне']):
            # For Rivne oblast contexts  
            coords = (51.2167, 26.0833)
            print(f"DEBUG Enhanced coord lookup: Found '{city_name}' using Rivne context -> {coords}")
            return coords
    
    # Handle regional prefixes in context
    regional_indicators = {
        'дніпропетровщина': 'дніпропетровська',
        'киівщина': 'київська', 
        'харківщина': 'харківська',
        'житомирщина': 'житомирська',
        'чернігівщина': 'чернігівська',
        'сумщина': 'сумська'
    }
    
    detected_region = None
    for indicator, region_name in regional_indicators.items():
        if indicator in context_lower:
            detected_region = region_name
            break
    
    # If region detected from context but not passed as parameter, use detected
    if detected_region and not region:
        region = detected_region
        print(f"DEBUG Enhanced coord lookup: Detected region '{region}' from context for '{city_name}'")
    
    # Handle specific directional contexts (e.g., "північніше Чернігова")
    if 'чернігов' in context_lower and any(direction in context_lower for direction in ['північн', 'півн', 'північ']):
        if city_name == 'любеч':
            # Любеч північніше Чернігова
            coords = (51.4961, 30.2675)  # Правильні координати Любеча
            print(f"DEBUG Enhanced coord lookup: Found '{city_name}' using directional context north of Chernigiv -> {coords}")
            return coords
    
    # PRIORITIZE NOMINATIM API when region is specified
    if region and NOMINATIM_AVAILABLE:
        # Normalize region name for Nominatim API
        normalized_region = region.lower()
        
        # Convert regional nicknames to standard oblast names
        region_mappings = {
            'миколаївщина': 'миколаївська область',
            'херсонщина': 'херсонська область', 
            'харківщина': 'харківська область',
            'донеччина': 'донецька область',
            'луганщина': 'луганська область',
            'запоріжжя': 'запорізька область',
            'дніпропетровщина': 'дніпропетровська область',
            'полтавщина': 'полтавська область',
            'сумщина': 'сумська область',
            'чернігівщина': 'чернігівська область',
            'київщина': 'київська область',
            'житомирщина': 'житомирська область',
            'вінниччина': 'вінницька область',
            'черкащина': 'черкаська область',
            'кіровоградщина': 'кіровоградська область',
            'тернопільщина': 'тернопільська область',
            'хмельниччина': 'хмельницька область',
            'рівненщина': 'рівненська область',
            'волинщина': 'волинська область',
            'львівщина': 'львівська область',
            'закарпаття': 'закарпатська область',
            'івано-франківщина': 'івано-франківська область',
            'буковина': 'чернівецька область',
            'одещина': 'одеська область',
            'одесщина': 'одеська область',
        }
        
        # Apply mapping if available
        nominatim_region = region_mappings.get(normalized_region, region)
        
        print(f"DEBUG Enhanced coord lookup: Trying Nominatim API first for '{city_name}' in {nominatim_region} (from {region})")
        coords = get_coordinates_nominatim(city_name, nominatim_region)
        if coords:
            print(f"DEBUG Enhanced coord lookup: Nominatim found '{city_name}' in {nominatim_region} -> {coords}")
            # Cache the result in local database for future use
            cache_key = f"{city_name} {region}"
            CITY_COORDS[cache_key] = coords
            return coords
        else:
            print(f"DEBUG Enhanced coord lookup: Nominatim could not find '{city_name}' in {nominatim_region}")
    
    # API-only geocoding - NO local database fallback
    coords = ensure_city_coords(city_name, region.lower() if isinstance(region, str) else None)
    if coords:
        print(f"DEBUG Enhanced coord lookup: API found '{city_name}' -> {coords}")
        return coords
    
    # API-only geocoding - NO local database fallback
    coords = ensure_city_coords(city_name, region.lower() if isinstance(region, str) else None)
    if coords:
        print(f"DEBUG Enhanced coord lookup: API found '{city_name}' -> {coords}")
        return coords
    
    # Fallback to Nominatim API for precise geocoding
    if NOMINATIM_AVAILABLE:
        print(f"DEBUG Enhanced coord lookup: Trying Nominatim API for '{city_name}'" + (f" in {region}" if region else ""))
        coords = get_coordinates_nominatim(city_name, region)
        if coords:
            print(f"DEBUG Enhanced coord lookup: Nominatim found '{city_name}' -> {coords}")
            # Cache the result in local database for future use
            cache_key = f"{city_name}" + (f" {region}" if region else "")
            CITY_COORDS[cache_key] = coords
            return coords
        else:
            print(f"DEBUG Enhanced coord lookup: Nominatim could not find '{city_name}'")
    
    print(f"DEBUG Enhanced coord lookup: No coordinates found for '{city_name}' anywhere")
    return None

def get_coordinates_context_aware(text: str) -> tuple:
    """
    Context-aware coordinate lookup using intelligent text analysis
    
    Args:
        text: Full message text for context analysis
        
    Returns:
        Tuple of (latitude, longitude, target_city_name) or None if not found
    """
    
    if not CONTEXT_GEOCODER_AVAILABLE:
        print("DEBUG Context geocoder: Not available")
        return None
    
    print(f"DEBUG Context geocoder: Analyzing text: '{text}'")
    
    # Get prioritized geocoding candidates
    candidates = get_context_aware_geocoding(text)
    
    if not candidates:
        print("DEBUG Context geocoder: No candidates found")
        return None
    
    print(f"DEBUG Context geocoder: Found {len(candidates)} candidates: {candidates}")
    
    # Try each candidate in order of confidence
    for city_name, region, confidence in candidates:
        # Skip obviously invalid candidates
        if len(city_name) < 2 or city_name in ['-', 'над', 'на', 'у', 'в', 'до', 'під', 'біля', 'а', 'курсом']:
            continue
            
        print(f"DEBUG Context geocoder: Trying candidate '{city_name}' (region: {region}, confidence: {confidence})")
        
        # Use enhanced coordinate lookup
        coords = get_coordinates_enhanced(city_name, region=region, context=text)
        
        if coords:
            print(f"DEBUG Context geocoder: SUCCESS - Found '{city_name}' -> {coords}")
            return coords[0], coords[1], city_name
    
    print("DEBUG Context geocoder: No valid coordinates found for any candidate")
    return None

def _extract_city_after_preposition_spacy(doc, prep_index: int, detected_regions: list,
                                        existing_city_coords: dict, existing_normalizer: dict) -> dict:
    """Extract city name after preposition using SpaCy tokens"""
    if prep_index + 1 >= len(doc):
        return None
    
    # Collect potential city tokens (proper nouns, nouns, adjectives)
    city_tokens = []
    start_idx = prep_index + 1
    
    for i in range(start_idx, min(start_idx + 3, len(doc))):  # Max 3 words
        token = doc[i]
        if token.pos_ in ['PROPN', 'NOUN', 'ADJ'] or token.text == '-':
            city_tokens.append(token)
        else:
            break
    
    if not city_tokens:
        return None
    
    # Build city name
    city_name = ' '.join(token.text for token in city_tokens)
    
    # Get morphological info from the main token (usually the first one)
    main_token = city_tokens[0]
    case_info = None
    if hasattr(main_token, 'morph') and main_token.morph:
        morph_dict = main_token.morph.to_dict()
        case_info = morph_dict.get('Case', None)
    
    # Normalize using lemma
    normalized_name = main_token.lemma_ if main_token.lemma_ != city_name.lower() else city_name.lower()
    
    # Apply intelligent normalization for Ukrainian place names
    normalized_name = normalize_ukrainian_toponym(normalized_name, city_name, case_info)
    
    # Apply existing normalization rules
    if normalized_name in existing_normalizer:
        normalized_name = existing_normalizer[normalized_name]
    
    # Look up coordinates using enhanced lookup with Nominatim fallback  
    region_context = detected_regions[0] if detected_regions else None
    coords = get_coordinates_enhanced(normalized_name, region_context, ' '.join(token.text for token in doc))
    
    return {
        'name': city_name,
        'normalized': normalized_name,
        'coords': coords,
        'region': detected_regions[0] if detected_regions else None,
        'confidence': 0.7,  # Medium confidence for pattern-based
        'source': 'spacy_pattern',
        'case': case_info
    }

# DEPRECATED: CITY_COORDS dictionary is no longer used for primary geocoding
# The system now uses Photon/Nominatim APIs for real-time geocoding
# This dictionary is kept only for backward compatibility and as fallback
# See ensure_city_coords() and ensure_city_coords_with_message_context() for current API-based implementation
CITY_COORDS = {
        # Core cities
        'київ': (50.4501, 30.5234), 'харків': (49.9935, 36.2304), 'одеса': (46.4825, 30.7233), 'дніпро': (48.4647, 35.0462),
        'львів': (49.8397, 24.0297), 'запоріжжя': (47.8388, 35.1396), 'вінниця': (49.2331, 28.4682), 'миколаїв': (46.9750, 31.9946),
        'маріуполь': (47.0971, 37.5434), 'полтава': (49.5883, 34.5514), 'чернігів': (51.4982, 31.2893), 'черкаси': (49.4444, 32.0598),
        'житомир': (50.2547, 28.6587), 'суми': (50.9077, 34.7981), 'хмельницький': (49.4229, 26.9871), 'чернівці': (48.2921, 25.9358),
    
    # Житомирська область - усі основні міста
    'овруч': (51.3244, 28.8006), 'коростень': (50.9550, 28.6336), 'новоград-волинський': (50.5833, 27.6167), 
    'бердичів': (49.8978, 28.6011), 'звягель': (50.5833, 27.6167), 'малин': (50.7726, 29.2360), 
    'радомишль': (50.4972, 29.2292), 'черняхів': (50.4583, 28.8500), 'баранівка': (50.3000, 27.6667),
    'попільня': (49.9333, 28.4167), 'ємільчине': (50.8667, 28.8500), 'олевськ': (51.2167, 27.6667),
    'лугини': (50.9333, 27.2667), 'чудnів': (50.0500, 28.1167), 'андрушівка': (50.0833, 29.8000),
    'романів': (50.1500, 28.2667), 'ружин': (49.6333, 28.6000), 'володарськ-волинський': (50.5500, 28.3833),
    'коростишів': (50.3167, 29.0333), 'народичі': (51.0583, 29.1167), 'іванківець': (50.1333, 29.3333),
    'любар': (49.9167, 27.7333), 'високе': (51.1000, 28.1000), 'чорнобиль': (51.2768, 30.2219),
    'поліське': (51.1833, 29.5000),
    
    # Форми відмінків для Овруча
    'овручі': (51.3244, 28.8006), 'овручу': (51.3244, 28.8006), 'овручем': (51.3244, 28.8006),
    'овручем': (51.3244, 28.8006), 'овруча': (51.3244, 28.8006),
    
    # Інші форми для міст Житомирської області
    'малині': (50.7726, 29.2360), 'малину': (50.7726, 29.2360), 'малином': (50.7726, 29.2360),
    'коростені': (50.9550, 28.6336), 'коростену': (50.9550, 28.6336), 'коростенем': (50.9550, 28.6336),
    'бердичеві': (49.8978, 28.6011), 'бердичеву': (49.8978, 28.6011), 'бердичевом': (49.8978, 28.6011),
    'новограді-волинському': (50.5833, 27.6167), 'новоград-волинському': (50.5833, 27.6167),
    
    # Бершадь - райцентр Вінницької області
    'бершадь': (48.3667, 29.5167),
    'бершаді': (48.3667, 29.5167),
    'бершадю': (48.3667, 29.5167),
    'бершадью': (48.3667, 29.5167),
    'бершадей': (48.3667, 29.5167),
    
    # Added per user report (обстріл alert should map): Костянтинівка (Donetsk Obl.)
    'костянтинівка': (48.5277, 37.7050),
    # Краснокутськ (Харківська обл.)
    'краснокутськ': (50.0640, 35.1630),
    # Огіївка (Харківська обл.)
    'огіївка': (49.085201, 35.769772),
    'огиевка': (49.085201, 35.769772),
    # Mezhova (Дніпропетровська обл.) to avoid fallback to Dnipro
    'межова': (48.2583, 36.7363),
    # Sviatohirsk (Святогірськ) Donetsk Oblast
    'святогірськ': (49.0339, 37.5663),
    # Antonivka (Kherson urban-type settlement, user report for UAV threat)
    'антонівка': (46.6925, 32.7186),
    # Alexandria (Kirovohrad Oblast) - avoid confusion with other cities named Alexandria
    'олександрія': (48.8033, 33.1147),
    # Vilshany (Kirovohrad Oblast) - separate from Vilshanka in other regions  
    'вільшани': (48.4667, 32.2667),
    'вільшанам': (48.4667, 32.2667),
    'вільшанах': (48.4667, 32.2667),
    # Baturyn (Chernihiv Obl.) for directional course reports
    'батурин': (51.3450, 32.8761),
        'рівне': (50.6199, 26.2516), 'івано-франківськ': (48.9226, 24.7111), 'луцьк': (50.7472, 25.3254), 'тернопіль': (49.5535, 25.5948),
        'ужгород': (48.6208, 22.2879), 'кропивницький': (48.5079, 32.2623), 'кременчук': (49.0670, 33.4204), 'краматорськ': (48.7389, 37.5848),
        'мелітополь': (46.8489, 35.3650), 'бердянськ': (46.7553, 36.7885), 'павлоград': (48.5350, 35.8700), 'нікополь': (47.5667, 34.4061),
        'марганець': (47.6433, 34.6289), 'херсон': (46.6350, 32.6169),
        'корабельний район херсон': (46.6578, 32.5099),
        'білозерка': (46.64, 32.88),  # Херсонська область
        'чорнобаївка': (46.6964, 32.5469),  # Херсонська область
    
    # Недостающие города из UAV сообщений (сентябрь 2025)
    'зарічне': (51.2167, 26.0833),      # Рівненська область (default - first in alphabetical order)
    'зарічне(дніпропетровська)': (48.15, 35.2),  # Зарічне, Дніпропетровська область
    'зарічне (дніпропетровська)': (48.15, 35.2),  # With space
    'зарічне(рівненська)': (51.2167, 26.0833),  # Explicit Рівненська
    'зарічне (рівненська)': (51.2167, 26.0833),  # With space
    'сенкевичівка': (51.5667, 25.8333), # Волинська область
    'голоби': (50.7833, 25.2167),       # Волинська область
    
    # Дополнительные города из UAV сообщений (сентябрь 2025)
    'корнин': (50.9167, 29.1167),       # Житомирська область, Малинський район
    'корнину': (50.9167, 29.1167),
    'корнином': (50.9167, 29.1167),
    'корнина': (50.9167, 29.1167),
    'устинівка': (50.7481, 29.0028),    # Житомирська область, Малинський район
    'устинівці': (50.7481, 29.0028),
    'устинівку': (50.7481, 29.0028),
    'устинівкою': (50.7481, 29.0028),
    'добротвір': (50.2053, 24.4239),    # Львівська область, енергетичний центр
    'добротворі': (50.2053, 24.4239),
    'добротвору': (50.2053, 24.4239),
    'добротвором': (50.2053, 24.4239),
    'добротвора': (50.2053, 24.4239),
    'слов\'янськ': (48.8417, 37.5983), 'дружківка': (48.6203, 37.5263),
    # Fallback key without apostrophe (some sources strip it)
    'словянськ': (48.8417, 37.5983),
    'білопілля': (51.1500, 34.3014),
        # Extended regional towns & settlements
        'гадяч': (50.3713, 34.0109), 'чорнухи': (50.2833, 33.0000), 'великі сорочинці': (50.0167, 33.9833), 'семенівка': (50.6633, 32.3933),
        'лубни': (50.0186, 32.9931), 'шишаки': (49.8992, 34.0072), 'широке': (47.6833, 34.5667), 'зеленодольськ': (47.5667, 33.5333),
        'бабанка': (48.9833, 30.4167), 'новий буг': (47.6833, 32.5167), 'березнегувате': (47.3167, 32.8500), 'новоархангельськ': (48.6667, 30.8000),
        'липняжка': (48.6167, 30.8667), 'голованівськ': (48.3772, 30.5322), 'бишів': (50.3167, 29.9833), 'обухів': (50.1072, 30.6211),
        'гребінки': (50.2500, 30.2500), 'біла церква': (49.7950, 30.1310), 'сквира': (49.7333, 29.6667), 'чорнобиль': (51.2768, 30.2219),
        'пулини': (50.4333, 28.4333), 'головине': (50.3833, 28.6667), 'радомишль': (50.4972, 29.2292), 'коростень': (50.9500, 28.6333),
        'погребище': (49.4833, 29.2667), 'теплик': (48.6667, 29.6667), 'оратів': (48.9333, 29.5167), 'дашів': (48.9000, 29.4333),
        'шаргород': (48.7333, 28.0833), 'бірки': (49.7517, 36.1025), 'златопіль': (49.9800, 35.5300), 'балаклія': (49.4627, 36.8586),
        'берестин': (50.2000, 35.0000), 'старий салтів': (50.0847, 36.7424), 'борки': (49.9380, 36.1260), 'кролевець': (51.5481, 33.3847),
    'глобине': (49.3833, 33.2667), 'кринички': (47.2333, 34.3500), 'солоне': (48.1436, 35.9933), 'брусилів': (50.2800, 29.5300),
    'терни': (50.9070, 34.0130), 'понорниця': (51.8033, 32.5333), 'куликівка': (51.3520, 31.6480),
    # Additional settlements from multi-region UAV course messages (September 2025)
    'путивль': (51.3361, 33.8692), 'бахмач': (51.1808, 32.8203), 'носівка': (50.9444, 32.0167), 'козелець': (50.9167, 31.1833),
    'страхолісся': (50.5167, 30.8833), 'білокоровичі': (51.1667, 27.75),
    'краснопавлівка': (50.0167, 35.95), 'божедрівка': (48.4167, 35.0167), 'пʼятихатки': (48.5667, 33.6833),
    'петрове': (48.7333, 32.8), 'брилівка': (46.8167, 32.7833),
    # Additional missing cities from napramok messages (September 2025)
    'десна': (51.0333, 31.1667), 'кіпті': (51.2833, 31.2167), 'ічня': (50.3833, 34.8833), 'цвіткове': (49.7167, 32.2167),
    'чоповичі': (50.8333, 28.7333), 'звягель': (50.5833, 27.6667), 'камʼянське': (48.5167, 34.6167),
    'піщаний брід': (48.1167, 32.0833), 'бобринець': (48.0333, 32.1833), 'тендрівська коса': (46.1833, 31.5333),
        'новгород-сіверський': (51.9874, 33.2620), 'сосниця': (51.5236, 32.4953), 'олишівка': (51.0725, 31.3525), 'березна': (51.5756, 31.7431),
        'зачепилівка': (49.1717, 35.2742), 'близнюки': (48.8520, 36.5440), 'нова водолага': (49.7270, 35.8570), 'сахновщина': (49.1544, 35.1460),
        'губиниха': (48.7437, 35.2960), 'перещепине': (48.6260, 35.3580), 'карлівка': (49.4586, 35.1272), 'магдалинівка': (48.8836, 34.8669),
        'савинці': (49.4365, 37.2981), 'шевченкове': (49.6996, 37.1770), 'обухівка': (48.6035, 34.8530), 'курилівка': (48.6715, 34.8740),
        'петриківка': (48.7330, 34.6300), 'підгородне': (48.5747, 35.1482), 'самар': (48.6500, 35.4200), 'верхньодніпровськ': (48.6535, 34.3372),
        'горішні плавні': (49.0123, 33.6450), "кам'янське": (48.5110, 34.6021), 'камянське': (48.5110, 34.6021), 'липова долина': (50.5700, 33.7900),
        'тростянець': (50.4833, 34.9667), 'лебедин': (50.5872, 34.4912), 'улянівка': (50.8530, 34.3170), 'уляновка': (50.8530, 34.3170),
        'богодухів': (50.1646, 35.5279), 'холми': (51.6272, 32.5531), 'блистова': (51.6833, 32.6333), 'ніжин': (51.0480, 31.8860),
        'мена': (51.5211, 32.2147), 'десна': (51.0833, 30.9333), 'євминка': (51.3167, 31.7167), 'м.-коцюбинське': (51.5833, 31.1167),
        'лосинівка': (51.1333, 31.7167), 'ічня': (51.0722, 32.3931), 'борзна': (51.2542, 32.4192), 'прилуки': (50.5931, 32.3878),
        'линовиця': (50.7833, 32.4167), 'валки': (49.8427, 35.6150), 'кегичівка': (49.5440, 35.7760), 'велика багачка': (50.1946, 33.7894),
        'велику багачку': (50.1946, 33.7894), 'велику багачу': (50.1946, 33.7894), 'липову долину': (50.5700, 33.7900), 'затока': (46.0660, 30.4680),
        'янське': (48.4567, 36.3342), 'чугуїв': (49.8376, 36.6881), 'ворожба': (51.8031, 34.4972), 'краснопілля': (50.4422, 35.3081),
        'бориспіль': (50.3527, 30.9550), 'жашків': (49.2431, 30.1122), 'есмань': (51.8833, 34.2833), 'мерефа': (49.8181, 36.0572),
        'глухів': (51.6781, 33.9169), 'недригайлів': (50.8281, 33.8781), 'вороніж': (51.8081, 33.3722), 'ромни': (50.7497, 33.4746),
    'ямпіль': (51.2247, 34.3224), 'ямпіль сумська': (51.2247, 34.3224), 'ямполь сумська': (51.2247, 34.3224),
    'хутір-михайлівський': (51.8000, 33.5000),
        'узин': (49.8216, 30.4567), 'гончарівське': (51.6272, 31.3192), 'голованівськ': (48.3772, 30.5322), 'новоукраїнка': (48.3122, 31.5272),
        'тульчин': (48.6783, 28.8486), 'бровари': (50.5110, 30.7909), 'канів': (49.7517, 31.4717), 'миронівка': (49.6631, 31.0100),
        'борова': (49.3742, 36.4892), 'буринь': (51.2000, 33.8500), 'конотоп': (51.2417, 33.2022), 'кролевец': (51.5486, 33.3856), 'остер': (50.9481, 30.8831),
        'плавні': (49.0123, 33.6450), 'голованівський район': (48.3772, 30.5322), 'новоукраїнський район': (48.3122, 31.5272),
        'безлюдівка': (49.8872, 36.2731), 'рогань': (49.9342, 36.4942), 'савинці(харківщина)': (49.6272, 36.9781),
        'слатине': (49.7500, 36.1500),  # Слатине, Дергачівський р-н, Харківська обл.
        'гути': (50.0167, 36.3833),  # Гути, Харьковская область
        # Temporary missing cities (should be in external data sources)
        'гусарівка': (49.1000, 37.1500),  # Гусарівка, Харківська область - TEMP: SpaCy не находит автоматически
        'протопопівка': (49.7000, 37.0000),  # Протопопівка, Харківська область - TEMP: SpaCy не находит автоматически
        'українка': (50.1447, 30.7381), 'царичанка': (48.9767, 34.3772), 'ріпки': (51.8122, 31.0817), 'михайло-коцюбинське': (51.5833, 31.1167),
    'андріївка': (49.9380, 36.9510),
        'макошине': (51.6275, 32.2731), 'парафіївка': (50.9833, 32.2833), 'дубовʼязівка': (51.1833, 33.7833), 'боромля': (50.7500, 34.9833),
    # Newly added (missing in earlier dictionary lookups reported by user)
    'городня': (51.8892, 31.6011),
        'жукин': (50.7800, 30.6820), 'велика димерка': (50.8140, 30.8080), 'велику димерку': (50.8140, 30.8080), 'вишгород': (50.5840, 30.4890),
    'димер': (50.8390, 30.3050),
        'ржищів': (49.9719, 31.0500), 'вишеньки': (50.2987, 30.6445), 'жуляни': (50.4017, 30.4519), 'троєщина': (50.5130, 30.6030),
        'троєщину': (50.5130, 30.6030), 'конча-заспа': (50.2650, 30.5760), 'любар': (50.0500, 27.7500), 'старий остропіль': (49.6503, 27.2291),
        'петрівці': (50.4167, 30.5833),
        'згурівка': (50.4950, 31.7780), 'мала дівиця': (50.8240, 32.4700), 'яготин': (50.2360, 31.7700), 'ставище': (49.3958, 30.1875),
        'березань': (50.3085, 31.4576), 'бортничі': (50.3915, 30.6695), 'старокостянтинів': (49.7574, 27.2039), 'адампіль': (49.6500, 27.3000),
        # Additional single-city early parser support
        'покровське': (48.1180, 36.2470), 'петропавлівка': (48.5000, 36.4500), 'шахтарське': (47.9500, 36.0500),
        # 'миколаївка': Удалено - неоднозначное название, используется контекстный поиск
        'низи': (50.7435, 34.9860), 'барвінкове': (48.9000, 37.0167), 'пісочин': (49.9500, 36.1330), 'берестове': (49.3500, 37.0000),
    'кобеляки': (49.1500, 34.2000), 'бердичів': (49.8942, 28.5986),
    'куцуруб': (46.7906, 31.9222), 'воскресенка': (50.4850, 30.6090),
    # Newly added Kyiv & Odesa region settlements / raion centers for alerts
    'гостомель': (50.5853, 30.2617), 'боярка': (50.3301, 30.5201), 'макарів': (50.4645, 29.8114),
    'бородянка': (50.6447, 29.9202), 'кілія': (45.4553, 29.2640),
    # Odesa region settlements for trajectory tracking
    'старі трояни': (45.3833, 28.8000), 'стара трояни': (45.3833, 28.8000),
    # Khmelnytskyi region settlements
    'вовковинці': (49.2074, 27.6560), 'вовковинця': (49.2074, 27.6560),
    # Cherkasy region settlement (directional course report: "БпЛА курсом на Цибулів")
    'цибулів': (49.0733, 29.8472),
    # Raion centers (approx: use main settlement or administrative center)
    'ізмаїльський район': (45.3516, 28.8365), # near Izmail
    'броварський район': (50.5110, 30.7909),
    'обухівський район': (50.1072, 30.6211),
    'херсонський район': (46.6350, 32.6169),
    'вінницький район': (49.2331, 28.4682)
    ,# --- Newly added (Sept 2 multi-line UAV message) ---
    'нечаяне': (46.8840, 32.0310), 'нечаянеу': (46.8840, 32.0310), 'нечаяному': (46.8840, 32.0310),
    'чечельник': (48.2156, 29.3708), 'чечельнику': (48.2156, 29.3708),
    'залісся': (51.0836, 30.1914), 'заліссям': (51.0836, 30.1914),
    'красятичі': (51.0410, 29.6000), 'красятичів': (51.0410, 29.6000),
    'іршанськ': (50.7833, 28.9000), 'іршанську': (50.7833, 28.9000),
    'хорошів': (50.7167, 28.6167), 'хорошеві': (50.7167, 28.6167), 'хорошеву': (50.7167, 28.6167),
    'народичі': (51.2000, 29.0833), 'народичів': (51.2000, 29.0833),
    'нові білокоровичі': (51.1333, 27.7667), 'нові білокоровичів': (51.1333, 27.7667),
    'городниця': (51.3270, 27.3460), 'городницю': (51.3270, 27.3460),
    'березне': (50.9833, 26.7500), 'березному': (50.9833, 26.7500),
    'божедарівка': (48.3014, 34.5522), 'божедарівку': (48.3014, 34.5522), 'божедарівці': (48.3014, 34.5522),
    'пʼятихатки': (48.5667, 33.6833), "п'ятихатки": (48.5667, 33.6833), 'пятихатки': (48.5667, 33.6833),
    'жовті води': (48.3500, 33.5000), 'жовтих вод': (48.3500, 33.5000),
    'згурівку': (50.4950, 31.7780), 'згурівці': (50.4950, 31.7780),
    'козятин': (49.7167, 28.8333), 'козятина': (49.7167, 28.8333),
    'теплик': (48.6650, 29.7480), 'теплика': (48.6650, 29.7480),
    'новий буг': (47.6833, 32.5167), 'нового буга': (47.6833, 32.5167),
    'семенівку': (50.6633, 32.3933), 'лубни': (50.0186, 32.9931),
    'згурівка (київщина)': (50.4950, 31.7780),
    'гребінку': (50.2500, 30.2500), 'згурівко': (50.4950, 31.7780),
    # Гребінка (Полтавська область) - правильні координати
    'гребінка': (50.1058, 32.4464), 'гребінці': (50.1058, 32.4464), 'гребінку полтавська': (50.1058, 32.4464),
    'хотінь': (51.0550, 34.0000), 'хотіні': (51.0550, 34.0000),
    # Додаткові міста з нових повідомлень
    'хмільник': (49.5500, 27.9667), 'хмільнику': (49.5500, 27.9667), 'хмільника': (49.5500, 27.9667),
    'балта': (47.9667, 29.6167), 'балту': (47.9667, 29.6167), 'балті': (47.9667, 29.6167),
    'голованівськ': (48.7667, 31.4833), 'голованівську': (48.7667, 31.4833), 'голованівська': (48.7667, 31.4833),
    'помічна': (48.4333, 32.5333), 'помічну': (48.4333, 32.5333), 'помічній': (48.4333, 32.5333),
    'звенигородка': (49.0803, 30.9617), 'звенигородку': (49.0803, 30.9617), 'звенигородці': (49.0803, 30.9617),
    'буки': (49.1167, 30.8833), 'букам': (49.1167, 30.8833), 'буках': (49.1167, 30.8833),
    'дубовʼязівка': (50.7833, 34.3667), 'дубовʼязівку': (50.7833, 34.3667), "дуб'язівка": (50.7833, 34.3667), "дубов'язівка": (50.7833, 34.3667),
    'парафіївка': (51.4833, 31.1167), 'парафіївку': (51.4833, 31.1167), 'парафіївці': (51.4833, 31.1167),
    'нова борова': (50.7167, 27.9167), 'нову борову': (50.7167, 27.9167), 'новій боровій': (50.7167, 27.9167),
    'чоповичі': (50.4333, 28.1167), 'чоповичів': (50.4333, 28.1167), 'чоповичах': (50.4333, 28.1167),
    'ємільчине': (50.8667, 27.8667), 'ємільчину': (50.8667, 27.8667), 'ємільчиному': (50.8667, 27.8667),
    'стара синява': (49.6333, 27.6167), 'стару синяву': (49.6333, 27.6167), 'старій синяві': (49.6333, 27.6167),
    'шепетівка': (50.1833, 27.0667), 'шепетівку': (50.1833, 27.0667), 'шепетівці': (50.1833, 27.0667),
    'сарни': (51.3333, 26.6000), 'сарнах': (51.3333, 26.6000), 'сарнів': (51.3333, 26.6000),
    'степань': (50.5167, 25.9167), 'степані': (50.5167, 25.9167), 'степаня': (50.5167, 25.9167),
    'любешів': (51.9000, 25.3333), 'любешеві': (51.9000, 25.3333), 'любешову': (51.9000, 25.3333),
    'маневичі': (51.3000, 25.5167), 'маневичів': (51.3000, 25.5167), 'маневичах': (51.3000, 25.5167),
    'колки': (51.9333, 24.7167), 'колках': (51.9333, 24.7167), 'колкам': (51.9333, 24.7167),
    'рожище': (51.6333, 24.2333), 'рожищу': (51.6333, 24.2333), 'рожищі': (51.6333, 24.2333),
    'рокині': (50.9833, 24.5167), 'рокинях': (50.9833, 24.5167), 'рокинів': (50.9833, 24.5167),
    'володимир': (50.8500, 24.3167), 'володимиру': (50.8500, 24.3167), 'володимирі': (50.8500, 24.3167),
    # Додаткові міста з нових повідомлень 2
    'жовква': (49.9333, 23.9667), 'жовкву': (49.9333, 23.9667), 'жовкві': (49.9333, 23.9667),
    'криве озеро': (47.9500, 30.3500), 'кривому озеру': (47.9500, 30.3500), 'кривого озера': (47.9500, 30.3500),
    'могилів-подільський': (48.4833, 27.8000), 'могилева-подільського': (48.4833, 27.8000),
    'ямпіль вінницька': (48.1333, 28.2833), 'ямполь вінницька': (48.1333, 28.2833),
    'ямполю': (48.1333, 28.2833), 'ямполі': (48.1333, 28.2833),
    'дзигівка': (49.2167, 28.1500), 'дзигівку': (49.2167, 28.1500), 'дзигівці': (49.2167, 28.1500),
    # березівка - removed duplicate, use Odesa region coordinates (47.2050, 30.9080) in Odesa section
    # 'миколаївка': Удалено - неоднозначное название, используется контекстный поиск
    'вільногірськ': (47.9333, 34.0167), 'вільногірську': (47.9333, 34.0167), 'вільногірська': (47.9333, 34.0167),
    'велика виска': (49.2333, 32.1833), 'великої виски': (49.2333, 32.1833), 'великій висці': (49.2333, 32.1833),
    'велику виску': (49.2333, 32.1833),  # accusative form
    'доброслав': (46.6000, 30.0500), 'доброславу': (46.6000, 30.0500), 'доброславі': (46.6000, 30.0500),
    'тишківка': (48.7667, 32.6833), 'тишківку': (48.7667, 32.6833), 'тишківці': (48.7667, 32.6833),
    'салькове': (48.6167, 32.4500), 'салькову': (48.6167, 32.4500), 'сальковому': (48.6167, 32.4500),
    'благовіщенське': (48.4167, 32.8833), 'благовіщенську': (48.4167, 32.8833), 'благовіщенського': (48.4167, 32.8833),
    'оржиця': (50.0667, 32.3833), 'оржицю': (50.0667, 32.3833), 'оржиці': (50.0667, 32.3833),
    'тальне': (49.1833, 30.6833), 'тальному': (49.1833, 30.6833), 'тального': (49.1833, 30.6833),
    'бобровиця': (51.0833, 32.1167), 'бобровицю': (51.0833, 32.1167), 'бобровиці': (51.0833, 32.1167),
    'холми': (51.6833, 32.4000), 'холмам': (51.6833, 32.4000), 'холмах': (51.6833, 32.4000),
    'сосниця': (51.9500, 32.4667), 'сосницю': (51.9500, 32.4667), 'сосниці': (51.9500, 32.4667),
    'вишгород': (50.5833, 30.4833), 'вишгороду': (50.5833, 30.4833), 'вишгороді': (50.5833, 30.4833),
    'малин': (50.7667, 29.2333), 'маліну': (50.7667, 29.2333), 'маліні': (50.7667, 29.2333),
    'бучмани': (50.2833, 28.3333), 'бучманам': (50.2833, 28.3333), 'бучманах': (50.2833, 28.3333),
    'червоне': (50.4167, 28.9167), 'червоному': (50.4167, 28.9167), 'червоного': (50.4167, 28.9167),
    'понінка': (49.6167, 27.4500), 'понінку': (49.6167, 27.4500), 'понінці': (49.6167, 27.4500),
    'теофіполь': (49.8833, 27.6500), 'теофіполю': (49.8833, 27.6500), 'теофіполі': (49.8833, 27.6500),
    'гоща': (50.6167, 26.4167), 'гощу': (50.6167, 26.4167), 'гощі': (50.6167, 26.4167),
    'клевань': (50.7667, 25.9833), 'клевані': (50.7667, 25.9833), 'клеваню': (50.7667, 25.9833),
    'володимирець': (51.4333, 25.9167), 'володимирцю': (51.4333, 25.9167), 'володимирці': (51.4333, 25.9167),
    'локачі': (51.1167, 24.2667), 'локачам': (51.1167, 24.2667), 'локачах': (51.1167, 24.2667),
    'іваничі': (51.2333, 24.3167), 'іваничам': (51.2333, 24.3167), 'іваничах': (51.2333, 24.3167),
    'турійськ': (51.0833, 24.7000), 'турійську': (51.0833, 24.7000), 'турійська': (51.0833, 24.7000),
    # Додаткові міста з великих повідомлень
    'великі мости': (48.9167, 25.3333), 'великих мостів': (48.9167, 25.3333), 'великих мостах': (48.9167, 25.3333),
    'снігурівка': (46.7500, 32.8167), 'снігурівку': (46.7500, 32.8167), 'снігурівці': (46.7500, 32.8167),
    'баранівка': (50.3000, 27.6667), 'баранівку': (50.3000, 27.6667), 'баранівці': (50.3000, 27.6667),
    'новоград-волинський': (50.5833, 27.6167), 'новограда-волинського': (50.5833, 27.6167),
    'красилів': (49.6500, 27.1667), 'красилову': (49.6500, 27.1667), 'красилові': (49.6500, 27.1667),
    'шепетівка': (50.1833, 27.0667), 'шепетівку': (50.1833, 27.0667), 'шепетівці': (50.1833, 27.0667),
    'славута': (50.3000, 26.8667), 'славуту': (50.3000, 26.8667), 'славуті': (50.3000, 26.8667),
    'нетішин': (50.3333, 26.6333), 'нетішину': (50.3333, 26.6333), 'нетішині': (50.3333, 26.6333),
    'острог': (50.3333, 26.5167), 'острогу': (50.3333, 26.5167), 'острозі': (50.3333, 26.5167),
    'дубно': (50.4167, 25.7667), 'дубну': (50.4167, 25.7667), 'дубні': (50.4167, 25.7667),
    'вараш': (51.3500, 25.8500), 'вараші': (51.3500, 25.8500), 'варашу': (51.3500, 25.8500),
    'костопіль': (50.8833, 26.4500), 'костополю': (50.8833, 26.4500), 'костополі': (50.8833, 26.4500),
    'сарни': (51.3333, 26.6000), 'сарнам': (51.3333, 26.6000), 'сарнах': (51.3333, 26.6000),
    'рокитне': (50.9333, 26.1667), 'рокитному': (50.9333, 26.1667), 'рокитного': (50.9333, 26.1667),
    'дубровиця': (51.5667, 26.5667), 'дубровицю': (51.5667, 26.5667), 'дубровиці': (51.5667, 26.5667),
    'березне': (51.4500, 26.7167), 'березному': (51.4500, 26.7167), 'березного': (51.4500, 26.7167),
    'шостку': (51.8667, 33.4833), 'конотопу': (51.2417, 33.2022), 'недригайлів': (50.8281, 33.8781),
    'липову долину': (50.5700, 33.7900), 'носівку': (50.9444, 32.0167), 'бахмач': (51.1808, 32.8203), 'бахмача': (51.1808, 32.8203)
    ,'пісківка': (50.6767, 29.5283), 'пісківку': (50.6767, 29.5283), 'пісківці': (50.6767, 29.5283)
    ,'зіньків': (49.2019, 34.3744), 'зінькові': (49.2019, 34.3744), 'зіньківу': (49.2019, 34.3744), 'зінькова': (49.2019, 34.3744)
}

# Optional district centers lookup (may be filled later)
DISTRICT_CENTERS = {}

# Donetsk Oblast cities (повний перелік міст області). Added per user request to ensure precise mapping.
# Sources: OpenStreetMap / GeoNames (approx to 4 decimal places). Using setdefault to avoid overriding existing entries.
DONETSK_CITY_COORDS = {
    'донецьк': (48.0028, 37.8053),
    'макіївка': (48.0478, 37.9258),
    'горлівка': (48.3336, 38.0925),
    'маріуполь': (47.0971, 37.5434),  # already present
    'краматорськ': (48.7389, 37.5848),  # already present
    'слов\'янськ': (48.8417, 37.5983),  # already present
    'дружківка': (48.6203, 37.5263),  # already present
    'костянтинівка': (48.5277, 37.7050),  # already present
    'бахмут': (48.5937, 38.0000),
    'авдіївка': (48.1417, 37.7425),
    'покровськ': (48.2833, 37.1833),
    'мирноград': (48.3000, 37.2667),
    'торецьк': (48.3976, 37.8687),
    'добропілля': (48.4697, 37.0851),
    'селидове': (48.1500, 37.3000),
    'новогродівка': (48.2065, 37.3467),
    'волноваха': (47.6000, 37.5000),
    'вугледар': (47.7811, 37.2358),
    'ліман': (48.9890, 37.8020),
    'святогірськ': (49.0339, 37.5663),  # already present
    'сіверськ': (48.8667, 38.1000),
    'соледар': (48.5356, 38.0875),
    'часів яр': (48.5969, 37.8350),
    'шахтарськ': (48.0500, 38.4500),
    'єнакієве': (48.2333, 38.2000),
    'амвросіївка': (47.7956, 38.4772),
    'дебальцеве': (48.3400, 38.4000),
    'докучаєвськ': (47.7489, 37.6789),
    'іловайськ': (47.9233, 38.1950),
    'жданівка': (48.1500, 38.2667),
    'зугрес': (48.0167, 38.2667),
    'харцизьк': (48.0400, 38.1500),
    'вуглегірськ': (48.3167, 38.2167),
    'ясинувата': (48.1167, 37.8333),
    'сніжне': (48.0333, 38.7667),
    'кальміуське': (47.6528, 38.0664),
    'моспине': (47.8583, 38.0000),
    'українськ': (48.0333, 37.9000),
    'родинське': (48.3500, 37.2000),
    'залізне': (48.3539, 37.8483),
    # Historical / alt names not added to avoid noise; add normalization separately if needed.
}

for _dn_name, _dn_coords in DONETSK_CITY_COORDS.items():
    CITY_COORDS.setdefault(_dn_name, _dn_coords)

# Kharkiv Oblast cities and key settlements (міста + важливі селища) per user request.
# Many already present; using setdefault to avoid override. Includes normalized variants.
KHARKIV_CITY_COORDS = {
    'ізюм': (49.2103, 37.2483),
    'куп\'янськ': (49.7106, 37.6156),
    'купянськ': (49.7106, 37.6156),  # variant without apostrophe
    'юріївка': (50.131641, 37.394371),  # Kupiansk district, near Russian border
    'юріївка харків': (50.131641, 37.394371),
    'юріївка харківська': (50.131641, 37.394371),
    'лозова': (48.8897, 36.3175),
    'липці': (50.3061, 36.7597),  # село біля кордону з Росією
    'первомайський': (49.3914, 36.2147),
    'вовчанськ': (50.3000, 36.9500),
    'люботин': (49.9486, 35.9292),
    'дергачі': (50.1061, 36.1217),
    'зміїв': (49.6897, 36.3472),
    'красноград': (49.3740, 35.4405),
    'печеніги': (49.8667, 36.9667),
    'золочів(харківщина)': (50.2744, 36.3592),
    'золочів': (50.2744, 36.3592),  # may conflict with Львівська обл.; disambiguation via region context
    'великий бурлук': (50.0514, 37.3903),
    'бурлук': (50.0514, 37.3903),  # скорочена форма від "Великий Бурлук"
    'приколотне': (49.8936, 37.2033),  # село в Харківській області
    # 'південне': Removed from Kharkiv section - this is Odesa region (46.6226, 31.1013)
    'покотилівка': (49.9345, 36.0603),
    'манченки': (49.9840, 35.9680),
    'малинівка': (49.6550, 36.7060),
    'коломак': (49.8422, 35.2761),
    'козача лопань': (49.8872, 36.4167),  # СМТ в Дергачівському районі
    'чкаловське': (49.7155296, 36.9322501),  # Правильне Чкаловське в Харківській області
    'першотравневий': (49.3914, 36.2147),  # с. Першотравневе, Харківська область (same as Первомайський)
    'вільшани': (50.0513573, 35.8839188),  # селище міського типу в Харківському районі
    'створ населеного пункту балки?': (49.4627, 36.8586),  # placeholder example – remove/replace if noise
}

for _kh_name, _kh_coords in KHARKIV_CITY_COORDS.items():
    CITY_COORDS.setdefault(_kh_name, _kh_coords)

# Chernihiv Oblast cities / key settlements (міста та важливі селища)
# Many base ones already in CITY_COORDS (чернігів, ніжин, прилуки, новгород-сіверський, коростень (інша обл.), корюківка maybe missing).
CHERNIHIV_CITY_COORDS = {
    'ніжин': (51.0480, 31.8860),  # already present
    'прилуки': (50.5931, 32.3878),  # already present
    'новгород-сіверський': (51.9874, 33.2620),  # already present
    'корюківка': (51.7725, 32.2494),
    'козелець': (51.5625, 31.2058),  # Added
    'носівка': (51.0325, 31.5522),   # Added
    'куликівка': (51.3667, 32.2000),  # Added
    'мена': (51.5211, 32.2147),      # Fixed typo
    'ічня': (51.0722, 32.3931),      # Added
    'борзна': (51.2542, 32.4192),  # already present
    'батиївка?': (51.4982, 31.2893),  # placeholder if appears; else remove
    'менa': (51.5211, 32.2147),  # variant with latin a? (typo guard)
    'м ена': (51.5211, 32.2147),  # spacing anomaly fallback
    'семенівка(чернігівщина)': (52.1833, 32.5833),  # north settlement (if referenced)
    'семенівка чернігівська': (52.1833, 32.5833),
    'семенівка': (52.1833, 32.5833),  # might conflict with Poltava one; context disambiguation may be needed
    'сновськ': (51.8200, 31.9500),
    'короп': (51.5667, 32.9667),
    'іхня': (51.0722, 32.3931),  # misspelling variant of ічня
    'ичня': (51.0722, 32.3931),  # alt transliteration
    'глухів?': (51.6781, 33.9169),  # actually Sumy oblast; placeholder if mis-tag appears
    'сосниця': (51.5236, 32.4953),  # already present
    'конотоп?': (51.2417, 33.2022),  # Sumy oblast - guard only
    'остер': (50.9481, 30.8831),  # already present
    'ніжину': (51.0480, 31.8860),  # accusative
    'борзні': (51.2542, 32.4192),
    'коропі': (51.5667, 32.9667),
    'корюківці': (51.7725, 32.2494),
    'корюківку': (51.7725, 32.2494),
    'сновську': (51.8200, 31.9500),
    'семенівці': (52.1833, 32.5833),
    'семенівку': (52.1833, 32.5833),
    # Дополнительные города и формы
    'седнів': (51.5211, 32.1897),
    'новгород': (51.9874, 33.2620),  # новгород-сіверський
    'новгород-сіверський': (51.9874, 33.2620),
}

for _ch_name, _ch_coords in CHERNIHIV_CITY_COORDS.items():
    CITY_COORDS.setdefault(_ch_name, _ch_coords)

# Dnipropetrovsk (Дніпропетровська) Oblast cities & key settlements.
DNIPRO_CITY_COORDS = {
    'кривий ріг': (47.9105, 33.3918),  # already implied in stems
    'жіовті води': (48.3456, 33.5022),  # typo guard for жовті води
    'жовті води': (48.3456, 33.5022),
    'кам\'янське': (48.5110, 34.6021),  # already present as variant
    'камянське': (48.5110, 34.6021),  # present
    'нікополь': (47.5667, 34.4061),  # present
    'марганець': (47.6433, 34.6289),  # present
    'покров': (47.6542, 34.1167),
    # 'тернівка' - REMOVED: Now handled via Photon/Nominatim API with military context priority
    'першотравенськ': (48.3460, 36.4030),
    'вільногірськ': (48.4850, 34.0300),
    'жовті': (48.3456, 33.5022),  # truncated mention mapping
    'новомосковськ': (48.6333, 35.2167),
    'зарічне': (48.15, 35.2),  # Зарічне, Покровський район, Дніпропетровська область
    'зарічне дніпропетровська': (48.15, 35.2),  # Спеціально для військового контексту  
    'зарічне покровський': (48.15, 35.2),  # Альтернативний ключ
    'синельникове': (48.3167, 35.5167),
    'петропавлівка': (48.5000, 36.4500),  # present
    'покровське(дніпропетровщина)': (48.1180, 36.2470),
    'покровське дніпропетровська': (48.1180, 36.2470),
    'покровське дніпропетровщини': (48.1180, 36.2470),
    'покровське': (48.1180, 36.2470),  # present
    'богданівка(дніпро)': (48.4647, 35.0462),  # fallback to oblast center if ambiguous
    'васильківка': (48.3550, 36.1240),
    'варварівка': (48.7440, 34.7000),
    'верхівцеве': (48.4769, 34.3458),
    'верхньодніпровськ': (48.6535, 34.3372),  # present
    'губиниха': (48.7437, 35.2960),  # present
    'домоткань': (48.6680, 34.2160),
    'жеребетівка': (48.2500, 36.7000),
    'зайцеве(дніпропетровщина)': (48.4647, 35.0462),  # generic fallback center
    'зелений гай': (48.4200, 35.1200),
    'зеленодольськ': (47.5667, 33.5333),  # present
    'карнаухівка': (48.4870, 34.5480),
    'карпівка': (47.5930, 33.5960),
    'маломихайлівка': (48.2300, 36.4500),
    'меліоративне': (48.6340, 35.1750),
    'магідалинівка': (48.8836, 34.8669),  # typo guard for магдалинівка
    'магдалинівка': (48.8836, 34.8669),  # present
    'межова': (48.2583, 36.7363),  # present
    'миколаївка(дніпро)': (48.4647, 35.0462),
    'новомиколаївка(дніпро)': (48.4647, 35.0462),
    'обухівка': (48.6035, 34.8530),  # present
    'орлівщина': (48.6110, 34.9550),
    'павлоград': (48.5350, 35.8700),  # present
    'перещепине': (48.6260, 35.3580),  # present
    'петриківка': (48.7330, 34.6300),  # present
    'підгородне': (48.5747, 35.1482),  # present
    'покровське (смт)': (48.1180, 36.2470),
    'самар': (48.6500, 35.4200),  # present
    'сурсько-литовське': (48.3720, 34.8130),
    'тернівські хутори': (48.6600, 34.9400),
    'томаківка': (47.8130, 34.7450),
    'царичанка': (48.9767, 34.3772),  # present
    'чумакове': (48.3400, 35.2800),
    'шевченківське(дніпро)': (48.4647, 35.0462),
    'юр’ївка': (48.7250, 36.0130),
    'юр'"'"'ївка': (48.7250, 36.0130),  # attempt to guard variant – may adjust quoting
    'юрївка': (48.7250, 36.0130),
    'юр’ївку': (48.7250, 36.0130),
    'юр'"'"'ївку': (48.7250, 36.0130),
}

for _dp_name, _dp_coords in DNIPRO_CITY_COORDS.items():
    CITY_COORDS.setdefault(_dp_name, _dp_coords)

# Sumy (Сумська) Oblast cities & key settlements.
SUMY_CITY_COORDS = {
    'суми': (50.9077, 34.7981),  # already present
    'шостка': (51.8733, 33.4800),
    'кременчук?': (49.0670, 33.4204),  # ignore (other oblast) placeholder if mis-ref
    'охтирка': (50.3116, 34.8988),
    'р омни': (50.7497, 33.4746),  # space anomaly guard
    'ромни': (50.7497, 33.4746),  # present
    'к о тростянець': (50.4833, 34.9667),  # anomaly
    'тростянець': (50.4833, 34.9667),  # present
    'глухів': (51.6781, 33.9169),  # present
    'конотоп': (51.2417, 33.2022),  # present
    'ліпова долина': (50.5700, 33.7900),  # typo
    'липова долина': (50.5700, 33.7900),  # present
    'буринь': (51.2000, 33.8500),  # present
    'путівль': (51.3375, 33.8700),
    'середина-буда': (52.1900, 33.9300),
    'лебедин': (50.5872, 34.4912),  # present
    'недригайлів': (50.8281, 33.8781),  # present
    'в сууликівка?': (50.9077, 34.7981),  # fallback noise
    'білопілля': (51.1500, 34.3014),  # present
    'краснопілля': (50.4422, 35.3081),  # present
    'сумської області центр': (50.9077, 34.7981),
    'велика писарівка': (50.4250, 35.4650),
    'велика писарівка смт': (50.4250, 35.4650),
    'велика писарівку': (50.4250, 35.4650),
    'бранцівка?': (50.9077, 34.7981),
    'дружба(сумщина)': (51.5230, 34.5770),
    'дружба': (51.5230, 34.5770),
    'зорине?': (50.9077, 34.7981),
    'кир ик івка?': (51.2000, 33.8500),
    'к и рик івка': (51.2000, 33.8500),
    'кирзаківка?': (51.2000, 33.8500),
    'кир ик івку': (51.2000, 33.8500),
    'кир иківка': (51.2000, 33.8500),
    'кир иківку': (51.2000, 33.8500),
    'кир ик івці': (51.2000, 33.8500),
    'кир ик івці?': (51.2000, 33.8500),
    'кир иківці': (51.2000, 33.8500),
    'кир иківці?': (51.2000, 33.8500),
    'кир ичівка?': (51.2000, 33.8500),
    'к ирик івка': (51.2000, 33.8500),
    'смородине': (50.9660, 34.5500),
    'смородино': (50.9660, 34.5500),
    'смородиному': (50.9660, 34.5500),
    'смородиного': (50.9660, 34.5500),
    'ясенок?': (51.5230, 34.5770),
    'ясенок': (51.5230, 34.5770),
    'ясенку': (51.5230, 34.5770),
    'ясенку?': (51.5230, 34.5770),
    'ясенка': (51.5230, 34.5770),
    'ясенка?': (51.5230, 34.5770),
    'ясенці': (51.5230, 34.5770),
    'ясенці?': (51.5230, 34.5770),
    'ясенців': (51.5230, 34.5770),
    'ясенців?': (51.5230, 34.5770),
    'миколаївка(сумська)': (51.5667, 34.1333),  # Миколаївка, районний центр Сумської області
    'миколаївка (сумська)': (51.5667, 34.1333),  # з пробілом
    'миколаївку(сумська)': (51.5667, 34.1333),  # винительный падеж
    'миколаївку (сумська)': (51.5667, 34.1333),  # винительный падеж з пробілом
}

for _sm_name, _sm_coords in SUMY_CITY_COORDS.items():
    CITY_COORDS.setdefault(_sm_name, _sm_coords)

# Zaporizhzhia (Запорізька) Oblast cities & key settlements.
ZAPORIZHZHIA_CITY_COORDS = {
    'запоріжжя': (47.8388, 35.1396),  # already present
    'бердянськ': (46.7553, 36.7885),  # present
    'мелітополь': (46.8489, 35.3650),  # present
    'енергодар': (47.4980, 34.6580),
    'токмак': (47.2550, 35.7120),
    'пологи': (47.4768, 36.2543),
    'вільнянськ': (47.9450, 35.4350),
    'оріхів': (47.5672, 35.7814),
    'гуляйполе': (47.6611, 36.2567),
    'приморськ': (46.7310, 36.3440),
    'дазовськ': (47.8388, 35.1396),  # typo guard (азовськ?) fallback
    'азовськ?': (47.8388, 35.1396),
    'васильівка': (47.4393, 35.2745),
    'дорожнянка': (47.5540, 36.0950),
    'роботине': (47.3780, 35.9300),
    'роботиному': (47.3780, 35.9300),
    'роботиного': (47.3780, 35.9300),
    'работине': (47.3780, 35.9300),  # transliteration variant
    'чернігівка(запоріжжя)': (47.0870, 36.2320),
    'чернігівка': (47.0870, 36.2320),
    'михайлівка(запоріжжя)': (47.2730, 35.2200),
    'михайлівка': (47.2730, 35.2200),  # may conflict (other oblast) – context disambiguation
    'костянтинівка(запоріжжя)': (47.2460, 35.3220),  # small settlement, not Donetsk one
    'степногірськ': (47.5660, 35.2850),
    'камянка-дніпровська': (47.4980, 34.4000),
    'кам\'янка-дніпровська': (47.4980, 34.4000),
    'кирпотине?': (47.3780, 35.9300),  # noise variant to robotyne
    'малокатеринівка': (47.7040, 35.2710),
    'комишуваха(запорізька)': (47.5760, 35.5090),
    'комишуваха': (47.5760, 35.5090),  # duplicate name in other oblasts
    'комишувасі': (47.5760, 35.5090),
    'комишуваху': (47.5760, 35.5090),
    'чергове?': (47.8388, 35.1396),
    'н ове?': (47.8388, 35.1396),
    'нововасилівка': (47.3290, 35.5130),
    'малинівка(зап)': (47.6260, 35.8700),
    'малинівка запорізька': (47.6260, 35.8700),
    'малинівка': (47.6260, 35.8700),  # may conflict with Kharkiv one
    'веселе(запоріжжя)': (47.1700, 35.1750),
    'веселе': (47.1700, 35.1750),  # generic name multiple oblasts
    'балабине': (47.7520, 35.1660),
    'кушугум': (47.7630, 35.2200),
    'тернувате': (47.8520, 35.5560),
    'чайкине?': (47.8388, 35.1396),
}

for _zp_name, _zp_coords in ZAPORIZHZHIA_CITY_COORDS.items():
    CITY_COORDS.setdefault(_zp_name, _zp_coords)

# Poltava (Полтавська) Oblast cities & key settlements.
POLTAVA_CITY_COORDS = {
    'полтава': (49.5883, 34.5514),  # already present
    'кременчук': (49.0670, 33.4204),  # present
    'горішні плавні': (49.0123, 33.6450),  # present
    'лубни': (50.0186, 32.9931),  # present
    'миргород': (49.9688, 33.6083),
    'гадяч': (50.3713, 34.0109),  # present
    'карлівка': (49.4586, 35.1272),  # present
    'решетилівка': (49.5630, 34.0720),
    'пирятин': (50.2444, 32.5144),
    'хорол': (49.7850, 33.2200),
    'чутове': (49.7070, 35.0960),
    'глобине': (49.3958, 33.2664),
    'голтвa?': (49.5883, 34.5514),  # noise
    'нові санжари': (49.3280, 34.3170),
    'великі сорочинці': (50.0167, 33.9833),  # present
    'дикистань?': (49.9688, 33.6083),  # noise dykanka variant
    'дика нка': (49.8214, 34.5769),
    'ди канка': (49.8214, 34.5769),
    'ди канку': (49.8214, 34.5769),
    'ди канці': (49.8214, 34.5769),
    'ди к анці': (49.8214, 34.5769),
    'ди к анку': (49.8214, 34.5769),
    'ди к анка': (49.8214, 34.5769),
    'ди канки': (49.8214, 34.5769),
    'ди к анки': (49.8214, 34.5769),
    'ди к анкою': (49.8214, 34.5769),
    'ди к анкою?': (49.8214, 34.5769),
    'ди к анкою.': (49.8214, 34.5769),
    'ди к анкою,': (49.8214, 34.5769),
    'ди канкою': (49.8214, 34.5769),
    'ди канкою,': (49.8214, 34.5769),
    'ди канкою.': (49.8214, 34.5769),
    'ди к анці?': (49.8214, 34.5769),
    'ди канці?': (49.8214, 34.5769),
    'ди к анок?': (49.8214, 34.5769),
    'ди к анок': (49.8214, 34.5769),
    'ди канок?': (49.8214, 34.5769),
    'ди канок': (49.8214, 34.5769),
    'ди к анці,': (49.8214, 34.5769),
    'ди канці,': (49.8214, 34.5769),
    'ди канок.': (49.8214, 34.5769),
    'ди к анок.': (49.8214, 34.5769),
    'ди канок,': (49.8214, 34.5769),
    'ди к анок,': (49.8214, 34.5769),
    'ди ка нка': (49.8214, 34.5769),
    'ди ка нку': (49.8214, 34.5769),
    'ди ка нці': (49.8214, 34.5769),
    'ди ка нкою': (49.8214, 34.5769),
    'дика нці': (49.8214, 34.5769),
    'дика нкою': (49.8214, 34.5769),
    'ди к анці.': (49.8214, 34.5769),
    'ди канці.': (49.8214, 34.5769),
    'ди ка нці.': (49.8214, 34.5769),
    'дика нці.': (49.8214, 34.5769),
    'ди ка нкою.': (49.8214, 34.5769),
    'дика нкою.': (49.8214, 34.5769),
    'ди ка нкою,': (49.8214, 34.5769),
    'дика нкою,': (49.8214, 34.5769),
    'диканька': (49.8214, 34.5769),
    'диканьку': (49.8214, 34.5769),
    'диканьці': (49.8214, 34.5769),
    'диканькою': (49.8214, 34.5769),
    'дика нка?': (49.8214, 34.5769),
    'дика нка.': (49.8214, 34.5769),
    'дика нка,': (49.8214, 34.5769),
    'диканці': (49.8214, 34.5769),
    'дика нці?': (49.8214, 34.5769),
    'дика нок': (49.8214, 34.5769),
    'дика нок?': (49.8214, 34.5769),
    'дика нок.': (49.8214, 34.5769),
    'дика нок,': (49.8214, 34.5769),
    'дика нці': (49.8214, 34.5769),
    'дика нкою': (49.8214, 34.5769),
    'ди ка нок': (49.8214, 34.5769),
    'ди ка нок?': (49.8214, 34.5769),
    'ди ка нок.': (49.8214, 34.5769),
    'ди ка нок,': (49.8214, 34.5769),
    'заводське': (50.0750, 33.4000),
    'машівка': (49.4410, 34.8680),
    'семенівка (полтавська)': (50.6633, 32.3933),
    'семенівка полтавська': (50.6633, 32.3933),
    'семенівка': (50.6633, 32.3933),  # conflict with others
    'кобеляки': (49.1500, 34.2000),  # present
    'чорнухи': (50.2833, 33.0000),  # present
    'шишаки': (49.8992, 34.0072),  # present
    'диканька?': (49.8214, 34.5769),
    'диканьці?': (49.8214, 34.5769),
    'диканці': (49.8214, 34.5769),
    'диканку': (49.8214, 34.5769),
    'диканкою': (49.8214, 34.5769),
    'диканкою,': (49.8214, 34.5769),
    'диканкою.': (49.8214, 34.5769),
    'дик анка': (49.8214, 34.5769),
    'дик анці': (49.8214, 34.5769),
    'дик анкою': (49.8214, 34.5769),
    'дик анок': (49.8214, 34.5769),
    'дик анок?': (49.8214, 34.5769),
    'дик анок.': (49.8214, 34.5769),
    'дик анок,': (49.8214, 34.5769),
    
    # ========== CITY+OBLAST SPECIFIC COORDINATES ==========
    # These entries resolve ambiguous city names by including oblast context
    
    # Срібне (different cities in different oblasts)
    'срібне чернігівська': (51.1300, 31.9400),  # Срібне, Чернігівська область  
    'срібне чернігівська обл.': (51.1300, 31.9400),
    'срібне (чернігівська обл.)': (51.1300, 31.9400),
    'срібне чернігівщина': (51.1300, 31.9400),
    'срібне чернігівщині': (51.1300, 31.9400),
    'срібне': (51.1300, 31.9400),  # Default to Chernihiv oblast variant
    
    # Златопіль (fixing incorrect coordinates - was pointing to Donetsk)
    'златопіль харківська': (49.9800, 35.5300),  # Златопіль, Харківська область (correct)
    'златопіль харківська обл.': (49.9800, 35.5300),
    'златопіль (харківська обл.)': (49.9800, 35.5300),
    'златопіль харківщина': (49.9800, 35.5300),
    'златопіль харківщині': (49.9800, 35.5300),
    # Keep old incorrect entry as fallback for other messages, but correct default
    'златопіль': (49.9800, 35.5300),  # Override with correct Kharkiv oblast coordinates
    
    # Вільхівка (Харківська область - Чугуївський район) - NOT Volyn!
    'вільхівка (харківська обл.)': (50.0284, 36.3931),
    'вільхівка харківська': (50.0284, 36.3931),
    'вільхівка харківська обл.': (50.0284, 36.3931),
    'вільхівка харківщина': (50.0284, 36.3931),
    
    # Чернігівська область - додаткові міста
    'любеч': (51.4961, 30.2675),  # Любеч, Чернігівська область
    'любеч чернігівська': (51.4961, 30.2675),
    'любеч чернігівська обл.': (51.4961, 30.2675),
    'любеч (чернігівська обл.)': (51.4961, 30.2675),
}

for _pl_name, _pl_coords in POLTAVA_CITY_COORDS.items():
    CITY_COORDS.setdefault(_pl_name, _pl_coords)

# Mykolaiv (Миколаївська) Oblast cities & key settlements.
MYKOLAIV_CITY_COORDS = {
    'миколаїв': (46.9750, 31.9946),  # already present
    'первомайськ': (48.0449, 30.8500),  # not to confuse with Первомайський (Kharkiv)
    'вознесенськ': (47.5679, 31.3336),
    'южноукраїнськ': (47.8178, 31.1800),
    'новий буг': (47.6833, 32.5167),  # present
    'нового буга': (47.6833, 32.5167),
    'нового бугу': (47.6833, 32.5167),
    'новому бугу': (47.6833, 32.5167),
    'радушне': (47.9333, 32.5167),
    'радушному': (47.9333, 32.5167),
    'радушним': (47.9333, 32.5167),
    'нова одеса': (47.3100, 31.7830),
    'нову одесу': (47.3100, 31.7830),
    'новій одесі': (47.3100, 31.7830),
    'очаків': (46.6167, 31.5500),
    'очаков': (46.6167, 31.5500),  # russian variant
    'снігурівка': (47.0750, 32.8050),
    'снігурівку': (47.0750, 32.8050),
    'снігурівці': (47.0750, 32.8050),
    'казанка': (47.8460, 32.8460),
    'арбатська стрілка?': (46.9750, 31.9946),  # noise guard
    'доманівка': (47.6290, 30.9920),
    'врадіївка': (47.8820, 30.5910),
    'криве озеро': (47.9500, 30.3500),
    'єланець': (47.8667, 31.8667), 'єланця': (47.8667, 31.8667), 'єланцю': (47.8667, 31.8667), 'єланці': (47.8667, 31.8667),
    'баштанка': (47.4086, 32.4389), 'баштанки': (47.4086, 32.4389), 'баштанку': (47.4086, 32.4389), 'баштанці': (47.4086, 32.4389),
    'березнегувате': (47.3167, 32.8500),  # present
    'березнегуватому': (47.3167, 32.8500),
    'аркасове?': (46.9750, 31.9946),
    'кашперо-миколаївка': (47.3620, 31.8790),
    'парутине': (46.7530, 31.0160),
    'парутиному': (46.7530, 31.0160),
    'парутиного': (46.7530, 31.0160),
    'парутині': (46.7530, 31.0160),
    'коблеве': (46.6670, 31.2170),
    'коблево': (46.6670, 31.2170),
    'коблевому': (46.6670, 31.2170),
    'коблевого': (46.6670, 31.2170),
    'коблеві': (46.6670, 31.2170),
    'галіцинове': (46.9710, 31.9400),
    'галицинове': (46.9710, 31.9400),
    'галіциновому': (46.9710, 31.9400),
    'галіциново': (46.9710, 31.9400),
    'лиман (миколаїв)': (46.5410, 31.3270),
    'кутузівка?': (46.9750, 31.9946),
    'олександрівка(мик)': (46.7160, 31.8660),
    'олександрівка миколаївська': (46.7160, 31.8660),
    'олександрівка': (46.7160, 31.8660),  # multiple oblasts
    'старий буг?': (47.6833, 32.5167),
    # Додаткові населені пункти Миколаївської області
    'братське': (47.5333, 32.1667), 'братську': (47.5333, 32.1667), 'братського': (47.5333, 32.1667),
    'возсіятське': (46.8167, 32.0833), 'возсіятську': (46.8167, 32.0833), 'возсіятського': (46.8167, 32.0833),
    'березівка(миколаївська)': (47.5167, 31.4500), 'березівку(миколаївська)': (47.5167, 31.4500), 'березівці(миколаївська)': (47.5167, 31.4500),
    'дорошівка': (47.5000, 32.0500), 'дорошівки': (47.5000, 32.0500), 'дорошівку': (47.5000, 32.0500),
    'шевченкове(миколаївська)': (47.45, 31.35), 'шевченкову(миколаївська)': (47.45, 31.35),  # Шевченкове, Вознесенський район
    # Часто вживані в повідомленнях mapstransler_bot
    'широколанівка': (47.25, 31.65), 'широколанівки': (47.25, 31.65), 'широколанівку': (47.25, 31.65), 'широколанівці': (47.25, 31.65),
    'дільниче': (47.65, 32.25), 'дільничому': (47.65, 32.25), 'дільничого': (47.65, 32.25),
    'веселинове': (47.3667, 31.2333), 'веселинового': (47.3667, 31.2333), 'веселинову': (47.3667, 31.2333),
    'білозірка': (47.7833, 32.3500), 'білозірки': (47.7833, 32.3500), 'білозірку': (47.7833, 32.3500), 'білозірці': (47.7833, 32.3500),
    'григорівка(миколаївська)': (47.4167, 32.2833), 'григорівку(миколаївська)': (47.4167, 32.2833),
    'рябоконове': (47.3833, 32.2500), 'рябоконового': (47.3833, 32.2500), 'рябоконову': (47.3833, 32.2500),
}

for _my_name, _my_coords in MYKOLAIV_CITY_COORDS.items():
    CITY_COORDS.setdefault(_my_name, _my_coords)

# Odesa (Одеська) Oblast cities & key settlements.
ODESA_CITY_COORDS = {
    'одеса': (46.4825, 30.7233),  # already present
    'одесса': (46.4825, 30.7233),  # russian variant
    'чорноморськ': (46.3019, 30.6548),
    'южне': (46.6226, 31.1013),
    'південне': (46.6226, 31.1013),  # Ukrainian name for Южне (Odesa region)
    'білгород-дністровський': (46.1900, 30.3400),
    'білгород-дністровськ': (46.1900, 30.3400),
    'білгород-дністровську': (46.1900, 30.3400),
    'белгород-днестровский': (46.1900, 30.3400),
    'подільськ': (47.7425, 29.5322),
    'подольськ': (47.7425, 29.5322),
    'балта': (47.9381, 29.6125),
    'балті': (47.9381, 29.6125),
    'балту': (47.9381, 29.6125),
    'балтою': (47.9381, 29.6125),
    'артемівськ(одеса)?': (46.4825, 30.7233),  # noise
    'роздільна': (46.8450, 30.0780),
    'роздільній': (46.8450, 30.0780),
    'роздільну': (46.8450, 30.0780),
    'килія': (45.4550, 29.2680),
    'ізмаїл': (45.3511, 28.8367),
    'ізмаїлі': (45.3511, 28.8367),
    'ізмаїл у': (45.3511, 28.8367),
    'ізмаїлу': (45.3511, 28.8367),
    'вилкове': (45.4031, 29.5986),
    'вилковому': (45.4031, 29.5986),
    # Чаплине (Дніпропетровська область)
    'чаплине': (47.3811, 34.5619),
    'чаплином': (47.3811, 34.5619),
    'чаплиному': (47.3811, 34.5619),
    'рений': (45.4560, 28.2830),
    'рені': (45.4560, 28.2830),
    'рено?': (45.4560, 28.2830),
    'татарбунари': (45.8417, 29.6128),
    'сарни(одеса)?': (46.4825, 30.7233),  # noise
    'болград': (45.6772, 28.6147),
    'болграді': (45.6772, 28.6147),
    'болградом': (45.6772, 28.6147),
    'арциз': (45.9919, 29.4181),
    'арцизі': (45.9919, 29.4181),
    'арцизом': (45.9919, 29.4181),
    'таврія(одеса)?': (46.4825, 30.7233),  # noise
    'любашівка': (47.8540, 30.2550),
    'любашівці': (47.8540, 30.2550),
    'ананьїв': (47.7244, 29.9686),
    'ананьєв': (47.7244, 29.9686),
    'ананьєві': (47.7244, 29.9686),
    'ананьєву': (47.7244, 29.9686),
    'березівка(одеська)': (47.2050, 30.9080),
    'березівці(одеська)': (47.2050, 30.9080),
    'березівку(одеська)': (47.2050, 30.9080),
    'березівка': (47.2050, 30.9080),
    'березівці': (47.2050, 30.9080),
    'березівку': (47.2050, 30.9080),
    'буялик': (46.7167, 30.4167),
    'буялику': (46.7167, 30.4167),
    'буялика': (46.7167, 30.4167),
    'зато ка?': (46.0660, 30.4680),  # noise for затока
    'затока': (46.0660, 30.4680),  # present
    'кароліно-бугаз': (46.1530, 30.5200),
    'кароліно-бугазі': (46.1530, 30.5200),
    'кароліно-бугазу': (46.1530, 30.5200),
    'кароліно-бугазом': (46.1530, 30.5200),
    'градізськ(одеса)?': (46.4825, 30.7233),  # noise
    'таїрове': (46.3990, 30.6940),
    'таїровому': (46.3990, 30.6940),
    'сергіївка': (46.0006, 29.9578),
    'сергіївці': (46.0006, 29.9578),
    'сергіївку': (46.0006, 29.9578),
    'сергіївкою': (46.0006, 29.9578),
    'тузли': (45.8650, 30.0975),
    'тузл': (45.8650, 30.0975),
    'тузлах': (45.8650, 30.0975),
    'тузлами': (45.8650, 30.0975),
    'таїрово': (46.3990, 30.6940),
    'лиман(одеса)': (46.3530, 30.6500),
    'лиман одеса': (46.3530, 30.6500),
    'лиман (одеса)': (46.3530, 30.6500),
}

for _od_name, _od_coords in ODESA_CITY_COORDS.items():
    CITY_COORDS.setdefault(_od_name, _od_coords)

# Kyiv (Київська) Oblast cities & key settlements (excluding Kyiv already present).
KYIV_OBLAST_CITY_COORDS = {
    'біла церква': (49.7950, 30.1310),  # present
    'бровари': (50.5110, 30.7909),  # present
    'броварах': (50.5110, 30.7909),
    'броварів': (50.5110, 30.7909),
    'броварам': (50.5110, 30.7909),
    'бориспіль': (50.3527, 30.9550),  # present
    'гнідин': (50.3722, 30.8639),  # село біля Борисполя
    'бішів': (50.2666, 29.8869),  # село Бишів, Фастівський район
    'бишів': (50.2666, 29.8869),  # альтернативне написання
    'бишева': (50.2666, 29.8869),
    'бишеві': (50.2666, 29.8869),
    'бишеву': (50.2666, 29.8869),
    'димер': (50.7500, 30.3167),  # смт Димер
    'димері': (50.7500, 30.3167),
    'димеру': (50.7500, 30.3167),
    'ірпінь': (50.5218, 30.2506),
    'ірпеня': (50.5218, 30.2506),
    'буча': (50.5436, 30.2120),
    'бучу': (50.5436, 30.2120),
    'бучі': (50.5436, 30.2120),
    'васильків': (50.1846, 30.3133),
    'василькові': (50.1846, 30.3133),
    'василькові?': (50.1846, 30.3133),
    'фастів': (50.0780, 29.9170),
    'фастові': (50.0780, 29.9170),
    'фастову': (50.0780, 29.9170),
    'обухів': (50.1072, 30.6211),  # present
    'обухові': (50.1072, 30.6211),
    'обухову': (50.1072, 30.6211),
    'обуховом': (50.1072, 30.6211),
    'славутич': (51.5226, 30.7203),
    'славутичі': (51.5226, 30.7203),
    'славутичу': (51.5226, 30.7203),
    'славутичем': (51.5226, 30.7203),
    'березань': (50.3085, 31.4576),  # present
    'березані': (50.3085, 31.4576),
    'березаньська?': (50.3085, 31.4576),
    'сквира': (49.7333, 29.6667),  # present
    'сквирі': (49.7333, 29.6667),
    'сквиру': (49.7333, 29.6667),
    'кагарлик': (49.6607, 30.8172),
    'кагарлику': (49.6607, 30.8172),
    'кагарлику?': (49.6607, 30.8172),
    'миронівка': (49.6631, 31.0100),  # present
    'миронівці': (49.6631, 31.0100),
    'миронівку': (49.6631, 31.0100),
    'богуслав': (49.5494, 30.8741),
    'богуславі': (49.5494, 30.8741),
    'богуславу': (49.5494, 30.8741),
    'узин': (49.8216, 30.4567),  # present
    'узині': (49.8216, 30.4567),
    'узином': (49.8216, 30.4567),
    'тетієв': (49.3717, 29.6969),
    'тетієві': (49.3717, 29.6969),
    'тетієву': (49.3717, 29.6969),
    'володимирівка(київска?)': (50.4501, 30.5234),  # noise center fallback
    'володарка': (49.5240, 29.9120),
    'володарці': (49.5240, 29.9120),
    'володарку': (49.5240, 29.9120),
    'таврижжя?': (50.4501, 30.5234),
    'колонщина': (50.4150, 29.9990),
    'колонщині': (50.4150, 29.9990),
    'колонщину': (50.4150, 29.9990),
    'гребінки': (50.2500, 30.2500),  # present
    'гребінках': (50.2500, 30.2500),
    'гребінкам': (50.2500, 30.2500),
    'гребінками': (50.2500, 30.2500),
    'гребінок': (50.2500, 30.2500),
    'вишгород': (50.5840, 30.4890),  # present
    'вишгороді': (50.5840, 30.4890),
    'вишгороду': (50.5840, 30.4890),
    'вишгородом': (50.5840, 30.4890),
    'вишневе': (50.3899, 30.3932),
    'вишневому': (50.3899, 30.3932),
    'вишнево': (50.3899, 30.3932),
    'вишневого': (50.3899, 30.3932),
    'ірпінсько-бучанська агломерація?': (50.5218, 30.2506),
    'козин (київська)': (50.1520, 30.6450),
    'козин київська': (50.1520, 30.6450),
    'козин': (50.1520, 30.6450),  # multiple oblasts
    'петрівське?': (50.4501, 30.5234),
    'петрівське(київ)': (50.4501, 30.5234),
    'петрівське київська': (50.4501, 30.5234),
    'переяслав': (50.0769, 31.4610),  # Переяслав-Хмельницький
    'переяслові': (50.0769, 31.4610),
    'переяславу': (50.0769, 31.4610),
    'переяславом': (50.0769, 31.4610),
    'власівка': (50.3706, 31.2381),  # Власівка, Броварський район
    'власівці': (50.3706, 31.2381),
    'власівку': (50.3706, 31.2381),
    'власівкою': (50.3706, 31.2381),
}

for _kv_name, _kv_coords in KYIV_OBLAST_CITY_COORDS.items():
    CITY_COORDS.setdefault(_kv_name, _kv_coords)

# Cherkasy (Черкаська) Oblast cities & key settlements.
CHERKASY_CITY_COORDS = {
    'черкаси': (49.4444, 32.0598),  # already present
    'черкасах': (49.4444, 32.0598),
    'черкасам': (49.4444, 32.0598),
    'умань': (48.7484, 30.2219),
    'умані': (48.7484, 30.2219),
    'уманьу?': (48.7484, 30.2219),
    'смiла': (49.2222, 31.8878),  # alt i
    'сміла': (49.2222, 31.8878),
    'смілі': (49.2222, 31.8878),
    'смiлі': (49.2222, 31.8878),
    'смiлу': (49.2222, 31.8878),
    'смілу': (49.2222, 31.8878),
    'золотоноша': (49.6676, 32.0401),
    'золотоноші': (49.6676, 32.0401),
    'золотоношу': (49.6676, 32.0401),
    'золотоношею': (49.6676, 32.0401),
    'звенигородка': (49.0777, 30.9697),
    'звенигородці': (49.0777, 30.9697),
    'звенигородку': (49.0777, 30.9697),
    'звенегородка': (49.0777, 30.9697),  # rus typo
    'звенегородку': (49.0777, 30.9697),
    'корсунь-шевченківський': (49.4186, 31.2581),
    'корсунь-шевченківському': (49.4186, 31.2581),
    'корсунь-шевченківським': (49.4186, 31.2581),
    'городище': (49.2886, 31.4547),
    'городищі': (49.2886, 31.4547),
    'городищею': (49.2886, 31.4547),
    'христинівка': (48.8122, 29.9806),
    'христинівці': (48.8122, 29.9806),
    'христинівку': (48.8122, 29.9806),
    'монастирище': (48.9905, 29.8036),
    'монастирищі': (48.9905, 29.8036),
    'монастирищем': (48.9905, 29.8036),
    'тальне': (48.8803, 30.6872),
    'тальному': (48.8803, 30.6872),
    'тальним': (48.8803, 30.6872),
    'жашків': (49.2431, 30.1122),  # already present
    'жашкові': (49.2431, 30.1122),
    'жашкові?': (49.2431, 30.1122),
    'лисянка': (49.2547, 30.8294),
    'лисянці': (49.2547, 30.8294),
    'лисянку': (49.2547, 30.8294),
    'чигирин': (49.0797, 32.6572),
    'чигирині': (49.0797, 32.6572),
    'чигирином': (49.0797, 32.6572),
    'кам\'янка': (49.0310, 32.1050),
    'камянка': (49.0310, 32.1050),
    'кам\'янці': (49.0310, 32.1050),
    'камянці': (49.0310, 32.1050),
    'кам\'янку': (49.0310, 32.1050),
    'ватутіне': (48.7500, 30.1833),
    'ватутіному': (48.7500, 30.1833),
    'ватутіним': (48.7500, 30.1833),
    'шпола': (49.0132, 31.3942),
    'шполі': (49.0132, 31.3942),
    'шполу': (49.0132, 31.3942),
    'катеринопіль': (48.9889, 30.9633),
    'катеринополі': (48.9889, 30.9633),
    'катеринополю': (48.9889, 30.9633),
    'драбів': (49.9700, 32.1490),
    'драбові': (49.9700, 32.1490),
    'драбовом': (49.9700, 32.1490),
    'маньківка': (48.9900, 30.3500),
    'маньківці': (48.9900, 30.3500),
    'маньківку': (48.9900, 30.3500),
    'стеблів': (49.3860, 31.0550),
    'стеблеві': (49.3860, 31.0550),
    'єрки': (49.0950, 30.9817),
    'єрках': (49.0950, 30.9817),
    'мошни': (49.1967, 30.8567),
    'мошнах': (49.1967, 30.8567),
    'мошни́': (49.1967, 30.8567),
    'гельмязів': (49.0364, 31.2772),
    'гельмязові': (49.0364, 31.2772),
    'гельмязовом': (49.0364, 31.2772),
}

for _ck_name, _ck_coords in CHERKASY_CITY_COORDS.items():
    CITY_COORDS.setdefault(_ck_name, _ck_coords)

# Lviv (Львівська) Oblast cities & key settlements.
LVIV_CITY_COORDS = {
    'бібрка': (49.6353, 24.2614),
    'бібрку': (49.6353, 24.2614),
    'бібрці': (49.6353, 24.2614),
    'борислав': (49.2897, 23.4267),
    'бориславі': (49.2897, 23.4267),
    'бориславу': (49.2897, 23.4267),
    'броди': (50.0869, 25.1531),
    'бродах': (50.0869, 25.1531),
    'бродам': (50.0869, 25.1531),
    'винники': (49.8097, 24.1431),
    'винниках': (49.8097, 24.1431),
    'винники́': (49.8097, 24.1431),
    'городок': (49.6889, 23.6514),
    'городку': (49.6889, 23.6514),
    'городком': (49.6889, 23.6514),
    'дрогобич': (49.3425, 23.5075),
    'дрогобичі': (49.3425, 23.5075),
    'дрогобичем': (49.3425, 23.5075),
    'жидачів': (49.8744, 24.1403),
    'жидачові': (49.8744, 24.1403),
    'жидачевом': (49.8744, 24.1403),
    'жовква': (49.9731, 23.9719),
    'жовкві': (49.9731, 23.9719),
    'жовкву': (49.9731, 23.9719),
    'золочів': (49.8072, 24.8906),
    'золочеві': (49.8072, 24.8906),
    'золочевом': (49.8072, 24.8906),
    'кам\'янка-бузька': (50.0914, 24.0361),
    'кам\'янці-бузькій': (50.0914, 24.0361),
    'кам\'янку-бузьку': (50.0914, 24.0361),
    'миколаїв': (46.9750, 31.9946),  # Миколаїв правильный (Миколаївська обл.)
    'миколаєві': (46.9750, 31.9946),
    'миколаєвом': (46.9750, 31.9946),
    'мостиська': (49.7956, 23.1533),
    'мостиськах': (49.7956, 23.1533),
    'мостиську': (49.7956, 23.1533),
    'новий розділ': (49.4761, 24.4506),
    'новому розділі': (49.4761, 24.4506),
    'новим розділом': (49.4761, 24.4506),
    'перемишляни': (49.6708, 24.6311),
    'перемишлянах': (49.6708, 24.6311),
    'перемишлянами': (49.6708, 24.6311),
    'пустомити': (49.7256, 24.1172),
    'пустомитах': (49.7256, 24.1172),
    'пустомитами': (49.7256, 24.1172),
    'радехів': (50.2831, 24.6411),
    'радехові': (50.2831, 24.6411),
    'радехевом': (50.2831, 24.6411),
    'самбір': (49.5117, 23.2019),
    'самборі': (49.5117, 23.2019),
    'самбором': (49.5117, 23.2019),
    'сокаль': (50.4656, 24.2728),
    'сокалі': (50.4656, 24.2728),
    'сокалем': (50.4656, 24.2728),
    'старий самбір': (49.4389, 23.0006),
    'старому самборі': (49.4389, 23.0006),
    'старим самбором': (49.4389, 23.0006),
    'стрий': (49.2622, 23.8603),
    'стрию': (49.2622, 23.8603),
    'стриєм': (49.2622, 23.8603),
    'трускавець': (49.2786, 23.5064),
    'трускавці': (49.2786, 23.5064),
    'трускавцем': (49.2786, 23.5064),
    'турка': (49.1528, 23.0306),
    'турці': (49.1528, 23.0306),
    'туркою': (49.1528, 23.0306),
    'яворів': (49.9358, 23.3917),
    'яворові': (49.9358, 23.3917),
    'яворовом': (49.9358, 23.3917),
}

for _lv_name, _lv_coords in LVIV_CITY_COORDS.items():
    CITY_COORDS.setdefault(_lv_name, _lv_coords)

# Вінницька область - усі основні міста та райцентри
VINNYTSIA_CITY_COORDS = {
    # Обласний центр
    'вінниця': (49.2331, 28.4682),
    'вінниці': (49.2331, 28.4682),
    'вінницю': (49.2331, 28.4682),
    'вінницею': (49.2331, 28.4682),
    'вінницей': (49.2331, 28.4682),
    
    # Міста обласного значення
    'козятин': (49.7167, 28.8333),
    'козятині': (49.7167, 28.8333),
    'козятину': (49.7167, 28.8333),
    'хмільник': (49.5500, 27.9500),
    'хмільнику': (49.5500, 27.9500),
    'хмільника': (49.5500, 27.9500),
    'ладижин': (48.6833, 29.2333),
    'ладижині': (48.6833, 29.2333),
    'ладижину': (48.6833, 29.2333),
    'могилів-подільський': (48.4500, 27.7833),
    'могилів-подільському': (48.4500, 27.7833),
    'могилів-подільського': (48.4500, 27.7833),
    
    # Райцентри
    'бар': (49.0667, 27.6833),
    'бару': (49.0667, 27.6833),
    'бара': (49.0667, 27.6833),
    'бердичів': (49.8978, 28.6011),  # вже є в основній базі
    'бершадь': (48.3667, 29.5167),  # Бершадь - райцентр Вінницької області
    'бершаді': (48.3667, 29.5167),
    'бершадю': (48.3667, 29.5167),
    'бершадью': (48.3667, 29.5167),
    'бершадей': (48.3667, 29.5167),
    'вінницький район': (49.2331, 28.4682),
    'гайсин': (49.4167, 29.3833),
    'гайсині': (49.4167, 29.3833),
    'гайсину': (49.4167, 29.3833),
    'жмеринка': (49.0333, 28.1167),
    'жмеринці': (49.0333, 28.1167),
    'жмеринку': (49.0333, 28.1167),
    'іллінці': (49.1000, 29.2167),
    'іллінцях': (49.1000, 29.2167),
    'іллінцам': (49.1000, 29.2167),
    'калинівка': (49.4500, 28.5167),
    'калинівці': (49.4500, 28.5167),
    'калинівку': (49.4500, 28.5167),
    'козятинський район': (49.7167, 28.8333),
    'крижопіль': (48.3833, 28.8667),
    'крижополі': (48.3833, 28.8667),
    'крижополю': (48.3833, 28.8667),
    'липовець': (49.2167, 29.1833),
    'липовці': (49.2167, 29.1833),
    'липовець': (49.2167, 29.1833),
    'літин': (49.7167, 28.0667),
    'літині': (49.7167, 28.0667),
    'літину': (49.7167, 28.0667),
    'муровані курилівці': (48.6667, 29.2667),
    'мурованих куриловцях': (48.6667, 29.2667),
    'мурованими куриловцями': (48.6667, 29.2667),
    'немирів': (49.0833, 28.8333),
    'немирові': (49.0833, 28.8333),
    'немирову': (49.0833, 28.8333),
    'оратів': (48.9333, 29.5167),
    'ораніввʼ': (48.9333, 29.5167),
    'оратові': (48.9333, 29.5167),
    'піщанка': (49.5833, 29.0833),
    'піщанці': (49.5833, 29.0833),
    'піщанку': (49.5833, 29.0833),
    'погребище': (49.4833, 29.2667),
    'погребищі': (49.4833, 29.2667),
    'погребище': (49.4833, 29.2667),
    'теплик': (48.6667, 29.6667),
    'теплику': (48.6667, 29.6667),
    'тепліка': (48.6667, 29.6667),
    'томашпіль': (48.5333, 28.5167),
    'томашполі': (48.5333, 28.5167),
    'томашполю': (48.5333, 28.5167),
    'тростянець': (48.8167, 29.0167),  # Вінницька область (основний в базі - Сумська)
    'тростянці': (48.8167, 29.0167),
    'тростянець вінницька': (48.8167, 29.0167),
    'тростянець вінницький': (48.8167, 29.0167),
    'тульчин': (48.6783, 28.8486),
    'тульчині': (48.6783, 28.8486),
    'тульчину': (48.6783, 28.8486),
    'тиврів': (49.4000, 28.3167),
    'тивріві': (49.4000, 28.3167),
    'тиврову': (49.4000, 28.3167),
    'хмільницький район': (49.5500, 27.9500),
    'чернівці': (49.4167, 27.7333),  # не плутати з Чернівцями (центр області)
    'чернівцях': (49.4167, 27.7333),
    'чернівцям': (49.4167, 27.7333),
    'чечельник': (48.2167, 28.1833),
    'чечельнику': (48.2167, 28.1833),
    'чечельника': (48.2167, 28.1833),
    'шаргород': (48.7333, 28.0833),
    'шаргороді': (48.7333, 28.0833),
    'шаргороду': (48.7333, 28.0833),
    'ямпіль вінницька': (48.1333, 28.2833),  # Вінницька область (основний в базі - Сумська)
    'ямполь вінницька': (48.1333, 28.2833),
    'ямпіль вінницький': (48.1333, 28.2833),
    'ямполі вінницька': (48.1333, 28.2833),
    'ямполю вінницька': (48.1333, 28.2833),
    
    # Селища міського типу та важливі села
    'браїлів': (49.0500, 28.2000),
    'браїлові': (49.0500, 28.2000),
    'браїлову': (49.0500, 28.2000),
    'вапнярка': (49.0333, 28.4500),
    'вапнярці': (49.0333, 28.4500),
    'вапнярку': (49.0333, 28.4500),
    'гнівань': (49.2833, 28.9167),
    'гнівані': (49.2833, 28.9167),
    'гнівань': (49.2833, 28.9167),
    'дашів': (48.9000, 29.4333),
    'дашеві': (48.9000, 29.4333),
    'дашову': (48.9000, 29.4333),
    'деражня': (50.0500, 27.2667),
    'деражні': (50.0500, 27.2667),
    'деражню': (50.0500, 27.2667),
    'джулинка': (49.2500, 28.7000),
    'джулинці': (49.2500, 28.7000),
    'джулинку': (49.2500, 28.7000),
    'крижопіль': (48.3833, 28.8667),
    'лука-мелешківська': (48.6333, 29.1167),
    'луці-мелешківській': (48.6333, 29.1167),
    'луку-мелешківську': (48.6333, 29.1167),
    'мурафа': (49.1833, 28.7833),
    'мурафі': (49.1833, 28.7833),
    'мурафу': (49.1833, 28.7833),
    'охматів': (49.7500, 29.2167),
    'охматові': (49.7500, 29.2167),
    'охматову': (49.7500, 29.2167),
    'печера': (49.6167, 28.8167),
    'печері': (49.6167, 28.8167),
    'печеру': (49.6167, 28.8167),
    'славута': (50.3000, 26.8500),  # технічно Хмельницька, але часто згадується з Вінницькою
    'станіславчик': (49.0333, 28.2167),
    'станіславчику': (49.0333, 28.2167),
    'станіславчика': (49.0333, 28.2167),
    'стрижавка': (49.6833, 28.6000),
    'стрижавці': (49.6833, 28.6000),
    'стрижавку': (49.6833, 28.6000),
    'чорний острів': (49.7167, 28.6167),
    'чорному острові': (49.7167, 28.6167),
    'чорний острів': (49.7167, 28.6167),
}

for _vn_name, _vn_coords in VINNYTSIA_CITY_COORDS.items():
    CITY_COORDS.setdefault(_vn_name, _vn_coords)

# Volyn Oblast settlements (auto-generated from city_ukraine.json)
VOLYN_CITY_COORDS = {
    'адамчуки': (50.7472, 25.3254),
    'адамівка': (50.7472, 25.3254),
    'амбуків': (50.7472, 25.3254),
    'антонівка': (50.7472, 25.3254),
    'арсеновичі': (50.7472, 25.3254),
    'бабаці': (50.7472, 25.3254),
    'байківці': (50.7472, 25.3254),
    'баківці': (50.7472, 25.3254),
    'барвінок': (50.7472, 25.3254),
    'бахів': (50.7472, 25.3254),
    'башлики': (50.7472, 25.3254),
    'башова': (50.7472, 25.3254),
    'баїв': (50.7472, 25.3254),
    'бегета': (50.7472, 25.3254),
    'берегове': (50.7472, 25.3254),
    'бережанка': (50.7472, 25.3254),
    'бережниця': (50.7472, 25.3254),
    'бережці': (50.7472, 25.3254),
    'береза': (50.7472, 25.3254),
    'березичі': (50.7472, 25.3254),
    'березна воля': (50.7472, 25.3254),
    'березники': (50.7472, 25.3254),
    'березовичі': (50.7472, 25.3254),
    'березолуки': (50.7472, 25.3254),
    'берестечко': (50.7472, 25.3254),
    'берестяне': (50.7472, 25.3254),
    'береськ': (50.7472, 25.3254),
    'бермешів': (50.7472, 25.3254),
    'бистровиця': (50.7472, 25.3254),
    'битень': (50.7472, 25.3254),
    'бихів': (50.7472, 25.3254),
    'благодатне': (50.7472, 25.3254),
    'блаженик': (50.7472, 25.3254),
    'бобичі': (50.7472, 25.3254),
    'бобли': (50.7472, 25.3254),
    'боголюби': (50.7472, 25.3254),
    'богунівка': (50.7472, 25.3254),
    'богушівка': (50.7472, 25.3254),
    "богушівська мар'янівка": (50.7472, 25.3254),
    'бодячів': (50.7472, 25.3254),
    'боратин': (50.7472, 25.3254),
    'боремщина': (50.7472, 25.3254),
    'борзова': (50.7472, 25.3254),
    'борисковичі': (50.7472, 25.3254),
    'борове': (50.7472, 25.3254),
    'боровичі': (50.7472, 25.3254),
    'боровне': (50.7472, 25.3254),
    'боровуха': (50.7472, 25.3254),
    'борохів': (50.7472, 25.3254),
    'борочиче': (50.7472, 25.3254),
    'бортнів': (50.7472, 25.3254),
    'бортяхівка': (50.7472, 25.3254),
    'борщівка': (50.7472, 25.3254),
    'ботин': (50.7472, 25.3254),
    'брани': (50.7472, 25.3254),
    'брище': (50.7472, 25.3254),
    'броди': (50.7472, 25.3254),
    'бродятине': (50.7472, 25.3254),
    'брониця': (50.7472, 25.3254),
    'брунетівка': (50.7472, 25.3254),
    'бруховичі': (50.7472, 25.3254),
    'брідки': (50.7472, 25.3254),
    'бубнів': (50.7472, 25.3254),
    'будище': (50.7472, 25.3254),
    'будки': (50.7472, 25.3254),
    'будники': (50.7472, 25.3254),
    'будятичі': (50.7472, 25.3254),
    'бужани': (50.7472, 25.3254),
    'бужанка': (50.7472, 25.3254),
    'бужковичі': (50.7472, 25.3254),
    'бузаки': (50.7472, 25.3254),
    'буків': (50.7472, 25.3254),
    'буркачі': (50.7472, 25.3254),
    'буцинь': (50.7472, 25.3254),
    'бучин': (50.7472, 25.3254),
    'буяни': (50.7472, 25.3254),
    'білашів': (50.7472, 25.3254),
    'білин': (50.7472, 25.3254),
    'біличі': (50.7472, 25.3254),
    'білопіль': (50.7472, 25.3254),
    'білосток': (50.7472, 25.3254),
    'бірки': (50.7472, 25.3254),
    "в'язівне": (50.7472, 25.3254),
    "валер'янівка": (50.7472, 25.3254),
    'ватин': (50.7472, 25.3254),
    'ватинець': (50.7472, 25.3254),
    'велика ведмежка': (50.7472, 25.3254),
    'велика глуша': (50.7472, 25.3254),
    'велика осниця': (50.7472, 25.3254),
    'велика яблунька': (50.7472, 25.3254),
    'великий курінь': (50.7472, 25.3254),
    'великий обзир': (50.7472, 25.3254),
    'великий окорськ': (50.7472, 25.3254),
    'великий омеляник': (50.7472, 25.3254),
    'великий порськ': (50.7472, 25.3254),
    'велимче': (50.7472, 25.3254),
    'велицьк': (50.7472, 25.3254),
    'верба': (50.7472, 25.3254),
    'вербаїв': (50.7472, 25.3254),
    'вербичне': (50.7472, 25.3254),
    'вербка': (50.7472, 25.3254),
    'вербівка': (50.7472, 25.3254),
    'верхи': (50.7472, 25.3254),
    'верхнів': (50.7472, 25.3254),
    'верхівка': (50.7472, 25.3254),
    'веселе': (50.7472, 25.3254),
    'веснянка': (50.7472, 25.3254),
    'ветли': (50.7472, 25.3254),
    'вигнанка': (50.7472, 25.3254),
    'вигуричі': (50.7472, 25.3254),
    'видерта': (50.7472, 25.3254),
    'видраниця': (50.7472, 25.3254),
    'видричі': (50.7472, 25.3254),
    'вижгів': (50.7472, 25.3254),
    'вижично': (50.7472, 25.3254),
    'винімок': (50.7472, 25.3254),
    'високе': (50.7472, 25.3254),
    'висоцьк': (50.7472, 25.3254),
    'височне': (50.7472, 25.3254),
    'витень': (50.7472, 25.3254),
    'витуле': (50.7472, 25.3254),
    'вишеньки': (50.7472, 25.3254),
    'вишнів': (50.7472, 25.3254),
    'вишнівка': (50.7472, 25.3254),
    'вовчицьк': (50.7472, 25.3254),
    'войнин': (50.7472, 25.3254),
    'волиця': (50.7472, 25.3254),
    'волиця-дружкопільська': (50.7472, 25.3254),
    'волиця-лобачівська': (50.7472, 25.3254),
    'волиця-морозовицька': (50.7472, 25.3254),
    'володимир-волинський': (50.7472, 25.3254),
    'володимирівка': (50.7472, 25.3254),
    'волошки': (50.7472, 25.3254),
    'воля': (50.7472, 25.3254),
    'воля-ковельська': (50.7472, 25.3254),
    'воля-любитівська': (50.7472, 25.3254),
    'воля-свійчівська': (50.7472, 25.3254),
    'ворокомле': (50.7472, 25.3254),
    'ворона': (50.7472, 25.3254),
    'ворончин': (50.7472, 25.3254),
    'воротнів': (50.7472, 25.3254),
    'ворчин': (50.7472, 25.3254),
    'вощатин': (50.7472, 25.3254),
    'воютин': (50.7472, 25.3254),
    'воєгоща': (50.7472, 25.3254),
    'всеволодівка': (50.7472, 25.3254),
    'вужиськ': (50.7472, 25.3254),
    'вівчицьк': (50.7472, 25.3254),
    'відути': (50.7472, 25.3254),
    'війниця': (50.7472, 25.3254),
    'вікторяни': (50.7472, 25.3254),
    'віл': (50.7472, 25.3254),
    'вілиця': (50.7472, 25.3254),
    'вілька-підгородненська': (50.7472, 25.3254),
    'вілька-садівська': (50.7472, 25.3254),
    'вільхівка': (50.7472, 25.3254),
    'вільшанка': (50.7472, 25.3254),
    'вільшани': (48.4667, 32.2667),  # Вільшани, Кіровоградська область
    'вільшанам': (48.4667, 32.2667),
    'вільшанах': (48.4667, 32.2667),
    'вітоніж': (50.7472, 25.3254),
    'вічині': (50.7472, 25.3254),
    # ... (truncated for brevity - 1087 total settlements)
    'ізов': (50.7472, 25.3254),
}

for _volyn_name, _volyn_coords in VOLYN_CITY_COORDS.items():
    CITY_COORDS.setdefault(_volyn_name, _volyn_coords)

# Kherson Oblast Cities - Adding specific variants for города with oblast designation
KHERSON_CITY_COORDS = {
    'білозерка херсонська': (46.64, 32.88),
    'білозерка (херсонська)': (46.64, 32.88),
    'білозерка херсонська обл.': (46.64, 32.88),
    'білозерка херсонська область': (46.64, 32.88),
    'білозерка херсонщина': (46.64, 32.88),
}

for _ks_name, _ks_coords in KHERSON_CITY_COORDS.items():
    CITY_COORDS.setdefault(_ks_name, _ks_coords)

# Additional missing settlements from large UAV course messages
MISSING_SETTLEMENTS = {
    # Vinnytsia Oblast
    'пеньківка': (49.1667, 28.5500), 'пеньківку': (49.1667, 28.5500), 'пеньківці': (49.1667, 28.5500),
    'станіславчик': (49.0333, 28.2167), 'станіславчику': (49.0333, 28.2167), 'станіславчики': (49.0333, 28.2167),
    'вендичани': (48.4167, 27.9500), 'вендичанах': (48.4167, 27.9500), 'вендичани́': (48.4167, 27.9500),
    'мазурівка': (49.1000, 28.8500), 'мазурівку': (49.1000, 28.8500), 'мазурівці': (49.1000, 28.8500),
    # Odesa Oblast
    'ширяєве': (46.6167, 30.1667), 'ширяєвому': (46.6167, 30.1667), 'ширяєва': (46.6167, 30.1667),
    # Kirovohrad Oblast
    'світловодськ': (49.0556, 33.2433),  # Світловодськ, Кіровоградська область
    'гайдамацьке': (48.7833, 32.4333), 'гайдамацьком': (48.7833, 32.4333), 'гайдамацького': (48.7833, 32.4333),
    'вільшани': (48.4667, 32.2667), 'вільшанам': (48.4667, 32.2667), 'вільшанах': (48.4667, 32.2667),
    # Poltava Oblast  
    'великі сорочинці': (50.0667, 34.2833), 'великих сорочинцях': (50.0667, 34.2833), 'великими сорочинцями': (50.0667, 34.2833),
    'глобине': (49.3833, 33.2667), 'глобиному': (49.3833, 33.2667), 'глобина': (49.3833, 33.2667),
    # Sumy Oblast
    'степанівка': (50.7833, 34.5500), 'степанівку': (50.7833, 34.5500), 'степанівці': (50.7833, 34.5500),
    'липова долина': (51.1167, 34.4500), 'липовій долині': (51.1167, 34.4500), 'липову долину': (51.1167, 34.4500),
    # Chernihiv Oblast
    'гончарівське': (51.3667, 31.7833), 'гончарівському': (51.3667, 31.7833), 'гончарівського': (51.3667, 31.7833),
    # Kyiv Oblast
    'красятичі': (50.3167, 30.0500), 'красятичах': (50.3167, 30.0500), 'красятичами': (50.3167, 30.0500),
    # Zhytomyr Oblast
    'нові білокоровичі': (51.3833, 27.7167), 'нових білокоровичах': (51.3833, 27.7167), 'новими білокоровичами': (51.3833, 27.7167),
    'черняхів': (50.0667, 28.8833), 'черняхові': (50.0667, 28.8833), 'черняховом': (50.0667, 28.8833),
    'андрушівка': (50.0833, 29.8167), 'андрушівку': (50.0833, 29.8167), 'андрушівці': (50.0833, 29.8167),
    'любар': (49.9167, 27.5333), 'любарі': (49.9167, 27.5333), 'любару': (49.9167, 27.5333),
    # Khmelnytskyi Oblast
    'адампіль': (49.7667, 26.9667), 'адамполі': (49.7667, 26.9667), 'адамполю': (49.7667, 26.9667),
    # Rivne Oblast
    'деражне': (50.9167, 25.7500), 'деражному': (50.9167, 25.7500), 'деражного': (50.9167, 25.7500),
    'рокитне': (50.3167, 26.1500), 'рокитному': (50.3167, 26.1500), 'рокитного': (50.3167, 26.1500),
    'дубровиця': (51.5667, 26.5667), 'дубровицю': (51.5667, 26.5667), 'дубровиці': (51.5667, 26.5667),
    # Volyn Oblast
    'камінь-каширський': (51.6167, 24.9667), 'каменю-каширському': (51.6167, 24.9667), 'каменем-каширським': (51.6167, 24.9667),
}

for _ms_name, _ms_coords in MISSING_SETTLEMENTS.items():
    CITY_COORDS.setdefault(_ms_name, _ms_coords)

# Mapping city -> oblast stem (lowercase stems used earlier) for disambiguation when region already detected.
# Minimal subset; extend as needed.
CITY_TO_OBLAST = {
    'павлоград': 'дніпропетров',
    'дніпро': 'дніпропетров',
    'кривий ріг': 'дніпропетров',
    'львів': 'львів',
    'стрий': 'львів',
    'дробобич': 'львів',
    'київ': 'київ',
    'біла церква': 'київ',
    'бориспіль': 'київ',
    'полтава': 'полтав',
    'кременчук': 'полтав',
    'велика багачка': 'полтав',
    'гадяч': 'полтав',
    'житомир': 'житом',
    'черкаси': 'черка',
    'чернігів': 'черніг',
    'суми': 'сум',
    'липова долина': 'сум',
    'тростянець': 'сум',
    'лебедин': 'сум',
    'улянівка': 'сум',
    'одеса': 'одес',
    'миколаїв': 'микола',
    'чернівці': 'чернівц',
    'рівне': 'рівн',
    'тернопіль': 'терноп',
    'ужгород': 'ужгород',
    'луцьк': 'волин',
    'запоріжжя': 'запор',
    'харків': 'харків',
    'ахтирка': 'сум',
}

OBLAST_CENTERS = {
    'донеччина': (48.0433, 37.7974), 'донеччини': (48.0433, 37.7974), 'донеччину': (48.0433, 37.7974), 'донецька область': (48.0433, 37.7974),
    'дніпропетровщина': (48.4500, 34.9830), 'дніпропетровщини': (48.4500, 34.9830), 'дніпропетровська область': (48.4500, 34.9830),
    'кіровоградщина': (48.5132, 32.2597), 'кіровоградщини': (48.5132, 32.2597), 'кіровоградська область': (48.5132, 32.2597),
    'днепропетровщина': (48.4500, 34.9830), 'днепропетровщины': (48.4500, 34.9830),
    'чернігівщина': (51.4982, 31.2893), 'чернігівщини': (51.4982, 31.2893),
    'харківщина': (49.9935, 36.2304), 'харківщини': (49.9935, 36.2304)
    , 'дніпропетровська обл.': (48.4500, 34.9830), 'днепропетровская обл.': (48.4500, 34.9830)
    , 'чернігівська обл.': (51.4982, 31.2893), 'черниговская обл.': (51.4982, 31.2893)
    , 'харківська обл.': (49.9935, 36.2304), 'харьковская обл.': (49.9935, 36.2304)
    , 'сумщина': (50.9077, 34.7981), 'сумщини': (50.9077, 34.7981), 'сумщину': (50.9077, 34.7981), 'сумська область': (50.9077, 34.7981), 'сумська обл.': (50.9077, 34.7981), 'сумская обл.': (50.9077, 34.7981)
    , 'полтавщина': (49.5883, 34.5514), 'полтавщини': (49.5883, 34.5514), 'полтавщину': (49.5883, 34.5514), 'полтавська область': (49.5883, 34.5514), 'полтавська обл.': (49.5883, 34.5514)
    , 'київщина': (50.4501, 30.5234), 'київщини': (50.4501, 30.5234), 'київщину': (50.4501, 30.5234), 'київська область': (50.4501, 30.5234), 'київська обл.': (50.4501, 30.5234)
    , 'львівщина': (49.8397, 24.0297), 'львівщини': (49.8397, 24.0297), 'львівщину': (49.8397, 24.0297), 'львівська область': (49.8397, 24.0297), 'львівська обл.': (49.8397, 24.0297)
    , 'черкащина': (49.4444, 32.0598), 'черкащини': (49.4444, 32.0598), 'черкащину': (49.4444, 32.0598), 'черкаська область': (49.4444, 32.0598), 'черкаська обл.': (49.4444, 32.0598)
    , 'житомирщина': (50.2547, 28.6587), 'житомирщини': (50.2547, 28.6587), 'житомирщину': (50.2547, 28.6587), 'житомирська область': (50.2547, 28.6587), 'житомирська обл.': (50.2547, 28.6587)
    , 'херсонщина': (46.6354, 32.6169), 'херсонщини': (46.6354, 32.6169), 'херсонську': (46.6354, 32.6169), 'херсонська область': (46.6354, 32.6169), 'херсонська обл.': (46.6354, 32.6169)
    , 'миколаївщина': (46.9750, 31.9946), 'миколаївщини': (46.9750, 31.9946), 'миколаївську': (46.9750, 31.9946), 'миколаївська область': (46.9750, 31.9946), 'миколаївська обл.': (46.9750, 31.9946)
    , 'одесщина': (46.4825, 30.7233), 'одесьчина': (46.4825, 30.7233), 'одесьщини': (46.4825, 30.7233), 'одеську': (46.4825, 30.7233), 'одеська область': (46.4825, 30.7233), 'одеська обл.': (46.4825, 30.7233)
    , 'одещина': (46.4825, 30.7233), 'одещини': (46.4825, 30.7233), 'одещину': (46.4825, 30.7233)
    , 'волинь': (50.7472, 25.3254), 'волинська область': (50.7472, 25.3254), 'волинська обл.': (50.7472, 25.3254)
    , 'рівненщина': (50.6199, 26.2516), 'рівненщини': (50.6199, 26.2516), 'рівненщину': (50.6199, 26.2516), 'рівненська область': (50.6199, 26.2516), 'рівненська обл.': (50.6199, 26.2516)
    , 'тернопільщина': (49.5535, 25.5948), 'тернопільщини': (49.5535, 25.5948), 'тернопільщину': (49.5535, 25.5948), 'тернопільська область': (49.5535, 25.5948), 'тернопільська обл.': (49.5535, 25.5948)
    , 'хмельниччина': (49.4229, 26.9871), 'хмельниччини': (49.4229, 26.9871), 'хмельниччину': (49.4229, 26.9871), 'хмельницька область': (49.4229, 26.9871), 'хмельницька обл.': (49.4229, 26.9871)
    , 'вінниччина': (49.2331, 28.4682), 'вінниччини': (49.2331, 28.4682), 'вінниччину': (49.2331, 28.4682), 'вінницька область': (49.2331, 28.4682), 'вінницька обл.': (49.2331, 28.4682)
    , 'вінничина': (49.2331, 28.4682), 'вінничини': (49.2331, 28.4682)
    , 'закарпаття': (48.6208, 22.2879), 'закарпатська область': (48.6208, 22.2879), 'закарпатська обл.': (48.6208, 22.2879)
    , 'чернівеччина': (48.2921, 25.9358), 'чернівецька область': (48.2921, 25.9358), 'чернівецька обл.': (48.2921, 25.9358)
    , 'луганщина': (48.5740, 39.3078), 'луганщини': (48.5740, 39.3078), 'луганщину': (48.5740, 39.3078), 'луганська область': (48.5740, 39.3078), 'луганська обл.': (48.5740, 39.3078)
}

# Add no-dot variants for keys ending with ' обл.' (common source variation without the dot)
_no_dot_variants = {}
for _k,_v in list(OBLAST_CENTERS.items()):
    if _k.endswith(' обл.'):
        nd = _k[:-1]  # remove trailing '.' only
        if nd not in OBLAST_CENTERS:
            _no_dot_variants[nd] = _v
OBLAST_CENTERS.update(_no_dot_variants)

# Canonical forms for geocoding queries (region headers -> '<adj> область')
REGION_GEOCODE_CANON = {
    'полтавщина':'полтавська область','київщина':'київська область','сумщина':'сумська область','харківщина':'харківська область',
    'черкащина':'черкаська область','житомирщина':'житомирська область','львівщина':'львівська область','рівненщина':'рівненська область',
    'волинь':'волинська область','одесщина':'одеська область','одесьчина':'одеська область','дніпропетровщина':'дніпропетровська область',
    'миколаївщина':'миколаївська область','херсонщина':'херсонська область','хмельниччина':'хмельницька область','тернопільщина':'тернопільська область',
    'чернівеччина':'чернівецька область','закарпаття':'закарпатська область','донеччина':'донецька область','луганщина':'луганська область',
    'вінниччина':'вінницька область','вінничина':'вінницька область'
}

# Explicit (city, oblast form) overrides to disambiguate duplicate settlement names across oblasts.
# Key: (normalized_city, normalized_region_hint as appears in message)
OBLAST_CITY_OVERRIDES = {
    ('борова', 'харківська обл.'): (49.3743, 37.6179),  # Борова (Ізюмський р-н, Харківська)
}

# Район (district) fallback centers (можно расширять). Ключи в нижнем регистре без слова 'район'.
RAION_FALLBACK = {
    'покровський': (48.2767, 37.1763),  # Покровськ (Донецька)
    'покровский': (48.2767, 37.1763),
    'павлоградський': (48.5350, 35.8700),  # Павлоград
    'павлоградский': (48.5350, 35.8700),
    'пологівський': (47.4840, 36.2536),  # Пологи (approx center of Polohivskyi raion)
    'пологовский': (47.4840, 36.2536),
    'краматорський': (48.7389, 37.5848),
    'миколаївський': (46.9750, 31.9946),  # Mykolaivskyi raion (approx Mykolaiv city center)
    'николаевский': (46.9750, 31.9946),
    'миколаевский': (46.9750, 31.9946),
    'краматорский': (48.7389, 37.5848),
    'бахмутський': (48.5941, 38.0021),
    'бахмутский': (48.5941, 38.0021),
    'черкаський': (49.4444, 32.0598),
    'черкасский': (49.4444, 32.0598),
    'одеський': (46.4825, 30.7233),
    'одесский': (46.4825, 30.7233),
    'харківський': (49.9935, 36.2304),
    'харьковский': (49.9935, 36.2304),
    # Новые районы для многократных сообщений
    'конотопський': (51.2375, 33.2020), 'конотопский': (51.2375, 33.2020),
    'сумський': (50.8500, 34.9500), 'сумский': (50.8500, 34.9500),  # Shifted SE from Sumy city center to represent district area
    'чернігівський': (51.4982, 31.2893), 'черниговский': (51.4982, 31.2893),
    'вишгородський': (50.5850, 30.4915), 'вышгородский': (50.5850, 30.4915),
    'новгород-сіверський': (51.9874, 33.2620), 'новгород-северский': (51.9874, 33.2620),
    'чугуївський': (49.8353, 36.6880), 'чугевский': (49.8353, 36.6880), 'чугевський': (49.8353, 36.6880), 'чугуевский': (49.8353, 36.6880)
    , 'синельниківський': (48.3167, 36.5000), 'синельниковский': (48.3167, 36.5000)
    # Zaporizkyi raion (shifted off exact city center to represent wider district)
    , 'запорізький': (47.9000, 35.2500), 'запорожский': (47.9000, 35.2500)
    , 'білгород-дністровський': (46.1871, 30.3410), 'білгород-дністровского': (46.1871, 30.3410), 'білгород-дністровського': (46.1871, 30.3410)
    # Dnipro oblast & Dnipro city internal districts (to avoid fallback to generic city center)
    , 'дніпровський': (48.4500, 35.1000), 'днепровский': (48.4500, 35.1000)  # Dnipro Raion (approx centroid)
    , 'самарський': (48.5380, 35.1500), 'самарский': (48.5380, 35.1500), 'самарівський': (48.5380, 35.1500)  # Samarskyi (approx east bank)
    , 'миргородський': (49.9640, 33.6121), 'миргородский': (49.9640, 33.6121)
    , 'бериславський': (46.8367, 33.4281), 'бериславский': (46.8367, 33.4281)
    # Added batch (air alarm coverage) — approximate district administrative centers
    , 'шепетівський': (50.1822, 27.0637), 'шепетовский': (50.1822, 27.0637)  # Shepetivka
    , 'полтавський': (49.5883, 34.5514), 'полтавский': (49.5883, 34.5514)    # Poltava (raion)
    , 'хмельницький': (49.4229, 26.9871), 'хмельницкий': (49.4229, 26.9871)  # Khmelnytskyi raion (city)
    , 'куп\'янський': (49.7106, 37.6156), 'купянський': (49.7106, 37.6156)   # Kupiansk raion (Kharkiv oblast)
    , 'роменський': (50.7515, 33.4746), 'роменский': (50.7515, 33.4746)      # Romny
    , 'охтирський': (50.3103, 34.8988), 'ахтырский': (50.3103, 34.8988)      # Okhtyrka translit variant
    , 'харківський': (49.9935, 36.2304), 'харьковский': (49.9935, 36.2304)   # ensure duplication above
    , 'голованівський': (48.3833, 30.4500), 'голованевский': (48.3833, 30.4500) # Holovanivsk
    , 'лубенський': (50.0165, 32.9969), 'лубенский': (50.0165, 32.9969)      # Lubny
    , 'шосткинський': (51.8736, 33.4806), 'шосткинский': (51.8736, 33.4806)  # Shostka
    , 'кременчуцький': (49.0631, 33.4030), 'кременчугский': (49.0631, 33.4030) # Kremenchuk
    , "кам'янець-подільський": (48.6845, 26.5853), 'камянец-подольский': (48.6845, 26.5853)
    , 'богодухівський': (50.1643, 35.5272), 'богодуховский': (50.1643, 35.5272) # Bohodukhiv
    , 'кропивницький': (48.5079, 32.2623), 'кропивницкий': (48.5079, 32.2623)   # Kropyvnytskyi raion center
    , 'сарненський': (51.3373, 26.6019), 'сарненский': (51.3373, 26.6019)       # Sarny
    , 'лозівський': (48.8926, 36.3172), 'лозовский': (48.8926, 36.3172)         # Lozova
    , 'новоукраїнський': (48.3174, 31.5167), 'новоукраинский': (48.3174, 31.5167) # Novoukrainka
    , 'олександрійський': (48.6696, 33.1176), 'александрийский': (48.6696, 33.1176) # Oleksandriia
    , 'березівський': (46.8183, 31.3972), 'березовский': (46.8183, 31.3972) # Berezivka (Odesa Oblast)
    , 'охтирский': (50.3103, 34.8988)  # Russian variant explicit
    # Potential typo in feed: 'берестинський' (if meant 'Бериславський' already covered). Placeholder guess -> skip precise to avoid misplot.
}

# Known external launch / airfield / training ground coordinates for Shahed (and similar) launch detection
# Keys are normalized (lowercase, hyphen instead of spaces). Approximate coordinates.
LAUNCH_SITES = {
    'навля': (52.8300, 34.4900),              # Navlya (Bryansk Oblast training area approx)
    'полігон навля': (52.8300, 34.4900),
    'полигон навля': (52.8300, 34.4900),
    'шаталово': (54.0500, 32.2900),            # Shatalovo (Smolensk Oblast)
    'орел-південний': (52.9340, 36.0020),      # Orel South (Oryol Yuzhny)
    'орёл-южный': (52.9340, 36.0020),
    'орел-южный': (52.9340, 36.0020),
    'орёл южный': (52.9340, 36.0020),
    'орел южный': (52.9340, 36.0020),
    'приморськ-ахтарськ': (46.0420, 38.1700),  # Primorsko-Akhtarsk (Krasnodar Krai)
    'приморск-ахтарск': (46.0420, 38.1700),
    'халіно': (51.7500, 36.2950),              # Khalino (Kursk)
    'халино': (51.7500, 36.2950),
    'міллерово': (48.9250, 40.4000),           # Millerovo (Rostov Oblast) approximate airbase
    'миллерово': (48.9250, 40.4000),
    # Newly added occupied launch / training areas
    'приморськ': (46.7306, 36.3456),           # Prymorsk (Zaporizhzhia oblast, occupied coastal area)
    'полігон приморськ': (46.7306, 36.3456),
    'полигон приморск': (46.7306, 36.3456),
    'чауда': (45.0710, 36.1320),               # Chauda range (Crimea)
    'полігон чауда': (45.0710, 36.1320),
    'полигон чауда': (45.0710, 36.1320),
}

# Active raion (district) air alarms: raion_base -> dict(place, lat, lng, since)
RAION_ALARMS = {}

# Territorial hromada fallback centers (selected). Keys lower-case without word 'територіальна громада'.
HROMADA_FALLBACK = {
    'хотінська': (51.0825, 34.5860),  # Хотінська громада (approx center, Sumy raion near border)
    'хотінь': (51.0825, 34.5860),  # с. Хотінь (explicit to avoid fallback to Суми center)
}

# Specific settlement fallback for mis-localized parsing
SETTLEMENT_FALLBACK = {
    'кипти': (51.2833, 31.2167),  # Russian / simplified spelling → 'кіпті'
    'покровський район': (48.2767, 37.1763),  # Покровський район (Донецька область) - use Pokrovsk city coords as center
    'покровський р-н': (48.2767, 37.1763),  # abbreviated form
    'покровського району': (48.2767, 37.1763),  # genitive case
    'краснопавлівка-олександрівка': (50.0167, 35.95),  # Харківська область - use Краснопавлівка coords
    'краснопавлівка олександрівка': (50.0167, 35.95),  # without dash variant
}

SETTLEMENTS_FILE = os.getenv('SETTLEMENTS_FILE', 'settlements_ua.json')
SETTLEMENTS_URL = os.getenv('SETTLEMENTS_URL')  # optional remote JSON (list of {name,lat,lng})
SETTLEMENTS_MAX = int(os.getenv('SETTLEMENTS_MAX', '150000'))  # safety cap
SETTLEMENTS_INDEX = {}
SETTLEMENTS_ORDERED = []

# --------------- Optional Git auto-commit settings ---------------
GIT_AUTO_COMMIT = os.getenv('GIT_AUTO_COMMIT', '0') not in ('0','false','False','')
GIT_REPO_SLUG = os.getenv('GIT_REPO_SLUG')  # e.g. 'vavaika22423232/neptun'

# ----------- Ukrainian place name normalization (force Ukrainian display) -----------
EN_UA_PLACE_MAP = {k.lower(): v for k,v in [
    ('kyiv','Київ'),('kiev','Київ'),('kharkiv','Харків'),('kharkov','Харків'),('odesa','Одеса'),('odessa','Одеса'),
    ('lviv','Львів'),('dnipro','Дніпро'),('zaporizhzhia','Запоріжжя'),('zaporizhia','Запоріжжя'),('mykolaiv','Миколаїв'),('nikolaev','Миколаїв'),
    ('chernihiv','Чернігів'),('poltava','Полтава'),('sumy','Суми'),('kherson','Херсон'),('rivne','Рівне'),('ternopil','Тернопіль'),
    ('ivano-frankivsk','Івано-Франківськ'),('chernivtsi','Чернівці'),('uzhhorod','Ужгород'),('kropyvnytskyi','Кропивницький'),
    ('kryvyi rih','Кривий Ріг'),('kryvyi-rih','Кривий Ріг'),('sloviansk','Словʼянськ'),('slavyansk','Словʼянськ'),
    ('bakhmut','Бахмут'),('mariupol','Маріуполь'),('berdyansk','Бердянськ'),('melitopol','Мелітополь'),
    ('pavlohrad','Павлоград'),('pavlograd','Павлоград'),('pokrovsk','Покровськ'),('sevastopol','Севастополь'),('simferopol','Сімферополь')
]}

def ensure_ua_place(name: str) -> str:
    if not name or not isinstance(name,str):
        return name
    n = name.strip()
    # Already contains Ukrainian-specific letters
    if re.search(r'[іїєґʼІЇЄҐ]', n):
        return n
    low = n.lower()
    if low in EN_UA_PLACE_MAP:
        return EN_UA_PLACE_MAP[low]
    # Basic transliteration fallback for ascii-only names
    if re.fullmatch(r'[a-zA-Z\-\s]+', n):
        s = low
        # multi-char sequences first
        repl = [
            ('shch','щ'),('sch','щ'),('kh','х'),('ch','ч'),('sh','ш'),('ya','я'),('yu','ю'),('ye','є'),('yi','ї'),('zh','ж'),('ii','ії'),
            ('ie','є'),('jo','йо'),('yo','йо')
        ]
        for a,b in repl:
            s = re.sub(a,b,s)
        single = {
            'a':'а','b':'б','c':'к','d':'д','e':'е','f':'ф','g':'г','h':'г','i':'і','j':'й','k':'к','l':'л','m':'м','n':'н','o':'о','p':'п',
            'q':'к','r':'р','s':'с','t':'т','u':'у','v':'в','w':'в','x':'кс','y':'и','z':'з','ʼ':'ʼ','-':'-',' ':' '
        }
        out = ''.join(single.get(ch,ch) for ch in s)
        # Capitalize first letter and letters after dash/space
        def cap_tokens(txt):
            # Use raw regex to avoid invalid escape sequence warning for \s
            parts = re.split(r'([-\s])', txt)
            return ''.join(p.capitalize() if i%2==0 else p for i,p in enumerate(parts))
        return cap_tokens(out)
    return n

# -------- Persistent visit tracking (SQLite) to survive redeploys --------
VISITS_DB = os.getenv('VISITS_DB','visits.db')
_SQLITE_PRAGMAS = [
    "PRAGMA journal_mode=WAL;",
    "PRAGMA synchronous=NORMAL;",
    "PRAGMA foreign_keys=ON;"
]
def _visits_db_conn():
    conn = sqlite3.connect(VISITS_DB, timeout=5, check_same_thread=False)
    try:
        # Apply pragmas every time (cheap) to ensure durability/performance settings even after restart
        for p in _SQLITE_PRAGMAS:
            try:
                conn.execute(p)
            except Exception:
                pass
    except Exception:
        pass
    return conn

_RECENT_SEEDED = False
def _seed_recent_from_sql():
    """If rolling recent visits file missing/outdated or lost after redeploy, rebuild from SQLite so
    Day / Week counts remain stable across deployments."""
    global _RECENT_SEEDED
    if _RECENT_SEEDED:
        return
    try:
        data = _load_recent_visits() or {}
        tz = pytz.timezone('Europe/Kyiv')
        now_dt = datetime.now(tz)
        today_str = now_dt.strftime('%Y-%m-%d')
        week_cut = now_dt - timedelta(days=7)
        today_start = tz.localize(datetime.strptime(today_str, '%Y-%m-%d')).timestamp()
        week_start_ts = week_cut.timestamp()
        with _visits_db_conn() as conn:
            cur_day = conn.execute("SELECT id FROM visits WHERE last_seen >= ?", (today_start,))
            day_ids = [r[0] for r in cur_day.fetchall()]
            cur_week = conn.execute("SELECT id FROM visits WHERE last_seen >= ?", (week_start_ts,))
            week_ids = [r[0] for r in cur_week.fetchall()]
        need_seed = False
        # Conditions to trigger seeding: empty/missing file, day mismatch, or counts smaller than SQL (lost state)
        if not data:
            need_seed = True
        else:
            if data.get('day') != today_str:
                need_seed = True
            elif len(set(data.get('today_ids', []))) < len(day_ids):
                need_seed = True
            elif len(set(data.get('week_ids', []))) < len(week_ids):
                need_seed = True
        if need_seed:
            data = {
                'day': today_str,
                'today_ids': list(dict.fromkeys(day_ids)),  # preserve order unique
                'week_ids': list(dict.fromkeys(week_ids)),
                'week_start': week_cut.strftime('%Y-%m-%d')  # informational; rolling window logic tolerates
            }
            _save_recent_visits(data)
            log.info(f"recent visits seeded from SQL: day={len(day_ids)} week={len(week_ids)}")
        _RECENT_SEEDED = True
    except Exception as e:
        log.warning(f"recent visits seeding failed: {e}")

def init_visits_db():
    try:
        with _visits_db_conn() as conn:
            conn.execute("CREATE TABLE IF NOT EXISTS visits (id TEXT PRIMARY KEY, ip TEXT, first_seen REAL, last_seen REAL)")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_visits_first ON visits(first_seen)")
            # Helpful for fast lookups of currently active users by recent activity window
            conn.execute("CREATE INDEX IF NOT EXISTS idx_visits_last ON visits(last_seen)")
            # Add ip column if missing (for existing databases)
            try:
                conn.execute("ALTER TABLE visits ADD COLUMN ip TEXT")
            except:
                pass  # Column already exists
    except Exception as e:
        log.warning(f"visits db init failed: {e}")

# --------------- Persistent comments (SQLite) ---------------
def init_comments_db():
    """Create comments table if missing. Uses same SQLite DB as visits for simplicity."""
    try:
        with _visits_db_conn() as conn:
            conn.execute("""
                CREATE TABLE IF NOT EXISTS comments (
                    id TEXT PRIMARY KEY,
                    text TEXT,
                    ts   TEXT,
                    epoch REAL
                )
            """)
            # Enhanced reactions table
            conn.execute("""
                CREATE TABLE IF NOT EXISTS comment_reactions (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    comment_id TEXT NOT NULL,
                    emoji TEXT NOT NULL,
                    user_ip TEXT NOT NULL,
                    timestamp REAL NOT NULL,
                    UNIQUE(comment_id, emoji, user_ip)
                )
            """)
            # Migration: ensure reply_to column exists
            cur = conn.execute("PRAGMA table_info(comments)")
            cols = [r[1] for r in cur.fetchall()]
            if 'reply_to' not in cols:
                try:
                    conn.execute("ALTER TABLE comments ADD COLUMN reply_to TEXT")
                    log.info('comments table migrated: added reply_to column')
                except Exception as me:
                    log.warning(f'failed adding reply_to column: {me}')
            # Create indexes (individually wrapped)
            for idx_sql in [
                "CREATE INDEX IF NOT EXISTS idx_comments_epoch ON comments(epoch)",
                "CREATE INDEX IF NOT EXISTS idx_comments_reply ON comments(reply_to)",
                "CREATE INDEX IF NOT EXISTS idx_reactions_comment ON comment_reactions(comment_id)",
                "CREATE INDEX IF NOT EXISTS idx_reactions_user ON comment_reactions(user_ip)"
            ]:
                try:
                    conn.execute(idx_sql)
                except Exception as ie:
                    log.debug(f'index create skipped: {ie}')
    except Exception as e:
        log.warning(f"comments db init failed: {e}")

# --------------- Redirect pages tracking ---------------
def init_redirect_tracking_db():
    """Create redirect_visits table for tracking redirect page visits"""
    try:
        with _visits_db_conn() as conn:
            conn.execute("""
                CREATE TABLE IF NOT EXISTS redirect_visits (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    page_name TEXT NOT NULL,
                    user_ip TEXT,
                    user_agent TEXT,
                    timestamp REAL NOT NULL
                )
            """)
            conn.execute("CREATE INDEX IF NOT EXISTS idx_redirect_page ON redirect_visits(page_name)")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_redirect_timestamp ON redirect_visits(timestamp)")
            log.info("Redirect tracking database initialized")
    except Exception as e:
        log.warning(f"redirect tracking db init failed: {e}")

def track_redirect_visit(page_name, user_ip=None, user_agent=None):
    """Track a visit to a redirect page"""
    try:
        with _visits_db_conn() as conn:
            conn.execute("""
                INSERT INTO redirect_visits (page_name, user_ip, user_agent, timestamp)
                VALUES (?, ?, ?, ?)
            """, (page_name, user_ip, user_agent, time.time()))
    except Exception as e:
        log.warning(f"Failed to track redirect visit: {e}")

def get_redirect_stats():
    """Get statistics for all redirect pages"""
    try:
        with _visits_db_conn() as conn:
            # Get total visits per page
            cur = conn.execute("""
                SELECT page_name, COUNT(*) as total_visits,
                       COUNT(DISTINCT user_ip) as unique_visitors,
                       MAX(timestamp) as last_visit
                FROM redirect_visits
                GROUP BY page_name
                ORDER BY total_visits DESC
            """)
            stats = {}
            for row in cur.fetchall():
                page_name, total, unique, last = row
                stats[page_name] = {
                    'total_visits': total,
                    'unique_visitors': unique,
                    'last_visit': datetime.fromtimestamp(last, tz=pytz.UTC).isoformat() if last else None
                }
            return stats
    except Exception as e:
        log.warning(f"Failed to get redirect stats: {e}")
        return {}

def save_comment_record(item:dict):
    try:
        with _visits_db_conn() as conn:
            conn.execute("INSERT OR REPLACE INTO comments (id,text,ts,epoch,reply_to) VALUES (?,?,?,?,?)",
                         (item.get('id'), item.get('text'), item.get('ts'), item.get('epoch'), item.get('reply_to')))
    except Exception as e:
        log.warning(f"save_comment_record failed: {e}")

def load_recent_comments(limit:int=80)->list[dict]:
    rows = []
    try:
        with _visits_db_conn() as conn:
            try:
                cur = conn.execute("SELECT id,text,ts,reply_to FROM comments ORDER BY epoch DESC LIMIT ?", (limit,))
                fetched = cur.fetchall()
            except Exception as sel_err:
                # Fallback legacy schema (no reply_to); try to migrate then retry
                log.warning(f'comments select fallback (legacy schema): {sel_err}')
                try:
                    conn.execute("ALTER TABLE comments ADD COLUMN reply_to TEXT")
                    cur = conn.execute("SELECT id,text,ts,reply_to FROM comments ORDER BY epoch DESC LIMIT ?", (limit,))
                    fetched = cur.fetchall()
                except Exception as mig_err:
                    log.warning(f'comments migration select failed: {mig_err}')
                    # Last resort: select without reply_to
                    try:
                        cur = conn.execute("SELECT id,text,ts FROM comments ORDER BY epoch DESC LIMIT ?", (limit,))
                        fetched = [(*r, None) for r in cur.fetchall()]
                    except Exception:
                        fetched = []
            for rid, text, ts, reply_to in fetched:
                d={'id': rid, 'text': text, 'ts': ts}
                if reply_to: d['reply_to']=reply_to
                
                # Load reactions for this comment
                try:
                    reactions = load_comment_reactions(rid, conn)
                    if reactions:
                        d['reactions'] = reactions
                except Exception:
                    pass  # Non-critical, skip reactions if failed
                
                rows.append(d)
    except Exception as e:
        log.warning(f"load_recent_comments failed: {e}")
    return list(reversed(rows))  # reverse so oldest of the slice first

def load_comment_reactions(comment_id: str, conn=None) -> dict:
    """Load reaction counts for a specific comment."""
    try:
        if conn:
            cur = conn.execute("""
                SELECT emoji, COUNT(*) as count 
                FROM comment_reactions 
                WHERE comment_id = ? 
                GROUP BY emoji
            """, (comment_id,))
            
            reactions = {}
            for emoji, count in cur.fetchall():
                reactions[emoji] = count
            return reactions
        else:
            with _visits_db_conn() as use_conn:
                cur = use_conn.execute("""
                    SELECT emoji, COUNT(*) as count 
                    FROM comment_reactions 
                    WHERE comment_id = ? 
                    GROUP BY emoji
                """, (comment_id,))
                
                reactions = {}
                for emoji, count in cur.fetchall():
                    reactions[emoji] = count
                return reactions
    except Exception as e:
        log.debug(f"load_comment_reactions failed: {e}")
        return {}

def toggle_comment_reaction(comment_id: str, emoji: str, user_ip: str) -> dict:
    """Toggle a reaction on a comment. Returns updated reaction counts."""
    try:
        with _visits_db_conn() as conn:
            # Check if reaction already exists
            cur = conn.execute("""
                SELECT id FROM comment_reactions 
                WHERE comment_id = ? AND emoji = ? AND user_ip = ?
            """, (comment_id, emoji, user_ip))
            
            existing = cur.fetchone()
            
            if existing:
                # Remove existing reaction
                conn.execute("DELETE FROM comment_reactions WHERE id = ?", (existing[0],))
                action = 'removed'
            else:
                # Add new reaction
                conn.execute("""
                    INSERT INTO comment_reactions (comment_id, emoji, user_ip, timestamp)
                    VALUES (?, ?, ?, ?)
                """, (comment_id, emoji, user_ip, time.time()))
                action = 'added'
            
            conn.commit()
            
            # Return updated counts
            reactions = load_comment_reactions(comment_id, conn)
            return {'action': action, 'reactions': reactions}
            
    except Exception as e:
        log.warning(f"toggle_comment_reaction failed: {e}")
        return {'action': 'error', 'reactions': {}}

def record_visit_sql(id_:str, now_ts:float, ip_addr:str=None):
    if not id_:
        return
    try:
        with _visits_db_conn() as conn:
            # Use upsert pattern to avoid race between SELECT and INSERT under concurrent requests
            conn.execute("INSERT OR IGNORE INTO visits (id,ip,first_seen,last_seen) VALUES (?,?,?,?)", (id_, ip_addr, now_ts, now_ts))
            conn.execute("UPDATE visits SET last_seen=?, ip=? WHERE id=?", (now_ts, ip_addr, id_))
    except Exception as e:
        log.warning(f"record_visit_sql failed: {e}")

def sql_unique_counts():
    try:
        with _visits_db_conn() as conn:
            tz = pytz.timezone('Europe/Kyiv')
            now_dt = datetime.now(tz)
            today_start = tz.localize(datetime.strptime(now_dt.strftime('%Y-%m-%d'), '%Y-%m-%d'))
            week_start = now_dt - timedelta(days=7)
            today_ts = today_start.timestamp()
            week_ts = week_start.timestamp()
            cur1 = conn.execute("SELECT COUNT(*) FROM visits WHERE last_seen >= ?", (today_ts,))
            day = cur1.fetchone()[0]
            cur2 = conn.execute("SELECT COUNT(*) FROM visits WHERE last_seen >= ?", (week_ts,))
            week = cur2.fetchone()[0]
            return day, week
    except Exception as e:
        log.warning(f"sql_unique_counts failed: {e}")
    return None, None

def _active_sessions_from_db(ttl:int)->list[dict]:
    """Return list of active sessions (id, first_seen, last_seen) from persistent DB within ttl seconds."""
    cutoff = time.time() - ttl
    out = []
    try:
        with _visits_db_conn() as conn:
            cur = conn.execute("SELECT id, first_seen, last_seen FROM visits WHERE last_seen >= ?", (cutoff,))
            for row in cur.fetchall():
                try:
                    out.append({'id': row[0], 'first': float(row[1] or 0), 'last': float(row[2] or 0)})
                except Exception:
                    continue
    except Exception as e:
        log.warning(f"active sessions db query failed: {e}")
    return out

# Initialize DB at import
init_visits_db()
init_comments_db()
init_redirect_tracking_db()
init_alarms_db()
init_alarm_events_db()
# Restore persisted active alarms
try:
    _obl,_r = load_active_alarms(APP_ALARM_TTL_MINUTES*60)
    if _obl: ACTIVE_OBLAST_ALARMS.update(_obl)
    if _r: ACTIVE_RAION_ALARMS.update(_r)
except Exception as _e_rec:
    log.debug(f'alarm restore failed: {_e_rec}')
# Preload recent comments into in-memory cache so first GET can serve quickly without hitting DB again
try:
    COMMENTS = load_recent_comments(limit=COMMENTS_MAX)
except Exception as _e:
    log.debug(f'preload comments failed: {_e}')
GIT_SYNC_TOKEN = os.getenv('GIT_SYNC_TOKEN')  # GitHub PAT (classic or fine-grained) with repo write
GIT_COMMIT_INTERVAL = int(os.getenv('GIT_COMMIT_INTERVAL', '180'))  # seconds between commits
_last_git_commit = 0

# Delay before first Telegram connect (helps избежать пересечения старого и нового инстанса при деплое)
FETCH_START_DELAY = int(os.getenv('FETCH_START_DELAY', '0'))  # seconds

# NOTE: maybe_git_autocommit() is defined later in the file (near line 16860)
# with full support for chat_messages.json and devices.json

def _download_settlements():
    if not SETTLEMENTS_URL or os.path.exists(SETTLEMENTS_FILE):
        return False
    try:
        import requests
        r = requests.get(SETTLEMENTS_URL, timeout=30)
        if r.status_code == 200:
            with open(SETTLEMENTS_FILE, 'wb') as f:
                f.write(r.content)
            log.info(f'Downloaded settlements file from {SETTLEMENTS_URL}')
            return True
        else:
            log.warning(f'Failed to download settlements ({r.status_code}) from {SETTLEMENTS_URL}')
    except Exception as e:
        log.warning(f'Error downloading settlements: {e}')
    return False

def _load_settlements():
    global SETTLEMENTS_INDEX, SETTLEMENTS_ORDERED
    if not os.path.exists(SETTLEMENTS_FILE):
        _download_settlements()
    if not os.path.exists(SETTLEMENTS_FILE):
        log.info('No settlements file present; only basic CITY_COORDS will be used.')
        return
    try:
        with open(SETTLEMENTS_FILE, 'r', encoding='utf-8') as f:
            data = json.load(f)
        count = 0
        for item in data:
            if count >= SETTLEMENTS_MAX:
                break
            try:
                name = item.get('name') or item.get('n')
                if not name:
                    continue
                lat_raw = item.get('lat')
                lng_raw = item.get('lng') or item.get('lon')
                if lat_raw is None or lng_raw is None:
                    continue
                lat = float(lat_raw)
                lng = float(lng_raw)
                key = name.strip().lower()
                if key and key not in SETTLEMENTS_INDEX:
                    SETTLEMENTS_INDEX[key] = (lat, lng)
                    count += 1
            except Exception:
                continue
        SETTLEMENTS_ORDERED = sorted(SETTLEMENTS_INDEX.keys(), key=len, reverse=True)[:SETTLEMENTS_MAX]
        log.info(f'Loaded settlements: {len(SETTLEMENTS_INDEX)} (cap {SETTLEMENTS_MAX})')
    except Exception as e:
        log.warning(f'Failed to load settlements file {SETTLEMENTS_FILE}: {e}')

_load_settlements()

# ---- External comprehensive cities/settlements file merge (user-provided) ----
# You supplied an external file with full coordinates of Ukrainian cities / settlements.
# Set EXT_CITIES_FILE env var (default 'city_ukraine.json') and place the file in the app working directory.
# Accepted JSON shapes:
#   1) List[ { name|city|settlement: str, lat|latitude: float, lng|lon|long|longitude: float } ]
#   2) List[ [ name, lat, lon ] ]
#   3) Dict[str, { lat: x, lng: y }] or Dict[str, [lat, lon]]
# Fields may also appear in Ukrainian/Russian ("назва","широта","довгота","долгота").
EXT_CITIES_FILE = os.getenv('EXT_CITIES_FILE', 'city_ukraine.json')

def _load_external_cities():
    global CITY_COORDS, SETTLEMENTS_INDEX, SETTLEMENTS_ORDERED
    path = EXT_CITIES_FILE
    if not path or not os.path.exists(path):
        return
    try:
        with open(path, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except Exception as e:
        log.warning(f"Failed reading {path}: {e}")
        return
    added = 0
    def add_entry(name_raw, lat_raw, lon_raw):
        nonlocal added
        try:
            if name_raw is None: return
            name = str(name_raw).strip().lower()
            if not name or len(name) < 2: return
            lat = float(lat_raw); lon = float(lon_raw)
            # Basic sanity bounds for Ukraine region (approx) to skip corrupt rows
            if not (43.0 <= lat <= 53.5 and 21.0 <= lon <= 41.5):
                return
            if name not in CITY_COORDS:
                CITY_COORDS[name] = (lat, lon)
            if name not in SETTLEMENTS_INDEX:
                SETTLEMENTS_INDEX[name] = (lat, lon)
                added += 1
        except Exception:
            return
    if isinstance(data, dict):
        # Expect mapping name -> {lat,lng} or name -> [lat,lon]
        for k,v in data.items():
            if isinstance(v, dict):
                lat = v.get('lat') or v.get('latitude') or v.get('широта')
                lon = v.get('lng') or v.get('lon') or v.get('long') or v.get('longitude') or v.get('довгота') or v.get('долгота')
                add_entry(k, lat, lon)
            elif isinstance(v, (list, tuple)) and len(v) >= 2:
                add_entry(k, v[0], v[1])
    elif isinstance(data, list):
        for item in data:
            if isinstance(item, dict):
                name = item.get('name') or item.get('city') or item.get('settlement') or item.get('населенный пункт') or item.get('населений пункт') or item.get('назва')
                lat = item.get('lat') or item.get('latitude') or item.get('широта')
                lon = item.get('lng') or item.get('lon') or item.get('long') or item.get('longitude') or item.get('довгота') or item.get('долгота')
                add_entry(name, lat, lon)
            elif isinstance(item, (list, tuple)) and len(item) >= 3:
                add_entry(item[0], item[1], item[2])
    # Rebuild ordered list (largest names first to prefer longer multi-word matches)
    if added:
        try:
            SETTLEMENTS_ORDERED = sorted(SETTLEMENTS_INDEX.keys(), key=len, reverse=True)[:SETTLEMENTS_MAX]
        except Exception:
            pass
        log.info(f"Merged external cities file {path}: +{added} settlements (total {len(SETTLEMENTS_INDEX)})")
    else:
        log.info(f"External cities file {path} parsed; no new settlements added (maybe already present)")

_load_external_cities()

def geocode_opencage(place: str):
    if not OPENCAGE_API_KEY:
        return None
    
    # Skip if known negative
    if neg_geocode_check(place):
        return None
    
    # Block general directional terms that don't represent specific places
    place_lower = place.lower().strip()
    directional_terms = [
        'напрямок', 'напрям', 'направлении', 'направление',
        'північно-східний', 'північно-західний', 'південно-східний', 'південно-західний',
        'північний', 'південний', 'східний', 'західний',
        'nord', 'south', 'east', 'west', 'northeast', 'northwest', 'southeast', 'southwest'
    ]
    
    if any(term in place_lower for term in directional_terms):
        # Add to negative cache to avoid repeated attempts
        neg_geocode_add(place, 'directional')
        return None
    
    cache = _load_opencage_cache()
    key = place.strip().lower()
    now = int(datetime.utcnow().timestamp())
    if key in cache:
        entry = cache[key]
        if now - entry.get('ts', 0) < OPENCAGE_TTL:
            return tuple(entry['coords']) if entry['coords'] else None
    import requests
    try:
        resp = requests.get('https://api.opencagedata.com/geocode/v1/json', params={
            'q': place,
            'key': OPENCAGE_API_KEY,
            'language': 'uk',
            'limit': 1,
            'countrycode': 'ua'
        }, timeout=6)
        if resp.status_code == 200:
            data = resp.json()
            if data.get('results'):
                g = data['results'][0]['geometry']
                coords = (g['lat'], g['lng'])
                cache[key] = {'ts': now, 'coords': coords}
                _save_opencage_cache()
                return coords
        # negative (no results or non-200)
        cache[key] = {'ts': now, 'coords': None}
        _save_opencage_cache(); neg_geocode_add(place,'nocode')
        return None
    except Exception as e:
        log.warning(f"OpenCage error for '{place}': {e}")
        cache[key] = {'ts': now, 'coords': None}
        _save_opencage_cache(); neg_geocode_add(place,'error')
        return None

def calculate_projected_path(source_lat, source_lng, target_lat, target_lng, speed_kmh=50):
    """
    Calculate projected path from source to target with intermediate points
    
    Args:
        source_lat, source_lng: Current/source coordinates
        target_lat, target_lng: Target coordinates  
        speed_kmh: Estimated speed in km/h (default: 50 km/h for UAVs)
    
    Returns:
        dict with path_points, estimated_arrival, total_distance
    """
    try:
        # Calculate distance using Haversine formula
        R = 6371  # Earth's radius in km
        
        lat1_rad = math.radians(source_lat)
        lon1_rad = math.radians(source_lng)
        lat2_rad = math.radians(target_lat)
        lon2_rad = math.radians(target_lng)
        
        dlat = lat2_rad - lat1_rad
        dlon = lon2_rad - lon1_rad
        
        a = math.sin(dlat/2)**2 + math.cos(lat1_rad) * math.cos(lat2_rad) * math.sin(dlon/2)**2
        c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))
        distance_km = R * c
        
        # Calculate estimated travel time
        travel_time_hours = distance_km / speed_kmh
        travel_time_minutes = travel_time_hours * 60
        
        # Generate intermediate points along the path (every ~10km or 10 points max)
        num_points = min(10, max(2, int(distance_km / 10)))
        path_points = []
        
        for i in range(num_points + 1):
            fraction = i / num_points
            
            # Linear interpolation for simple path
            lat = source_lat + (target_lat - source_lat) * fraction
            lng = source_lng + (target_lng - source_lng) * fraction
            
            # Calculate ETA for this point
            point_travel_time = travel_time_minutes * fraction
            
            path_points.append({
                'lat': lat,
                'lng': lng,
                'eta_minutes': point_travel_time,
                'fraction': fraction
            })
        
        return {
            'path_points': path_points,
            'total_distance_km': distance_km,
            'estimated_arrival_minutes': travel_time_minutes,
            'speed_kmh': speed_kmh
        }
        
    except Exception as e:
        print(f"ERROR calculating projected path: {e}")
        return None

def create_eta_circles(center_lat, center_lng, time_minutes, speed_kmh=50):
    """
    Create ETA circles showing possible positions after given time
    
    Args:
        center_lat, center_lng: Center coordinates
        time_minutes: Time in minutes
        speed_kmh: Speed in km/h
        
    Returns:
        List of circle definitions for different confidence levels
    """
    try:
        # Calculate distance that can be covered in given time
        max_distance_km = (speed_kmh * time_minutes) / 60
        
        # Create circles with different confidence levels
        circles = []
        
        # 90% confidence circle (slightly smaller radius)
        circles.append({
            'center_lat': center_lat,
            'center_lng': center_lng,
            'radius_km': max_distance_km * 0.9,
            'confidence': 90,
            'color': '#ff4444',
            'opacity': 0.3,
            'stroke_color': '#cc0000',
            'stroke_width': 2
        })
        
        # 50% confidence circle (even smaller)
        circles.append({
            'center_lat': center_lat,
            'center_lng': center_lng,
            'radius_km': max_distance_km * 0.6,
            'confidence': 50,
            'color': '#ffaa00',
            'opacity': 0.4,
            'stroke_color': '#ff8800',
            'stroke_width': 2
        })
        
        return circles
        
    except Exception as e:
        print(f"ERROR creating ETA circles: {e}")
        return []

def _create_directional_trajectory_markers(text, mid, date_str, channel):
    """
    Create trajectory markers for directional movement messages
    Instead of showing destination marker, show projected path and ETA circles
    """
    import re
    from datetime import datetime, timedelta
    
    try:
        text_lower = text.lower()
        
        # Extract target city from directional patterns
        target_city = None
        source_direction = None
        
        # Patterns to extract target city
        target_patterns = [
            r'у напрямку\s+([а-яіїєґ\'\-\s]+?)(?:\s|$|з)',
            r'в напрямку\s+([а-яіїєґ\'\-\s]+?)(?:\s|$|з)',
            r'курс на\s+([а-яіїєґ\'\-\s]+?)(?:\s|$|з)',
            r'прямує до\s+([а-яіїєґ\'\-\s]+?)(?:\s|$|з)'
        ]
        
        for pattern in target_patterns:
            match = re.search(pattern, text_lower)
            if match:
                target_city = match.group(1).strip()
                break
        
        # Extract source direction
        direction_patterns = [
            r'з\s+(північного?-?сходу?)',
            r'з\s+(південного?-?заходу?)', 
            r'з\s+(північного?-?заходу?)',
            r'з\s+(південного?-?сходу?)',
            r'з\s+(півночі)',
            r'з\s+(півдня)',
            r'з\s+(заходу)',
            r'з\s+(сходу)'
        ]
        
        for pattern in direction_patterns:
            match = re.search(pattern, text_lower)
            if match:
                source_direction = match.group(1)
                break
        
        if not target_city:
            return []
        
        # Normalize target city name and get coordinates
        target_city_normalized = target_city.lower().strip()
        
        # Try to find coordinates for target city
        target_coords = None
        
        # Check in CITY_COORDS
        if target_city_normalized in CITY_COORDS:
            target_coords = CITY_COORDS[target_city_normalized]
        else:
            # Try common variations and declensions
            common_variations = {
                'дніпро': 'дніпро',
                'киев': 'київ', 
                'київа': 'київ',
                'харков': 'харків',
                'харкова': 'харків',
                'одесса': 'одеса',
                'одеси': 'одеса'
            }
            
            for variant, canonical in common_variations.items():
                if variant in target_city_normalized or target_city_normalized in variant:
                    if canonical in CITY_COORDS:
                        target_coords = CITY_COORDS[canonical]
                        break
            
            # If still not found, try removing common endings (declensions)
            if not target_coords:
                endings_to_try = ['а', 'у', 'ом', 'і', 'ів', 'ами']
                for ending in endings_to_try:
                    if target_city_normalized.endswith(ending) and len(target_city_normalized) > len(ending) + 2:
                        base_form = target_city_normalized[:-len(ending)]
                        # Special case for київ + а = києва -> київ  
                        if base_form + ending == 'києва':
                            base_form = 'київ'
                        if base_form in CITY_COORDS:
                            target_coords = CITY_COORDS[base_form]
                            break
        
        if not target_coords:
            # Fallback - return empty if we can't find target coordinates
            return []
        
        target_lat, target_lng = target_coords
        
        # Estimate source coordinates based on direction
        source_lat, source_lng = _estimate_source_coordinates(target_lat, target_lng, source_direction)
        
        # Create projected path
        projected_path = calculate_projected_path(source_lat, source_lng, target_lat, target_lng)
        
        if not projected_path:
            return []
        
        # Create trajectory markers
        markers = []
        
        # Add path markers (intermediate points)
        for i, point in enumerate(projected_path['path_points'][1:-1], 1):  # Skip first and last
            if i % 2 == 0:  # Only show every other point to avoid clutter
                continue
                
            markers.append({
                'id': f"{mid}_path_{i}",
                'place': f"Траєкторія ({int(point['eta_minutes'])}хв)",
                'lat': point['lat'],
                'lng': point['lng'],
                'threat_type': 'trajectory',
                'text': f"Проміжна точка маршруту до {target_city.title()}",
                'date': date_str,
                'channel': channel,
                'marker_icon': 'trajectory.png',
                'source_match': 'projected_path',
                'eta_minutes': point['eta_minutes'],
                'marker_type': 'trajectory_point',
                'opacity': 0.7
            })
        
        # Add ETA circles around target - DISABLED
        # eta_circles = create_eta_circles(target_lat, target_lng, projected_path['estimated_arrival_minutes'])
        
        # Create main target marker with trajectory info
        markers.append({
            'id': f"{mid}_target",
            'place': f"{target_city.title()} (ціль)",
            'lat': target_lat,
            'lng': target_lng,
            'threat_type': 'trajectory_target',
            'text': f"Ціль: {target_city.title()}",  # ETA removed
            'date': date_str,
            'channel': channel,
            'marker_icon': 'target.png',
            'source_match': 'trajectory_target',
            'distance_km': projected_path['total_distance_km'],
            'marker_type': 'trajectory_target',
            # 'eta_circles': eta_circles,  # DISABLED
            'projected_path': projected_path['path_points']
        })
        
        return markers
        
    except Exception as e:
        print(f"ERROR creating directional trajectory markers: {e}")
        return []

def _estimate_source_coordinates(target_lat, target_lng, direction):
    """Estimate source coordinates based on target and direction"""
    
    # Default distance for estimation (50km)
    distance_km = 50
    
    # Direction offsets (approximate)
    direction_offsets = {
        'північного-сходу': (-0.45, 0.45),
        'південного-заходу': (0.45, -0.45),
        'північного-заходу': (-0.45, -0.45), 
        'південного-сходу': (0.45, 0.45),
        'півночі': (-0.45, 0),
        'півдня': (0.45, 0),
        'заходу': (0, -0.45),
        'сходу': (0, 0.45)
    }
    
    # Get offset or default to east
    lat_offset, lng_offset = direction_offsets.get(direction, (0, 0.45))
    
    # Apply offset (rough approximation: 1 degree ≈ 111km)
    source_lat = target_lat + lat_offset
    source_lng = target_lng + lng_offset
    
    return source_lat, source_lng

# =============================================================================
# TRAJECTORY PARSER - Parse various Ukrainian message formats for drone courses
# =============================================================================
# Supports formats like:
# - "БпЛА з півночі на Суми" (direction + target city)
# - "Група БпЛА на сході Миколаївщини курсом на Кіровоградщину" (region + direction + target)
# - "БпЛА з Херсонщини на Миколаївщину" (source region → target region)
# - "БпЛА курсом на м.Запоріжжя з північно-східного напрямку" (city target + direction)
# - "Харків: БпЛА на місто з північно-східного напрямку" (city prefix + direction)
# - "БпЛА на Дніпропетровщині, напрямок Синельникове" (region + target city)
# =============================================================================

# Direction mappings (Ukrainian → offset vector)
DIRECTION_VECTORS = {
    # Cardinal directions - all forms
    'північ': (-0.5, 0), 'півночі': (-0.5, 0), 'північн': (-0.5, 0), 'північний': (-0.5, 0),
    'південь': (0.5, 0), 'півдня': (0.5, 0), 'півд': (0.5, 0), 'південн': (0.5, 0), 'півдні': (0.5, 0), 'південний': (0.5, 0),
    'схід': (0, 0.5), 'сходу': (0, 0.5), 'східн': (0, 0.5), 'сході': (0, 0.5), 'східний': (0, 0.5),
    'захід': (0, -0.5), 'заходу': (0, -0.5), 'західн': (0, -0.5), 'заході': (0, -0.5), 'західний': (0, -0.5),
    # Intercardinal directions - all forms
    'північно-східн': (-0.35, 0.35), 'північний схід': (-0.35, 0.35), 'північного сходу': (-0.35, 0.35),
    'північно-східний': (-0.35, 0.35), 'північно-схід': (-0.35, 0.35),
    'північно-західн': (-0.35, -0.35), 'північний захід': (-0.35, -0.35), 'північного заходу': (-0.35, -0.35),
    'північно-західний': (-0.35, -0.35), 'північно-захід': (-0.35, -0.35),
    'південно-східн': (0.35, 0.35), 'південний схід': (0.35, 0.35), 'південного сходу': (0.35, 0.35),
    'південно-східний': (0.35, 0.35), 'південно-схід': (0.35, 0.35),
    'південно-західн': (0.35, -0.35), 'південний захід': (0.35, -0.35), 'південного заходу': (0.35, -0.35),
    'південно-західний': (0.35, -0.35), 'південно-захід': (0.35, -0.35),
}

# Direction keywords in messages (source direction - "з" pattern)
DIRECTION_FROM_KEYWORDS = [
    'з північно-східного напрямку', 'з північно-західного напрямку',
    'з південно-східного напрямку', 'з південно-західного напрямку',
    'з північного напрямку', 'з південного напрямку', 
    'з східного напрямку', 'з західного напрямку',
    'з півночі', 'з півдня', 'з сходу', 'з заходу',
    'з північного сходу', 'з північного заходу',
    'з південного сходу', 'з південного заходу',
]

# Course keywords in messages (target direction - "курс" pattern)
DIRECTION_COURSE_KEYWORDS = [
    'курс північно-східний', 'курс північно-західний',
    'курс південно-східний', 'курс південно-західний',
    'курс північний', 'курс південний', 'курс східний', 'курс західний',
    'курсом на північ', 'курсом на південь', 'курсом на схід', 'курсом на захід',
]

def _get_direction_vector(direction_text):
    """Get lat/lng offset vector for a direction text"""
    direction_lower = direction_text.lower().strip()
    for key, vector in DIRECTION_VECTORS.items():
        if key in direction_lower:
            return vector
    return None

def _get_region_center(region_name):
    """Get center coordinates for a region (oblast)"""
    region_lower = region_name.lower().strip()
    # Check in OBLAST_CENTERS directly
    if region_lower in OBLAST_CENTERS:
        return OBLAST_CENTERS[region_lower]
    
    # Normalize instrumental case "над вінницькою областю" → "вінницька область"
    # Pattern: Xькою областю → Xька область
    instrumental_match = re.match(r'^(.+?)(ькою|ською|цькою)\s*(областю|обл\.?)$', region_lower)
    if instrumental_match:
        base = instrumental_match.group(1)
        # Convert back to nominative: ькою→ька, ською→ська, цькою→цька
        suffix_map = {'ькою': 'ька', 'ською': 'ська', 'цькою': 'цька'}
        new_suffix = suffix_map.get(instrumental_match.group(2), 'ька')
        normalized = f"{base}{new_suffix} область"
        if normalized in OBLAST_CENTERS:
            return OBLAST_CENTERS[normalized]
        # Try without ' область'
        normalized_short = f"{base}{new_suffix}"
        if normalized_short in OBLAST_CENTERS:
            return OBLAST_CENTERS[normalized_short]
    
    # Try removing common endings and searching again
    # Ukrainian oblast name endings: -щина/-щини/-щині/-щину, -ччина/-ччини/-ччині
    base_region = region_lower
    for ending in ['щині', 'щину', 'щини', 'щина', 'ччині', 'ччину', 'ччини', 'ччина']:
        if region_lower.endswith(ending):
            base_region = region_lower[:-len(ending)]
            break
    
    # Try to find with base + common endings
    for ending in ['щина', 'щини', 'ччина', 'ччини']:
        test_key = base_region + ending
        if test_key in OBLAST_CENTERS:
            return OBLAST_CENTERS[test_key]
    
    # Try partial match
    for key, coords in OBLAST_CENTERS.items():
        if base_region in key or key.startswith(base_region):
            return coords
    
    return None

def _get_city_coords(city_name):
    """Get coordinates for a city"""
    city_lower = city_name.lower().strip()
    # Remove prefixes like "м.", "н.п.", "с."
    city_lower = re.sub(r'^(м\.|м\s|н\.п\.|н\.п\s|с\.|с\s|сел\.|смт\.?|смт\s)', '', city_lower).strip()
    
    # Check in CITY_COORDS
    if city_lower in CITY_COORDS:
        return CITY_COORDS[city_lower]
    
    # Try variations without endings
    endings = ['а', 'у', 'ом', 'і', 'ів', 'ами', 'е', 'ої', 'ою', 'и']
    for ending in endings:
        if city_lower.endswith(ending) and len(city_lower) > len(ending) + 2:
            base = city_lower[:-len(ending)]
            if base in CITY_COORDS:
                return CITY_COORDS[base]
            # Handle vowel alternations: одеси → одес → одеса
            if ending == 'и':
                base_a = base + 'а'  # одеси → одеса
                if base_a in CITY_COORDS:
                    return CITY_COORDS[base_a]
    
    # Handle Ukrainian vowel alternation in genitive: миколаєва → миколаїв
    # Pattern: base + 'єва' (genitive) → base + 'їв' (nominative)
    if city_lower.endswith('єва'):
        base = city_lower[:-3] + 'їв'  # миколаєва → миколаїв
        if base in CITY_COORDS:
            return CITY_COORDS[base]
    
    # Also try simple base search for partial matches
    for key, coords in CITY_COORDS.items():
        if city_lower.startswith(key) or key.startswith(city_lower.rstrip('аеоуіїю')):
            return coords
    
    return None

def _offset_coords(lat, lng, direction_vector):
    """Apply direction offset to coordinates"""
    lat_offset, lng_offset = direction_vector
    return (lat + lat_offset, lng + lng_offset)

def _ai_trajectory_to_coords(ai_result):
    """Convert AI trajectory result to coordinates.
    
    Takes AI result with source_type, source_name, target_type, target_name
    and returns trajectory dict with start/end coordinates.
    """
    if not ai_result:
        return None
    
    source_type = ai_result.get('source_type')
    source_name = ai_result.get('source_name')
    target_type = ai_result.get('target_type')
    target_name = ai_result.get('target_name')
    source_position = ai_result.get('source_position')  # e.g. "схід" for "на сході Сумщини"
    
    # Get target coordinates
    end_coords = None
    if target_type == 'city' and target_name:
        end_coords = _get_city_coords(target_name)
    elif target_type == 'region' and target_name:
        end_coords = _get_region_center(target_name)
    elif target_type == 'direction' and target_name:
        # Direction only - need source to calculate end
        pass
    
    # Get source coordinates
    start_coords = None
    if source_type == 'city' and source_name:
        start_coords = _get_city_coords(source_name)
    elif source_type == 'region' and source_name:
        start_coords = _get_region_center(source_name)
        # Apply position offset if specified (e.g. "на сході Сумщини")
        if start_coords and source_position:
            pos_vec = _get_direction_vector(source_position)
            if pos_vec:
                start_coords = (start_coords[0] + pos_vec[0] * 0.3, start_coords[1] + pos_vec[1] * 0.3)
    elif source_type == 'direction' and source_name:
        # Direction source - calculate from target
        if end_coords:
            dir_vec = _get_direction_vector(source_name)
            if dir_vec:
                # Invert direction to get source position
                start_coords = (end_coords[0] - dir_vec[0], end_coords[1] - dir_vec[1])
    
    # Handle target direction (when target is a direction like "курс південний")
    if target_type == 'direction' and target_name and start_coords and not end_coords:
        dir_vec = _get_direction_vector(target_name)
        if dir_vec:
            end_coords = (start_coords[0] + dir_vec[0] * 0.5, start_coords[1] + dir_vec[1] * 0.5)
    
    # =========================================================================
    # AI ROUTE PREDICTION: If we have source but no target, use AI to predict
    # MAX DISTANCE: 300 km (only neighboring regions) - prevents Kharkiv->Lutsk errors
    # =========================================================================
    MAX_PREDICTION_DISTANCE_KM = 300  # ~neighboring oblast
    
    if start_coords and not end_coords and GROQ_ENABLED:
        try:
            prediction = predict_route_with_ai(source_name or '')
            if prediction and prediction.get('confidence', 0) >= 0.6:
                predicted_targets = prediction.get('predicted_targets', [])
                if predicted_targets:
                    # Try each predicted target, use first within distance limit
                    for target in predicted_targets:
                        predicted_coords = _get_region_center(target) or _get_city_coords(target)
                        if predicted_coords:
                            # Calculate distance between start and predicted end
                            from math import radians, sin, cos, sqrt, atan2
                            lat1, lon1 = radians(start_coords[0]), radians(start_coords[1])
                            lat2, lon2 = radians(predicted_coords[0]), radians(predicted_coords[1])
                            dlat, dlon = lat2 - lat1, lon2 - lon1
                            a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2
                            distance_km = 6371 * 2 * atan2(sqrt(a), sqrt(1-a))
                            
                            if distance_km <= MAX_PREDICTION_DISTANCE_KM:
                                end_coords = predicted_coords
                                target_name = target + ' (прогноз)'
                                print(f"DEBUG AI Route Prediction used: {source_name} -> {target} ({distance_km:.0f}km, conf={prediction.get('confidence')})")
                                break
                            else:
                                print(f"DEBUG AI Route Prediction REJECTED (too far): {source_name} -> {target} ({distance_km:.0f}km > {MAX_PREDICTION_DISTANCE_KM}km)")
        except Exception as e:
            print(f"DEBUG: AI route prediction failed: {e}")
    
    # Need both start and end to create trajectory
    if not start_coords or not end_coords:
        return None
    
    return {
        'start': [start_coords[0], start_coords[1]],
        'end': [end_coords[0], end_coords[1]],
        'source_name': source_name or 'unknown',
        'target_name': target_name or 'unknown',
        'kind': f'ai_{source_type}_to_{target_type}',
        'predicted': end_coords and '(прогноз)' in (target_name or '')
    }

def parse_trajectory_from_message(text):
    """
    Parse trajectory info from Ukrainian drone movement messages.
    
    Uses AI (Groq) when available for intelligent parsing, with regex fallback.
    
    Returns dict with:
        - start: [lat, lng] - source coordinates
        - end: [lat, lng] - target coordinates  
        - source_name: str - source location name
        - target_name: str - target location name
        - kind: str - type of trajectory match
    Or None if no trajectory pattern found.
    """
    import re
    if not text:
        return None
    
    # ==========================================================================
    # TRY AI FIRST (if enabled) - much smarter than regex
    # ==========================================================================
    if GROQ_ENABLED:
        try:
            ai_result = extract_trajectory_with_ai(text)
            if ai_result and ai_result.get('confidence', 0) >= 0.7:
                trajectory = _ai_trajectory_to_coords(ai_result)
                if trajectory:
                    print(f"DEBUG: AI trajectory parsed successfully: {trajectory.get('kind')}")
                    return trajectory
        except Exception as e:
            print(f"DEBUG: AI trajectory failed, falling back to regex: {e}")
    
    # ==========================================================================
    # FALLBACK TO REGEX PATTERNS
    # ==========================================================================
    text_lower = text.lower()
    # Remove emoji prefixes for pattern matching
    text_clean = re.sub(r'^[^\w\s]*\s*', '', text_lower)
    
    # =========================================================================
    # Pattern 1: "БпЛА з [напрямок] на [місто]"
    # Example: "БпЛА з півночі на Суми"
    # =========================================================================
    p1 = re.search(r'(?:група\s+)?(?:бпла|шахед|дрон)\s+з\s+(півноч[іи]|півдн[яю]|сход[уі]|заход[уі]|північн\w*[\s-]*схо\w*|північн\w*[\s-]*захо\w*|південн\w*[\s-]*схо\w*|південн\w*[\s-]*захо\w*)\s+на\s+([а-яіїєґ\'\-]+)', text_lower)
    if p1:
        direction_text = p1.group(1)
        target_city = p1.group(2)
        
        target_coords = _get_city_coords(target_city)
        if target_coords:
            direction_vec = _get_direction_vector(direction_text)
            if direction_vec:
                # Invert direction to get source (from direction -> opposite)
                start_lat = target_coords[0] - direction_vec[0]
                start_lng = target_coords[1] - direction_vec[1]
                return {
                    'start': [start_lat, start_lng],
                    'end': [target_coords[0], target_coords[1]],
                    'source_name': f'з {direction_text}',
                    'target_name': target_city.title(),
                    'kind': 'direction_to_city'
                }
    
    # =========================================================================
    # Pattern 2: "БпЛА з [регіон] на [регіон]"
    # Example: "БпЛА з Херсонщини на Миколаївщину"
    # =========================================================================
    p2 = re.search(r'(?:група\s+)?(?:бпла|шахед|дрон)\s+з\s+([а-яіїєґ]+(щин|ччин)[ауиіи])\s+на\s+([а-яіїєґ]+(щин|ччин)[ауиію])', text_lower)
    if p2:
        source_region = p2.group(1)
        target_region = p2.group(3)
        
        source_coords = _get_region_center(source_region)
        target_coords = _get_region_center(target_region)
        
        if source_coords and target_coords:
            return {
                'start': [source_coords[0], source_coords[1]],
                'end': [target_coords[0], target_coords[1]],
                'source_name': source_region.title(),
                'target_name': target_region.title(),
                'kind': 'region_to_region'
            }
    
    # =========================================================================
    # Pattern 2a: "БпЛА з [регіон] курсом на [регіон], напрямок [місто/міста]"
    # Example: "БпЛА з Київщини курсом на Житомирщину, напрямок Коростень/Овруч"
    # =========================================================================
    p2a = re.search(r'(?:група\s+)?(?:бпла|шахед|дрон)\s+з\s+([а-яіїєґ]+(щин|ччин)[иіау])\s+курсом\s+на\s+([а-яіїєґ]+(щин|ччин)[у|ю])[,\s]+(?:напрямок|напрям)\s+(?:м\.?|н\.?п\.?)?\s*([а-яіїєґ\'\-/]+)', text_lower)
    if p2a:
        source_region = p2a.group(1)
        target_region = p2a.group(3)
        target_cities = p2a.group(5)  # May contain multiple cities like "Коростень/Овруч"
        
        source_coords = _get_region_center(source_region)
        # Try to get coords for the first city mentioned
        first_city = target_cities.split('/')[0].split(',')[0].strip()
        target_coords = _get_city_coords(first_city)
        
        # Fallback to region center if city not found
        if not target_coords:
            target_coords = _get_region_center(target_region)
        
        if source_coords and target_coords:
            return {
                'start': [source_coords[0], source_coords[1]],
                'end': [target_coords[0], target_coords[1]],
                'source_name': source_region.title(),
                'target_name': target_cities.title(),
                'kind': 'region_course_to_city'
            }
    
    # =========================================================================
    # Pattern 2b: "БпЛА з [регіон] курсом на [регіон]" (без напрямку)
    # Example: "БпЛА з Київщини курсом на Житомирщину"
    # =========================================================================
    p2b = re.search(r'(?:група\s+)?(?:бпла|шахед|дрон)\s+з\s+([а-яіїєґ]+(щин|ччин)[иіау])\s+курсом\s+на\s+([а-яіїєґ]+(щин|ччин)[уюі])', text_lower)
    if p2b:
        source_region = p2b.group(1)
        target_region = p2b.group(3)
        
        source_coords = _get_region_center(source_region)
        target_coords = _get_region_center(target_region)
        
        if source_coords and target_coords:
            return {
                'start': [source_coords[0], source_coords[1]],
                'end': [target_coords[0], target_coords[1]],
                'source_name': source_region.title(),
                'target_name': target_region.title(),
                'kind': 'region_course_to_region'
            }
    
    # =========================================================================
    # Pattern 3: "БпЛА на [напрямок] [регіон] курсом на [регіон]"
    # Example: "Група БпЛА на сході Миколаївщини курсом на Кіровоградщину"
    # =========================================================================
    p3 = re.search(r'(?:група\s+)?(?:бпла|шахед|дрон)\s+на\s+(півноч[іи]|півдн[іи]|сход[іиі]|заход[іиі]|північн\w*[\s-]*схо\w*|північн\w*[\s-]*захо\w*|південн\w*[\s-]*схо\w*|південн\w*[\s-]*захо\w*)\s+([а-яіїєґ]+(щин|ччин)[иі])\s+курсом\s+на\s+([а-яіїєґ]+(щин|ччин)[ауиію])', text_lower)
    if p3:
        direction_in_region = p3.group(1)
        source_region = p3.group(2)
        target_region = p3.group(4)
        
        source_coords = _get_region_center(source_region)
        target_coords = _get_region_center(target_region)
        
        if source_coords and target_coords:
            # Offset source by direction within the region
            direction_vec = _get_direction_vector(direction_in_region)
            if direction_vec:
                start_lat = source_coords[0] + direction_vec[0] * 0.3
                start_lng = source_coords[1] + direction_vec[1] * 0.3
            else:
                start_lat, start_lng = source_coords
            
            return {
                'start': [start_lat, start_lng],
                'end': [target_coords[0], target_coords[1]],
                'source_name': f'{direction_in_region} {source_region}'.title(),
                'target_name': target_region.title(),
                'kind': 'region_direction_to_region'
            }
    
    # =========================================================================
    # Pattern 4: "БпЛА курсом на м.[місто] з [напрямок] напрямку"
    # Example: "БпЛА курсом на м.Запоріжжя з північно-східного напрямку"
    # =========================================================================
    p4 = re.search(r'(?:група\s+)?(?:бпла|шахед|дрон)\s+курсом\s+на\s+(?:м\.?|місто\s+)?([а-яіїєґ\'\-]+)\s+з\s+(північн\w*[\s-]*схід\w*|північн\w*[\s-]*захід\w*|південн\w*[\s-]*схід\w*|південн\w*[\s-]*захід\w*|північн\w*|південн\w*|східн\w*|західн\w*)\s*напрямку', text_lower)
    if p4:
        target_city = p4.group(1)
        direction_text = p4.group(2)
        
        target_coords = _get_city_coords(target_city)
        if target_coords:
            direction_vec = _get_direction_vector(direction_text)
            if direction_vec:
                start_lat = target_coords[0] - direction_vec[0]
                start_lng = target_coords[1] - direction_vec[1]
                return {
                    'start': [start_lat, start_lng],
                    'end': [target_coords[0], target_coords[1]],
                    'source_name': f'з {direction_text} напрямку',
                    'target_name': target_city.title(),
                    'kind': 'city_from_direction'
                }
    
    # =========================================================================
    # Pattern 5: "[Місто]: БпЛА на місто з [напрямок] напрямку"
    # Example: "🛵 Харків: БпЛА на місто з північно-східного напрямку"
    # =========================================================================
    p5 = re.search(r'([а-яіїєґ\'\-]+)\s*:\s*(?:група\s+)?(?:бпла|шахед|дрон)\s+на\s+місто\s+з\s+(північн\w*[\s-]*схід\w*|північн\w*[\s-]*захід\w*|південн\w*[\s-]*схід\w*|південн\w*[\s-]*захід\w*|північн\w*|південн\w*|східн\w*|західн\w*)\s*напрямку', text_clean)
    if p5:
        target_city = p5.group(1)
        direction_text = p5.group(2)
        
        target_coords = _get_city_coords(target_city)
        if target_coords:
            direction_vec = _get_direction_vector(direction_text)
            if direction_vec:
                start_lat = target_coords[0] - direction_vec[0]
                start_lng = target_coords[1] - direction_vec[1]
                return {
                    'start': [start_lat, start_lng],
                    'end': [target_coords[0], target_coords[1]],
                    'source_name': f'з {direction_text}',
                    'target_name': target_city.title(),
                    'kind': 'city_prefix_direction'
                }
    
    # =========================================================================
    # Pattern 6: "[Місто]: БпЛА з [напрямок]"
    # Example: "🛵 Харків: БпЛА з півночі"
    # =========================================================================
    p6 = re.search(r'([а-яіїєґ\'\-]+)\s*:\s*(?:група\s+)?(?:бпла|шахед|дрон)\s+з\s+(півноч[іи]|півдн[яю]|сход[уі]|заход[уі]|північн\w*[\s-]*схо\w*|північн\w*[\s-]*захо\w*|південн\w*[\s-]*схо\w*|південн\w*[\s-]*захо\w*)', text_clean)
    if p6:
        target_city = p6.group(1)
        direction_text = p6.group(2)
        
        target_coords = _get_city_coords(target_city)
        if target_coords:
            direction_vec = _get_direction_vector(direction_text)
            if direction_vec:
                start_lat = target_coords[0] - direction_vec[0]
                start_lng = target_coords[1] - direction_vec[1]
                return {
                    'start': [start_lat, start_lng],
                    'end': [target_coords[0], target_coords[1]],
                    'source_name': f'з {direction_text}',
                    'target_name': target_city.title(),
                    'kind': 'city_prefix_from'
                }
    
    # =========================================================================
    # Pattern 7: "БпЛА на [регіон], напрямок/курс на [місто]"
    # Example: "БпЛА на Дніпропетровщині, напрямок Синельникове"
    # Example: "Група БпЛА на Одещині, курс на н.п. Кілія"
    # =========================================================================
    p7 = re.search(r'(?:група\s+)?(?:бпла|шахед|дрон)\s+на\s+([а-яіїєґ]+(щин|ччин)[іиї])[,.\s]+(?:напрямок|напрям|у напрямку|в напрямку|курс на|курс)\s+(?:м\.?|н\.?п\.?)?\s*([а-яіїєґ\'\-\s]+?)(?:\.|$)', text_lower)
    if p7:
        source_region = p7.group(1)
        target_city = p7.group(3).strip()
        
        source_coords = _get_region_center(source_region)
        target_coords = _get_city_coords(target_city)
        
        if source_coords and target_coords:
            return {
                'start': [source_coords[0], source_coords[1]],
                'end': [target_coords[0], target_coords[1]],
                'source_name': source_region.title(),
                'target_name': target_city.title(),
                'kind': 'region_to_city'
            }
    
    # =========================================================================
    # Pattern 7b: "БпЛА над [регіон] курсом на [напрямок]"
    # Example: "🛵 Шахед над Вінницькою областю курсом на північ"
    # =========================================================================
    p7b = re.search(r'(?:група\s+)?(?:бпла|шахед|дрон)\s+(?:над|на)\s+([а-яіїєґ]+(?:ою|ій)\s+област[іиюь]|[а-яіїєґ]+(щин|ччин)[іиою])\s*,?\s*курсом?\s+на\s+(північ|південь|схід|захід|північний[\s-]*схід|північний[\s-]*захід|південний[\s-]*схід|південний[\s-]*захід)', text_lower)
    if p7b:
        source_region = p7b.group(1)
        direction = p7b.group(3)
        
        source_coords = _get_region_center(source_region)
        if source_coords:
            direction_vec = _get_direction_vector(direction)
            if direction_vec:
                end_lat = source_coords[0] + direction_vec[0] * 0.5
                end_lng = source_coords[1] + direction_vec[1] * 0.5
                return {
                    'start': [source_coords[0], source_coords[1]],
                    'end': [end_lat, end_lng],
                    'source_name': source_region.title(),
                    'target_name': f'курс на {direction}',
                    'kind': 'region_course_direction'
                }
    
    # =========================================================================
    # Pattern 7c: "Група БпЛА на [регіон] в напрямку [місто]"
    # Example: "🛵 Група БпЛА на Одещині в напрямку Миколаєва"
    # =========================================================================
    p7c = re.search(r'(?:група\s+)?(?:бпла|шахед|дрон)\s+(?:на|над)\s+([а-яіїєґ]+(щин|ччин)[іиї])\s*,?\s*(?:в|у)\s+напрямку\s+(?:м\.?|н\.?п\.?)?\s*([а-яіїєґ\'\-]+)', text_lower)
    if p7c:
        source_region = p7c.group(1)
        target_city = p7c.group(3).strip()
        
        source_coords = _get_region_center(source_region)
        target_coords = _get_city_coords(target_city)
        
        if source_coords and target_coords:
            return {
                'start': [source_coords[0], source_coords[1]],
                'end': [target_coords[0], target_coords[1]],
                'source_name': source_region.title(),
                'target_name': target_city.title(),
                'kind': 'region_towards_city_v2'
            }
    
    # =========================================================================
    # Pattern 7a: "БпЛА з акваторії [море] на [регіон], курс на [місто]"
    # Example: "Група БпЛА з акваторії Чорного моря на Одещині. курс на Старі Трояни."
    # =========================================================================
    p7a = re.search(r'(?:група\s+)?(?:бпла|шахед|дрон)\s+з\s+акваторії\s+([а-яіїєґ\'\-\s]+моря)\s+на\s+([а-яіїєґ]+(щин|ччин)[іиї])[,.\s]+курс\s+(?:на\s+)?(?:м\.?|н\.?п\.?)?\s*([а-яіїєґ\'\-\s]+?)(?:\.|$)', text_lower)
    if p7a:
        sea_name = p7a.group(1)
        region = p7a.group(2)
        target_city = p7a.group(4).strip()
        
        # Coordinates for seas (approximate entry points to Ukraine)
        sea_coords = {
            'чорного моря': (45.5, 31.5),  # Black Sea south of Odesa
            'азовського моря': (46.5, 36.5),  # Azov Sea
        }
        
        source_coords = sea_coords.get(sea_name, (45.5, 31.5))  # Default to Black Sea
        target_coords = _get_city_coords(target_city)
        
        # Fallback to region center if city not found
        if not target_coords:
            target_coords = _get_region_center(region)
        
        if target_coords:
            return {
                'start': [source_coords[0], source_coords[1]],
                'end': [target_coords[0], target_coords[1]],
                'source_name': sea_name.title(),
                'target_name': target_city.title(),
                'kind': 'sea_to_city'
            }
    
    # =========================================================================
    # Pattern 8: "БпЛА на [напрямок] [регіон]" (position only, no course)
    # Example: "БпЛА на півдні Миколаївщини"
    # Note: This is just a position, not a full trajectory
    # =========================================================================
    p8 = re.search(r'(?:група\s+)?(?:бпла|шахед|дрон)\s+на\s+(півноч[іи]|півдн[іи]|сход[іи]|заход[іи]|північн\w*[\s-]*схо\w*|північн\w*[\s-]*захо\w*|південн\w*[\s-]*схо\w*|південн\w*[\s-]*захо\w*)\s+([а-яіїєґ]+(щин|ччин)[иі])', text_lower)
    if p8:
        direction_in_region = p8.group(1)
        region = p8.group(2)
        
        # Check if there's a course direction mentioned later in the text
        # Put compound directions FIRST to match them before simple ones
        course_match = re.search(r'курс\s+(північн\w*-?схід\w*|північн\w*-?захід\w*|південн\w*-?схід\w*|південн\w*-?захід\w*|північн\w*|південн\w*|східн\w*|західн\w*)', text_lower)
        
        source_coords = _get_region_center(region)
        if source_coords:
            direction_vec = _get_direction_vector(direction_in_region)
            if direction_vec:
                start_lat = source_coords[0] + direction_vec[0] * 0.3
                start_lng = source_coords[1] + direction_vec[1] * 0.3
                
                if course_match:
                    course_direction = course_match.group(1)
                    course_vec = _get_direction_vector(course_direction)
                    if course_vec:
                        end_lat = start_lat + course_vec[0] * 0.5
                        end_lng = start_lng + course_vec[1] * 0.5
                        return {
                            'start': [start_lat, start_lng],
                            'end': [end_lat, end_lng],
                            'source_name': f'{direction_in_region} {region}'.title(),
                            'target_name': f'курс {course_direction}',
                            'kind': 'region_position_with_course'
                        }
    
    # =========================================================================
    # Pattern 9: "БпЛА на [регіон], повз м.[місто] курсом на [регіон]"
    # Example: "БпЛА на Миколаївщині, повз М.Миколаїв курсом на Одещину"
    # =========================================================================
    p9 = re.search(r'(?:група\s+)?(?:бпла|шахед|дрон)\s+на\s+([а-яіїєґ]+(щин|ччин)[іиї])[,\s]+повз\s+(?:м\.?|місто\s+)?([а-яіїєґ\'\-]+)\s+курсом\s+на\s+([а-яіїєґ]+(щин|ччин)[ауиію])', text_lower)
    if p9:
        source_region = p9.group(1)
        via_city = p9.group(3)
        target_region = p9.group(4)
        
        via_coords = _get_city_coords(via_city)
        target_coords = _get_region_center(target_region)
        
        if via_coords and target_coords:
            return {
                'start': [via_coords[0], via_coords[1]],
                'end': [target_coords[0], target_coords[1]],
                'source_name': f'{via_city} ({source_region})'.title(),
                'target_name': target_region.title(),
                'kind': 'via_city_to_region'
            }
    
    # =========================================================================
    # Pattern 10: "БпЛА з [регіон] на [регіон], напрямок м.[місто]"  
    # Example: "БпЛА з Херсонщини на Миколаївщину, напрямок м.Миколаїв"
    # =========================================================================
    p10 = re.search(r'(?:група\s+)?(?:бпла|шахед|дрон)\s+з\s+([а-яіїєґ]+(щин|ччин)[иі])\s+на\s+([а-яіїєґ]+(щин|ччин)[ауиію])[,\s]+(?:напрямок|напрям)\s+(?:м\.?|н\.?п\.?)?\s*([а-яіїєґ\'\-]+)', text_lower)
    if p10:
        source_region = p10.group(1)
        mid_region = p10.group(3)
        target_city = p10.group(5)
        
        source_coords = _get_region_center(source_region)
        target_coords = _get_city_coords(target_city)
        
        if source_coords and target_coords:
            return {
                'start': [source_coords[0], source_coords[1]],
                'end': [target_coords[0], target_coords[1]],
                'source_name': source_region.title(),
                'target_name': f'{target_city} ({mid_region})'.title(),
                'kind': 'region_via_region_to_city'
            }
    
    # =========================================================================
    # Pattern 11: "БпЛА на [напрямок] [регіон], напрямок н.п.[місто]"
    # Example: "БпЛА на сході Сумщини, напрямок н.п.Лебедин"
    # =========================================================================
    p11 = re.search(r'(?:група\s+)?(?:бпла|шахед|дрон)\s+на\s+(півноч[іи]|півдн[іи]|сход[іи]|заход[іи]|північн\w*[\s-]*схо\w*|північн\w*[\s-]*захо\w*|південн\w*[\s-]*схо\w*|південн\w*[\s-]*захо\w*)\s+([а-яіїєґ]+(щин|ччин)[иі])[,\s]+(?:напрямок|напрям)\s+(?:м\.?|н\.?п\.?)?\s*([а-яіїєґ\'\-]+)', text_lower)
    if p11:
        direction_in_region = p11.group(1)
        source_region = p11.group(2)
        target_city = p11.group(4)
        
        source_coords = _get_region_center(source_region)
        target_coords = _get_city_coords(target_city)
        
        if source_coords and target_coords:
            direction_vec = _get_direction_vector(direction_in_region)
            if direction_vec:
                start_lat = source_coords[0] + direction_vec[0] * 0.3
                start_lng = source_coords[1] + direction_vec[1] * 0.3
            else:
                start_lat, start_lng = source_coords
            
            return {
                'start': [start_lat, start_lng],
                'end': [target_coords[0], target_coords[1]],
                'source_name': f'{direction_in_region} {source_region}'.title(),
                'target_name': target_city.title(),
                'kind': 'region_position_to_city'
            }
    
    # =========================================================================
    # Pattern 12: "БпЛА на межі [регіон1] та [регіон2] областей, курс [напрямок]"
    # Example: "БпЛА на межі Сумської та Чернігівської областей,курс південний"
    # =========================================================================
    p12 = re.search(r'(?:група\s+)?(?:бпла|шахед|дрон)\s+на\s+меж[іи]\s+([а-яіїєґ]+)\w*\s+(?:та|і|й)\s+([а-яіїєґ]+)\w*\s+(?:областей|обл)[,\s]*курс\s+(північн\w*|південн\w*|східн\w*|західн\w*|північн\w*[\s-]*схід\w*|північн\w*[\s-]*захід\w*|південн\w*[\s-]*схід\w*|південн\w*[\s-]*захід\w*)', text_lower)
    if p12:
        region1_base = p12.group(1)
        region2_base = p12.group(2)
        course_direction = p12.group(3)
        
        # Try to find both regions
        region1_coords = None
        region2_coords = None
        
        for key, coords in OBLAST_CENTERS.items():
            if region1_base in key:
                region1_coords = coords
            if region2_base in key:
                region2_coords = coords
        
        if region1_coords and region2_coords:
            # Start at midpoint between regions
            start_lat = (region1_coords[0] + region2_coords[0]) / 2
            start_lng = (region1_coords[1] + region2_coords[1]) / 2
            
            course_vec = _get_direction_vector(course_direction)
            if course_vec:
                end_lat = start_lat + course_vec[0] * 0.5
                end_lng = start_lng + course_vec[1] * 0.5
                return {
                    'start': [start_lat, start_lng],
                    'end': [end_lat, end_lng],
                    'source_name': f'межа {region1_base}/{region2_base}',
                    'target_name': f'курс {course_direction}',
                    'kind': 'border_with_course'
                }
    
    # =========================================================================
    # Pattern 13: "БпЛА в напрямку м.[місто]"
    # Example: "БпЛА на Дніпропетровщині в напрямку м.Павлоград"
    # =========================================================================
    p13 = re.search(r'(?:бпла|шахед|дрон|група\s+бпла)\s+(?:на\s+)?([а-яіїєґ]+(щин|ччин)[іи])?\s*(?:в|у)\s+напрямку\s+(?:м\.?|н\.?п\.?)?\s*([а-яіїєґ\'\-]+)', text_lower)
    if p13:
        source_region = p13.group(1) if p13.group(1) else None
        target_city = p13.group(3)
        
        target_coords = _get_city_coords(target_city)
        
        if target_coords:
            if source_region:
                source_coords = _get_region_center(source_region)
                if source_coords:
                    return {
                        'start': [source_coords[0], source_coords[1]],
                        'end': [target_coords[0], target_coords[1]],
                        'source_name': source_region.title(),
                        'target_name': target_city.title(),
                        'kind': 'region_towards_city'
                    }
    
    return None

def process_message(text, mid, date_str, channel, _disable_multiline=False):  # type: ignore
    import re
    
    # Helper function to clean text from subscription prompts
    def clean_text(text_to_clean):
        if not text_to_clean:
            return text_to_clean
        import re as re_import
        cleaned = []
        for ln in text_to_clean.splitlines():
            ln2 = ln.strip()
            if not ln2:
                continue
            # Remove invisible/unicode spaces and normalize
            ln2 = re_import.sub(r'[\u200B-\u200D\uFEFF\u3164\u2060\u00A0\u1680\u180E\u2000-\u200F\u202A-\u202E\u2028\u2029\u205F\u3000]+', ' ', ln2)
            ln2 = ln2.strip()
            
            # Check if line ends with subscription text after meaningful content (including bold **text**)
            subscription_match = re_import.search(r'^(.+?)\s+[➡→>⬇⬆⬅⬌↗↘↙↖]\s*(\*\*)?підписатися(\*\*)?\s*$', ln2, re_import.IGNORECASE)
            if subscription_match:
                # Extract the part before the subscription text
                main_content = subscription_match.group(1).strip()
                if main_content and len(main_content) > 5:  # Only keep if meaningful content
                    cleaned.append(main_content)
                continue
                
            # remove any line that is ONLY a subscribe CTA (including bold)
            if re_import.search(r'^[➡→>⬇⬆⬅⬌↗↘↙↖]?\s*(\*\*)?підписатися(\*\*)?\s*$', ln2, re_import.IGNORECASE):
                continue
            
            # Remove URLs and links from text
            ln2 = re_import.sub(r'https?://[^\s]+', '', ln2)  # Remove http/https links
            ln2 = re_import.sub(r'www\.[^\s]+', '', ln2)      # Remove www links
            ln2 = re_import.sub(r't\.me/[^\s]+', '', ln2)     # Remove Telegram links
            ln2 = re_import.sub(r'@[a-zA-Z0-9_]+', '', ln2)  # Remove @mentions
            ln2 = re_import.sub(r'_+', '', ln2)  # Remove leftover underscores
            ln2 = re_import.sub(r'[✙✚]+[^✙✚]*✙[^✙✚]*✙', '', ln2)  # Remove ✙...✙ patterns
            
            # Remove card numbers and bank details
            ln2 = re_import.sub(r'\d{4}\s*\d{4}\s*\d{4}\s*\d{4}', '', ln2)  # Card numbers
            ln2 = re_import.sub(r'[—-]\s*Картка:', '', ln2)  # Card labels
            ln2 = re_import.sub(r'[—-]\s*Банка:', '', ln2)   # Bank labels
            ln2 = re_import.sub(r'[—-]\s*Конверт:', '', ln2) # Envelope labels
            
            # Clean up multiple spaces and trim
            ln2 = re_import.sub(r'\s+', ' ', ln2).strip()
            
            # Skip empty lines after cleaning
            if not ln2:
                continue
                
            cleaned.append(ln2)
        return '\n'.join(cleaned)
    
    # PRIORITY: Check for trajectory patterns FIRST using the comprehensive parser
    trajectory_data = parse_trajectory_from_message(text)
    if trajectory_data:
        print(f"DEBUG: Trajectory parsed - kind={trajectory_data.get('kind')}, source={trajectory_data.get('source_name')}, target={trajectory_data.get('target_name')}")
        
        # Create marker at target location with trajectory data
        target_coords = trajectory_data['end']
        source_coords = trajectory_data['start']
        
        # Classify threat type based on message text
        text_lower = text.lower()
        if 'шахед' in text_lower or 'shahed' in text_lower:
            threat_type, icon = 'shahed', 'icon_drone.svg'
        elif 'бпла' in text_lower or 'дрон' in text_lower:
            threat_type, icon = 'shahed', 'icon_drone.svg'
        elif 'ракет' in text_lower:
            threat_type, icon = 'raketa', 'icon_balistic.svg'
        else:
            threat_type, icon = 'shahed', 'icon_drone.svg'
        
        # =====================================================================
        # ENHANCED AI PREDICTION: Add ETA, multi-targets, confidence
        # =====================================================================
        enhanced_trajectory = get_enhanced_trajectory_prediction(trajectory_data, text)
        if enhanced_trajectory:
            trajectory_data = enhanced_trajectory
            # Update icon based on refined threat type
            if enhanced_trajectory.get('threat_type') == 'ballistic':
                icon = 'icon_balistic.svg'
            elif enhanced_trajectory.get('threat_type') == 'cruise':
                icon = 'icon_rocket.svg'
        
        place_name = f"{trajectory_data.get('target_name', 'Ціль')} ← {trajectory_data.get('source_name', 'Джерело')}"
        
        # ETA in place name - DISABLED
        # eta_info = trajectory_data.get('eta', {})
        # if eta_info.get('formatted'):
        #     place_name += f" (ETA: {eta_info['formatted']})"
        
        trajectory_marker = {
            'id': str(mid),
            'place': place_name,
            'lat': target_coords[0],
            'lng': target_coords[1],
            'threat_type': threat_type,
            'text': text[:500],
            'date': date_str,
            'channel': channel,
            'marker_icon': icon,
            'source_match': f'trajectory_{trajectory_data.get("kind", "unknown")}',
            'trajectory': trajectory_data
        }
        
        # Add enhanced prediction data
        if trajectory_data.get('eta'):
            trajectory_marker['eta'] = trajectory_data['eta']
        if trajectory_data.get('alternative_targets'):
            trajectory_marker['alternative_targets'] = trajectory_data['alternative_targets']
        if trajectory_data.get('confidence'):
            trajectory_marker['prediction_confidence'] = trajectory_data['confidence']
        if trajectory_data.get('confidence_level'):
            trajectory_marker['confidence_level'] = trajectory_data['confidence_level']
        if trajectory_data.get('distance_km'):
            trajectory_marker['distance_km'] = trajectory_data['distance_km']
        if trajectory_data.get('speed_kmh'):
            trajectory_marker['speed_kmh'] = trajectory_data['speed_kmh']
        
        # AUTO-RECORD: Save observed route for pattern learning (non-blocking)
        try:
            if not trajectory_data.get('predicted'):  # Only record confirmed routes
                update_route_pattern_with_ai({
                    'source_region': trajectory_data.get('source_name'),
                    'target_region': trajectory_data.get('target_name'),
                    'waypoints': [],
                    'threat_type': threat_type
                })
        except Exception as e:
            print(f"DEBUG: Failed to record route pattern: {e}")
        
        return [trajectory_marker]
    
    # EARLY FILTERS: Check for messages that should be completely filtered out
    def _is_russian_strategic_aviation(t: str) -> bool:
        """Suppress messages about Russian strategic aviation (Tu-95, etc.) from Russian airbases"""
        t_lower = t.lower()
        
        # Check for Russian strategic bombers
        russian_bombers = ['ту-95', 'tu-95', 'ту-160', 'tu-160', 'ту-22', 'tu-22']
        has_bomber = any(bomber in t_lower for bomber in russian_bombers)
        
        # Check for Russian airbases and regions
        russian_airbases = ['енгельс', 'engels', 'энгельс', 'саратов', 'рязань', 'муром', 'украінка', 'українка']
        has_russian_airbase = any(airbase in t_lower for airbase in russian_airbases)
        
        # Check for Russian regions/areas
        russian_regions = ['саратовській області', 'саратовской области', 'тульській області', 'рязанській області']
        has_russian_region = any(region in t_lower for region in russian_regions)
        
        # Check for terms indicating Russian territory/airbases
        russian_territory_terms = ['аеродрома', 'аэродрома', 'з аеродрому', 'с аэродрома', 'мета вильоту невідома', 'цель вылета неизвестна']
        has_russian_territory = any(term in t_lower for term in russian_territory_terms)
        
        # Check for generic relocation/transfer terms without specific threats
        relocation_terms = ['передислокація', 'передислокация', 'переліт', 'перелет', 'відмічено', 'отмечено']
        has_relocation = any(term in t_lower for term in relocation_terms)
        
        # Suppress if it's about Russian bombers from Russian territory
        if has_bomber and (has_russian_airbase or has_russian_territory or has_russian_region):
            return True
            
        # Suppress relocation/transfer messages between Russian airbases
        if has_relocation and has_bomber and (has_russian_airbase or has_russian_region):
            return True
            
        # Also suppress general strategic aviation reports without specific Ukrainian targets
        if ('борт' in t_lower or 'борти' in t_lower) and ('мета вильоту невідома' in t_lower or 'цель вылета неизвестна' in t_lower):
            return True
            
        return False

    def _is_general_warning_without_location(t: str) -> bool:
        """Suppress general warnings without specific locations or threat details"""
        t_lower = t.lower()
        
        # Check for general warning phrases
        warning_phrases = [
            'протягом ночі уважним бути',
            'протягом дня уважним бути', 
            'уважним бути',
            'загальне попередження',
            'общее предупреждение'
        ]
        has_general_warning = any(phrase in t_lower for phrase in warning_phrases)
        
        # Check for alert messages that should only be in events, not on map
        alert_phrases = [
            'відбій тривоги',
            'повітряна тривога',
            'відбой тревоги',
            'воздушная тревога'
        ]
        has_alert_message = any(phrase in t_lower for phrase in alert_phrases)
        
        # Suppress alert messages - they should only be in events
        if has_alert_message:
            return True
        
        # Check for tactical threat messages first - these should NEVER be filtered
        tactical_phrases = [
            'бпла',
            'крилаті ракети',
            'ракет',
            'ракета',
            'ракети',
            'загроза',
            'курсом на',
            'наближається',
            'повз',
            'поблизу',
            'напрямок',
            'напрямку',
            'у напрямку',
            'кв шахед',
            'шахед',
            'каб',
            'умп',
            'іскандер'
        ]
        has_tactical_info = any(phrase in t_lower for phrase in tactical_phrases)
        
        # Check for informational/historical messages that should be filtered
        # even if they contain tactical terms
        informational_phrases = [
            'пролетів',
            'відвернув',
            'здійснив посадку',
            'посадку на аеродром',
            'активність бортів',
            'буду оновлювати',
            'в разі додаткової інформації',
            'наразі це єдина',
            'фактична активність'
        ]
        has_informational_content = any(phrase in t_lower for phrase in informational_phrases)
        
        # Check if this is actually a current location message (not brief update)
        current_location_phrases = [
            'над',
            'в районі',
            'атакував',
            'вибухи в',
            'влучання в',
            'збито в',
            'знищено в',
            'на херсонщині',
            'на дніпропетровщині',
            'на запоріжжі',
            'на харківщині',
            'в області',
            'область',
            'щині'
        ]
        has_current_location = any(phrase in t_lower for phrase in current_location_phrases)
        
        # Check for count prefix (e.g., "16х БпЛА", "3х БпЛА") - these are real threats
        has_count_prefix = re.search(r'\d+\s*[xх]\s*бпла', t_lower)
        
        # If message has threat count or current location, do NOT filter it
        if has_count_prefix or has_current_location:
            return False
        
        # Check for general status messages that contain tactical terms but are informational
        status_phrases = [
            'український | ппошник',
            'український|ппошник',
            'поділ лук\'янівка'
        ]
        has_status_message = any(phrase in t_lower for phrase in status_phrases)
        
        # Check for route/location listing messages (format: "city — city1/city2 | region:")
        route_listing_pattern = r'київ.*—.*жуляни.*вишневе.*київ'
        has_route_listing = re.search(route_listing_pattern, t_lower, re.IGNORECASE)
        
        # Filter route listing messages as they are informational
        if has_route_listing:
            return True
        
        # If message is informational/historical, filter it out
        if has_informational_content:
            return True
            
        # If message is a general status update with tactical info, filter it out
        if has_status_message and has_tactical_info:
            return True
        
        # If message contains tactical information and is not informational, do NOT filter it
        if has_tactical_info:
            return False
        
        # Check for donation/fundraising messages (use more specific phrases)
        donation_phrases = [
            'підтримайте мене',
            'підтримати канал',
            'реквізити',
            'картка:',
            'банка:',
            'грн на каву',
            'на каву та енергетики',
            'по бажанню',
            'підтримка тільки',
            'monobank.ua',
            'privat24.ua',
            'send.monobank',
            'www.privat24',
            'донати',
            'донат',
            'дуже вдячний',
            'вдячний вам за підтримку',
            'за підтримку',
            'дякую за підтримку'
        ]
        has_donation_message = any(phrase in t_lower for phrase in donation_phrases)
        
        # Suppress donation messages
        if has_donation_message:
            return True
        
        # Check for channel promotion messages
        promotion_phrases = [
            'підтримати канал',
            'спасибо за подписку',
            'подписывайтесь',
            'наш канал',
            'наш телеграм'
        ]
        has_promotion_message = any(phrase in t_lower for phrase in promotion_phrases)
        
        # Suppress promotion messages
        if has_promotion_message:
            return True
        
        # Check for general informational messages without threats
        info_phrases = [
            'наразі це єдина',
            'фактична активність',
            'буду оновлювати',
            'в разі додаткової інформації',
            'здійснив посадку',
            'посадку на аеродром',
            'активність бортів'
        ]
        has_info_message = any(phrase in t_lower for phrase in info_phrases)
        
        # Suppress general info messages
        if has_info_message:
            return True
        
        # Check for very broad regions without specific cities
        broad_regions = [
            'києву, київщина і західна україна',
            'київ, київщина і західна україна', 
            'центр і північ', 
            'південь і схід'
        ]
        has_broad_region = any(region in t_lower for region in broad_regions)
        
        # Suppress if it's a general warning with broad regions
        if has_general_warning and has_broad_region:
            return True
            
        # Also suppress very short messages that are just general alerts
        if len(t.strip()) < 50 and has_general_warning:
            return True
            
        return False

    # Apply early filters
    if _is_russian_strategic_aviation(text):
        return []
        
    if _is_general_warning_without_location(text):
        return []
    
    # PRIORITY: Handle directional movement patterns (у напрямку, в направлении)
    # These should show trajectory/direction, not markers at destination
    def _is_directional_movement_message(t: str) -> bool:
        """Check if message describes movement towards a destination"""
        t_lower = t.lower()
        
        # Patterns indicating movement toward destination, not presence at location
        directional_patterns = [
            'у напрямку',
            'в напрямку', 
            'напрямок',
            'рухається в напрямку',
            'летить у напрямку',
            'курс на',
            'прямує до'
        ]
        
        # Additional context that suggests this is about movement, not current location
        movement_context = [
            'з північного-сходу',
            'з півдня',
            'з заходу',
            'з сходу',  
            'рухається',
            'летить',
            'прямує'
        ]
        
        has_directional = any(pattern in t_lower for pattern in directional_patterns)
        has_movement_context = any(context in t_lower for context in movement_context)
        
        return has_directional and has_movement_context
    
    # Handle directional movement messages - create projected path instead of filtering
    if _is_directional_movement_message(text):
        return _create_directional_trajectory_markers(text, mid, date_str, channel)
    
    # PRIORITY: Try SpaCy enhanced processing first
    if SPACY_AVAILABLE:
        try:
            spacy_results = spacy_enhanced_geocoding(text)
            if spacy_results:
                # Convert SpaCy results to the format expected by the rest of the system
                threat_markers = []
                
                # Process cities with coordinates first
                cities_with_coords = [city for city in spacy_results if city['coords']]
                
                for spacy_city in cities_with_coords:
                    lat, lng = spacy_city['coords']
                    
                    # Determine threat type using our classify function
                    threat_type, icon = classify(text, spacy_city['name'])
                    
                    # Create a proper place label
                    place_label = spacy_city['name'].title()
                    if spacy_city['region']:
                        place_label += f" [{spacy_city['region'].title()}]"
                    
                    marker = {
                        'id': f"{mid}_spacy_{len(threat_markers)+1}",
                        'place': place_label,
                        'lat': lat,
                        'lng': lng,
                        'threat_type': threat_type,
                        'text': clean_text(text)[:500],
                        'date': date_str,
                        'channel': channel,
                        'marker_icon': icon,
                        'source_match': f'spacy_{spacy_city["source"]}',
                        'count': 1,
                        'confidence': spacy_city['confidence']
                    }
                    threat_markers.append(marker)
                    
                    add_debug_log(f"SPACY: Created marker for {spacy_city['name']} -> {spacy_city['normalized']} "
                                f"(case: {spacy_city.get('case', 'unknown')}, confidence: {spacy_city['confidence']})", 
                                "spacy_integration")
                
                if threat_markers:
                    add_debug_log(f"SPACY: Successfully processed message with {len(threat_markers)} markers", "spacy_integration")
                    return threat_markers
                    
        except Exception as e:
            add_debug_log(f"SPACY: Error processing message: {e}", "spacy_integration")
            # Continue with fallback processing
    
    # FALLBACK: Original regex-based processing continues below
    
    # PRIORITY: Handle "[city] на [region]" patterns early to avoid misprocessing
    regional_city_match = re.search(r'(\d+)\s+шахед[а-яіїєёыийї]*\s+на\s+([а-яіїєё\'\-\s]+?)\s+на\s+([а-яіїє]+щині?)', text.lower()) if text else None
    if regional_city_match:
        count_str = regional_city_match.group(1)
        city_raw = regional_city_match.group(2).strip()
        region_raw = regional_city_match.group(3).strip()
        
        # Use context-aware resolution
        coords = ensure_city_coords_with_message_context(city_raw, text)
        if coords:
            lat, lng, approx = coords
            add_debug_log(f"PRIORITY: Regional city pattern - {city_raw} на {region_raw} -> ({lat}, {lng})", "priority_regional_city")
            
            result_entry = {
                'id': f"{mid}_priority_regional",
                'place': f"{city_raw.title()} на {region_raw.title()}",
                'lat': lat, 'lng': lng,
                'type': 'shahed', 'count': int(count_str),
                'timestamp': date_str, 'channel': channel
            }
            return [result_entry]
    
    # EARLY CHECK: General multi-line threat detection (before specific cases)
    if not _disable_multiline:
        text_lines = (text or '').split('\n')
        threat_lines = []
        
        # Track current oblast context from headers like "Полтавщина:", "Харківщина:"
        current_oblast = None
        oblast_header_pattern = re.compile(r'^([а-яіїєґ]+(?:щина|ська\s+обл(?:асть)?\.?)):?\s*$', re.IGNORECASE)
        # Pattern for inline oblast: "Сумщина: 2 шахеди на Лебедин"
        inline_oblast_pattern = re.compile(r'^([а-яіїєґ]+(?:щина|ська\s+обл(?:асть)?\.?)):\s+(.+)$', re.IGNORECASE)
        
        # Look for lines that contain threats with quantities and targets
        for line in text_lines:
            line_stripped = line.strip()
            if not line_stripped:
                continue
            
            # Check if this line has inline oblast format: "Область: threat text"
            inline_match = inline_oblast_pattern.match(line_stripped)
            if inline_match:
                oblast_name = inline_match.group(1).lower()
                threat_text = inline_match.group(2).strip()
                
                # Add the threat with oblast context
                enhanced_line = f"{oblast_name}: {threat_text}"
                threat_lines.append(enhanced_line)
                add_debug_log(f"MULTI-LINE: Detected inline oblast threat: {oblast_name} -> {threat_text[:50]}", "multi_line_inline_oblast")
                continue
            
            # Check if this line is a standalone oblast header
            oblast_match = oblast_header_pattern.match(line_stripped)
            if oblast_match:
                current_oblast = oblast_match.group(1).lower()
                add_debug_log(f"MULTI-LINE: Detected oblast header: {current_oblast}", "multi_line_oblast")
                continue
                
            line_lower = line_stripped.lower()
            
            # Check if line contains threat patterns with quantities and targets
            has_threat_pattern = (
                # Pattern: "Ціль на [target]" - target city for missiles/drones
                (re.search(r'ціль\s+на\s+([а-яіїєё\'\-\s]+)', line_lower, re.IGNORECASE)) or
                # Pattern: "N БпЛА на [region]щині" - regional threats like "16х БпЛА на Херсонщині"
                (re.search(r'\d+\s*[xх×]?\s*бпла\s+на\s+([а-яіїєё]+щині)', line_lower, re.IGNORECASE)) or
                # Pattern: "БпЛА на [direction] [region]" - regional directional threats
                (re.search(r'бпла\s+на\s+(півночі|півдні|сході|заході|північ|південь|схід|захід)\s+([а-яіїєё]+щин[іауи]?)', line_lower, re.IGNORECASE)) or
                # Pattern: "БпЛА ... з акваторії Чорного моря" - Black Sea threats
                (re.search(r'бпла.*?(з\s+акваторії|з\s+моря|з\s+чорного\s+моря)', line_lower, re.IGNORECASE)) or
                # Pattern: "N x/× БпЛА курсом на [target]"
                (re.search(r'\d+\s*[xх×]\s*бпла.*?(курс|на)\s+([а-яіїєё\'\-\s]+)', line_lower)) or
                # Pattern: "N шахедів/шахеди на [target]" - all forms of Shahed
                (re.search(r'\d+\s+шахед[а-яіїєёыийї]*\s+на\s+([а-яіїєё\'\-\s]+)', line_lower)) or
                # Pattern: "N шахедів/шахеди біля [target]" - near target
                (re.search(r'\d+\s+шахед[а-яіїєёыийї]*\s+біля\s+([а-яіїєё\'\-\s]+)', line_lower)) or
                # Pattern: "N шахед маневрує в районі [target]" - maneuvering in area
                (re.search(r'\d+\s+шахед[а-яіїєёыийї]*\s+маневру[юєї]+\s+в\s+район[іуи]\s+([а-яіїєё\'\-\s]+)', line_lower)) or
                # Pattern: "N ударних БпЛА на [target]"
                (re.search(r'\d+\s+ударн.*?бпла.*?на\s+([а-яіїєё\'\-\s]+)', line_lower)) or
                # Pattern: "N БпЛА на [target]" or "N бпла на [target]"  
                (re.search(r'\d+\s+бпла.*?на\s+([а-яіїєё\'\-\s]+)', line_lower)) or
                # Pattern: "БпЛА курсом на [target]" (without count)
                (re.search(r'бпла.*?курс.*?на\s+([а-яіїєё\'\-\s]+)', line_lower)) or
                # Pattern: "N шахедів через [target]" - via target  
                (re.search(r'\d+\s+шахед[а-яіїєёыийї]*\s+через\s+([а-яіїєё\'\-\s]+)', line_lower)) or
                # Pattern: "N шахедів з боку [target]" - from direction of target
                (re.search(r'\d+\s+шахед[а-яіїєёыийї]*\s+з\s+боку\s+([а-яіїєё\'\-\s]+)', line_lower))
            )
            
            if has_threat_pattern:
                # If we have oblast context, prepend it to the line
                if current_oblast:
                    # Add oblast context to help city resolution
                    enhanced_line = f"{current_oblast}: {line_stripped}"
                    threat_lines.append(enhanced_line)
                    add_debug_log(f"MULTI-LINE: Added threat with oblast context: {current_oblast} -> {line_stripped[:50]}", "multi_line_context")
                else:
                    threat_lines.append(line_stripped)
        
        # If we have multiple threat lines, process them separately
        if len(threat_lines) >= 2:
            add_debug_log(f"MULTI-LINE THREAT PROCESSING: {len(threat_lines)} threat lines detected", "multi_line_threats")
            
            all_tracks = []
            for i, line in enumerate(threat_lines):
                if not line.strip():
                    continue
                    
                add_debug_log(f"Processing threat line {i+1}: {line[:100]}", "threat_line")
                
                # Process each line as a separate message with multiline disabled
                line_result = process_message(line.strip(), f"{mid}_threat_{i+1}", date_str, channel, _disable_multiline=True)
                if line_result and isinstance(line_result, list):
                    all_tracks.extend(line_result)
                    add_debug_log(f"Threat line {i+1} produced {len(line_result)} tracks", "threat_line_result")
                else:
                    add_debug_log(f"Threat line {i+1} produced no tracks", "threat_line_result")
            
            if all_tracks:
                add_debug_log(f"Multi-line threat processing complete: {len(all_tracks)} total tracks", "multi_line_threats_complete")
                return all_tracks
    
    # PRIORITY FIRST: All air alarm messages should be list-only (no map markers)
    # This must be checked BEFORE any other processing to prevent other logic from creating markers
    original_text = text or ''
    low_orig = original_text.lower()
    
    # Clear any previous priority result
    globals()['_current_priority_result'] = None
    
    # PRIORITY CHECK: Black Sea aquatory - must check BEFORE multi-regional processing
    # Messages like "БпЛА курсом на Миколаїв з акваторії Чорного моря" or "15 шахедів з моря на Ізмаїл" should NOT place markers on cities
    lower_text = original_text.lower()
    # Check for Black Sea references: акваторія OR "з моря" OR "з чорного моря"
    is_black_sea = (('акватор' in lower_text or 'акваторії' in lower_text) and ('чорного моря' in lower_text or 'чорне море' in lower_text or 'чорному морі' in lower_text)) or \
                   ('з моря' in lower_text and ('курс' in lower_text or 'на ' in lower_text)) or \
                   ('з чорного моря' in lower_text)
    
    if is_black_sea:
        # Extract target region/direction if mentioned
        m_target = re.search(r'курс(?:ом)?\s+на\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-]{3,})', lower_text)
        m_direction = re.search(r'на\s+(північ|південь|схід|захід|північний\s+схід|північний\s+захід|південний\s+схід|південний\s+захід)', lower_text)
        m_region = re.search(r'(одещин|одеськ|миколаїв|херсон)', lower_text)
        
        target_info = None
        sea_lat, sea_lng = 45.3, 30.7  # Default: northern Black Sea central coords
        
        # Adjust position based on direction/region
        if m_direction:
            direction = m_direction.group(1)
            if 'південь' in direction:
                sea_lat = 45.0  # Further south
            elif 'північ' in direction:
                sea_lat = 45.6  # Further north
            if 'схід' in direction:
                sea_lng = 31.2  # Further east
            elif 'захід' in direction:
                sea_lng = 30.2  # Further west
        
        if m_region:
            region_name = m_region.group(1)
            if 'одещин' in region_name or 'одеськ' in region_name:
                # South of Odesa region - in the sea 50km offshore
                sea_lat, sea_lng = 45.7, 30.7
                target_info = 'Одещини'
            elif 'миколаїв' in region_name:
                sea_lat, sea_lng = 45.9, 31.4
                target_info = 'Миколаївщини'
            elif 'херсон' in region_name:
                sea_lat, sea_lng = 45.7, 32.5
                target_info = 'Херсонщини'
        
        if m_target:
            tc = m_target.group(1).lower()
            tc = UA_CITY_NORMALIZE.get(tc, tc)
            target_info = tc.title()
        
        threat_type, icon = classify(original_text)
        place_label = 'Акваторія Чорного моря'
        if target_info:
            place_label += f' (на {target_info})'
        
        # Try to find target city coordinates for trajectory
        target_coords = None
        if m_target:
            tc_normalized = m_target.group(1).lower()
            tc_normalized = UA_CITY_NORMALIZE.get(tc_normalized, tc_normalized)
            if tc_normalized in CITY_COORDS:
                target_coords = CITY_COORDS[tc_normalized]
        
        result = {
            'id': str(mid), 'place': place_label, 'lat': sea_lat, 'lng': sea_lng,
            'threat_type': threat_type, 'text': original_text[:500], 'date': date_str, 'channel': channel,
            'marker_icon': icon, 'source_match': 'black_sea_course_priority'
        }
        
        # Add trajectory data if we have target coordinates
        if target_coords:
            result['trajectory'] = {
                'start': [sea_lat, sea_lng],
                'end': list(target_coords),
                'target': target_info
            }
        
        return [result]
    
    # IMMEDIATE CHECK: Multi-regional UAV messages (highest priority)
    text_lines = original_text.split('\n')
    region_count = sum(1 for line in text_lines if any(region in line.lower() for region in ['щина:', 'щина]', 'область:', 'край:']) or (
        'щина' in line.lower() and line.lower().strip().endswith(':')
    ) or any(region in line.lower() for region in ['щина)', 'щини', 'щину', 'одещина', 'чернігівщина', 'дніпропетровщина', 'харківщина', 'київщина']))
    # Look for lines with emoji + UAV mentions (more flexible detection)
    uav_lines = [line for line in text_lines if 'бпла' in line.lower() and ('🛵' in line or '🛸' in line)]
    uav_count = len(uav_lines)
    
    # NEW: Look for lines with Shahed mentions and regions (without emoji requirement)
    shahed_region_lines = [line for line in text_lines if 
                          ('шахед' in line.lower() or 'shahed' in line.lower()) and 
                          ('щина' in line.lower() or 'щину' in line.lower() or 'щині' in line.lower())]
    shahed_count = len(shahed_region_lines)
    
    # NEW: Check for multiple regional aviation/БПЛА threats in one message
    # Pattern: "🛫 Донеччина та Дніпропетровщина - загроза застосування авіаційних засобів ураження. 🛵 Харківщина - загроза застосування ударних БпЛА"
    aviation_threat_lines = []
    for line in text_lines:
        line_lower = line.lower().strip()
        if not line_lower:
            continue
        # Check if line contains region + aviation/БПЛА threat
        has_region = any(region in line_lower for region in ['щина', 'область'])
        has_aviation = any(pattern in line_lower for pattern in ['авіаційних засобів', 'авіації', 'тактична авіація'])
        has_bpla = 'бпла' in line_lower or 'безпілотн' in line_lower
        
        if has_region and (has_aviation or has_bpla):
            aviation_threat_lines.append(line)
    
    aviation_threat_count = len(aviation_threat_lines)
    
    add_debug_log(f"DEBUG COUNT CHECK: {region_count} regions, {uav_count} UAV lines, {shahed_count} Shahed+region lines, {aviation_threat_count} aviation threat lines", "count_check")
    
    # Process multiple regional aviation threats
    if aviation_threat_count >= 1:
        add_debug_log(f"MULTI-REGIONAL AVIATION THREATS: {aviation_threat_count} lines detected", "multi_aviation")
        
        all_tracks = []
        
        # Regional aviation coordinates mapping (Black Sea / oblast centers)
        region_aviation_coords = {
            'одещина': (46.373528, 31.284023),  # Black Sea near Odesa
            'одесщина': (46.373528, 31.284023),
            'донеччина': (48.5, 37.8),  # Donetsk oblast center
            'дніпропетровщина': (48.45, 35.0),  # Dnipro
            'харківщина': (49.9935, 36.2304),  # Kharkiv
            'луганщина': (48.567, 39.317),  # Luhansk oblast
            'запорожжя': (47.8388, 35.1396),  # Zaporizhzhia
            'херсонщина': (46.6354, 32.6169),  # Kherson
            'миколаївщина': (46.975, 32.0),  # Mykolaiv oblast
        }
        
        for line in aviation_threat_lines:
            line_stripped = line.strip()
            line_lower = line_stripped.lower()
            
            # Split by emoji or sentence patterns to separate different threats
            # Pattern: "🛫 Region - threat. 🛵 Region - threat"
            import re
            
            # Split by emoji patterns or full stops followed by emoji
            segments = re.split(r'[\.\!]\s*(?=[🛫🛵🛸⚠️])|(?<=[🛫🛵🛸⚠️])\s+(?=[А-ЯІЇЄа-яіїє])', line_stripped)
            if len(segments) <= 1:
                # No clear segments, treat as one line
                segments = [line_stripped]
            
            for segment in segments:
                segment = segment.strip()
                if not segment or len(segment) < 10:
                    continue
                    
                segment_lower = segment.lower()
                
                # Extract all regions from this segment
                regions_found = re.findall(r'(одещина|одесщина|донеччина|дніпропетровщина|харківщина|луганщина|запорожжя|херсонщина|миколаївщина)', segment_lower)
                
                # Determine threat type from segment content
                is_aviation = any(pattern in segment_lower for pattern in ['авіаційних засобів', 'авіації', 'тактична авіація'])
                is_bpla = 'бпла' in segment_lower or 'безпілотн' in segment_lower
                is_strike_bpla = 'ударних бпла' in segment_lower or 'ударних безпілотн' in segment_lower
                
                threat_type = 'avia' if is_aviation else ('shahed' if is_bpla else 'artillery')
                icon = 'avia.png' if is_aviation else ('icon_drone.svg' if is_bpla else 'artillery.png')
                threat_label = 'Авіація' if is_aviation else ('Ударні БпЛА' if is_strike_bpla else 'БпЛА')
                
                # Create marker for each region mentioned in this segment
                for region in regions_found:
                    if region in region_aviation_coords:
                        coords = region_aviation_coords[region]
                        lat, lng = coords
                        
                        region_display = region.title()
                        place_name = f"{threat_label} [{region_display}]"
                        
                        track = {
                            'id': f"{mid}_aviation_{region}_{len(all_tracks)}",
                            'place': place_name,
                            'lat': lat,
                            'lng': lng,
                            'threat_type': threat_type,
                            'text': segment[:500],
                            'date': date_str,
                            'channel': channel,
                            'marker_icon': icon,
                            'source_match': 'multi_regional_aviation',
                            'count': 1
                        }
                        
                        all_tracks.append(track)
                        add_debug_log(f"Aviation threat: {place_name} at {coords} (segment: {segment[:50]})", "multi_aviation")
                    else:
                        add_debug_log(f"No coords for region: {region}", "multi_aviation")
        
        if all_tracks:
            add_debug_log(f"Multi-regional aviation processing complete: {len(all_tracks)} total tracks", "multi_aviation_complete")
            return all_tracks
    
    add_debug_log(f"DEBUG COUNT CHECK: {region_count} regions, {uav_count} UAV lines, {shahed_count} Shahed+region lines", "count_check")
    
    # If we have multiple Shahed lines with regions, process them separately
    if shahed_count >= 2:
        add_debug_log(f"MULTI-LINE SHAHED PROCESSING: {shahed_count} Shahed+region lines detected", "multi_shahed")
        
        all_tracks = []
        for i, line in enumerate(shahed_region_lines):
            if not line.strip():
                continue
                
            add_debug_log(f"Processing Shahed line {i+1}: {line[:100]}", "shahed_line")
            
            # Process each line as a separate message
            line_result = process_message(line.strip(), f"{mid}_shahed_{i+1}", date_str, channel, _disable_multiline=True)
            if line_result and isinstance(line_result, list):
                all_tracks.extend(line_result)
                add_debug_log(f"Shahed line {i+1} produced {len(line_result)} tracks", "shahed_line_result")
            else:
                add_debug_log(f"Shahed line {i+1} produced no tracks", "shahed_line_result")
        
        if all_tracks:
            add_debug_log(f"Multi-line Shahed processing complete: {len(all_tracks)} total tracks", "multi_shahed_complete")
            return all_tracks
    
    # If we have multiple UAV lines with emojis, process them separately even if they don't have explicit regions
    if uav_count >= 2 and (region_count >= 1 or any('району' in line.lower() or 'області' in line.lower() or 'обл.' in line.lower() for line in uav_lines)):
        add_debug_log(f"MULTI-LINE UAV PROCESSING: {uav_count} UAV lines detected", "multi_uav")
        
        all_tracks = []
        for i, line in enumerate(uav_lines):
            if not line.strip():
                continue
                
            add_debug_log(f"Processing UAV line {i+1}: {line[:100]}", "uav_line")
            
            # Process each line as a separate message
            line_result = process_message(line.strip(), f"{mid}_line_{i+1}", date_str, channel, _disable_multiline=True)
            if line_result and isinstance(line_result, list):
                all_tracks.extend(line_result)
                add_debug_log(f"Line {i+1} produced {len(line_result)} tracks", "uav_line_result")
            else:
                add_debug_log(f"Line {i+1} produced no tracks", "uav_line_result")
        
        if all_tracks:
            add_debug_log(f"Multi-line UAV processing complete: {len(all_tracks)} total tracks", "multi_uav_complete")
            return all_tracks
    
    # Legacy multi-regional detection (keep for backward compatibility)
    if region_count >= 2 and sum(1 for line in text_lines if 'бпла' in line.lower() and ('курс' in line.lower() or 'на ' in line.lower())) >= 3:
        add_debug_log(f"IMMEDIATE MULTI-REGIONAL UAV: {region_count} regions, {uav_count} UAVs - ENTERING EARLY PROCESSING", "multi_regional")
        # Process directly without going through other logic
        import re
        
        # Define essential functions inline for immediate processing
        def get_city_coords_quick(city_name, region_hint=None):
            """Quick coordinate lookup with accusative case normalization and regional context"""
            city_norm = city_name.strip().lower()
            
            # Handle specific multi-word cities in accusative case
            if city_norm == 'велику димерку':
                city_norm = 'велика димерка'
            elif city_norm == 'велику виску':
                city_norm = 'велика виска'
            elif city_norm == 'мену':
                city_norm = 'мена'
            elif city_norm == 'пісківку':
                city_norm = 'пісківка'
            elif city_norm == 'новгород-сіверський':
                city_norm = 'новгород-сіверський'
            elif city_norm == 'києвом':
                city_norm = 'київ'
            
            # General accusative case endings (винительный падеж)
            elif city_norm.endswith('у') and len(city_norm) > 3:
                city_norm = city_norm[:-1] + 'а'
            elif city_norm.endswith('ю') and len(city_norm) > 3:
                city_norm = city_norm[:-1] + 'я'
            elif city_norm.endswith('ку') and len(city_norm) > 4:
                city_norm = city_norm[:-2] + 'ка'
            
            # Apply UA_CITY_NORMALIZE rules
            if city_norm in UA_CITY_NORMALIZE:
                city_norm = UA_CITY_NORMALIZE[city_norm]
            
            # PRIORITY 0: Check UKRAINE_ALL_SETTLEMENTS first (26000+ entries, fastest)
            if city_norm in UKRAINE_ALL_SETTLEMENTS:
                coords = UKRAINE_ALL_SETTLEMENTS[city_norm]
                add_debug_log(f"UKRAINE_ALL_SETTLEMENTS HIT: '{city_norm}' -> {coords}", "multi_regional")
                return coords
            
            # Also try original city name (without normalization)
            city_orig = city_name.strip().lower()
            if city_orig in UKRAINE_ALL_SETTLEMENTS:
                coords = UKRAINE_ALL_SETTLEMENTS[city_orig]
                add_debug_log(f"UKRAINE_ALL_SETTLEMENTS HIT (orig): '{city_orig}' -> {coords}", "multi_regional")
                return coords
            
            # PRIORITY 1: Check CITY_COORDS (legacy, smaller set)
            if city_norm in CITY_COORDS:
                coords = CITY_COORDS[city_norm]
                add_debug_log(f"CITY_COORDS HIT: '{city_norm}' -> {coords}", "multi_regional")
                return coords
            
            # CRITICAL FIX: If region_hint is provided, build a context string with it
            # This ensures the city is geocoded in the correct oblast
            if region_hint:
                context_text = f"{region_hint}: БпЛА курсом на {city_norm}"
                add_debug_log(f"Using region context: '{region_hint}' for city '{city_norm}'", "multi_regional")
            else:
                context_text = text
            
            # FALLBACK: Use API geocoding with proper regional context
            coords = ensure_city_coords_with_message_context(city_norm, context_text)
            
            add_debug_log(f"API lookup: '{city_name}' -> '{city_norm}' (region={region_hint}) -> {coords}", "multi_regional")
            return coords
        
        # Map regional header patterns to oblast names for API
        region_header_to_oblast = {
            'сумщина': 'Сумська область',
            'чернігівщина': 'Чернігівська область',
            'київщина': 'Київська область',
            'полтавщина': 'Полтавська область',
            'дніпропетровщина': 'Дніпропетровська область',
            'харківщина': 'Харківська область',
            'миколаївщина': 'Миколаївська область',
            'одещина': 'Одеська область',
            'запоріжжя': 'Запорізька область',
            'херсонщина': 'Херсонська область',
            'черкащина': 'Черкаська область',
            'вінниччина': 'Вінницька область',
            'житомирщина': 'Житомирська область',
            'рівненщина': 'Рівненська область',
            'волинь': 'Волинська область',
            'львівщина': 'Львівська область',
            'донеччина': 'Донецька область',
            'луганщина': 'Луганська область',
        }
        
        threats = []
        processed_cities = set()  # Избегаем дубликатов
        current_region = None  # Track current region from headers
        
        for line in text_lines:
            line_stripped = line.strip()
            if not line_stripped:
                continue
            
            line_lower = line_stripped.lower()
            
            # CHECK FOR REGION HEADER (e.g., "Київщина:", "Харківщина:")
            # This is CRITICAL for multi-regional messages
            region_header_match = re.match(r'^([а-яіїєґ]+щина|[а-яіїєґ]+ь):?\s*$', line_lower)
            if region_header_match:
                region_name = region_header_match.group(1)
                if region_name in region_header_to_oblast:
                    current_region = region_header_to_oblast[region_name]
                    add_debug_log(f"REGION HEADER detected: '{line_stripped}' -> current_region = '{current_region}'", "multi_regional")
                continue  # Skip processing the header line itself
            
            # Also check for inline region header like "Сумщина: БпЛА..."
            inline_region_match = re.match(r'^([а-яіїєґ]+щина|[а-яіїєґ]+ь):\s*(.+)$', line_lower)
            if inline_region_match:
                region_name = inline_region_match.group(1)
                if region_name in region_header_to_oblast:
                    current_region = region_header_to_oblast[region_name]
                    line_stripped = inline_region_match.group(2).strip()  # Process the rest of the line
                    line_lower = line_stripped.lower()
                    add_debug_log(f"INLINE REGION HEADER: '{region_name}' -> current_region = '{current_region}', processing: '{line_stripped}'", "multi_regional")
            
            line_lower = line_stripped.lower()
            
            # PRIORITY: Handle "напрямок м.X" or "напрямок на X" pattern first
            napryamok_match = re.search(r'напрямок\s+(?:м\.|місто|на)?\s*([а-яїієґ\-]+)', line_lower)
            if napryamok_match:
                target_city = napryamok_match.group(1).strip()
                target_norm = target_city
                if target_norm.endswith('у') and len(target_norm) > 3:
                    target_norm = target_norm[:-1] + 'а'
                elif target_norm.endswith('ку') and len(target_norm) > 4:
                    target_norm = target_norm[:-2] + 'ка'
                if target_norm in UA_CITY_NORMALIZE:
                    target_norm = UA_CITY_NORMALIZE[target_norm]
                
                # Get coordinates using region context from headers
                target_coords = get_city_coords_quick(target_norm, current_region)
                
                if target_coords:
                    if len(target_coords) == 3:
                        lat, lng, approx = target_coords
                    else:
                        lat, lng = target_coords[:2]
                    
                    # Check if not already processed
                    city_key = target_norm
                    if city_key not in processed_cities:
                        processed_cities.add(city_key)
                        
                        uav_count = 1
                        # Try to extract UAV count from line
                        count_match = re.search(r'(\d+)\s*[xх×]?\s*бпла', line_lower)
                        if count_match:
                            uav_count = int(count_match.group(1))
                        
                        threat_id = f"{mid}_napryamok_{len(threats)}"
                        threats.append({
                            'id': threat_id,
                            'place': target_norm.title(),
                            'lat': lat,
                            'lng': lng,
                            'threat_type': 'shahed',
                            'text': f"Напрямок → {target_norm.title()}",
                            'date': date_str,
                            'channel': channel,
                            'marker_icon': 'icon_drone.svg',
                            'source_match': 'immediate_napryamok',
                            'count': uav_count
                        })
                        
                        add_debug_log(f"Напрямок pattern: {target_norm} at {target_coords}", "napryamok")
                        continue  # Skip other processing for this line
            
            # Look for UAV course patterns
            if 'бпла' in line_lower and ('курс' in line_lower or ' на ' in line_lower or 'над' in line_lower or 'повз' in line_lower):
                # Extract city name from patterns - handle both plain text and markdown links
                patterns = [
                    # Pattern for markdown links: БпЛА курсом на [Бровари](link)
                    r'(\d+(?:-\d+)?)?[xх×]?\s*бпла\s+(?:курсом?)?\s*(?:на|над)\s+\[([А-ЯІЇЄЁа-яіїєёʼ\'\-\s]+?)\]',
                    # Pattern for plain text: БпЛА курсом на Конотоп (improved to capture multi-word cities + districts)
                    # Fixed: Added " з " and " район" to lookahead to properly capture "Миколаїв з акваторії" and "Покровський район"
                    r'(\d+(?:-\d+)?)?[xх×]?\s*бпла\s+.*?курс(?:ом)?\s+на\s+(?:н\.п\.?\s*)?([А-ЯІЇЄЁа-яіїєёʼ\'\-\s]+?(?:\s+район)?)(?=\s*(?:\n|$|[,\.\!\?;]|\s+з\s+|\s+\d+[xх×]?\s*бпла|\s+[А-ЯІЇЄЁа-яіїєё]+щина:|\s+\())',
                    # PRIORITY: Pattern for "повз ... курсом на" (e.g., "БпЛА повз Юріївку курсом на Павлоград")
                    # Must be BEFORE the simple "повз" pattern to capture both cities correctly
                    # Ignored for marker creation - handled separately below to create marker at bypass city with trajectory
                ]
                
                # SPECIAL HANDLING: "повз ... курсом на" pattern - create marker at bypass city with trajectory to target
                povz_course_match = re.search(r'(\d+(?:-\d+)?)?[xх×]?\s*бпла\s+повз\s+([А-ЯІЇЄЁа-яіїєёʼ\'\-\s]{3,50}?)\s+курсом?\s+на\s+([А-ЯІЇЄЁа-яіїєёʼ\'\-\s]{3,50}?)(?=\s*(?:\n|$|[,\.\!\?;]))', line_lower, re.IGNORECASE)
                if povz_course_match:
                    count_str, bypass_city_raw, target_city_raw = povz_course_match.groups()
                    
                    # Normalize bypass city name
                    bypass_city = bypass_city_raw.strip()
                    bypass_norm = bypass_city.lower()
                    if bypass_norm.endswith('у') and len(bypass_norm) > 3:
                        bypass_norm = bypass_norm[:-1] + 'а'
                    elif bypass_norm.endswith('ку') and len(bypass_norm) > 4:
                        bypass_norm = bypass_norm[:-2] + 'ка'
                    if bypass_norm in UA_CITY_NORMALIZE:
                        bypass_norm = UA_CITY_NORMALIZE[bypass_norm]
                    
                    # Normalize target city name
                    target_city = target_city_raw.strip()
                    target_norm = target_city.lower()
                    if target_norm.endswith('у') and len(target_norm) > 3:
                        target_norm = target_norm[:-1] + 'а'
                    elif target_norm.endswith('ку') and len(target_norm) > 4:
                        target_norm = target_norm[:-2] + 'ка'
                    if target_norm in UA_CITY_NORMALIZE:
                        target_norm = UA_CITY_NORMALIZE[target_norm]
                    
                    # Get coordinates for bypass city using region context
                    bypass_coords = get_city_coords_quick(bypass_norm, current_region)
                    
                    if bypass_coords:
                        if len(bypass_coords) == 3:
                            lat, lng, approx = bypass_coords
                        else:
                            lat, lng = bypass_coords
                        
                        uav_count = 1
                        if count_str and count_str.isdigit():
                            uav_count = int(count_str)
                        
                        # Create marker at bypass city with trajectory info
                        threat_id = f"{mid}_povz_course_{len(threats)}"
                        threats.append({
                            'id': threat_id,
                            'place': bypass_norm.title(),
                            'lat': lat,
                            'lng': lng,
                            'threat_type': 'shahed',
                            'text': f"Повз {bypass_norm.title()} → {target_norm.title()}",
                            'date': date_str,
                            'channel': channel,
                            'marker_icon': 'icon_drone.svg',
                            'source_match': 'immediate_povz_course',
                            'count': uav_count,
                            'course_source': bypass_norm,
                            'course_target': target_norm
                        })
                        
                        add_debug_log(f"Повз курсом на: {bypass_norm} -> {target_norm} at {bypass_coords}", "povz_course")
                        continue  # Skip normal processing for this line
                
                # Normal patterns (after special handling)
                patterns.append(
                    # Pattern for "повз" without "курсом на" (e.g., "БпЛА повз Славутич в бік Білорусі")
                    r'(\d+(?:-\d+)?)?[xх×]?\s*бпла\s+(?:.*?)?повз\s+([А-ЯІЇЄЁа-яіїєёʼ\'\-\s]{3,50}?)(?=\s+(?:в\s+бік|до|на|через|$|[,\.\!\?;]))'
                )
                
                # Also check for bracket city pattern like "Вилково (Одещина)"
                bracket_matches = re.finditer(r'([А-ЯІЇЄЁа-яіїєё\'\-\s]{3,30})\s*\(([А-ЯІЇЄЁа-яіїєё\'\-\s]+щина|[А-ЯІЇЄЁа-яіїєё\'\-\s]+обл\.?)\)', line_stripped, re.IGNORECASE)
                for bmatch in bracket_matches:
                    city_clean = bmatch.group(1).strip()
                    region_info = bmatch.group(2).strip()
                    
                    city_normalized = city_clean.lower()
                    city_key = city_normalized
                    
                    # Skip if already processed
                    if city_key in processed_cities:
                        continue
                    processed_cities.add(city_key)
                    
                    # Try to get coordinates using region from bracket or current_region
                    # Extract oblast from bracket (e.g., "Одещина" -> "Одеська область")
                    bracket_region = None
                    region_info_lower = region_info.lower()
                    if region_info_lower in region_header_to_oblast:
                        bracket_region = region_header_to_oblast[region_info_lower]
                    elif region_info_lower.replace('щина', 'щина') in region_header_to_oblast:
                        bracket_region = region_header_to_oblast.get(region_info_lower)
                    
                    coords = get_city_coords_quick(city_clean, bracket_region or current_region)
                    
                    if coords:
                        if len(coords) == 3:
                            lat, lng, approx = coords
                        else:
                            lat, lng = coords
                        
                        threat_id = f"{mid}_imm_bracket_{len(threats)}"
                        threats.append({
                            'id': threat_id,
                            'place': city_clean.title(),
                            'lat': lat,
                            'lng': lng,
                            'threat_type': 'shahed',
                            'text': f"{line_stripped} (bracket city)",
                            'date': date_str,
                            'channel': channel,
                            'marker_icon': 'icon_drone.svg',
                            'source_match': 'immediate_multi_regional_bracket',
                            'count': 1
                        })
                        
                        add_debug_log(f"Immediate Multi-regional bracket: {city_clean} -> {coords}", "multi_regional")
                    else:
                        add_debug_log(f"Immediate Multi-regional bracket: No coords for {city_clean}", "multi_regional")
                
                for pattern in patterns:
                    matches = re.finditer(pattern, line_stripped, re.IGNORECASE)
                    for match in matches:
                        if len(match.groups()) == 2:
                            count_str, city_raw = match.groups()
                        else:
                            count_str = None
                            city_raw = match.group(1)
                        
                        if not city_raw:
                            continue
                            
                        # Clean city name (remove trailing spaces)
                        city_clean = city_raw.strip()
                        
                        # Normalize city name for coordinate lookup  
                        city_normalized = city_clean.lower()
                        
                        # Normalize for display (convert accusative to nominative)
                        city_display = city_clean
                        if city_normalized == 'велику димерку':
                            city_display = 'Велика Димерка'
                        elif city_normalized == 'велику виску':
                            city_display = 'Велика Виска'
                        elif city_normalized == 'мену':
                            city_display = 'Мена'
                        elif city_normalized == 'пісківку':
                            city_display = 'Пісківка'
                        elif city_normalized == 'києвом':
                            city_display = 'Київ'
                            city_normalized = 'київ'  # Also normalize for lookup
                        elif city_normalized.endswith('ом') and len(city_normalized) > 4:
                            # Handle other accusative masculine endings
                            city_display = city_normalized[:-2]
                            city_display = city_display.title()
                            city_normalized = city_normalized[:-2]
                        elif city_normalized.endswith('у') and len(city_normalized) > 3:
                            city_display = city_normalized[:-1] + 'а'
                            city_display = city_display.title()
                        elif city_normalized.endswith('ю') and len(city_normalized) > 3:
                            city_display = city_normalized[:-1] + 'я'
                            city_display = city_display.title()
                        elif city_normalized.endswith('ку') and len(city_normalized) > 4:
                            city_display = city_normalized[:-2] + 'ка'
                            city_display = city_display.title()
                        else:
                            city_display = city_clean.title()
                        
                        city_key = city_normalized
                        
                        # Skip if already processed
                        if city_key in processed_cities:
                            continue
                        processed_cities.add(city_key)
                        
                        # Try to get coordinates using current region context
                        coords = get_city_coords_quick(city_clean, current_region)
                        
                        if coords:
                            if len(coords) == 3:
                                lat, lng, approx = coords
                            else:
                                lat, lng = coords
                            
                            # Extract count if present
                            uav_count_num = 1
                            if count_str and count_str.isdigit():
                                uav_count_num = int(count_str)
                            
                            # Create multiple tracks for multiple drones
                            tracks_to_create = max(1, uav_count_num)
                            for i in range(tracks_to_create):
                                track_display_name = city_display
                                if tracks_to_create > 1:
                                    track_display_name += f" #{i+1}"
                                
                                # Add small coordinate offsets to prevent marker overlap
                                marker_lat = lat
                                marker_lng = lng
                                if tracks_to_create > 1:
                                    # Create a chain pattern - drones one after another
                                    offset_distance = 0.03  # ~3km offset between each drone
                                    marker_lat += offset_distance * i
                                    marker_lng += offset_distance * i * 0.5
                                
                                threat_id = f"{mid}_imm_multi_{len(threats)}"
                                threats.append({
                                    'id': threat_id,
                                    'place': track_display_name,  # Use numbered display name for multiple drones
                                    'lat': marker_lat,
                                    'lng': marker_lng,
                                    'threat_type': 'shahed',
                                    'text': f"{line_stripped} (мультирегіональне)",
                                    'date': date_str,
                                    'channel': channel,
                                    'marker_icon': 'icon_drone.svg',
                                    'source_match': f'immediate_multi_regional_uav_{uav_count_num}x',
                                    'count': 1  # Each track represents 1 drone
                                })
                            
                            add_debug_log(f"Immediate Multi-regional: {city_clean} ({uav_count_num}x) -> {tracks_to_create} tracks at {coords}", "multi_regional")
                        else:
                            add_debug_log(f"Immediate Multi-regional: No coords for {city_clean}", "multi_regional")
        
        # Also check for regional UAV references without specific cities
        for line in text_lines:
            line_stripped = line.strip()
            if not line_stripped:
                continue
            line_lower = line_stripped.lower()
            
            # Look for UAV + region patterns without specific cities
            if 'бпла' in line_lower and any(region in line_lower for region in ['щини', 'щину', 'одещина', 'чернігівщина', 'дніпропетровщини']):
                # Skip if this specific line contains a city that was already processed
                line_has_processed_city = False
                for city in processed_cities:
                    if city in line_lower:
                        line_has_processed_city = True
                        break
                
                if line_has_processed_city:
                    continue
                
                # Special case: movement messages with direction in parentheses
                # Pattern: "БпЛА на півдні Чернігівщини, рухаються на південь (Київщина)"
                # Here (Київщина) indicates direction, not location
                directional_movement = re.search(r'на\s+([\w\-\s/]+?)\s+([а-яіїєґ]+щини|[а-яіїєґ]+щину|дніпропетровщини|одещини|чернігівщини).*рухаються.*\(([^)]+)\)', line_lower)
                if directional_movement:
                    direction = directional_movement.group(1).strip()
                    region_raw = directional_movement.group(2).strip()
                    target_direction = directional_movement.group(3).strip()
                    
                    # Map region to oblast center (current location, not target)
                    region_coords = None
                    if 'дніпропетров' in region_raw:
                        region_coords = (48.45, 35.0)
                        region_name = 'Дніпропетровщини'
                    elif 'чернігів' in region_raw:
                        region_coords = (51.4982, 31.3044)
                        region_name = 'Чернігівщини'
                    elif 'одес' in region_raw:
                        region_coords = (46.5197, 30.7495)
                        region_name = 'Одещини'
                    
                    if region_coords:
                        # Apply directional offset for current location
                        lat, lng = region_coords
                        if 'півдн' in direction or 'южн' in direction:
                            lat -= 0.5
                        elif 'північ' in direction or 'север' in direction:
                            lat += 0.5
                        elif 'захід' in direction or 'запад' in direction:
                            lng -= 0.8
                        elif 'схід' in direction or 'восток' in direction:
                            lng += 0.8
                        
                        direction_label = direction.replace('півдн', 'південн').replace('північ', 'північн')
                        place_name = f"{region_name} ({direction_label}а частина) → {target_direction}"
                        
                        threat_id = f"{mid}_imm_regional_movement_{len(threats)}"
                        threats.append({
                            'id': threat_id,
                            'place': place_name,
                            'lat': lat,
                            'lng': lng,
                            'threat_type': 'shahed',
                            'text': f"{line_stripped} (рух у напрямку {target_direction})",
                            'date': date_str,
                            'channel': channel,
                            'marker_icon': 'icon_drone.svg',
                            'source_match': 'immediate_multi_regional_movement',
                            'count': 1,
                            'movement_target': target_direction
                        })
                        
                        add_debug_log(f"Immediate Multi-regional movement: {place_name} -> {lat}, {lng} (target: {target_direction})", "multi_regional")
                        continue
                
                # Check if this is a directional reference like "на півдні Дніпропетровщини"
                region_match = re.search(r'на\s+([\w\-\s/]+?)\s+([а-яіїєґ]+щини|[а-яіїєґ]+щину|дніпропетровщини|одещини|чернігівщини)', line_lower)
                if region_match:
                    direction = region_match.group(1).strip()
                    region_raw = region_match.group(2).strip()
                    
                    # Map region to oblast center
                    region_coords = None
                    if 'дніпропетров' in region_raw:
                        region_coords = (48.45, 35.0)
                        region_name = 'Дніпропетровщини'
                    elif 'чернігів' in region_raw:
                        region_coords = (51.4982, 31.3044)
                        region_name = 'Чернігівщини'
                    elif 'одес' in region_raw:
                        region_coords = (46.5197, 30.7495)
                        region_name = 'Одещини'
                    
                    if region_coords:
                        # Apply directional offset
                        lat, lng = region_coords
                        if 'півдн' in direction or 'южн' in direction:
                            lat -= 0.5
                        elif 'північ' in direction or 'север' in direction:
                            lat += 0.5
                        elif 'захід' in direction or 'запад' in direction:
                            lng -= 0.8
                        elif 'схід' in direction or 'восток' in direction:
                            lng += 0.8
                        
                        direction_label = direction.replace('півдн', 'південн').replace('північ', 'північн')
                        place_name = f"{region_name} ({direction_label}а частина)"
                        
                        threat_id = f"{mid}_imm_regional_{len(threats)}"
                        threats.append({
                            'id': threat_id,
                            'place': place_name,
                            'lat': lat,
                            'lng': lng,
                            'threat_type': 'shahed',
                            'text': f"{line_stripped} (регіональний)",
                            'date': date_str,
                            'channel': channel,
                            'marker_icon': 'icon_drone.svg',
                            'source_match': 'immediate_multi_regional_region',
                            'count': 1
                        })
                        
                        add_debug_log(f"Immediate Multi-regional regional: {place_name} -> {lat}, {lng}", "multi_regional")
        
        if threats:
            add_debug_log(f"IMMEDIATE MULTI-REGIONAL RESULT: {len(threats)} threats", "multi_regional")
            return threats
    
    if 'повітряна тривога' in low_orig or 'тривога' in low_orig or 'тривог' in low_orig:
        # Always event-only record (list), never create map markers for air alarms or cancellations
        place = None
        low = low_orig.lower()
        # Try to extract oblast/region info for place
        for name in ['запорізька', 'одеська', 'миколаївська', 'херсонська', 'київська', 'львівська', 'харківська', 'дніпропетровська', 'чернігівська', 'сумська', 'полтавська', 'тернопільська', 'волинська', 'рівненська', 'житомирська', 'вінницька', 'закарпатська', 'івано-франківська', 'кіровоградська', 'черкаська', 'хмельницька', 'луганська', 'донецька']:
            if name in low:
                place = name.title() + ' Обл.'
                break
        
        # Also try to find city names
        if not place:
            for city in ['запоріжжя', 'одеса', 'миколаїв', 'херсон', 'київ', 'львів', 'харків', 'дніпро', 'чернігів', 'суми', 'полтава']:
                if city in low:
                    place = city.title()
                    break
        
        # Determine if this is alarm start or cancellation
        threat_type = 'alarm_cancel' if ('відбій' in low_orig or 'отбой' in low_orig) else 'alarm'
        icon = 'vidboi.png' if threat_type == 'alarm_cancel' else 'trivoga.png'
        
        # Clean subscription links from air alarm messages before returning
        import re as re_import
        cleaned_text = original_text
        if original_text:
            # remove lines containing subscription prompts
            cleaned = []
            for ln in original_text.splitlines():
                ln2 = ln.strip()
                if not ln2:
                    continue
                # remove any line that is just a subscribe CTA or starts with arrow+subscribe
                if re_import.search(r'(підписатись|підписатися|підписатися|подписаться|подпишись|subscribe)', ln2, re_import.IGNORECASE):
                    continue
                # remove arrow+subscribe pattern specifically
                if re_import.search(r'[➡→>]\s*підписатися', ln2, re_import.IGNORECASE):
                    continue
                cleaned.append(ln2)
            cleaned_text = '\n'.join(cleaned)
        
        return [{
            'id': str(mid), 'place': place, 'lat': None, 'lng': None,
            'threat_type': threat_type, 'text': cleaned_text[:500], 'date': date_str, 'channel': channel,
            'marker_icon': icon, 'list_only': True
        }]

    # Define classify function at the start so it's available throughout process_message
    def classify(th: str, city_context: str = ""):
        import re  # Import re module locally for pattern matching
        l = th.lower()
        
        # Add debug logging (temporarily disabled)
        # print(f"[CLASSIFY DEBUG] Input text: {th}")
        # print(f"[CLASSIFY DEBUG] Lowercase text: {l}")
        # print(f"[CLASSIFY DEBUG] City context: {city_context}")
        # print(f"[CLASSIFY DEBUG] Contains 🚀: {'🚀' in th}")
        # print(f"[CLASSIFY DEBUG] Contains 'ціль': {'ціль' in l}")
        # print(f"[CLASSIFY DEBUG] Contains 'високошвидкісн': {'високошвидкісн' in l}")
        # print(f"[CLASSIFY DEBUG] Contains 'бпла': {'бпла' in l}")
        
        # PRIORITY: Artillery shelling warning (обстріл / загроза обстрілу) -> use obstril.png
        # This should have priority over FPV cities when explicit shelling threat is mentioned
        if 'обстріл' in l or 'обстрел' in l or 'загроза обстрілу' in l or 'угроза обстрела' in l:
            # print(f"[CLASSIFY DEBUG] Classified as artillery")
            return 'artillery', 'obstril.png'
        
        # Special override for specific cities - Kherson, Nikopol, Marhanets always get FPV icon
        city_lower = city_context.lower() if city_context else ""
        fpv_cities = ['херсон', 'никополь', 'нікополь', 'марганець', 'марганец']
        
        # Check both city context and message text for FPV cities
        if any(fpv_city in city_lower for fpv_city in fpv_cities) or any(fpv_city in l for fpv_city in fpv_cities):
            return 'fpv', 'fpv.png'
        # Recon / розвід дрони -> use pvo icon (rozved.png) per user request - PRIORITY: check BEFORE general БПЛА
        if 'розвід' in l or 'розвідуваль' in l or 'развед' in l:
            return 'rozved', 'rozved.png'
        # PRIORITY: КАБы (управляемые авиационные бомбы) -> icon_missile.svg - check BEFORE пуски to avoid misclassification
        if any(k in l for k in ['каб','kab','умпк','umpk','модуль','fab','умпб','фаб','кабу']) or \
           ('авіаційн' in l and 'бомб' in l) or ('керован' in l and 'бомб' in l):
            return 'kab', 'icon_missile.svg'
        # Launch site detections for Shahed / UAV launches ("пуски" + origin phrases). User wants pusk.png marker.
        # Exclude КАБ launches - they should be classified as КАБ, not пуски
        if ('пуск' in l or 'пуски' in l) and (any(k in l for k in ['shahed','шахед','шахеді','шахедів','бпла','uav','дрон']) or ('аеродром' in l) or ('аэродром' in l)) and not any(k in l for k in ['каб','kab','умпк','fab','фаб']):
            return 'pusk', 'pusk.png'
        # Explicit launches from occupied Berdyansk airbase (Запорізька область) should also show as pusk (not avia)
        if ('пуск' in l or 'пуски' in l) and 'бердян' in l and ('авіабаз' in l or 'аеродром' in l or 'авиабаз' in l):
            return 'pusk', 'pusk.png'
        # Air alarm start
        if ('повітряна тривога' in l or 'повітряна тривога.' in l or ('тривога' in l and 'повітр' in l)) and not ('відбій' in l or 'отбой' in l):
            return 'alarm', 'trivoga.png'
        # Air alarm cancellation
        if ('відбій тривоги' in l) or ('отбой тревоги' in l):
            return 'alarm_cancel', 'vidboi.png'
        # Explosions reporting -> vibuh icon (cover broader fixation phrases)
        if ('повідомляють про вибух' in l or 'повідомлено про вибух' in l or 'зафіксовано вибух' in l or 'зафіксовано вибухи' in l
            or 'фіксація вибух' in l or 'фіксують вибух' in l or re.search(r'\b(вибух|вибухи|вибухів)\b', l)):
            return 'vibuh', 'vibuh.png'
        # Alarm cancellation (відбій тривоги / отбой тревоги)
        if ('відбій' in l and 'тривог' in l) or ('отбой' in l and 'тревог' in l):
            print(f"[CLASSIFY DEBUG] Classified as alarm_cancel")
            return 'alarm_cancel', 'vidboi.png'
        
        # PRIORITY: High-speed targets / missile threats with rocket emoji (🚀) -> icon_balistic.svg
        # This should have priority over drones to handle missile-like threats with rocket emoji
        if '🚀' in th or any(k in l for k in ['ціль','цілей','цілі','високошвидкісн','high-speed']):
            print(f"[CLASSIFY DEBUG] Classified as raketa (high-speed targets/rocket emoji)")
            return 'raketa', 'icon_balistic.svg'
            
        # PRIORITY: drones (частая путаница). Если присутствуют слова шахед/бпла/дрон -> это shahed
        if any(k in l for k in ['shahed','шахед','шахеді','шахедів','geran','герань','дрон','дрони','бпла','uav']):
            print(f"[CLASSIFY DEBUG] Classified as shahed (drones/UAV)")
            return 'shahed', 'icon_drone.svg'
        # PRIORITY: Aircraft activity & tactical aviation (avia) -> avia.png (jets, tactical aviation, но БЕЗ КАБов)
        if any(k in l for k in ['літак','самол','avia','tactical','тактичн','fighter','истребит','jets']) or \
           ('авіаційн' in l and ('засоб' in l or 'ураж' in l)):
            return 'avia', 'avia.png'
        # Rocket / missile attacks (ракета, ракети) -> icon_balistic.svg
        if any(k in l for k in ['ракет','rocket','міжконтинент','межконтинент','балістичн','крилат','cruise']):
            return 'raketa', 'icon_balistic.svg'
        # РСЗВ (MLRS, град, ураган, смерч) -> icon_missile.svg
        if any(k in l for k in ['рсзв','mlrs','град','ураган','смерч','рсув','tор','tорнадо','торнадо']):
            return 'rszv', 'icon_missile.svg'
        # Korabel (naval/ship-related threats) -> use icon_balistic.svg as fallback
        if any(k in l for k in ['корабел','флот','корабл','ship','fleet','морськ','naval']):
            return 'raketa', 'icon_balistic.svg'
        # Artillery
        if any(k in l for k in ['арт','artillery','гармат','гаубиц','минометн','howitzer']):
            return 'artillery', 'artillery.png'
        # PVO (air defense activity) -> use vidboi.png as fallback
        if any(k in l for k in ['ппо','pvo','defense','оборон','зенітн','с-','patriot']):
            return 'vidboi', 'vidboi.png'
        # Naval mines -> use icon_balistic.svg as fallback
        if any(k in l for k in ['міна','мін ','mine','neptun','нептун','противокорабел']):
            return 'raketa', 'icon_balistic.svg'
        # FPV drones -> fpv.png
        if any(k in l for k in ['fpv','фпв','камікадз','kamikaze']):
            print(f"[CLASSIFY DEBUG] Classified as fpv")
            return 'fpv', 'fpv.png'
        
        # General fallback for unclassified threats
        print(f"[CLASSIFY DEBUG] Using default fallback: shahed")
        return 'shahed', 'icon_drone.svg'  # default fallback
    
    # PRIORITY CHECK: District-level UAV messages (e.g., "вишгородський р-н київська обл.")
    # Added after classify function to ensure it's available
    lower_text = original_text.lower()
    district_pattern = re.compile(r'([а-яіїєґ\'\-\s]+ський|[а-яіїєґ\'\-\s]+цький)\s+р[-\s]*н\s+([а-яіїєґ\'\-\s]+(?:обл\.?|область|щина))', re.IGNORECASE)
    district_match = district_pattern.search(lower_text)
    
    if district_match and 'бпла' in lower_text:
        district_raw = district_match.group(1).strip()
        region_raw = district_match.group(2).strip()
        
        add_debug_log(f"DISTRICT UAV: found '{district_raw} р-н {region_raw}'", "district_uav")
        
        # Try to map district to city coordinates
        district_city = district_raw.replace('ський', '').replace('цький', '').strip()
        
        # Check if we have coordinates for this district city
        coords = CITY_COORDS.get(district_city)
        if not coords and district_city in UA_CITY_NORMALIZE:
            coords = CITY_COORDS.get(UA_CITY_NORMALIZE[district_city])
        
        if coords:
            lat, lng = coords
            threat_type, icon = classify(original_text, district_city)
            
            # Create district-level marker
            district_track = {
                'id': f"{mid}_district",
                'place': f"{district_city.title()} ({district_raw} р-н)",
                'lat': lat,
                'lng': lng,
                'threat_type': threat_type,
                'text': original_text[:500],
                'date': date_str,
                'channel': channel,
                'marker_icon': icon,
                'source_match': 'district_priority_uav',
                'count': 1
            }
            
            add_debug_log(f"DISTRICT UAV SUCCESS: {district_city} -> {coords}", "district_uav")
            return [district_track]
        else:
            add_debug_log(f"DISTRICT UAV: No coords for '{district_city}'", "district_uav")
    
    # PRIORITY CHECK: Single-region numbered UAV lists (н.п. patterns)
    # For messages like "Київщина:\n• н.п. Бровари - постійна загроза БпЛА"
    lower_text = original_text.lower()
    text_lines = original_text.split('\n')
    
    # Check if this is a single-region message with numbered н.п. cities
    region_lines = [line for line in text_lines if any(region in line.lower() for region in ['щина:', 'щина]', 'область:']) and line.strip().endswith(':')]
    np_lines = [line for line in text_lines if ('н.п.' in line.lower() or 'н. п.' in line.lower()) and 'бпла' in line.lower()]
    
    if len(region_lines) == 1 and len(np_lines) >= 1:  # Single region with н.п. cities
        region_line = region_lines[0]
        region_name = region_line.replace(':', '').strip()
        
        add_debug_log(f"SINGLE-REGION NUMBERED: found {len(np_lines)} н.п. cities in {region_name}", "single_region_numbered")
        
        numbered_tracks = []
        for i, line in enumerate(np_lines):
            # Extract city name from н.п. pattern
            np_match = re.search(r'н\.?\s*п\.?\s+([а-яіїєґ\'\-\s]+)', line.lower())
            if np_match:
                city_name_raw = np_match.group(1).strip()
                # Clean up - take only the city name before any separators
                city_name = city_name_raw.split(' - ')[0].split(' –')[0].split(' ')[0].strip()
                
                # Try to find coordinates for this city
                coords = CITY_COORDS.get(city_name)
                if not coords and city_name in UA_CITY_NORMALIZE:
                    coords = CITY_COORDS.get(UA_CITY_NORMALIZE[city_name])
                
                if coords:
                    lat, lng = coords
                    threat_type, icon = classify(line, city_name)
                    
                    numbered_tracks.append({
                        'id': f"{mid}_np_{i+1}",
                        'place': f"{city_name.title()} ({region_name})",
                        'lat': lat,
                        'lng': lng,
                        'threat_type': threat_type,
                        'text': line[:500],
                        'date': date_str,
                        'channel': channel,
                        'marker_icon': icon,
                        'source_match': 'single_region_numbered_np',
                        'count': 1
                    })
                    add_debug_log(f"NUMBERED UAV SUCCESS: {city_name} -> {coords}", "single_region_numbered")
                else:
                    # Fallback to region coordinates if city not found
                    region_key = region_name.lower().replace('щина', '').replace('область', '').strip()
                    region_coords = CITY_COORDS.get(region_key)
                    if region_coords:
                        lat, lng = region_coords
                        threat_type, icon = classify(line)
                        
                        numbered_tracks.append({
                            'id': f"{mid}_np_fallback_{i+1}",
                            'place': f"{region_name} (н.п. {city_name.title()})",
                            'lat': lat,
                            'lng': lng,
                            'threat_type': threat_type,
                            'text': line[:500],
                            'date': date_str,
                            'channel': channel,
                            'marker_icon': icon,
                            'source_match': 'single_region_numbered_np_fallback',
                            'count': 1
                        })
                        add_debug_log(f"NUMBERED UAV FALLBACK: {city_name} -> {region_name} {region_coords}", "single_region_numbered")
        
        if numbered_tracks:
            add_debug_log(f"SINGLE-REGION NUMBERED SUCCESS: {len(numbered_tracks)} markers created", "single_region_numbered")
            return numbered_tracks

    # HIGHEST PRIORITY: Check for region-district patterns immediately
    import re as _re_priority
    region_district_pattern = _re_priority.compile(r'([а-яіїєґ]+щин[ауи]?)\s*\(\s*([а-яіїєґ\'\-\s]+)\s+р[-\s]*н\)', _re_priority.IGNORECASE)
    region_district_match = region_district_pattern.search(original_text)
    
    if region_district_match:
        region_raw, district_raw = region_district_match.groups()
        target_city = district_raw.strip()
        
        add_debug_log(f"PRIORITY REGION-DISTRICT pattern FOUND: region='{region_raw}', district='{district_raw}'", "priority_region_district")
        
        # Normalize city name and try to find coordinates via API
        city_norm = target_city.lower()
        # Apply UA_CITY_NORMALIZE rules if available
        if 'UA_CITY_NORMALIZE' in globals():
            city_norm = UA_CITY_NORMALIZE.get(city_norm, city_norm)
        
        # Use API geocoding with message context
        coords_result = ensure_city_coords_with_message_context(city_norm, original_text)
        coords = (coords_result[0], coords_result[1]) if coords_result else None
        
        add_debug_log(f"Priority district city API lookup: '{target_city}' -> '{city_norm}' -> {coords}", "priority_region_district")
        
        if coords:
            lat, lng = coords
            threat_type, icon = classify(original_text)
            
            priority_result = [{
                'id': f"{mid}_priority_district",
                'place': target_city.title(),
                'lat': lat,
                'lng': lng,
                'threat_type': threat_type,
                'text': original_text[:500],
                'date': date_str,
                'channel': channel,
                'marker_icon': icon,
                'source_match': 'priority_region_district',
                'count': 1
            }]
            add_debug_log(f"Created PRIORITY region-district marker: {target_city.title()}", "priority_region_district")
            
            # Store priority result globally for combination with other results
            globals()['_current_priority_result'] = priority_result
            
            # Store priority result and continue with normal processing to catch other cities
            # This allows other parsers to find additional cities in the same message
        else:
            add_debug_log(f"No coordinates found for priority district city: '{target_city}' (normalized: '{city_norm}')", "priority_region_district")
            priority_result = None
    else:
        priority_result = None

    # ВСЕГДА логируем каждое входящее сообщение для отладки
    try:
        add_debug_log(f"process_message called - mid={mid}, channel={channel}, text_length={len(text or '')}", "message_processing")
        add_debug_log(f"message text preview: {(text or '')[:200]}...", "message_processing")
        # Check if this is our test message
        if 'чернігівщина' in (text or '').lower() and 'сумщина' in (text or '').lower():
            add_debug_log("MULTI-REGION MESSAGE DETECTED!", "multi_region")
            add_debug_log(f"Full text: {text}", "multi_region")
    except Exception:
        pass

    # PRIORITY: Handle emoji + city + oblast format BEFORE any other processing
    try:
        import re  # Import re module for pattern matching
        head = text.split('\n', 1)[0][:160] if text else ""
        
        # Handle general emoji + city + oblast format with any UAV threat (more flexible pattern)
        general_emoji_pattern = r'^[^\w\s]*\s*([А-ЯІЇЄЁа-яіїєё\'\-\s]+)\s*\(([^)]*обл[^)]*)\)'
        general_emoji_match = re.search(general_emoji_pattern, head, re.IGNORECASE)
        add_debug_log(f"PRIORITY: Testing general emoji pattern on head: {repr(head)}", "emoji_debug")
        add_debug_log(f"PRIORITY: General emoji match result: {general_emoji_match}", "emoji_debug")
        
        if general_emoji_match and any(uav_word in text.lower() for uav_word in ['бпла', 'дрон', 'шахед', 'активність', 'загроза', 'тривога', 'обстріл', 'обстрел']):
            city_from_general = general_emoji_match.group(1).strip()
            oblast_from_general = general_emoji_match.group(2).strip()
            
            # Strip UAV-related prefixes from city name (БПЛА, дрон, шахед, etc.)
            uav_prefixes = ['бпла', 'дрон', 'дрони', 'шахед', 'шахеди', 'безпілотник', 'безпілотники', 'ворожий', 'ворожі']
            city_lower = city_from_general.lower()
            for prefix in uav_prefixes:
                if city_lower.startswith(prefix + ' '):
                    city_from_general = city_from_general[len(prefix):].strip()
                    city_lower = city_from_general.lower()
                    add_debug_log(f"PRIORITY: Stripped UAV prefix '{prefix}', city now: {repr(city_from_general)}", "emoji_debug")

            # Strip course/direction suffixes from city name
            city_from_general = re.sub(r'\s+(курсом|курс|напрям(?:ком)?|в\s+напрямку|у\s+напрямку)\s+.+$', '', city_from_general, flags=re.IGNORECASE).strip()
            
            add_debug_log(f"PRIORITY: Found city: {repr(city_from_general)}, oblast: {repr(oblast_from_general)}", "emoji_debug")
            
            if city_from_general and 2 <= len(city_from_general) <= 40:
                base = city_from_general.lower().replace('\u02bc',"'").replace('ʼ',"'").replace("'","'").replace('`',"'")
                base = re.sub(r'\s+',' ', base)
                norm = UA_CITY_NORMALIZE.get(base, base)
                
                # First try to find city+oblast specific coordinates
                oblast_key = oblast_from_general.lower()
                coords = None
                
                # Try different lookup strategies for city+oblast disambiguation
                if 'сум' in oblast_key and norm == 'миколаївка':
                    coords = (51.5667, 34.1333)  # Миколаївка, Сумська область
                    add_debug_log(f"PRIORITY: Using specific coordinates for Миколаївка (Сумська обл.): {coords}", "emoji_debug")
                elif 'миколаївськ' in oblast_key and norm == 'миколаївка':
                    coords = (47.0667, 31.8333)  # Миколаївка, Миколаївська область
                    add_debug_log(f"PRIORITY: Using specific coordinates for Миколаївка (Миколаївська обл.): {coords}", "emoji_debug")
                # Handle districts by mapping to their administrative centers
                elif 'район' in norm:
                    if 'синельниківський район' in norm:
                        coords = CITY_COORDS.get('синельникове')  # Синельникове - центр району
                        add_debug_log(f"PRIORITY: Mapping Синельниківський район -> Синельникове: {coords}", "emoji_debug")
                    elif 'миколаївський район' in norm and 'миколаївськ' in oblast_key:
                        coords = CITY_COORDS.get('миколаїв')  # Миколаїв - центр району
                        add_debug_log(f"PRIORITY: Mapping Миколаївський район -> Миколаїв: {coords}", "emoji_debug")
                    # For other districts, try to find coordinates in DISTRICT_CENTERS first
                    else:
                        # Extract district name without 'район' suffix
                        district_name = norm.replace('район', '').strip()
                        district_coords = DISTRICT_CENTERS.get(district_name)
                        if district_coords:
                            coords = district_coords
                            add_debug_log(f"PRIORITY: Found district coordinates for '{district_name}': {coords}", "emoji_debug")
                        else:
                            coords = CITY_COORDS.get(district_name)
                            if coords:
                                add_debug_log(f"PRIORITY: District fallback to city center '{district_name}': {coords}", "emoji_debug")
                
                if not coords:
                    # Fallback to general lookup
                    coords = CITY_COORDS.get(norm)
                    add_debug_log(f"PRIORITY: General lookup: base={repr(base)}, norm={repr(norm)}, coords={coords}", "emoji_debug")
                
                if not coords and 'SETTLEMENTS_INDEX' in globals():
                    idx_map = globals().get('SETTLEMENTS_INDEX') or {}
                    coords = idx_map.get(norm)
                if coords:
                    lat, lon = coords[:2]
                    
                    # Check for threat cancellation BEFORE creating marker
                    text_lower = text.lower()
                    if ('відбій загрози' in text_lower or 
                        'відбій тривоги' in text_lower or
                        ('відбій' in text_lower and any(cancel_word in text_lower for cancel_word in ['загрози', 'тривоги']))):
                        # This is a cancellation message - create list_only entry, no map marker
                        track = {
                            'id': f"{mid}_priority_emoji_cancel_{city_from_general.replace(' ','_')}",
                            'place': city_from_general.title(),
                            'threat_type': 'alarm_cancel',
                            'text': clean_text(text)[:500], 
                            'date': date_str, 
                            'channel': channel,
                            'list_only': True,  # NO map marker for cancellation
                            'source_match': 'priority_emoji_cancel'
                        }
                        add_debug_log(f'PRIORITY CANCELLATION: {city_from_general} -> list_only=True (no marker)', "emoji_debug")
                        return [track]  # Early return - cancellation handled
                    
                    # Regular threat - create map marker
                    threat_type, icon = classify(text, city_from_general)
                    track = {
                        'id': f"{mid}_priority_emoji_{city_from_general.replace(' ','_')}",
                        'place': city_from_general.title(),
                        'lat': lat, 'lng': lon,
                        'threat_type': threat_type,
                        'text': clean_text(text)[:500], 'date': date_str, 'channel': channel,
                        'marker_icon': icon, 'source_match': 'priority_emoji_threat'
                    }
                    add_debug_log(f'PRIORITY EARLY RETURN: {city_from_general} -> {coords} -> {icon}', "emoji_debug")
                    return [track]  # Early return - highest priority
    except Exception as e:
        add_debug_log(f"PRIORITY emoji processing error: {e}", "emoji_debug")

    # PRIORITY: Handle emoji + oblast format (when only oblast is specified, place marker in regional center)
    try:
        import re  # Import re module for pattern matching
        head = text.split('\n', 1)[0][:160] if text else ""
        
        # Handle emoji + oblast format (e.g. "👁️ Миколаївська обл.")
        oblast_emoji_pattern = r'^[^\w\s]*\s*([А-ЯІЇЄЁа-яіїєё\'\-\s]*обл\.?)\s*\*\*'
        oblast_emoji_match = re.search(oblast_emoji_pattern, head, re.IGNORECASE)
        add_debug_log(f"PRIORITY: Testing oblast emoji pattern on head: {repr(head)}", "emoji_debug")
        add_debug_log(f"PRIORITY: Oblast emoji match result: {oblast_emoji_match}", "emoji_debug")
        
        if oblast_emoji_match and any(uav_word in text.lower() for uav_word in ['бпла', 'дрон', 'шахед', 'активність', 'загроза', 'тривога']):
            oblast_from_emoji = oblast_emoji_match.group(1).strip()
            add_debug_log(f"PRIORITY: Found oblast from emoji: {repr(oblast_from_emoji)}", "emoji_debug")
            
            # Map oblast to regional center
            regional_center = None
            coords = None
            
            oblast_key = oblast_from_emoji.lower()
            if 'миколаївськ' in oblast_key:
                regional_center = 'Миколаїв'
                coords = CITY_COORDS.get('миколаїв')
            elif 'дніпропетровськ' in oblast_key:
                regional_center = 'Дніпро'
                coords = CITY_COORDS.get('дніпро')
            elif 'харківськ' in oblast_key:
                regional_center = 'Харків'
                coords = CITY_COORDS.get('харків')
            elif 'сумськ' in oblast_key:
                regional_center = 'Суми'
                coords = CITY_COORDS.get('суми')
            elif 'херсонськ' in oblast_key:
                regional_center = 'Херсон'
                coords = CITY_COORDS.get('херсон')
            elif 'одеськ' in oblast_key:
                regional_center = 'Одеса'
                coords = CITY_COORDS.get('одеса')
            elif 'запорізьк' in oblast_key:
                regional_center = 'Запоріжжя'
                coords = CITY_COORDS.get('запоріжжя')
            elif 'полтавськ' in oblast_key:
                regional_center = 'Полтава'
                coords = CITY_COORDS.get('полтава')
            
            add_debug_log(f"PRIORITY: Oblast {oblast_from_emoji} -> regional center {regional_center} -> coords {coords}", "emoji_debug")
            
            if coords and regional_center:
                lat, lon = coords[:2]
                threat_type, icon = classify(text)
                track = {
                    'id': f"{mid}_priority_oblast_{regional_center.replace(' ','_')}",
                    'place': regional_center,
                    'lat': lat, 'lng': lon,
                    'threat_type': threat_type,
                    'text': text[:160], 'date': date_str, 'channel': channel,
                    'marker_icon': icon, 'source_match': 'priority_oblast_threat'
                }
                add_debug_log(f'PRIORITY OBLAST EARLY RETURN: {oblast_from_emoji} -> {regional_center} -> {coords} -> {icon}', "emoji_debug")
                return [track]  # Early return - highest priority
    except Exception as e:
        add_debug_log(f"PRIORITY oblast processing error: {e}", "emoji_debug")
    
    # Continue with existing logic...
    
    # Strip embedded links (Markdown [text](url) or raw URLs) while keeping core message text.
    # Requested: if message contains links, remove them but keep the rest.
    try:
        import re as _re_strip  # type: ignore
        if text:
            _orig_text = text
            # Remove markdown links [ ... ](http...). Keep the visible text (group 1) only.
            text = _re_strip.sub(r"\[([^\]]*)\]\((?:https?|tg|mailto)://[^)]+\)", lambda m: (m.group(1) or '').strip(), text)
            # Remove any residual raw URLs (http/https/t.me) leaving a single space
            text = _re_strip.sub(r"https?://\S+", " ", text)
            text = _re_strip.sub(r"t\.me/\S+", " ", text)
            # Remove lone decorative symbols (✙, •, ★) that may have surrounded links
            text = _re_strip.sub(r"[✙•★]{1,}", " ", text)
            # Collapse multiple spaces and trim each line
            cleaned_lines = []
            for _ln in text.splitlines():
                _cl = ' '.join(_ln.split())
                if _cl:
                    cleaned_lines.append(_cl)
            if cleaned_lines:
                text = '\n'.join(cleaned_lines)
            else:
                # If stripping removed everything, fall back to original
                text = _orig_text
    except Exception:
        pass
    # Ensure original_text is defined early to avoid UnboundLocalError in early parsing branches
    original_text = text
    
    # Special handling for oblast+raion format: "чернігівська область (чернігівський район), київська область (вишгородський район)"
    import re as _re_oblast
    oblast_raion_pattern = r'([а-яіїєґ]+ська\s+область)\s*\(([^)]*?райони?[^)]*?)\)'
    oblast_raion_matches = _re_oblast.findall(oblast_raion_pattern, text.lower(), _re_oblast.IGNORECASE)
    
    # Also check for pattern without requiring "райони" in parentheses - some messages might have just names
    if not oblast_raion_matches:
        oblast_raion_pattern_simple = r'([а-яіїєґ]+ська\s+область)\s*\(([^)]+)\)'
        oblast_raion_matches_simple = _re_oblast.findall(oblast_raion_pattern_simple, text.lower(), _re_oblast.IGNORECASE)
        # Filter to only those that contain district-like words
        oblast_raion_matches = [(oblast, raion) for oblast, raion in oblast_raion_matches_simple 
                               if any(word in raion for word in ['район', 'р-н', 'ський', 'цький'])]
    
    add_debug_log(f"Oblast+raion pattern check: found {len(oblast_raion_matches)} matches in text: {text[:200]}...", "oblast_raion")
    
    if oblast_raion_matches and any(word in text.lower() for word in ['бпла', 'загроза', 'укриття']):
        add_debug_log(f"Oblast+raion format detected: {oblast_raion_matches}", "oblast_raion")
        tracks = []
        
        for oblast_text, raion_text in oblast_raion_matches:
            add_debug_log(f"Processing oblast: '{oblast_text}', raion_text: '{raion_text}'", "oblast_raion")
            # Extract individual raions from the parentheses
            # Handle both single and multiple raions: "сумський, конотопський райони"
            raion_parts = _re_oblast.split(r',\s*|\s+та\s+', raion_text)
            add_debug_log(f"Split raion_parts: {raion_parts}", "oblast_raion")
            
            for raion_part in raion_parts:
                raion_part = raion_part.strip()
                if not raion_part:
                    continue
                    
                add_debug_log(f"Processing raion_part: '{raion_part}'", "oblast_raion")
                    
                # Extract raion name (remove "район"/"райони" suffix)
                raion_name = _re_oblast.sub(r'\s*(райони?|р-н\.?).*$', '', raion_part).strip()
                add_debug_log(f"After removing suffix, raion_name: '{raion_name}'", "oblast_raion")
                
                # Normalize raion name
                raion_normalized = _re_oblast.sub(r'(ському|ского|ського|ский|ськiй|ськой|ським|ском)$', 'ський', raion_name)
                add_debug_log(f"Normalized raion: '{raion_normalized}', checking in RAION_FALLBACK", "oblast_raion")
                
                if raion_normalized in RAION_FALLBACK:
                    lat, lng = RAION_FALLBACK[raion_normalized]
                    add_debug_log(f"Creating oblast+raion marker: {raion_normalized} at {lat}, {lng}", "oblast_raion")
                    
                    # Use classify function to determine correct threat type and icon
                    threat_type, icon = classify(original_text, raion_normalized)
                    
                    tracks.append({
                        'id': f"{mid}_raion_{raion_normalized}",
                        'place': f"{raion_normalized.title()} район",
                        'lat': lat,
                        'lng': lng,
                        'threat_type': threat_type,
                        'text': original_text[:500],
                        'date': date_str,
                        'channel': channel,
                        'marker_icon': icon,
                        'source_match': 'oblast_raion_format'
                    })
                else:
                    add_debug_log(f"Raion not found in RAION_FALLBACK: '{raion_normalized}'. Available keys: {list(RAION_FALLBACK.keys())[:10]}...", "oblast_raion")
        
        if tracks:
            add_debug_log(f"Returning {len(tracks)} oblast+raion markers", "oblast_raion")
            return tracks
    
    large_message_mode = False
    LARGE_THRESHOLD = 15000
    HARD_CUTOFF = 40000  # safety to avoid pathological regex backtracking
    parse_started_ts = time.perf_counter()
    if text and len(text) > LARGE_THRESHOLD:
        large_message_mode = True
        orig_len = len(text)
        if orig_len > HARD_CUTOFF:
            # Keep head + tail slices to retain some closing context
            head = text[:HARD_CUTOFF//2]
            tail = text[-2000:]
            text = head + "\n...TRUNCATED...\n" + tail
            log.debug(f"mid={mid} large_message_mode truncation {orig_len}->{len(text)} chars")
        else:
            log.debug(f"mid={mid} large_message_mode len={orig_len}")
        # Quick complexity metrics
        try:
            lc = text.lower()
            metrics = {
                'len': orig_len,
                'lines': text.count('\n') + 1,
                'bpla': lc.count('бпла'),
                'shahed': lc.count('шахед'),
                'course': lc.count('курс'),
                'napr': lc.count('напрям') + lc.count('напрямку')
            }
            log.debug(f"mid={mid} large_msg_metrics {metrics}")
        except Exception:
            pass
        # Pre-scan chunk optimization: if many repeated 'бпла курсом на', extract tokens fast before heavy regex blocks
        try:
            if text.lower().count('курс') > 8 and text.lower().count('бпла') > 8:
                fast_tokens = []
                for ln in text.split('\n'):
                    lnl = ln.lower()
                    if 'бпла' in lnl and 'курс' in lnl and ' на ' in lnl:
                        # light-weight extraction (avoid complex backtracking)
                        # Regex: capture token after 'курс(ом) на' up to 40 chars (letters, spaces, dashes)
                        m = re.search(r"курс(?:ом)?\s+на\s+([a-zа-яіїєґ\-\s]{3,40})", lnl, re.IGNORECASE)
                        if m:
                            tok = m.group(1).strip()
                            if tok and tok not in fast_tokens:
                                fast_tokens.append(tok)
                if fast_tokens:
                    log.debug(f"mid={mid} pre-scan collected {len(fast_tokens)} fast_tokens (will still run main parser)")
        except Exception as _e_fast:
            log.debug(f"mid={mid} pre-scan error: {_e_fast}")
    # Early benign filter: city name + emojis / hearts without any threat keywords -> ignore
    try:
        lt = (text or '').lower().strip()
        if lt:
            # threat indicator tokens (broad stems)
            threat_tokens = (
                'шахед','shahed','бпла','дрон','ракет','каб','вибух','прил','удар','загроз','тривог',
                'пуск','зліт','злет','avia','авіа','пво','обстр','mlrs','rszv','fpv','артил','зеніт','зенит'
            )
            if not any(t in lt for t in threat_tokens):
                # strip emojis & symbols leaving letters, spaces and apostrophes
                import re as _re_benign
                core = _re_benign.sub(r"[^a-zа-яіїєґ'’ʼ`\s-]","", lt)
                core = ' '.join(core.split())
                # If core matches exactly a known city (or its normalized form) and original text length small -> benign
                if 2 <= len(core) <= 30:
                    base = UA_CITY_NORMALIZE.get(core, core)
                    if base in CITY_COORDS or ('SETTLEMENTS_INDEX' in globals() and (globals().get('SETTLEMENTS_INDEX') or {}).get(base)):
                        # Ignore this message (no tracks)
                        add_debug_log(f"BENIGN FILTER blocked message mid={mid} - detected city name without threats: '{core}'", "filter")
                        return []
            # NEW suppression: reconnaissance-only notes ("дорозвідка по БпЛА") should not produce a marker
            # Pattern triggers if word 'дорозвідк' present together with UAV terms but no other threat verbs
            if 'дорозвідк' in lt and any(k in lt for k in ['бпла','shahed','шахед','дрон']):
                # Avoid suppressing if explosions or launches also present
                if not any(k in lt for k in ['вибух','удар','пуск','прил','обстріл','обстрел','зліт','злет']):
                    add_debug_log(f"RECONNAISSANCE FILTER blocked message mid={mid} - reconnaissance only", "filter")
                    return []
    except Exception:
        pass
    
    # SPECIAL: Handle multiple threats in one message BEFORE other parsing
    def handle_multiple_threats():
        """Check for messages with multiple different threats and process each separately"""
        all_threats = []
        text_lower = text.lower()
        
        # 1. Check for northeast tactical aviation threat
        if ('тактичн' in text_lower or 'авіаці' in text_lower or 'авиац' in text_lower) and (
            'північно-східн' in text_lower or 'північно східн' in text_lower or 'северо-восточ' in text_lower or 'північного-сходу' in text_lower
        ):
            lat, lng = 51.0, 36.5  # On Russian territory near Belgorod (before Ukraine border)
            all_threats.append({
                'id': f"{mid}_ne_multi", 'place': 'Північно-східний напрямок', 'lat': lat, 'lng': lng,
                'threat_type': 'avia', 'text': text[:500], 'date': date_str, 'channel': channel,
                'marker_icon': 'avia.png', 'source_match': 'multiple_threats_northeast_aviation'
            })
        
        # 2. Check for reconnaissance UAV in Mykolaiv oblast (миколаївщини/миколаївщині)
        if ('розвід' in text_lower or 'розведуваль' in text_lower) and ('миколаївщини' in text_lower or 'миколаївщині' in text_lower or 'миколаївщина' in text_lower):
            # Use Mykolaiv city coordinates
            lat, lng = 46.9750, 31.9946
            all_threats.append({
                'id': f"{mid}_mykolaiv_recon", 'place': 'Миколаївщина', 'lat': lat, 'lng': lng,
                'threat_type': 'rozved', 'text': text[:500], 'date': date_str, 'channel': channel,
                'marker_icon': 'rozved.png', 'source_match': 'multiple_threats_mykolaiv_recon'
            })
        
        # 3. Check for general БПЛА threats in oblast format (миколаївщини/миколаївщині) without "розвід"
        elif ('бпла' in text_lower or 'дрон' in text_lower) and ('миколаївщини' in text_lower or 'миколаївщині' in text_lower or 'миколаївщина' in text_lower):
            lat, lng = 46.9750, 31.9946
            all_threats.append({
                'id': f"{mid}_mykolaiv_uav", 'place': 'Миколаївщина', 'lat': lat, 'lng': lng,
                'threat_type': 'shahed', 'text': clean_text(text)[:500], 'date': date_str, 'channel': channel,
                'marker_icon': 'icon_drone.svg', 'source_match': 'multiple_threats_mykolaiv_uav'
            })
        
        return all_threats

    # Check if this is a multi-threat message
    if '🛬' in text and '🛸' in text:
        multi_threats = handle_multiple_threats()
        if multi_threats:
            add_debug_log(f"MULTIPLE THREATS DETECTED: Found {len(multi_threats)} threats", "multi_threats")
            return multi_threats

    # EARLY CHECK: Multi-regional UAV messages (before other logic can interfere)
    text_lines = text.split('\n')
    region_count = sum(1 for line in text_lines if any(region in line.lower() for region in ['щина:', 'щина]', 'область:', 'край:']) or (
        'щина' in line.lower() and line.lower().strip().endswith(':')
    ))
    uav_count = sum(1 for line in text_lines if 'бпла' in line.lower() and ('курс' in line.lower() or 'на ' in line.lower()))
    
    if region_count >= 2 and uav_count >= 3:
        add_debug_log(f"EARLY MULTI-REGIONAL UAV DETECTION: {region_count} regions, {uav_count} UAVs", "multi_regional")
        # We'll process this later when all functions are defined
        # Set a flag for now
        multi_regional_flag = True
    else:
        multi_regional_flag = False

    # ... existing parsing logic continues ...
    # At the very end of function (before return default) we'll log duration.
    # Air alarm region/raion tracking (start / cancel) before other parsing
    try:
        low_full = (text or '').lower()
        now_ep = time.time()
        lines = [l.strip() for l in (text or '').split('\n') if l.strip()][:3]
        if lines:
            header = lines[0].lower()
            header_norm = header.replace('область', 'обл.').replace('обл..','обл.')
            # Oblast alarm start: contains '<adj> обл.' and body has 'повітряна тривога'
            if ('повітр' in low_full or 'тривог' in low_full) and ' обл' in header_norm:
                m_obl = re.search(r"([а-яіїєґ\-']+?)\s+обл\.?", header_norm)
                if m_obl:
                    stem = m_obl.group(1)
                    # Match against OBLAST_CENTERS keys
                    for k in OBLAST_CENTERS.keys():
                        if k.startswith(stem):
                            is_new = k not in ACTIVE_OBLAST_ALARMS
                            rec = ACTIVE_OBLAST_ALARMS.setdefault(k, {'since': now_ep, 'last': now_ep})
                            if rec['since'] > now_ep: rec['since'] = now_ep
                            rec['last'] = now_ep
                            persist_alarm('oblast', k, rec['since'], rec['last'])
                            if is_new:
                                log_alarm_event('oblast', k, 'start', now_ep)
                            break
            # Raion alarm start: '<name> район'
            if ('повітр' in low_full or 'тривог' in low_full) and ' район' in header:
                m_r = re.search(r"([а-яіїєґ\-']+?)\s+район", header)
                if m_r:
                    rb = m_r.group(1).replace('’',"'").replace('ʼ',"'")
                    if rb in RAION_FALLBACK:
                        is_new_r = rb not in ACTIVE_RAION_ALARMS
                        rec = ACTIVE_RAION_ALARMS.setdefault(rb, {'since': now_ep, 'last': now_ep})
                        if rec['since'] > now_ep: rec['since'] = now_ep
                        rec['last'] = now_ep
                        persist_alarm('raion', rb, rec['since'], rec['last'])
                        if is_new_r:
                            log_alarm_event('raion', rb, 'start', now_ep)
        # Cancellation lines contain 'відбій тривоги' or 'отбой тревоги'
        if ('відбій' in low_full or 'отбой' in low_full) and ('тривог' in low_full or 'тревог' in low_full):
            # Precise: look for explicit oblast adjectives endings '-ська', '-цька', '-ницька', etc.
            # Pattern: відбій тривоги у / в <word...> області OR '<adj> обл.'
            m_cancel_obl = re.findall(r"(\b[а-яіїєґ\-']+?)(?:ська|цька|ницька|зька|жська)\s+обл(?:асть|\.|)", low_full)
            removed_any = False
            if m_cancel_obl:
                for stem in m_cancel_obl:
                    for k in list(ACTIVE_OBLAST_ALARMS.keys()):
                        if k.startswith(stem):
                            ACTIVE_OBLAST_ALARMS.pop(k, None); remove_alarm('oblast', k); log_alarm_event('oblast', k, 'cancel', now_ep); removed_any=True
            # Raion precise cancel: "відбій тривоги у <name> районі" (locative: -ському / -івському)
            m_cancel_r = re.findall(r"відбій[^\n]*?\b([а-яіїєґ\-']+?)(?:ському|івському|ському)\s+районі", low_full)
            if m_cancel_r:
                for stem in m_cancel_r:
                    for r in list(ACTIVE_RAION_ALARMS.keys()):
                        if r.startswith(stem):
                            ACTIVE_RAION_ALARMS.pop(r, None); remove_alarm('raion', r); log_alarm_event('raion', r, 'cancel', now_ep); removed_any=True
            # Fallback broad cancel if phrase generic and no explicit names matched
            if not removed_any and re.search(r"відбій\s+тривог|отбой\s+тревог", low_full):
                # remove all (global відбій)
                for k in list(ACTIVE_OBLAST_ALARMS.keys()):
                    ACTIVE_OBLAST_ALARMS.pop(k, None); remove_alarm('oblast', k); log_alarm_event('oblast', k, 'cancel', now_ep)
                for r in list(ACTIVE_RAION_ALARMS.keys()):
                    ACTIVE_RAION_ALARMS.pop(r, None); remove_alarm('raion', r); log_alarm_event('raion', r, 'cancel', now_ep)
        # Expire stale
        ttl_cut = now_ep - APP_ALARM_TTL_MINUTES*60
        for dct in (ACTIVE_OBLAST_ALARMS, ACTIVE_RAION_ALARMS):
            for k in list(dct.keys()):
                if dct[k]['last'] < ttl_cut:
                    level = 'oblast' if dct is ACTIVE_OBLAST_ALARMS else 'raion'
                    dct.pop(k, None)
                    remove_alarm(level, k)
                    log_alarm_event(level, k, 'expire', now_ep)
    except Exception as _e_alarm:
        log.debug(f'alarm tracking block error: {_e_alarm}')
    # Early single-city (bold/emoji tolerant) parser
    try:
        orig = text
        head = orig.split('\n',1)[0][:160]
        
        # PRIORITY: Handle mapstransler_bot format: "[count]х БПЛА Місто (Область обл.) Загроза застосування БПЛА"
        # Examples:
        #   "2х БПЛА Барвінкове (Харківська обл.) Загроза застосування БПЛА."
        #   "БПЛА Єланець (Миколаївська обл.) Загроза застосування БПЛА."
        #   "Димер (Київська обл.) Загроза застосування БПЛА."
        #   "БПЛА Федорівку/Піщане (Харківська обл.)" - multiple cities with /
        #   "БПЛА Вільхівку⚠ (Харківська обл.)" - emoji after city name
        # Note: [^(]* allows any chars (including emoji) between city name and (
        mapstransler_pattern = r'^[^\w]*(\d+)[xх×]?\s*БПЛА\s+([А-ЯІЇЄЁа-яіїєё\'\'\-\s/]+)[^(]*\(([^)]+обл[^)]*)\)'
        mapstransler_match = re.search(mapstransler_pattern, head, re.IGNORECASE)
        
        # Also try without count prefix
        if not mapstransler_match:
            mapstransler_pattern2 = r'^[^\w]*БПЛА\s+([А-ЯІЇЄЁа-яіїєё\'\'\-\s/]+)[^(]*\(([^)]+обл[^)]*)\)'
            mapstransler_match2 = re.search(mapstransler_pattern2, head, re.IGNORECASE)
            if mapstransler_match2:
                city_raw = mapstransler_match2.group(1).strip()
                oblast_raw = mapstransler_match2.group(2).strip()
                uav_count = 1
            else:
                city_raw = None
                oblast_raw = None
                uav_count = 1
        else:
            uav_count = int(mapstransler_match.group(1))
            city_raw = mapstransler_match.group(2).strip()
            oblast_raw = mapstransler_match.group(3).strip()
        
        # Handle multiple cities separated by / (take first one)
        if city_raw and '/' in city_raw:
            cities_list = city_raw.split('/')
            city_raw = cities_list[0].strip()  # Take first city
            add_debug_log(f"Multiple cities in message, using first: '{city_raw}' from {cities_list}", "mapstransler")
        
        # Also try format without БПЛА prefix: "Димер (Київська обл.) Загроза..."
        if not city_raw:
            no_bpla_pattern = r'^[^\w]*([А-ЯІЇЄЁа-яіїєё][А-ЯІЇЄЁа-яіїєё\'\'\-\s/]+)[^(]*\(([^)]+обл[^)]*)\)\s*загроза'
            no_bpla_match = re.search(no_bpla_pattern, head, re.IGNORECASE)
            if no_bpla_match:
                city_raw = no_bpla_match.group(1).strip()
                # Handle multiple cities
                if '/' in city_raw:
                    city_raw = city_raw.split('/')[0].strip()
                oblast_raw = no_bpla_match.group(2).strip()
                uav_count = 1
        
        if city_raw and oblast_raw:
            # Strip course/direction suffixes from city name before normalization
            city_raw = re.sub(r'\s+(курсом|курс|напрям(?:ком)?|в\s+напрямку|у\s+напрямку)\s+.+$', '', city_raw, flags=re.IGNORECASE).strip()
            # Normalize city name (accusative -> nominative) - COMPREHENSIVE
            city_norm = city_raw.lower().replace('\u02bc',"'").replace('ʼ',"'").replace("'","'").replace('`',"'")
            city_norm = re.sub(r'\s+',' ', city_norm).strip()
            
            # Store original for API search
            city_original = city_norm
            
            # COMPOUND NAMES: Handle "Adjective + Noun" patterns (e.g., "Малу Дівицю" -> "Мала Дівиця")
            # Split into words and normalize each
            words = city_norm.split()
            if len(words) == 2:
                adj, noun = words[0], words[1]
                
                # Normalize adjective (feminine accusative -> nominative)
                # -у → -а (Малу → Мала, Велику → Велика, Нову → Нова)
                if adj.endswith('у') and len(adj) > 3:
                    adj = adj[:-1] + 'а'
                # -ю → -я (Синю → Синя)
                elif adj.endswith('ю') and len(adj) > 3:
                    adj = adj[:-1] + 'я'
                
                # Normalize noun
                # -ку → -ка (Дівицку → Дівицка? No, Дівицю → Дівиця)
                if noun.endswith('ку') and len(noun) > 4:
                    noun = noun[:-2] + 'ка'
                elif noun.endswith('цю') and len(noun) > 3:
                    noun = noun[:-1] + 'я'  # Дівицю → Дівиця
                elif noun.endswith('ну') and len(noun) > 4:
                    noun = noun[:-2] + 'на'
                elif noun.endswith('у') and len(noun) > 3:
                    noun = noun[:-1] + 'а'
                elif noun.endswith('ю') and len(noun) > 3:
                    noun = noun[:-1] + 'я'
                
                city_norm = f"{adj} {noun}"
            else:
                # Single word - apply standard normalization
                # -ку → -ка (Юріївку → Юріївка, Сахновщину → Сахновщина)
                if city_norm.endswith('ку') and len(city_norm) > 4:
                    city_norm = city_norm[:-2] + 'ка'
                # -ну → -на (Сахновщину → Сахновщина)  
                elif city_norm.endswith('ну') and len(city_norm) > 4:
                    city_norm = city_norm[:-2] + 'на'
                # -у → -а (Одесу → Одеса)
                elif city_norm.endswith('у') and len(city_norm) > 3:
                    city_norm = city_norm[:-1] + 'а'
                # -ю → -я (Балаклію → Балаклія)
                elif city_norm.endswith('ю') and len(city_norm) > 3:
                    city_norm = city_norm[:-1] + 'я'
            
            city_norm = UA_CITY_NORMALIZE.get(city_norm, city_norm)
            
            # Extract oblast name for Photon API filtering
            oblast_lower = oblast_raw.lower()
            oblast_to_state = {
                'дніпропетровська': 'Дніпропетровська область',
                'харківська': 'Харківська область', 
                'київська': 'Київська область',
                'чернігівська': 'Чернігівська область',
                'сумська': 'Сумська область',
                'полтавська': 'Полтавська область',
                'миколаївська': 'Миколаївська область',
                'одеська': 'Одеська область',
                'херсонська': 'Херсонська область',
                'запорізька': 'Запорізька область',
                'донецька': 'Донецька область',
                'луганська': 'Луганська область',
                'черкаська': 'Черкаська область',
                'вінницька': 'Вінницька область',
                'житомирська': 'Житомирська область',
                'рівненська': 'Рівненська область',
                'волинська': 'Волинська область',
                'львівська': 'Львівська область',
                'тернопільська': 'Тернопільська область',
                'хмельницька': 'Хмельницька область',
                'івано-франківська': 'Івано-Франківська область',
                'закарпатська': 'Закарпатська область',
                'чернівецька': 'Чернівецька область',
                'кіровоградська': 'Кіровоградська область',
            }
            
            target_state = None
            for key, state in oblast_to_state.items():
                if key in oblast_lower:
                    target_state = state
                    break
            
            add_debug_log(f"Mapstransler pattern: city='{city_raw}' -> norm='{city_norm}', oblast='{oblast_raw}' -> state='{target_state}', count={uav_count}", "mapstransler")
            
            coords = None
            
            # Check in-memory cache first
            cache_key = f"{city_norm}|{target_state}"
            if cache_key in _mapstransler_geocode_cache:
                cached = _mapstransler_geocode_cache[cache_key]
                if cached:
                    coords = cached
                    add_debug_log(f"Cache HIT: {city_norm} -> ({coords[0]}, {coords[1]})", "mapstransler")
                else:
                    add_debug_log(f"Cache HIT (negative): {city_norm} not found previously", "mapstransler")
            
            # PRIORITY 0: Check UKRAINE_SETTLEMENTS_BY_OBLAST first (oblast-aware, BEST for disambiguation)
            if not coords and cache_key not in _mapstransler_geocode_cache:
                city_norm_lower = city_norm.lower()
                # Extract oblast key from target_state (e.g., "Миколаївська область" -> "миколаївська")
                oblast_key = None
                if target_state:
                    oblast_key = target_state.lower().replace(' область', '').replace('область', '').strip()
                
                # Try oblast-aware lookup first
                if oblast_key and (city_norm_lower, oblast_key) in UKRAINE_SETTLEMENTS_BY_OBLAST:
                    coords = UKRAINE_SETTLEMENTS_BY_OBLAST[(city_norm_lower, oblast_key)]
                    _mapstransler_geocode_cache[cache_key] = coords
                    add_debug_log(f"UKRAINE_SETTLEMENTS_BY_OBLAST HIT: ({city_norm}, {oblast_key}) -> ({coords[0]}, {coords[1]})", "mapstransler")
                # Fallback to simple lookup
                elif city_norm_lower in UKRAINE_ALL_SETTLEMENTS:
                    coords = UKRAINE_ALL_SETTLEMENTS[city_norm_lower]
                    _mapstransler_geocode_cache[cache_key] = coords
                    add_debug_log(f"UKRAINE_ALL_SETTLEMENTS HIT: {city_norm} -> ({coords[0]}, {coords[1]})", "mapstransler")
            
            # PRIORITY 0.5: Check CITY_COORDS (legacy, smaller set but has special entries)
            if not coords and cache_key not in _mapstransler_geocode_cache:
                city_norm_lower = city_norm.lower()
                if city_norm_lower in CITY_COORDS:
                    coords = CITY_COORDS[city_norm_lower]
                    _mapstransler_geocode_cache[cache_key] = coords
                    add_debug_log(f"CITY_COORDS HIT: {city_norm} -> ({coords[0]}, {coords[1]})", "mapstransler")
            
            # PRIORITY 1: Nominatim API (best for Ukrainian cities)
            if not coords and target_state and cache_key not in _mapstransler_geocode_cache:
                try:
                    import requests
                    
                    # Build search query with oblast context
                    oblast_name = target_state.replace('область', '').strip()
                    # Use title case for better Nominatim matching
                    city_norm_title = city_norm.title()
                    search_queries = [
                        f"{city_norm_title}, {oblast_name} область, Україна",  # normalized first
                        f"{city_raw}, {oblast_name} область, Україна",
                        f"{city_norm_title}, Ukraine",
                        f"{city_raw}, Ukraine",
                    ]
                    
                    nominatim_url = 'https://nominatim.openstreetmap.org/search'
                    headers = {'User-Agent': 'NeptunAlarm/1.0'}
                    
                    for search_q in search_queries:
                        params = {
                            'q': search_q,
                            'format': 'json',
                            'limit': 5,
                            'addressdetails': 1,
                            'countrycodes': 'ua'
                        }
                        
                        response = requests.get(nominatim_url, params=params, headers=headers, timeout=4)
                        if response.ok:
                            data = response.json()
                            
                            for item in data:
                                item_type = item.get('type', '')
                                item_class = item.get('class', '')
                                display_name = item.get('display_name', '')
                                
                                # Filter: only settlements (village, town, city, hamlet, etc)
                                valid_types = ['village', 'town', 'city', 'hamlet', 'suburb', 'neighbourhood', 'residential', 'administrative']
                                if item_type not in valid_types and item_class != 'place':
                                    continue
                                
                                # Check oblast match in display_name
                                oblast_keywords = [oblast_name.lower(), target_state.lower()]
                                display_lower = display_name.lower()
                                
                                oblast_match = any(kw in display_lower for kw in oblast_keywords)
                                if not oblast_match:
                                    continue
                                
                                lat_val = safe_float(item.get('lat'))
                                lon_val = safe_float(item.get('lon'))
                                
                                if lat_val and lon_val and validate_ukraine_coords(lat_val, lon_val):
                                    coords = (lat_val, lon_val)
                                    add_debug_log(f"Nominatim FOUND: '{search_q}' -> '{display_name[:60]}' ({lat_val}, {lon_val})", "mapstransler")
                                    break
                            
                            if coords:
                                break  # Found, stop searching
                                
                except Exception as e:
                    add_debug_log(f"Nominatim API error: {e}", "mapstransler")
            
            # PRIORITY 2: Photon API as backup
            if not coords and target_state:
                try:
                    import requests
                    
                    name_variants = [city_norm, city_raw.lower()]
                    name_variants = list(dict.fromkeys(name_variants))
                    
                    for search_name in name_variants:
                        photon_url = 'https://photon.komoot.io/api/'
                        params = {'q': search_name, 'limit': 15}
                        
                        response = requests.get(photon_url, params=params, timeout=3)
                        if response.ok:
                            data = response.json()
                            
                            for feature in data.get('features', []):
                                props = feature.get('properties', {})
                                state = props.get('state', '')
                                country = props.get('country', '')
                                osm_key = props.get('osm_key', '')
                                osm_value = props.get('osm_value', '')
                                name_found = props.get('name', '')
                                
                                if osm_key not in ['place', 'boundary']:
                                    continue
                                valid_types = ['city', 'town', 'village', 'hamlet', 'suburb', 'neighbourhood', 'administrative']
                                if osm_key == 'place' and osm_value not in valid_types:
                                    continue
                                
                                if (country == 'Україна' or country == 'Ukraine') and target_state in state:
                                    coords_arr = feature.get('geometry', {}).get('coordinates', [])
                                    if coords_arr and len(coords_arr) >= 2:
                                        lng_val = safe_float(coords_arr[0])
                                        lat_val = safe_float(coords_arr[1])
                                        if lat_val and lng_val and validate_ukraine_coords(lat_val, lng_val):
                                            coords = (lat_val, lng_val)
                                            add_debug_log(f"Photon FOUND: '{search_name}' -> '{name_found}' ({lat_val}, {lng_val})", "mapstransler")
                                            break
                            
                            if coords:
                                break
                                
                except Exception as e:
                    add_debug_log(f"Photon API error: {e}", "mapstransler")
            
            # PRIORITY 3: GeoNames API (free, good coverage of settlements)
            if not coords and target_state:
                try:
                    import requests
                    
                    # GeoNames search - uses username 'demo' or can set GEONAMES_USER env var
                    geonames_user = os.environ.get('GEONAMES_USER', 'demo')
                    geonames_url = 'http://api.geonames.org/searchJSON'
                    
                    city_norm_title = city_norm.title()
                    for search_name in [city_norm_title, city_raw]:
                        params = {
                            'q': search_name,
                            'country': 'UA',
                            'featureClass': 'P',  # populated places only
                            'maxRows': 10,
                            'username': geonames_user
                        }
                        
                        response = requests.get(geonames_url, params=params, timeout=4)
                        if response.ok:
                            data = response.json()
                            oblast_name = target_state.replace('область', '').strip().lower()
                            
                            for place in data.get('geonames', []):
                                admin_name = place.get('adminName1', '').lower()
                                
                                # Check oblast match
                                if oblast_name not in admin_name and target_state.lower() not in admin_name:
                                    continue
                                
                                lat_val = safe_float(place.get('lat'))
                                lng_val = safe_float(place.get('lng'))
                                place_name = place.get('name', '')
                                
                                if lat_val and lng_val and validate_ukraine_coords(lat_val, lng_val):
                                    coords = (lat_val, lng_val)
                                    add_debug_log(f"GeoNames FOUND: '{search_name}' -> '{place_name}' in {admin_name} ({lat_val}, {lng_val})", "mapstransler")
                                    break
                            
                            if coords:
                                break
                                
                except Exception as e:
                    add_debug_log(f"GeoNames API error: {e}", "mapstransler")
            
            # PRIORITY 4: Nominatim with looser search (just city name + Ukraine)
            if not coords:
                try:
                    import requests
                    
                    nominatim_url = 'https://nominatim.openstreetmap.org/search'
                    headers = {'User-Agent': 'NeptunAlarm/1.0'}
                    
                    city_norm_title = city_norm.title()
                    # Looser search without strict oblast matching
                    params = {
                        'q': f"{city_norm_title}",
                        'format': 'json',
                        'limit': 20,
                        'addressdetails': 1,
                        'countrycodes': 'ua'
                    }
                    
                    response = requests.get(nominatim_url, params=params, headers=headers, timeout=4)
                    if response.ok:
                        data = response.json()
                        oblast_name = target_state.replace('область', '').strip().lower() if target_state else ''
                        
                        for item in data:
                            item_type = item.get('type', '')
                            display_name = item.get('display_name', '').lower()
                            
                            valid_types = ['village', 'town', 'city', 'hamlet', 'suburb', 'neighbourhood', 'residential', 'administrative']
                            if item_type not in valid_types:
                                continue
                            
                            # Looser oblast check - also accept if no oblast specified
                            if oblast_name and oblast_name not in display_name:
                                continue
                            
                            lat_val = safe_float(item.get('lat'))
                            lon_val = safe_float(item.get('lon'))
                            
                            if lat_val and lon_val and validate_ukraine_coords(lat_val, lon_val):
                                coords = (lat_val, lon_val)
                                add_debug_log(f"Nominatim LOOSE: '{city_norm_title}' -> '{display_name[:50]}' ({lat_val}, {lon_val})", "mapstransler")
                                break
                                
                except Exception as e:
                    add_debug_log(f"Nominatim loose search error: {e}", "mapstransler")
            
            # PRIORITY 5: OSM Overpass API for small villages (last resort)
            if not coords and target_state:
                try:
                    import requests
                    
                    city_norm_title = city_norm.title()
                    # Overpass query for place nodes with name
                    overpass_url = 'https://overpass-api.de/api/interpreter'
                    query = f'''
                    [out:json][timeout:10];
                    area["name"="Україна"]->.ua;
                    (
                      node["place"~"village|hamlet|town|city"]["name"~"{city_norm_title}",i](area.ua);
                    );
                    out center 5;
                    '''
                    
                    response = requests.post(overpass_url, data={'data': query}, timeout=12)
                    if response.ok:
                        data = response.json()
                        oblast_name = target_state.replace('область', '').strip().lower() if target_state else ''
                        
                        for element in data.get('elements', []):
                            lat_val = safe_float(element.get('lat'))
                            lon_val = safe_float(element.get('lon'))
                            tags = element.get('tags', {})
                            name = tags.get('name', '')
                            
                            if lat_val and lon_val and validate_ukraine_coords(lat_val, lon_val):
                                coords = (lat_val, lon_val)
                                add_debug_log(f"Overpass FOUND: '{city_norm_title}' -> '{name}' ({lat}, {lon})", "mapstransler")
                                break
                                
                except Exception as e:
                    add_debug_log(f"Overpass API error: {e}", "mapstransler")
            
            # Save to cache (both positive and negative results)
            if coords:
                _mapstransler_geocode_cache[cache_key] = coords
                add_debug_log(f"Cache SAVED: {city_norm} -> ({coords[0]}, {coords[1]})", "mapstransler")
            elif cache_key not in _mapstransler_geocode_cache:
                _mapstransler_geocode_cache[cache_key] = None  # Negative cache
                add_debug_log(f"Cache SAVED (negative): {city_norm} not found", "mapstransler")
            
            # NO FALLBACK TO OBLAST CENTER - if not found, skip this city
            if not coords:
                add_debug_log(f"City NOT FOUND after all APIs, skipping: {city_raw} ({oblast_raw})", "mapstransler")
            
            if coords:
                if len(coords) == 3:
                    lat, lon = coords[0], coords[1]
                else:
                    lat, lon = coords[:2]
                
                threat_type, icon = classify(text)
                track = {
                    'id': f"{mid}_mapstransler_{city_norm.replace(' ','_')}",
                    'place': city_raw.title(),
                    'lat': lat, 'lng': lon,
                    'threat_type': threat_type,
                    'text': clean_text(orig)[:500], 'date': date_str, 'channel': channel,
                    'marker_icon': icon, 'source_match': 'mapstransler_format',
                    'count': uav_count
                }
                add_debug_log(f'Mapstransler parser SUCCESS: {city_raw} ({oblast_raw}) -> {coords}, count={uav_count}', "mapstransler")
                return [track]  # Early return
            else:
                add_debug_log(f'Mapstransler parser: No coords for {city_norm} ({oblast_raw})', "mapstransler")
        
        # NEW: Handle emoji-prefixed threat messages like "🛸 Звягель (Житомирська обл.) Загроза застосування БПЛА"
        emoji_threat_pattern = r'^[^\w\s]*\s*([А-ЯІЇЄЁа-яіїєё\'\-\s]+)\s*\([^)]*обл[^)]*\)\s*загроза\s+застосування\s+бпла'
        emoji_match = re.search(emoji_threat_pattern, head, re.IGNORECASE)
        if emoji_match:
            city_from_emoji = emoji_match.group(1).strip()
            if city_from_emoji and 2 <= len(city_from_emoji) <= 40:
                base = city_from_emoji.lower().replace('\u02bc',"'").replace('ʼ',"'").replace("'","'").replace('`',"'")
                base = re.sub(r'\s+',' ', base)
                norm = UA_CITY_NORMALIZE.get(base, base)
                coords = CITY_COORDS.get(norm)
                if not coords and 'SETTLEMENTS_INDEX' in globals():
                    idx_map = globals().get('SETTLEMENTS_INDEX') or {}
                    coords = idx_map.get(norm)
                if coords:
                    lat, lon = coords[:2]
                    threat_type, icon = classify(text)
                    track = {
                        'id': f"{mid}_emoji_threat_{city_from_emoji.replace(' ','_')}",
                        'place': city_from_emoji,
                        'lat': lat, 'lng': lon,
                        'threat_type': threat_type,
                        'text': clean_text(orig)[:500], 'date': date_str, 'channel': channel,
                        'marker_icon': icon, 'source_match': 'emoji_threat'
                    }
                    log.debug(f'Emoji threat parser: {city_from_emoji} -> {coords} -> {icon}')
                    return [track]  # Early return
        
        # NEW: Handle general emoji + city + oblast format with any UAV threat (more flexible pattern)
        general_emoji_pattern = r'^[^\w\s]*\s*([А-ЯІЇЄЁа-яіїєё\'\-\s]+)\s*\([^)]*обл[^)]*\)'
        general_emoji_match = re.search(general_emoji_pattern, head, re.IGNORECASE)
        add_debug_log(f"Testing general emoji pattern on head: {repr(head)}", "emoji_debug")
        add_debug_log(f"General emoji match result: {general_emoji_match}", "emoji_debug")
        
        if general_emoji_match and any(uav_word in text.lower() for uav_word in ['бпла', 'дрон', 'шахед', 'активність', 'загроза']):
            city_from_general = general_emoji_match.group(1).strip()
            
            # Strip UAV-related prefixes from city name (БПЛА, дрон, шахед, etc.)
            uav_prefixes = ['бпла', 'дрон', 'дрони', 'шахед', 'шахеди', 'безпілотник', 'безпілотники', 'ворожий', 'ворожі']
            city_lower = city_from_general.lower()
            for prefix in uav_prefixes:
                if city_lower.startswith(prefix + ' '):
                    city_from_general = city_from_general[len(prefix):].strip()
                    city_lower = city_from_general.lower()
                    add_debug_log(f"Stripped UAV prefix '{prefix}', city now: {repr(city_from_general)}", "emoji_debug")
            
            add_debug_log(f"Found city from general emoji: {repr(city_from_general)}", "emoji_debug")
            
            if city_from_general and 2 <= len(city_from_general) <= 40:
                base = city_from_general.lower().replace('\u02bc',"'").replace('ʼ',"'").replace("'","'").replace('`',"'")
                base = re.sub(r'\s+',' ', base)
                norm = UA_CITY_NORMALIZE.get(base, base)
                coords = CITY_COORDS.get(norm)
                add_debug_log(f"Looking up coordinates: base={repr(base)}, norm={repr(norm)}, coords={coords}", "emoji_debug")
                
                if not coords and 'SETTLEMENTS_INDEX' in globals():
                    idx_map = globals().get('SETTLEMENTS_INDEX') or {}
                    coords = idx_map.get(norm)
                if coords:
                    lat, lon = coords[:2]
                    threat_type, icon = classify(text)
                    track = {
                        'id': f"{mid}_general_emoji_{city_from_general.replace(' ','_')}",
                        'place': city_from_general.title(),
                        'lat': lat, 'lng': lon,
                        'threat_type': threat_type,
                        'text': clean_text(text)[:500], 'date': date_str, 'channel': channel,
                        'marker_icon': icon, 'source_match': 'general_emoji_threat'
                    }
                    add_debug_log(f'EARLY RETURN: General emoji threat parser: {city_from_general} -> {coords} -> {icon}', "emoji_debug")
                    return [track]  # Early return
        
        if '(' in head and ('обл' in head.lower() or 'область' in head.lower()):
            import re as _re_early
            cleaned = head.replace('**','')
            for _zw in ('\u200b','\u200c','\u200d','\ufeff','\u2060','\u00a0'):
                cleaned = cleaned.replace(_zw,' ')
            cleaned = ' '.join(cleaned.split())
            cleaned = _re_early.sub(r'^[^A-Za-zА-Яа-яЇїІіЄєҐґ]+','', cleaned)
            # NEW: if pipe '|' separates multiple city headers in one line, attempt multi-city extraction here
            if '|' in cleaned:
                parts = [p.strip() for p in cleaned.split('|') if p.strip()]
                multi_tracks = []
                for idx, part in enumerate(parts, start=1):
                    if '(' not in part:
                        continue
                    par_pos = part.find('(')
                    if par_pos <= 1:
                        continue
                    city_candidate = part[:par_pos].strip()
                    if not (2 <= len(city_candidate) <= 40):
                        continue
                    try:
                        base = city_candidate.lower().replace('\u02bc',"'").replace('ʼ',"'").replace('’',"'").replace('`',"'")
                        base = _re_early.sub(r'\s+',' ', base)
                        norm = UA_CITY_NORMALIZE.get(base, base)
                        coords = CITY_COORDS.get(norm)
                        if not coords and 'SETTLEMENTS_INDEX' in globals():
                            idx_map = globals().get('SETTLEMENTS_INDEX') or {}
                            coords = idx_map.get(norm)
                        approx_flag = False
                        if not coords:
                            enriched = ensure_city_coords(norm)
                            if enriched:
                                if isinstance(enriched, tuple) and len(enriched) == 3:
                                    coords = (enriched[0], enriched[1])
                                    approx_flag = enriched[2]
                                else:
                                    coords = enriched
                        if not coords:
                            continue
                        # classification per segment
                        lseg = part.lower()
                        if any(ph in lseg for ph in ['повідомляють про вибух','повідомлено про вибух','зафіксовано вибух','зафіксовано вибухи','фіксація вибух','фіксують вибух',' вибух.',' вибухи.']):
                            threat, icon = 'vibuh','vibuh.png'
                        elif 'відбій загрози обстр' in lseg or 'відбій загрози застосування' in lseg or 'відбій загрози бпла' in lseg:
                            # treat as list-only cancellation fragment -> skip map marker for this part
                            multi_tracks.append({
                                'id': f"{mid}_p{idx}", 'text': part[:500], 'date': date_str, 'channel': channel,
                                'list_only': True, 'threat_type': 'alarm_cancel', 'place': city_candidate.title()
                            })
                            continue
                        elif 'загроза застосування бпла' in lseg or 'загроза застосування безпілот' in lseg:
                            threat, icon = 'shahed','icon_drone.svg'
                        elif 'загроза обстрілу' in lseg or 'загроза обстрела' in lseg:
                            threat, icon = 'artillery','obstril.png'
                        else:
                            threat, icon = classify(part)
                        lat, lng = coords
                        track = {
                            'id': f"{mid}_p{idx}", 'place': city_candidate.title(), 'lat': lat, 'lng': lng,
                            'threat_type': threat, 'text': part[:500], 'date': date_str, 'channel': channel,
                            'marker_icon': icon, 'source_match': 'multi_city_pipe'
                        }
                        if approx_flag:
                            track['approx'] = True
                        multi_tracks.append(track)
                    except Exception:
                        continue
                # Return only if 2+ actual geo tracks (ignore if we only produced one, fall back to single-city logic)
                geo_count = sum(1 for t in multi_tracks if not t.get('list_only'))
                if geo_count >= 2:
                    return multi_tracks
            par = cleaned.find('(')
            if par > 1:
                city_candidate = cleaned[:par].strip()
                
                # CRITICAL FIX: Remove BPLA/count prefixes that should NOT be part of city name
                # Examples: "БПЛА Васильків" -> "Васильків", "2х БПЛА Ніжин" -> "Ніжин"
                city_candidate = _re_early.sub(r'^[^а-яіїєґА-ЯІЇЄҐ]*(\d+[xхX×]?\s*)?БПЛА\s+', '', city_candidate, flags=_re_early.IGNORECASE)
                city_candidate = _re_early.sub(r'^[^а-яіїєґА-ЯІЇЄҐ]*(\d+[xхX×]?\s*)?бпла\s+', '', city_candidate, flags=_re_early.IGNORECASE)
                # Also remove "біля" prefix (e.g., "біля Нового Буга" -> "Нового Буга")
                city_candidate = _re_early.sub(r'^біля\s+', '', city_candidate, flags=_re_early.IGNORECASE)
                # Remove "/груп транзитом" and similar routing noise
                city_candidate = _re_early.sub(r'^/\s*груп\s+транзитом\s+', '', city_candidate, flags=_re_early.IGNORECASE)
                city_candidate = city_candidate.strip()
                
                if 2 <= len(city_candidate) <= 40:
                    base = city_candidate.lower().replace('\u02bc',"'").replace('ʼ',"'").replace('’',"'").replace('`',"'")
                    base = _re_early.sub(r'\s+',' ', base)
                    norm = UA_CITY_NORMALIZE.get(base, base)
                    
                    # CRITICAL: Extract oblast from parentheses for oblast-aware lookup
                    # Format: "City (Oblast обл.)" - extract oblast to disambiguate same-name cities
                    coords = None
                    oblast_key_early = None
                    par_end = cleaned.find(')', par)
                    if par_end > par:
                        oblast_raw_early = cleaned[par+1:par_end].strip()
                        # Extract oblast key: "Миколаївська обл." -> "миколаївська"
                        oblast_lower_early = oblast_raw_early.lower()
                        if ' обл' in oblast_lower_early:
                            oblast_key_early = oblast_lower_early.split(' обл')[0].strip()
                        elif 'область' in oblast_lower_early:
                            oblast_key_early = oblast_lower_early.replace('область', '').strip()
                        
                        # PRIORITY 0: Oblast-aware lookup in UKRAINE_SETTLEMENTS_BY_OBLAST
                        if oblast_key_early and 'UKRAINE_SETTLEMENTS_BY_OBLAST' in globals():
                            settlements_by_oblast = globals().get('UKRAINE_SETTLEMENTS_BY_OBLAST') or {}
                            lookup_key_early = (norm, oblast_key_early)
                            if lookup_key_early in settlements_by_oblast:
                                coords = settlements_by_oblast[lookup_key_early]
                                _log(f"[single_city_simple_early] OBLAST-AWARE HIT: {lookup_key_early} -> {coords}")
                    
                    # Fallback to simple lookup if oblast-aware failed
                    if not coords:
                        coords = CITY_COORDS.get(norm)
                    if not coords and 'SETTLEMENTS_INDEX' in globals():
                        idx = globals().get('SETTLEMENTS_INDEX') or {}
                        coords = idx.get(norm)
                    approx_flag = False
                    if not coords:
                        enriched = ensure_city_coords_with_message_context(norm, orig)
                        if enriched:
                            if isinstance(enriched, tuple) and len(enriched) == 3:
                                coords = (enriched[0], enriched[1])
                                approx_flag = enriched[2]
                            else:
                                coords = enriched
                    if coords:
                        l = orig.lower()
                        if any(ph in l for ph in ['повідомляють про вибух','повідомлено про вибух','зафіксовано вибух','зафіксовано вибухи','фіксація вибух','фіксують вибух',' вибух.',' вибухи.']):
                            threat, icon = 'vibuh','vibuh.png'
                        elif 'відбій загрози обстр' in l or 'відбій загрози застосування' in l or 'відбій загрози бпла' in l:
                            # Treat city-level cancellation as list event, not a geo marker
                            return [{
                                'id': str(mid), 'text': orig[:500], 'date': date_str, 'channel': channel,
                                'list_only': True, 'threat_type': 'alarm_cancel', 'place': city_candidate.title()
                            }]
                        elif 'загроза застосування бпла' in l or 'загроза застосування безпілот' in l:
                            threat, icon = 'shahed','icon_drone.svg'
                        elif 'загроза обстрілу' in l or 'загроза обстрела' in l:
                            threat, icon = 'artillery','obstril.png'
                        else:
                            threat, icon = classify(orig)
                        lat,lng = coords
                        track = {
                            'id': str(mid), 'place': city_candidate.title(), 'lat': lat, 'lng': lng,
                            'threat_type': threat, 'text': orig[:500], 'date': date_str, 'channel': channel,
                            'marker_icon': icon, 'source_match': 'single_city_simple_early'
                        }
                        if approx_flag:
                            track['approx'] = True
                        return [track]
    except Exception:
        pass

    
    # Directional multi-region (e.g. "група БпЛА на Донеччині курсом на Дніпропетровщину") -> list-only, no fixed marker
    try:
        lorig = text.lower()
        # Skip if this message has route patterns (handled by route parser above)
        if 'через' in lorig or 'повз' in lorig:
            pass
        elif (('курс' in lorig or '➡' in lorig or '→' in lorig or 'напрям' in lorig) and ('бпла' in lorig or 'дрон' in lorig or 'груп' in lorig)) or ('бпла' in lorig and 'частин' in lorig) or ('дрон' in lorig and 'частин' in lorig):
            # Special case: BPLA current location with directional info
            # e.g., "БпЛА в північно-західній частині Полтавщини, курсом на Київщину"
            # or "БпЛА в південно-східній частині Харківщини"
            import re as _re_loc
            
            # Look for current location patterns
            location_match = _re_loc.search(r'(?:бпла|дрон[иа]?)\s+(?:в|на|над)\s+([а-яіїєґ\-\s]+(?:частин[іа]|район[іе]|округ[уі])\s+[а-яіїєґ]+щин[иаю])', lorig)
            if location_match:
                current_location = location_match.group(1).strip()
                print(f"DEBUG: Found current BPLA location: {current_location}")
                
                # Extract region from current location
                region_in_location = None
                for reg_key in OBLAST_CENTERS.keys():
                    if reg_key in current_location:
                        region_in_location = reg_key
                        break
                
                if region_in_location:
                    # Get region center and apply directional offset
                    region_coords = OBLAST_CENTERS.get(region_in_location, (50.0, 30.0))
                    
                    # Apply directional offset based on specified part of region
                    offset_lat, offset_lon = 0, 0
                    if 'північно-західн' in current_location:
                        offset_lat, offset_lon = 0.8, -0.8  # Northwest
                    elif 'північно-східн' in current_location:
                        offset_lat, offset_lon = 0.8, 0.8   # Northeast
                    elif 'південно-західн' in current_location:
                        offset_lat, offset_lon = -0.8, -0.8 # Southwest
                    elif 'південно-східн' in current_location:
                        offset_lat, offset_lon = -0.8, 0.8  # Southeast
                    elif 'північн' in current_location:
                        offset_lat, offset_lon = 0.8, 0     # North
                    elif 'південн' in current_location:
                        offset_lat, offset_lon = -0.8, 0    # South
                    elif 'західн' in current_location:
                        offset_lat, offset_lon = 0, -0.8    # West
                    elif 'східн' in current_location:
                        offset_lat, offset_lon = 0, 0.8     # East
                    elif 'центральн' in current_location:
                        offset_lat, offset_lon = 0, 0       # Center
                    
                    final_lat = region_coords[0] + offset_lat
                    final_lon = region_coords[1] + offset_lon
                    
                    # Clean up city name for display
                    region_name = region_in_location.replace('щини', 'щина').replace('щину', 'щина')
                    direction_part = ""
                    if 'північно-західн' in current_location:
                        direction_part = "Пн-Зх "
                    elif 'північно-східн' in current_location:
                        direction_part = "Пн-Сх "
                    elif 'південно-західн' in current_location:
                        direction_part = "Пд-Зх "
                    elif 'південно-східн' in current_location:
                        direction_part = "Пд-Сх "
                    elif 'північн' in current_location:
                        direction_part = "Пн "
                    elif 'південн' in current_location:
                        direction_part = "Пд "
                    elif 'західн' in current_location:
                        direction_part = "Зх "
                    elif 'східн' in current_location:
                        direction_part = "Сх "
                    elif 'центральн' in current_location:
                        direction_part = "Центр "
                    
                    display_name = f"{direction_part}{region_name.title()}"
                    
                    print(f"DEBUG: Location '{current_location}' in {region_in_location} -> ({final_lat}, {final_lon})")
                    
                    return [{
                        'id': str(mid), 'text': clean_text(text)[:600], 'date': date_str, 'channel': channel,
                        'lat': final_lat, 'lon': final_lon, 'city': display_name,
                        'source_match': 'trajectory_current_location'
                    }]
            
            # Quick reject if explicit single settlement in parentheses (handled elsewhere)
            if '(' not in lorig:
                present_regions = []
                for reg_key in OBLAST_CENTERS.keys():
                    if reg_key in lorig:
                        present_regions.append(reg_key)
                        if len(present_regions) >= 4:
                            break
                distinct = {r.split()[0] for r in present_regions}
                # Accept patterns like "нова група ударних БпЛА на Донеччині курсом на Дніпропетровщину"
                # even if only 2 region stems present
                if len(distinct) >= 2:
                    # Check if message contains specific cities that should create markers instead
                    city_keywords = ['на кролевец', 'на конотоп', 'на чернігів', 'на вишгород', 'на петрівці', 'на велика димерка', 'на білу церкву', 'на бровари', 'на суми', 'на харків', 'на дніпро', 'на кропивницький', 'на житомир', 'на миколаївку', 'на липовець', 'на ріпки', 'на терни', 'на павлоград']
                    has_specific_cities = any(city_kw in lorig for city_kw in city_keywords)
                    
                    # Also check for pattern "БпЛА на [city]" which should create markers
                    import re as _re_cities
                    bpla_na_pattern = _re_cities.findall(r'бпла\s+на\s+([a-zа-яіїєґʼ`\-\s]{3,20})', lorig)
                    if bpla_na_pattern:
                        has_specific_cities = True
                    
                    if has_specific_cities:
                        # Let multi-city parser handle this instead
                        pass
                    else:
                        # Extra guard: if a well-known large city (e.g. дніпро, харків, київ) appears ONLY because it's substring of region
                        # we still treat as region directional, not city marker
                        # But if message contains multiple explicit directional part-of-region clauses ("на сході <області>" ... "на сході <області>")
                        # then we want to produce separate segment markers instead of a single list-only event.
                        import re as _re_dd
                        dir_clause_count = len(_re_dd.findall(r'на\s+(?:північ|півден|схід|заход|північно|південно)[^\.]{0,40}?(?:щина|щини|щину)', lorig))
                        if dir_clause_count < 2:
                            return [{
                                'id': str(mid), 'text': clean_text(text)[:600], 'date': date_str, 'channel': channel,
                                'list_only': True, 'source_match': 'region_direction_multi'
                            }]
    except Exception:
        pass
    # Comparative directional relative to a city ("північніше Городні", "східніше Кролевця") -> use base city location
    try:
        import re as _re_rel
        low_txt = text.lower()
        # NEW: pattern "<city> - до вас БпЛА" -> marker at city
        m_dash = _re_rel.search(r"([a-zа-яіїєґ'ʼ’`\-]{3,40})\s*[-–—]\s*до вас\s+бпла", low_txt)
        if m_dash:
            raw_city = m_dash.group(1)
            raw_city = raw_city.replace('\u02bc',"'").replace('ʼ',"'").replace('’',"'").replace('`',"'")
            base = UA_CITY_NORMALIZE.get(raw_city, raw_city)
            coords = CITY_COORDS.get(base)
            if not coords and 'SETTLEMENTS_INDEX' in globals():
                coords = (globals().get('SETTLEMENTS_INDEX') or {}).get(base)
            if coords:
                lat,lng = coords
                threat, icon = 'shahed','icon_drone.svg'
                return [{
                    'id': str(mid), 'place': base.title(), 'lat': lat, 'lng': lng,
                    'threat_type': threat, 'text': clean_text(text)[:500], 'date': date_str, 'channel': channel,
                    'marker_icon': icon, 'source_match': 'city_dash_uav'
                }]
        # NEW: pattern "БпЛА на <city>" or "бпла на <city>" -> marker at city
        uav_city_pattern = _re_rel.compile(r"бпла\s+на\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ\`\s/]+?)(?=\s+(?:з|на|до|від|через|повз|курсом|напрям)\s|[,\.\!\?;:\n]|$)")
        uav_cities = list(uav_city_pattern.finditer(low_txt))
        if uav_cities:
            threats = []
            for idx, match in enumerate(uav_cities):
                rc = match.group(1)
                # If the message continues with course wording immediately after this fragment,
                # treat it as a transit description (let region-course logic handle it)
                tail = low_txt[match.end():match.end()+80]
                if 'курс' in tail:
                    continue
                rc = rc.replace('\u02bc',"'").replace('ʼ',"'").replace("'","'").replace('`',"'")
                
                # Handle cities separated by slash (e.g., "вишгород/петрівці")
                cities_to_process = []
                if '/' in rc:
                    cities_to_process.extend(rc.split('/'))
                else:
                    cities_to_process.append(rc)
                
                for city_idx, city in enumerate(cities_to_process):
                    city = city.strip()
                    if not city:
                        continue
                        
                    base = UA_CITY_NORMALIZE.get(city, city)
                    
                    # Special handling for Kyiv - show directional approach instead of center point
                    if base.lower() == 'київ':
                        kyiv_lat, kyiv_lng, kyiv_label, direction_info = get_kyiv_directional_coordinates(text, base)
                        threat_type, icon = classify(text)
                        
                        # Use specialized icon for directional Kyiv threats
                        if direction_info:
                            icon = 'icon_drone.svg'  # Could create special directional icon later
                            
                        threats.append({
                            'id': f"{mid}_uav_{idx}_{city_idx}_kyiv_dir", 'place': kyiv_label, 'lat': kyiv_lat, 'lng': kyiv_lng,
                            'threat_type': threat_type, 'text': clean_text(text)[:500], 'date': date_str, 'channel': channel,
                            'marker_icon': icon, 'source_match': 'uav_on_city_kyiv_directional',
                            'direction_info': direction_info
                        })
                        continue
                    
                    coords = CITY_COORDS.get(base)
                    if not coords and 'SETTLEMENTS_INDEX' in globals():
                        coords = (globals().get('SETTLEMENTS_INDEX') or {}).get(base)
                    if coords:
                        lat,lng = coords
                        threats.append({
                            'id': f"{mid}_uav_{idx}_{city_idx}", 'place': base.title(), 'lat': lat, 'lng': lng,
                            'threat_type': 'shahed', 'text': clean_text(text)[:500], 'date': date_str, 'channel': channel,
                            'marker_icon': 'icon_drone.svg', 'source_match': 'uav_on_city'
                        })
            if threats:
                return threats
        # pattern captures direction word + city morph form
        m_rel = _re_rel.search(r'(північніше|південніше|східніше|західніше)\s+([a-zа-яіїєґ\'ʼ’`\-]{3,40})', low_txt)
        if m_rel:
            raw_city = m_rel.group(2)
            # normalize apostrophes
            raw_city = raw_city.replace('\u02bc',"'").replace('ʼ',"'").replace('’',"'").replace('`',"'")
            base = UA_CITY_NORMALIZE.get(raw_city, raw_city)
            coords = CITY_COORDS.get(base)
            if not coords and 'SETTLEMENTS_INDEX' in globals():
                idx = globals().get('SETTLEMENTS_INDEX') or {}
                coords = idx.get(base)
            if not coords:
                enriched = ensure_city_coords(base)
                if enriched:
                    if isinstance(enriched, tuple) and len(enriched)==3:
                        coords = (enriched[0], enriched[1])
                    else:
                        coords = enriched
            if coords:
                lat,lng = coords
                threat_type, icon = classify(text)
                return [{
                    'id': str(mid), 'place': base.title(), 'lat': lat, 'lng': lng,
                    'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
                    'marker_icon': icon, 'source_match': 'relative_direction_city'
                }]
    except Exception:
        pass
    # Multi-segment UAV messages with pipe separator (e.g., "БпЛА курсом на Кагарлик | 2х БпЛА Білоцерківський район | 3х БпЛА Вишеньки / Українка")
    try:
        if '|' in text and 'бпла' in text.lower():
            segments = [seg.strip() for seg in text.split('|') if seg.strip()]
            if len(segments) >= 2:  # At least 2 segments
                threats = []
                import re as _re_multi
                
                for seg_idx, segment in enumerate(segments):
                    seg_lower = segment.lower()
                    if 'бпла' not in seg_lower:
                        continue
                    
                    # Pattern 1: "БпЛА курсом на [city]" (with optional н.п. prefix)
                    course_match = _re_multi.search(r'бпла\s+курсом?\s+на\s+(?:н\.п\.?\s*)?([а-яіїєґ\'\-\s]+?)(?:\s*$|\s*\|)', seg_lower)
                    if course_match:
                        city_name = course_match.group(1).strip()
                        city_norm = clean_text(city_name).lower()
                        
                        # Accusative case normalization (винительный падеж)
                        if city_norm == 'велику димерку':
                            city_norm = 'велика димерка'
                        elif city_norm == 'мену':
                            city_norm = 'мена'
                        elif city_norm == 'пісківку':
                            city_norm = 'пісківка'
                        elif city_norm == 'києвом':
                            city_norm = 'київ'
                        # General accusative case endings
                        elif city_norm.endswith('у') and len(city_norm) > 3:
                            city_norm = city_norm[:-1] + 'а'
                        elif city_norm.endswith('ю') and len(city_norm) > 3:
                            city_norm = city_norm[:-1] + 'я'
                        elif city_norm.endswith('ку') and len(city_norm) > 4:
                            city_norm = city_norm[:-2] + 'ка'
                        
                        if city_norm in UA_CITY_NORMALIZE:
                            city_norm = UA_CITY_NORMALIZE[city_norm]
                        
                        coords = ensure_city_coords_with_message_context(city_norm, text)
                        
                        if coords and isinstance(coords, tuple) and len(coords) >= 2:
                            lat, lng = coords[0], coords[1]
                            threat_type, icon = classify(text)
                            # Use normalized city name for display, not the original accusative form
                            display_name = city_norm.title()
                            threats.append({
                                'id': f"{mid}_multi_{seg_idx}",
                                'place': display_name,
                                'lat': lat,
                                'lng': lng,
                                'threat_type': threat_type,
                                'text': f"Курсом на {display_name}",
                                'date': date_str,
                                'channel': channel,
                                'marker_icon': icon,
                                'source_match': 'multi_segment_course',
                                'count': 1
                            })
                    
                    # Pattern 1.5: "БпЛА повз [city1] курсом на [city2]" - extract both cities  
                    povz_match = _re_multi.search(r'(\d+(?:-\d+)?)?[xх×]?\s*бпла\s+повз\s+([а-яіїєґ\'\-\s]+?)\s+курсом?\s+на\s+([а-яіїєґ\'\-\s]+?)(?:\s*$|\s*\|)', seg_lower)
                    if povz_match and not course_match:  # Don't double-process if already handled by Pattern 1
                        count_str, city1_name, city2_name = povz_match.groups()
                        count = int(count_str) if count_str and count_str.isdigit() else 1
                        
                        for city_idx, city_raw in enumerate([city1_name, city2_name]):
                            if not city_raw:
                                continue
                                
                            city_name = city_raw.strip()
                            city_norm = clean_text(city_name).lower()
                            
                            # Accusative case normalization for both cities
                            if city_norm == 'велику димерку':
                                city_norm = 'велика димерка'
                            elif city_norm == 'мену':
                                city_norm = 'мена'
                            elif city_norm == 'пісківку':
                                city_norm = 'пісківка'
                            elif city_norm == 'києвом':
                                city_norm = 'київ'
                            # General accusative case endings
                            elif city_norm.endswith('у') and len(city_norm) > 3:
                                city_norm = city_norm[:-1] + 'а'
                            elif city_norm.endswith('ю') and len(city_norm) > 3:
                                city_norm = city_norm[:-1] + 'я'
                            elif city_norm.endswith('ку') and len(city_norm) > 4:
                                city_norm = city_norm[:-2] + 'ка'
                            
                            if city_norm in UA_CITY_NORMALIZE:
                                city_norm = UA_CITY_NORMALIZE[city_norm]
                            
                            coords = ensure_city_coords(city_norm)
                            
                            if coords and isinstance(coords, tuple) and len(coords) >= 2:
                                lat, lng = coords[0], coords[1]
                                threat_type, icon = classify(text)
                                action = "Повз" if city_idx == 0 else "Курсом на"
                                # Use normalized city name for display
                                display_name = city_norm.title()
                                threats.append({
                                    'id': f"{mid}_multi_{seg_idx}_povz_{city_idx}",
                                    'place': display_name,
                                    'lat': lat,
                                    'lng': lng,
                                    'threat_type': threat_type,
                                    'text': f"{action} {display_name} ({count}x)",
                                    'date': date_str,
                                    'channel': channel,
                                    'marker_icon': icon,
                                    'source_match': 'multi_segment_povz',
                                    'count': count
                                })
                    
                    # Pattern 2: "[N]х БпЛА [location]" - extract cities
                    location_match = _re_multi.search(r'(\d+(?:-\d+)?)?[xх×]?\s*бпла\s+(.+?)(?:\.|$)', seg_lower)
                    if location_match and not course_match:  # Don't double-process course segments
                        count_str = location_match.group(1) or "1"
                        location_text = location_match.group(2).strip()
                        count = int(count_str) if count_str.isdigit() else 1
                        
                        # Split by common separators to get individual cities
                        cities = []
                        for sep in [' / ', ' та ', ' і ', ', ']:
                            if sep in location_text:
                                cities = [c.strip() for c in location_text.split(sep) if c.strip()]
                                break
                        if not cities:
                            cities = [location_text]
                        
                        for city_idx, city in enumerate(cities):
                            city = city.strip()
                            if not city:
                                continue
                            
                            # Handle district references (e.g., "Білоцерківський район")
                            if 'район' in city:
                                # Extract district name and try to find main city
                                district_name = city.replace('район', '').replace('ський', '').replace('цький', '').strip()
                                
                                # Special case mappings
                                if 'білоцерків' in district_name:
                                    district_name = 'біла церква'
                                
                                if district_name:
                                    city = district_name
                                else:
                                    continue
                                
                            city_norm = clean_text(city).lower()
                            if city_norm in UA_CITY_NORMALIZE:
                                city_norm = UA_CITY_NORMALIZE[city_norm]
                            
                            coords = ensure_city_coords(city_norm)
                            
                            if coords and isinstance(coords, tuple) and len(coords) >= 2:
                                lat, lng = coords[0], coords[1]
                                threat_type, icon = classify(text)
                                threats.append({
                                    'id': f"{mid}_multi_{seg_idx}_{city_idx}",
                                    'place': city.title(),
                                    'lat': lat,
                                    'lng': lng,
                                    'threat_type': threat_type,
                                    'text': f"{count}х БпЛА на {city.title()}",
                                    'date': date_str,
                                    'channel': channel,
                                    'marker_icon': icon,
                                    'source_match': f'multi_segment_location_{count}x',
                                    'count': count
                                })
                
                if threats:
                    # ALSO: Extract cities from emoji structure in the same text 
                    # Pattern for "| 🛸 Город (Область)"
                    emoji_pattern = r'\|\s*🛸\s*([А-ЯІЇЄЁа-яіїєё\'\-\s]+?)\s*\([^)]*обл[^)]*\)'
                    emoji_matches = re.finditer(emoji_pattern, text, re.IGNORECASE)
                    
                    for match in emoji_matches:
                        city_raw = match.group(1).strip()
                        if not city_raw or len(city_raw) < 2:
                            continue
                            
                        city_norm = clean_text(city_raw).lower()
                        if city_norm in UA_CITY_NORMALIZE:
                            city_norm = UA_CITY_NORMALIZE[city_norm]
                        
                        coords = ensure_city_coords(city_norm)
                        
                        if coords:
                            lat, lng = coords[:2]
                            threat_type, icon = classify(text)
                            
                            threat_id = f"{mid}_emoji_struct_{len(threats)}"
                            threats.append({
                                'id': threat_id,
                                'place': city_raw.title(),
                                'lat': lat,
                                'lng': lng,
                                'threat_type': threat_type,
                                'text': f"Загроза в {city_raw}",
                                'date': date_str,
                                'channel': channel,
                                'marker_icon': icon,
                                'source_match': 'emoji_structure_multi',
                                'count': 1
                            })
                            
                            add_debug_log(f"Multi emoji structure: {city_raw} -> {coords}", "emoji_struct_multi")
                        else:
                            add_debug_log(f"Multi emoji structure: No coords for {city_raw}", "emoji_struct_multi")
                    
                    # Check for priority result to combine
                    if '_current_priority_result' in globals() and globals()['_current_priority_result']:
                        combined_result = globals()['_current_priority_result'] + threats
                        add_debug_log(f"MULTI-SEGMENT: Combined priority result ({len(globals()['_current_priority_result'])}) with threats ({len(threats)}) = {len(combined_result)} total", "priority_combine")
                        # Clear the global priority result after use
                        globals()['_current_priority_result'] = None
                        return combined_result
                    return threats
                    
    except Exception:
        pass
    
    # Course towards single city ("курс(ом) на Батурин") -> place marker at that city
    try:
        import re as _re_course
        low_txt2 = text.lower()
        m_course = _re_course.search(r"курс(?:ом)?\s+на\s+([a-zа-яіїєґ\'ʼ'`\-\s]{3,60})(?=\s*(?:$|[,\.\!\?;]|\n))", low_txt2)
        if m_course:
            raw_city = m_course.group(1).strip()
            raw_city = raw_city.replace('\u02bc',"'").replace('ʼ',"'").replace('’',"'").replace('`',"'")
            base = UA_CITY_NORMALIZE.get(raw_city, raw_city)
            
            # Use enhanced coordinate lookup with Nominatim fallback
            coords = get_coordinates_enhanced(base, context="БпЛА курсом на")
            
            if not coords:
                # Legacy fallback for backwards compatibility
                enriched = ensure_city_coords(base)
                if enriched:
                    if isinstance(enriched, tuple) and len(enriched)==3:
                        coords = (enriched[0], enriched[1])
                    else:
                        coords = enriched
                    if isinstance(enriched, tuple) and len(enriched)==3:
                        coords = (enriched[0], enriched[1])
                    else:
                        coords = enriched
            if coords:
                lat,lng = coords
                threat_type, icon = classify(text)
                
                # Extract course information for Shahed threats
                course_info = None
                if threat_type == 'shahed':
                    course_info = extract_shahed_course_info(text)
                
                # Extract count from text (look for pattern like "10х БпЛА")
                uav_count = 1
                import re as _re_count
                count_match = _re_count.search(r'(\d+)\s*[xх×]\s*бпла', low_txt2)
                if count_match:
                    uav_count = int(count_match.group(1))
                
                # Create multiple tracks for multiple drones
                tracks_to_create = max(1, uav_count)
                threat_tracks = []
                
                for i in range(tracks_to_create):
                    track_name = base.title()
                    if tracks_to_create > 1:
                        track_name += f" #{i+1}"
                    
                    # Add small coordinate offsets to prevent marker overlap
                    marker_lat = lat
                    marker_lng = lng
                    if tracks_to_create > 1:
                        # Create a chain pattern - drones one after another
                        offset_distance = 0.03  # ~3km offset between each drone
                        marker_lat += offset_distance * i
                        marker_lng += offset_distance * i * 0.5
                    
                    threat_data = {
                        'id': f"{mid}_{i+1}", 'place': track_name, 'lat': marker_lat, 'lng': marker_lng,
                        'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
                        'marker_icon': icon, 'source_match': 'course_to_city', 'count': 1
                    }
                    
                    # Add course information if available
                    if course_info:
                        threat_data.update({
                            'course_source': course_info.get('source_city'),
                            'course_target': course_info.get('target_city'),
                            'course_direction': course_info.get('course_direction'),
                            'course_type': course_info.get('course_type')
                        })
                    
                    threat_tracks.append(threat_data)
                
                return threat_tracks
    except Exception:
        pass
    
    # --- PRIORITY: Early explicit pattern for districts - MOVED UP TO AVOID CONFLICTS ---
    # Check before region direction processing to prevent fallback to oblast centers
    try:
        import re as _re_raion
        # Pattern 1: "<RaionName> район (<Oblast ...>)"
        m_raion_oblast = _re_raion.search(r'([A-Za-zА-Яа-яЇїІіЄєҐґ\'\-]{4,})\s+район\s*\(([^)]*обл[^)]*)\)', text)
        if m_raion_oblast:
            raion_token = m_raion_oblast.group(1).strip().lower()
            # Normalize morphological endings
            raion_base = _re_raion.sub(r'(ському|ского|ського|ский|ськiй|ськой|ським|ском)$', 'ський', raion_token)
            if raion_base in RAION_FALLBACK:
                lat, lng = RAION_FALLBACK[raion_base]
                threat_type, icon = classify(text)
                add_debug_log(f"PRIORITY: Early district processing - {raion_base} район -> {lat}, {lng}", "district_early")
                return [{
                    'id': str(mid), 'place': f"{raion_base.title()} район", 'lat': lat, 'lng': lng,
                    'threat_type': threat_type, 'text': text[:500],
                    'date': date_str, 'channel': channel, 'marker_icon': icon, 'source_match': 'raion_oblast_combo_early'
                }]
            else:
                add_debug_log(f"Early district processing - {raion_base} not found in RAION_FALLBACK", "district_early")

        # Pattern 2: "<RaionName> район <OblastName>" (без дужок)
        m_raion_oblast2 = _re_raion.search(r'([A-Za-zА-Яа-яЇїІіЄєҐґ\'\-]{4,})\s+район\s+([\w\']+(?:щини|щину|области|області))', text)
        if m_raion_oblast2:
            raion_token = m_raion_oblast2.group(1).strip().lower()
            # Normalize morphological endings
            raion_base = _re_raion.sub(r'(ському|ского|ського|ский|ськiй|ськой|ським|ском)$', 'ський', raion_token)
            if raion_base in RAION_FALLBACK:
                lat, lng = RAION_FALLBACK[raion_base]
                threat_type, icon = classify(text)
                add_debug_log(f"PRIORITY: Early district processing (format 2) - {raion_base} район -> {lat}, {lng}", "district_early")
                return [{
                    'id': str(mid), 'place': f"{raion_base.title()} район", 'lat': lat, 'lng': lng,
                    'threat_type': threat_type, 'text': text[:500],
                    'date': date_str, 'channel': channel, 'marker_icon': icon, 'source_match': 'raion_oblast_combo_early_v2'
                }]
            else:
                add_debug_log(f"Early district processing (format 2) - {raion_base} not found in RAION_FALLBACK", "district_early")
    except Exception as e:
        add_debug_log(f"Early district processing error: {e}", "district_early")
    
    # Region directional segments specifying part of oblast ("на сході Дніпропетровщини") possibly multiple in one line
    try:
        import re as _re_seg
        lower_full = text.lower()
        pattern = _re_seg.compile(r'на\s+([\w\-\s/]+?)\s+(?:частині\s+)?([a-zа-яіїєґ]+щина|[a-zа-яіїєґ]+щини|[a-zа-яіїєґ]+щину)')
        seg_matches = list(pattern.finditer(lower_full))
        seg_tracks = []
        used_spans = []
        if seg_matches:
            # Map Ukrainian directional forms to codes
            dir_map_words = {
                'північ':'n','південь':'s','схід':'e','захід':'w','сході':'e','заході':'w','півночі':'n','півдні':'s',
                'північно-схід':'ne','північно-сход':'ne','північно схід':'ne','південно-схід':'se','південно схід':'se',
                'північно-захід':'nw','північно захід':'nw','південно-захід':'sw','південно захід':'sw'
            }
            def direction_codes(raw:str):
                parts = [p.strip() for p in raw.replace('–','-').split('/') if p.strip()]
                out = []
                for p in parts:
                    # compress multiple spaces
                    p2 = ' '.join(p.split())
                    # find best match in dir_map_words by prefix
                    code=None
                    for k,v in dir_map_words.items():
                        if k in p2:
                            code=v; break
                    if not code:
                        # try simple endings
                        if p2.startswith('схід'): code='e'
                        elif p2.startswith('захід'): code='w'
                    if code and code not in out:
                        out.append(code)
                return out or ['center']
            for m in seg_matches:
                dir_raw = m.group(1).strip()
                region_raw = m.group(2).strip()
                # Normalize region key to match OBLAST_CENTERS keys
                region_key = None
                for k in OBLAST_CENTERS.keys():
                    if region_raw in k:
                        region_key = k
                        break
                if not region_key:
                    continue
                base_lat, base_lng = OBLAST_CENTERS[region_key]
                codes = direction_codes(dir_raw)
                for idx, code in enumerate(codes,1):
                    # offset placement (reuse logic similar to later region_direction block)
                    def offset(lat,lng,code):
                        lat_step = 0.55
                        lng_step = 0.85 / max(0.2, abs(math.cos(math.radians(lat))))
                        if code=='n': return lat+lat_step, lng
                        if code=='s': return lat-lat_step, lng
                        if code=='e': return lat, lng+lng_step
                        if code=='w': return lat, lng-lng_step
                        lat_diag=lat_step*0.8; lng_diag=lng_step*0.8
                        if code=='ne': return lat+lat_diag, lng+lng_diag
                        if code=='nw': return lat+lat_diag, lng-lng_diag
                        if code=='se': return lat-lat_diag, lng+lng_diag
                        if code=='sw': return lat-lat_diag, lng-lng_diag
                        return lat, lng
                    lat_o, lng_o = offset(base_lat, base_lng, code)
                    label_region = region_key.split()[0].title()
                    dir_label_map = {
                        'n':'північна частина','s':'південна частина','e':'східна частина','w':'західна частина',
                        'ne':'північно-східна частина','nw':'північно-західна частина','se':'південно-східна частина','sw':'південно-західна частина','center':'частина'
                    }
                    label = f"{label_region} ({dir_label_map.get(code,'частина')})"
                    threat_type, icon = classify(text)
                    
                    # Skip if this segment contains "курсом на [city]" after the region match
                    # to give priority to specific city course tracking
                    segment_after = text[m.end():]
                    if _re_seg.search(r'курсом?\s+на\s+(?:н\.п\.?\s*)?[А-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,}', segment_after, _re_seg.IGNORECASE):
                        continue
                    
                    seg_tracks.append({
                        'id': f"{mid}_rd{len(seg_tracks)+1}", 'place': label, 'lat': lat_o, 'lng': lng_o,
                        'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
                        'marker_icon': icon, 'source_match': 'region_direction_segment'
                    })
            if seg_tracks:
                return seg_tracks
    except Exception as e:
        try: log.debug(f'region_dir_segments error: {e}')
        except: pass
    # --- Pre-split case: several bold oblast headers inside a single line (e.g. **Полтавщина:** ... **Дніпропетровщина:** ... ) ---
    try:
        import re as _pre_hdr_re
        # Detect two or more bold oblast headers
        hdr_pat = re.compile(r'(\*\*[A-Za-zА-Яа-яЇїІіЄєҐґ]+щина\*\*:)')
        if text.count('**') >= 4:  # quick filter
            matches = list(hdr_pat.finditer(text))
            if len(matches) >= 2:
                # Insert newline before each header (except first) if not already line-start
                # Build new text chunk-wise
                new_parts = []
                last = 0
                for i, m in enumerate(matches):
                    start = m.start()
                    if i == 0 and start > 0 and text[start-1] != '\n':
                        # ensure header is at line start
                        new_parts.append(text[last:start])
                    elif i > 0:
                        # append text before header ensuring newline separation
                        segment = text[last:start]
                        if not segment.endswith('\n'):
                            segment += '\n'
                        new_parts.append(segment)
                    last = start
                # append remaining
                new_parts.append(text[last:])
                new_text_joined = ''.join(new_parts)
                if new_text_joined != text:
                    text = new_text_joined
    except Exception:
        pass
    # --- Спец. обработка многострочных сообщений с заголовками-областями и списком городов ---
    import unicodedata
    def normalize_city_name(name):
        # Привести к нижнему регистру, заменить все апострофы на стандартный, убрать лишние пробелы
        n = name.lower().strip()
        n = n.replace('ʼ', "'").replace('’', "'").replace('`', "'")
        n = unicodedata.normalize('NFC', n)
        
        # Convert mixed Latin/Cyrillic to full Cyrillic (e.g. "Kov'яги" -> "ков'яги")
        # Common Latin-Cyrillic lookalikes in Ukrainian city names
        latin_to_cyrillic = {
            'a': 'а', 'e': 'е', 'i': 'і', 'o': 'о', 'p': 'р', 'c': 'с', 
            'y': 'у', 'x': 'х', 'k': 'к', 'h': 'н', 't': 'т', 'm': 'м',
            'b': 'в', 'v': 'в', 'n': 'н', 's': 'с', 'r': 'р'
        }
        
        # Only convert if string contains mixed Latin + Cyrillic (heuristic: has both ranges)
        has_cyrillic = any(ord(c) >= 0x0400 and ord(c) <= 0x04FF for c in n)
        has_latin = any('a' <= c <= 'z' for c in n)
        
        if has_cyrillic and has_latin:
            # Convert Latin lookalikes to Cyrillic
            n_converted = ''
            for c in n:
                if 'a' <= c <= 'z':
                    n_converted += latin_to_cyrillic.get(c, c)
                else:
                    n_converted += c
            n = n_converted
        
        return n

    def sanitize_course_destination(name: str) -> str:
        if not name:
            return ''
        cleaned = name.strip()
        cleaned = re.sub(r'[\\/|]+', ' ', cleaned)
        cleaned = re.sub(r'\s+', ' ', cleaned)
        cleaned = re.sub(r'(район|району|районі|районів|района|р-н|область|області|обл\.|громада|громаді|громади|community|district|sector|сектор|місто|місті)$', '', cleaned, flags=re.IGNORECASE).strip()
        cleaned = re.sub(r'\b(район|району|районі|района|р-н|область|області|обл\.|громада|громади|community|district|sector|сектор|місто|місті)\b', '', cleaned, flags=re.IGNORECASE)
        cleaned = re.sub(r'\s+', ' ', cleaned).strip(" .,'-\"")
        return cleaned

    def extract_course_targets(raw: str):
        if not raw:
            return []
        parts = re.split(r'\s*(?:[\\/|,;]|\s+та\s+|\s+і\s+|\s+и\s+|\s+або\s+|\s+or\s+)\s*', raw, flags=re.IGNORECASE)
        targets = []
        for part in parts:
            candidate = sanitize_course_destination(part)
            if candidate:
                targets.append(candidate)
        if targets:
            return targets
        cleaned = sanitize_course_destination(raw)
        return [cleaned] if cleaned else []
    # Если сообщение содержит несколько строк с заголовками-областями и городами
    # Предварительно уберём чисто донатные/подписи строки из многострочного блока, чтобы они не мешали
    raw_lines = text.splitlines()
    
    # NEW: Handle single-line messages with multiple regions like "Чернігівщина: 1 БпЛА на Козелець ... Сумщина: 3 БпЛА..."
    # First try to split by region headers in single line
    single_line_regions = ['чернігівщин', 'сумщин', 'харківщин', 'полтавщин', 'херсонщин', 'донецьк', 'луганщин']
    if len(raw_lines) == 1 and any(region in text.lower() for region in single_line_regions):
        add_debug_log(f"Single-line multi-region message detected, raw_lines count: {len(raw_lines)}", "multi_region")
        # Split by oblast headers that have colon after them
        import re as _re_split
        region_split = _re_split.split(r'([А-ЯІЇЄЁа-яіїєё]+щина):\s*', text)
        add_debug_log(f"Region split result: {region_split}", "multi_region")
        if len(region_split) > 2:  # We have actual splits
            new_lines = []
            for i in range(1, len(region_split), 2):  # Take every odd element (region name) and next even (content)
                if i+1 < len(region_split):
                    region_name = region_split[i]
                    content = region_split[i+1].strip()
                    new_lines.append(f"{region_name}:")
                    new_lines.append(content)
                    add_debug_log(f"Added region header: '{region_name}:' and content: '{content}'", "multi_region")
            if new_lines:
                raw_lines = new_lines
                add_debug_log(f"Split single line into {len(raw_lines)} lines for multi-region processing", "multi_region")
        else:
            add_debug_log("Region split failed, keeping original format", "multi_region")
    
    cleaned_for_multiline = []
    import re as _re_clean
    donation_keys = ['монобанк','send.monobank','patreon','donat','донат','підтримати канал','підтримати']
    for l in raw_lines:
        ls = l.strip()
        if not ls:
            continue
        # If line combines header and content ("Хмельниччина: Група КР ..." possibly with formatting ** **)
        m_comb = _re_clean.match(r'^\**([A-Za-zА-Яа-яЇїІіЄєҐґ]+щина)\**:\s*(.+)$', ls)
        if m_comb:
            header_part = m_comb.group(1) + ':'
            rest_part = m_comb.group(2).strip()
            cleaned_for_multiline.append(header_part)
            ls = rest_part  # continue processing rest_part below (could still contain links)
        low_ls = ls.lower()
        # Strip markdown links / segments that are purely donation or service references, keep threat fragment
        def _strip_bad_links(s: str):
            # Remove any [text](url) where text or url contains donation_keys
            def _repl(m):
                inner_text = m.group(1).lower()
                url = m.group(2).lower()
                if any(k in inner_text or k in url for k in donation_keys):
                    return ''
                return m.group(0)
            s2 = _re_clean.sub(r'\[([^\]]{0,60})\]\(([^) ]+?)\)', _repl, s)
            return s2
        ls_no_links = _strip_bad_links(ls)
        low_no_links = ls_no_links.lower()
        if any(k in low_no_links for k in donation_keys):
            # If after stripping links still only donation noise and no threat keywords, skip.
            if not any(t in low_no_links for t in ['бпла','курс','ракета','ракети','рупа','група','кр']):
                continue
            # Else remove the donation substrings explicitly.
            for k in donation_keys:
                low_no_links = low_no_links.replace(k,' ')
            ls_no_links = ' '.join(low_no_links.split())
        cleaned_for_multiline.append(ls_no_links.strip())
    lines = cleaned_for_multiline
    
    oblast_hdr = None
    multi_city_tracks = []
    processed_lines_count = 0
    add_debug_log(f"Processing {len(lines)} cleaned lines for multi-city tracks", "multi_region")
    
    for ln in lines:
        processed_lines_count += 1
        add_debug_log(f"Processing line {processed_lines_count}/{len(lines)}: '{ln[:80]}...'", "multi_region")
        
        # PRIORITY: Check for specific region-city patterns FIRST
        import re as _re_region_city
        ln_lower = ln.lower()
        
        # Pattern 1: "на [region] [count] шахедів на [city]"
        region_city_pattern1 = _re_region_city.compile(r'на\s+([а-яіїєґ]+щин[іау]?)\s+(\d+)\s+шахед[іїв]*\s+на\s+([а-яіїєґ\'\-\s]+)', _re_region_city.IGNORECASE)
        region_city_match1 = region_city_pattern1.search(ln_lower)
        
        # Pattern 2: "[region] - шахеди на [city]"
        region_city_pattern2 = _re_region_city.compile(r'([а-яіїєґ]+щин[ауи]?)\s*-\s*шахед[іїив]*\s+на\s+([а-яіїєґ\'\-\s]+)', _re_region_city.IGNORECASE)
        region_city_match2 = region_city_pattern2.search(ln_lower)
        
        # Pattern 3: "[region] ([city] р-н)" - for district headquarters
        region_district_pattern = _re_region_city.compile(r'([а-яіїєґ]+щин[ауи]?)\s*\(\s*([а-яіїєґ\'\-\s]+)\s+р[-\s]*н\)', _re_region_city.IGNORECASE)
        region_district_match = region_district_pattern.search(ln_lower)
        
        add_debug_log(f"CHECKING region-city patterns for line: '{ln_lower}'", "region_city_debug")
        
        region_city_match = region_city_match1 or region_city_match2
        
        if region_district_match:
            # Handle "чернігівщина (новгород-сіверський р-н)" format
            region_raw, district_raw = region_district_match.groups()
            target_city = district_raw.strip()
            
            add_debug_log(f"REGION-DISTRICT pattern FOUND: region='{region_raw}', district='{district_raw}'", "region_district")
            
            # Normalize city name and try to find coordinates
            city_norm = target_city.lower()
            # Apply UA_CITY_NORMALIZE rules if available
            if 'UA_CITY_NORMALIZE' in globals():
                city_norm = UA_CITY_NORMALIZE.get(city_norm, city_norm)
            coords = CITY_COORDS.get(city_norm)
            
            add_debug_log(f"District city lookup: '{target_city}' -> '{city_norm}' -> {coords}", "region_district")
            
            if coords:
                lat, lng = coords
                threat_type, icon = classify(ln)
                
                multi_city_tracks.append({
                    'id': f"{mid}_region_district_{len(multi_city_tracks)+1}",
                    'place': target_city.title(),
                    'lat': lat,
                    'lng': lng,
                    'threat_type': threat_type,
                    'text': ln[:500],
                    'date': date_str,
                    'channel': channel,
                    'marker_icon': icon,
                    'source_match': 'region_district',
                    'count': 1
                })
                add_debug_log(f"Created region-district marker: {target_city.title()}", "region_district")
                continue  # Skip further processing of this line
            else:
                add_debug_log(f"No coordinates found for district city: '{target_city}' (normalized: '{city_norm}')", "region_district")
        
        elif region_city_match:
            if region_city_match1:
                region_raw, count_str, city_raw = region_city_match1.groups()
                count = int(count_str) if count_str.isdigit() else 1
            else:  # region_city_match2
                region_raw, city_raw = region_city_match2.groups()
                count = 1  # default count for pattern 2
                
            target_city = city_raw.strip()
            
            add_debug_log(f"REGION-CITY pattern FOUND: region='{region_raw}', count={count}, city='{target_city}'", "region_city")
            
            # Normalize city name and try to find coordinates
            city_norm = target_city.lower()
            # Apply UA_CITY_NORMALIZE rules if available
            if 'UA_CITY_NORMALIZE' in globals():
                city_norm = UA_CITY_NORMALIZE.get(city_norm, city_norm)
            coords = CITY_COORDS.get(city_norm)
            
            add_debug_log(f"City lookup: '{target_city}' -> '{city_norm}' -> {coords}", "region_city")
            
            if coords:
                lat, lng = coords
                threat_type, icon = classify(ln)
                
                multi_city_tracks.append({
                    'id': f"{mid}_region_city_{len(multi_city_tracks)+1}",
                    'place': target_city.title(),
                    'lat': lat,
                    'lng': lng,
                    'threat_type': threat_type,
                    'text': ln[:500],
                    'date': date_str,
                    'channel': channel,
                    'marker_icon': icon,
                    'source_match': 'region_city_shahed',
                    'count': count
                })
                add_debug_log(f"Created region-city marker: {target_city.title()} ({count} шахедів)", "region_city")
                continue  # Skip further processing of this line
            else:
                add_debug_log(f"No coordinates found for city: '{target_city}' (normalized: '{city_norm}')", "region_city")
        else:
            add_debug_log(f"REGION-CITY pattern NOT FOUND for line: '{ln_lower}'", "region_city_debug")
        
        # NEW: Pattern "БпЛА на [direction] [region_genitive] курсом на [target]"
        # Example: "БпЛА на півночі Херсонщини курсом на Миколаївщину"
        regional_course_pattern = re.search(r'(бпла|безпілотник|шахед|дрон).*(на\s+(півночі|півдні|сході|заході|центрі))?\s*([а-яіїєґ]+щин[іуиа])\s*.*курсом\s+на\s+([а-яіїєґ\'\-\s]+)', ln_lower, re.IGNORECASE)
        if regional_course_pattern:
            direction_part = regional_course_pattern.group(3) if regional_course_pattern.group(2) else None
            region_genitive = regional_course_pattern.group(4)
            target_raw = regional_course_pattern.group(5).strip()
            
            # Normalize target (could be city or region)
            target_norm = target_raw.replace('щину', 'щина').replace('щини', 'щина').strip()
            
            add_debug_log(f"REGIONAL COURSE pattern: direction={direction_part}, region={region_genitive}, target={target_raw} -> {target_norm}", "regional_course")
            
            # Try to find coordinates for target
            target_city = normalize_city_name(target_norm)
            target_city = UA_CITY_NORMALIZE.get(target_city, target_city)
            coords = CITY_COORDS.get(target_city)
            if not coords and SETTLEMENTS_INDEX:
                coords = SETTLEMENTS_INDEX.get(target_city)
            
            # If target is a region (щина), use region center
            if not coords and ('щина' in target_city or 'щини' in target_city):
                # Try to get region center coordinates
                region_centers = {
                    'миколаївщина': (46.975, 31.995),
                    'херсонщина': (46.635, 32.617),
                    'чернігівщина': (51.4982, 31.2893),
                    'сумщина': (50.9077, 34.7981),
                    'полтавщина': (49.5883, 34.5514),
                    'харківщина': (49.9935, 36.2304),
                    'дніпропетровщина': (48.4647, 35.0462),
                    'запоріжжя': (47.8388, 35.1396),
                    'донеччина': (48.0159, 37.8028),
                }
                coords = region_centers.get(target_city)
                if coords:
                    add_debug_log(f"Using region center for '{target_city}': {coords}", "regional_course")
            
            if coords:
                lat, lng = coords
                threat_type, icon = classify(ln)
                
                # Extract count if present
                count_match = re.search(r'(\d+)\s*[xх×]?\s*(бпла|шахед)', ln_lower)
                count = int(count_match.group(1)) if count_match else 1
                
                place_label = target_norm.title()
                if direction_part:
                    place_label += f" ({direction_part})"
                
                multi_city_tracks.append({
                    'id': f"{mid}_regional_course_{len(multi_city_tracks)+1}",
                    'place': place_label,
                    'lat': lat,
                    'lng': lng,
                    'threat_type': threat_type,
                    'text': clean_text(ln)[:500],
                    'date': date_str,
                    'channel': channel,
                    'marker_icon': icon,
                    'source_match': 'regional_course',
                    'count': count
                })
                add_debug_log(f"Created regional course marker: {place_label} at {lat}, {lng}", "regional_course")
                continue
            else:
                add_debug_log(f"No coordinates for regional course target: '{target_raw}' (norm: '{target_city}')", "regional_course")
        
        # NEW: Check for regional direction patterns WITHOUT specific city (e.g. "БпЛА на сході Сумщини ➡️ курсом на південь")
        # These should create regional markers, not skip
        region_direction_pattern = re.search(r'(бпла|безпілотник|шахед|дрон).*(на\s+(півночі|півдні|сході|заході)).*([а-яіїєґ]+щин[іуиа])', ln_lower, re.IGNORECASE)
        if region_direction_pattern and not region_city_match and not regional_course_pattern:
            add_debug_log(f"REGIONAL DIRECTION pattern detected (no specific city): {ln[:100]}", "regional_direction")
            # This line should be processed by regional parser - don't add to multi_city_tracks yet
            # Instead, extract the region and direction to create a regional marker later
            # For now, just mark it for special processing
        
        # Check if line contains БпЛА information without specific course
        ln_lower = ln.lower()
        # Support both Cyrillic БпЛА and Latin-mixed БпЛA variants, and also Shahed
        has_uav = 'бпла' in ln_lower or 'бпла' in ln_lower or 'безпілотник' in ln_lower or 'дрон' in ln_lower or 'bpla' in ln_lower or 'шахед' in ln_lower or 'shahed' in ln_lower
        if has_uav:
            add_debug_log(f"Line contains UAV keywords", "multi_region")
            if not any(keyword in ln_lower for keyword in ['курс', 'на ', 'районі']):
                add_debug_log(f"UAV line lacks direction keywords (курс/на/районі) - general activity message", "multi_region")
        else:
            add_debug_log(f"Line does not contain UAV keywords", "multi_region")
        # Если строка — это заголовок области (например, "Сумщина:")
        # Заголовок области: строка, заканчивающаяся на ':' (возможен пробел перед / после) или формой '<область>:' с лишними пробелами
        # NEW: Also handle format like "**🚨 Конотопський район (Сумська обл.)**"
        import re
        oblast_hdr_match = None
        
        # Standard format: "Сумщина:" or "Чернігівщина:"
        if re.match(r'^[A-Za-zА-Яа-яЇїІіЄєҐґ\-ʼ`\s]+:\s*$', ln):
            oblast_hdr = ln.split(':')[0].strip().lower()
            oblast_hdr_match = True
            add_debug_log(f"Standard region header format detected: '{oblast_hdr}'", "multi_region")
        
        # NEW format: "**🚨 Конотопський район (Сумська обл.)**" or similar with oblast in parentheses
        elif re.search(r'\(([А-ЯІЇЄЁа-яіїєё]+ська\s+обл\.?)\)', ln):
            oblast_match = re.search(r'\(([А-ЯІЇЄЁа-яіїєё]+ська\s+обл\.?)\)', ln)
            if oblast_match:
                oblast_full = oblast_match.group(1).lower().strip()
                # Convert "сумська обл." to "сумщина"
                oblast_hdr = oblast_full.replace('ська обл.', 'щина').replace('ська обл', 'щина')
                oblast_hdr_match = True
                add_debug_log(f"Parentheses region header format detected: '{oblast_full}' -> '{oblast_hdr}'", "multi_region")
        
        # NEW format: "Харківщина — БпЛА на Гути" - region with dash followed by content
        elif re.search(r'^([А-ЯІЇЄЁа-яіїєё]+щина)\s*[-–—]\s*(.+)', ln):
            dash_match = re.search(r'^([А-ЯІЇЄЁа-яіїєё]+щина)\s*[-–—]\s*(.+)', ln)
            if dash_match:
                oblast_hdr = dash_match.group(1).lower().strip()
                remaining_content = dash_match.group(2).strip()
                oblast_hdr_match = True
                add_debug_log(f"Dash region header format detected: '{oblast_hdr}' with content: '{remaining_content}'", "multi_region")
                # Set the line content to just the remaining part after dash for further processing
                ln = remaining_content
        
        # NEW: Detect regional genitive forms like "Сумщини", "Харківщини", etc.
        elif re.search(r'\b([а-яіїєґ]+щин[иі])\b', ln_lower):
            genitive_match = re.search(r'\b([а-яіїєґ]+щин[иі])\b', ln_lower)
            if genitive_match:
                genitive_form = genitive_match.group(1)
                # Convert genitive to nominative: "сумщини" -> "сумщина"
                potential_oblast = genitive_form.replace('щини', 'щина').replace('щині', 'щина')
                
                # Validate that this is actually a known region, not just any word ending with щин[иі]
                known_regions = ['сумщина', 'чернігівщина', 'харківщина', 'полтавщина', 'херсонщина', 
                               'донеччина', 'луганщина', 'запорожжя', 'дніпропетровщина', 'київщина',
                               'львівщина', 'івано-франківщина', 'тернопільщина', 'хмельниччина',
                               'рівненщина', 'волинщина', 'житомирщина', 'вінниччина', 'черкащина',
                               'кіровоградщина', 'миколаївщина', 'одещина']
                
                if potential_oblast in known_regions:
                    oblast_hdr = potential_oblast
                    oblast_hdr_match = True
                    add_debug_log(f"Genitive region format detected: '{genitive_form}' -> '{oblast_hdr}' in line: '{ln}'", "multi_region")
                    add_debug_log(f"POTENTIAL ISSUE: Oblast set to '{oblast_hdr}' from genitive pattern in: '{ln}'", "oblast_detection")
                else:
                    add_debug_log(f"Ignored potential genitive form '{genitive_form}' -> '{potential_oblast}' (not in known regions) in line: '{ln}'", "multi_region")
        
        if oblast_hdr_match:
            add_debug_log(f"Region header detected: '{oblast_hdr}'", "multi_region")
            if oblast_hdr.startswith('на '):  # handle 'на харківщина:' header variant
                oblast_hdr = oblast_hdr[3:].strip()
            if oblast_hdr and oblast_hdr[0] in ('е','є') and oblast_hdr.endswith('гівщина'):
                # восстановить черниговщина -> чернігівщина (fix dropped leading Ч)
                oblast_hdr = 'чернігівщина'
            # Доп. почин восстановлений первых букв для областей (потеря первой буквы)
            if oblast_hdr and oblast_hdr.endswith('ївщина') and oblast_hdr != 'київщина':
                oblast_hdr = 'київщина'
            if oblast_hdr and oblast_hdr.endswith('нниччина') and oblast_hdr != 'вінниччина':
                oblast_hdr = 'вінниччина'
            # header detected
            add_debug_log(f"Final region header: '{oblast_hdr}'", "multi_region")
            continue
        try:
            add_debug_log(f"MLINE_LINE oblast={oblast_hdr} raw='{ln}'", "multi_region")
        except Exception:
            pass
        
        # NEW: Check for specific direction patterns before falling back to general UAV activity
        import re
        ln_lower = ln.lower()
        
        # NEW: Pattern "кружляє над/над [city]"
        if 'кружляє' in ln_lower or 'кружля' in ln_lower:
            kruzhlia_match = re.search(r'кружля[єюя]\s+(?:над\s+)?([А-ЯІЇЄЁа-яіїєё\'\-\s]+?)(?:\s*[\.\,\!\?;]|$)', ln, re.IGNORECASE)
            if kruzhlia_match:
                city_raw = kruzhlia_match.group(1).strip()
                city_norm = normalize_city_name(city_raw)
                city_norm = UA_CITY_NORMALIZE.get(city_norm, city_norm)
                coords = CITY_COORDS.get(city_norm) or (SETTLEMENTS_INDEX.get(city_norm) if SETTLEMENTS_INDEX else None)
                
                if coords:
                    lat, lng = coords
                    threat_type, icon = classify(ln)
                    count_match = re.search(r'(\d+)[xх×]?\s*бпла', ln_lower)
                    count = int(count_match.group(1)) if count_match else 1
                    
                    # Create multiple tracks if count > 1
                    for i in range(count):
                        place_label = city_norm.title()
                        if count > 1:
                            place_label += f" #{i+1} (кружляє)"
                        else:
                            place_label += f" (кружляє)"
                        
                        # Add offset for multiple drones
                        marker_lat, marker_lng = lat, lng
                        if count > 1:
                            offset_distance = 0.03
                            marker_lat += offset_distance * i
                            marker_lng += offset_distance * i * 0.5
                        
                        multi_city_tracks.append({
                            'id': f"{mid}_kruzhlia_{len(multi_city_tracks)+1}",
                            'place': place_label,
                            'lat': marker_lat,
                            'lng': marker_lng,
                            'threat_type': threat_type,
                            'text': clean_text(ln)[:500],
                            'date': date_str,
                            'channel': channel,
                            'marker_icon': icon,
                            'source_match': 'kruzhlia_nad',
                            'count': 1
                        })
                    add_debug_log(f"Created {count} marker(s) for 'кружляє': {city_norm.title()}", "kruzhlia")
                    continue
        
        # NEW: Pattern "північніше/південніше/східніше/західніше [city]"
        if any(direction in ln_lower for direction in ['північніше', 'південніше', 'східніше', 'західніше']):
            direction_match = re.search(r'(північніше|південніше|східніше|західніше)\s+([А-ЯІЇЄЁа-яіїєё\'\-\s]+?)(?:\s*[\.\,\!\?;]|$)', ln, re.IGNORECASE)
            if direction_match:
                direction_type = direction_match.group(1).lower()
                city_raw = direction_match.group(2).strip()
                city_norm = normalize_city_name(city_raw)
                city_norm = UA_CITY_NORMALIZE.get(city_norm, city_norm)
                coords = CITY_COORDS.get(city_norm) or (SETTLEMENTS_INDEX.get(city_norm) if SETTLEMENTS_INDEX else None)
                
                if coords:
                    lat, lng = coords
                    # Apply directional offset based on direction type
                    offset = 0.15  # ~15km
                    if direction_type == 'північніше':
                        lat += offset
                    elif direction_type == 'південніше':
                        lat -= offset
                    elif direction_type == 'східніше':
                        lng += offset
                    elif direction_type == 'західніше':
                        lng -= offset
                    
                    threat_type, icon = classify(ln)
                    count_match = re.search(r'(\d+)[xх×]?\s*бпла', ln_lower)
                    count = int(count_match.group(1)) if count_match else 1
                    
                    # Create multiple tracks if count > 1
                    for i in range(count):
                        place_label = f"{direction_type.title()} {city_norm.title()}"
                        if count > 1:
                            place_label += f" #{i+1}"
                        
                        # Add offset for multiple drones
                        marker_lat, marker_lng = lat, lng
                        if count > 1:
                            offset_distance = 0.03
                            marker_lat += offset_distance * i
                            marker_lng += offset_distance * i * 0.5
                        
                        multi_city_tracks.append({
                            'id': f"{mid}_direction_{len(multi_city_tracks)+1}",
                            'place': place_label,
                            'lat': marker_lat,
                            'lng': marker_lng,
                            'threat_type': threat_type,
                            'text': clean_text(ln)[:500],
                            'date': date_str,
                            'channel': channel,
                            'marker_icon': icon,
                            'source_match': f'directional_{direction_type}',
                            'count': 1
                        })
                    add_debug_log(f"Created {count} marker(s) for '{direction_type}': {city_norm.title()}", "directional")
                    continue
        
        # NEW: Pattern "на/через [city]" - combined "на" and "через"
        if re.search(r'на/через\s+[А-ЯІЇЄЁа-яіїєё]', ln, re.IGNORECASE):
            na_cherez_match = re.search(r'(\d+)[xх×]?\s*бпла\s+на/через\s+([А-ЯІЇЄЁа-яіїєё\'\-\s]+?)(?:\s*[\.\,\!\?;]|$)', ln, re.IGNORECASE)
            if na_cherez_match:
                count = int(na_cherez_match.group(1)) if na_cherez_match.group(1) else 1
                city_raw = na_cherez_match.group(2).strip()
                city_norm = normalize_city_name(city_raw)
                city_norm = UA_CITY_NORMALIZE.get(city_norm, city_norm)
                coords = CITY_COORDS.get(city_norm) or (SETTLEMENTS_INDEX.get(city_norm) if SETTLEMENTS_INDEX else None)
                
                if coords:
                    lat, lng = coords
                    threat_type, icon = classify(ln)
                    
                    # Create multiple tracks if count > 1
                    for i in range(count):
                        place_label = city_norm.title()
                        if count > 1:
                            place_label += f" #{i+1} (на/через)"
                        else:
                            place_label += f" (на/через)"
                        
                        # Add offset for multiple drones
                        marker_lat, marker_lng = lat, lng
                        if count > 1:
                            offset_distance = 0.03
                            marker_lat += offset_distance * i
                            marker_lng += offset_distance * i * 0.5
                        
                        multi_city_tracks.append({
                            'id': f"{mid}_na_cherez_{len(multi_city_tracks)+1}",
                            'place': place_label,
                            'lat': marker_lat,
                            'lng': marker_lng,
                            'threat_type': threat_type,
                            'text': clean_text(ln)[:500],
                            'date': date_str,
                            'channel': channel,
                            'marker_icon': icon,
                            'source_match': 'na_cherez',
                            'count': 1
                        })
                    add_debug_log(f"Created {count} marker(s) for 'на/через': {city_norm.title()}", "na_cherez")
                    continue
        
        # NEW: Pattern "з ТОТ в напрямку [city]" - drones from occupied territory
        if 'з тот' in ln_lower or 'з tot' in ln_lower:
            tot_match = re.search(r'(\d+)[xх×]?\s*бпла\s+з\s+тот\s+(?:в\s+напрямку|на)\s+([А-ЯІЇЄЁа-яіїєё\'\-\s]+?)(?:\s*[\.\,\!\?;]|$)', ln, re.IGNORECASE)
            if tot_match:
                count = int(tot_match.group(1)) if tot_match.group(1) else 1
                city_raw = tot_match.group(2).strip()
                city_norm = normalize_city_name(city_raw)
                city_norm = UA_CITY_NORMALIZE.get(city_norm, city_norm)
                coords = CITY_COORDS.get(city_norm) or (SETTLEMENTS_INDEX.get(city_norm) if SETTLEMENTS_INDEX else None)
                
                if coords:
                    lat, lng = coords
                    threat_type, icon = classify(ln)
                    
                    # Create multiple tracks if count > 1
                    for i in range(count):
                        place_label = city_norm.title()
                        if count > 1:
                            place_label += f" #{i+1} (з ТОТ)"
                        else:
                            place_label += f" (з ТОТ)"
                        
                        # Add offset for multiple drones
                        marker_lat, marker_lng = lat, lng
                        if count > 1:
                            offset_distance = 0.03
                            marker_lat += offset_distance * i
                            marker_lng += offset_distance * i * 0.5
                        
                        multi_city_tracks.append({
                            'id': f"{mid}_tot_{len(multi_city_tracks)+1}",
                            'place': place_label,
                            'lat': marker_lat,
                            'lng': marker_lng,
                            'threat_type': threat_type,
                            'text': clean_text(ln)[:500],
                            'date': date_str,
                            'channel': channel,
                            'marker_icon': icon,
                            'source_match': 'z_tot',
                            'count': 1
                        })
                    add_debug_log(f"Created {count} marker(s) for 'з ТОТ': {city_norm.title()}", "z_tot")
                    continue
        
        # Check if line has БпЛА or starts with a number (implying drones)
        has_bpla = 'бпла' in ln_lower
        starts_with_number = re.match(r'^\d+', ln.strip())
        has_direction_pattern = any(pattern in ln_lower for pattern in ['у напрямку', 'через', 'повз'])
        
        if (has_bpla or starts_with_number) and has_direction_pattern:
            target_cities = []
            
            # Pattern 1: "у напрямку [city]"
            naprym_pattern = r'у\s+напрямку\s+([А-ЯІЇЄЁа-яіїєё\'\-\s]+?)(?:\s*[\.\,\!\?;]|$)'
            naprym_matches = re.findall(naprym_pattern, ln, re.IGNORECASE)
            for city_raw in naprym_matches:
                target_cities.append(('у напрямку', city_raw.strip()))
            
            # Pattern 2: "через [city]"
            cherez_pattern = r'через\s+([А-ЯІЇЄЁа-яіїєё\'\-\s]+?)(?:\s*[\.\,\!\?;]|$)'
            cherez_matches = re.findall(cherez_pattern, ln, re.IGNORECASE)
            for city_raw in cherez_matches:
                target_cities.append(('через', city_raw.strip()))
            
            # Pattern 3: "повз [city]"
            povz_pattern = r'повз\s+([А-ЯІЇЄЁа-яіїєё\'\-\s]+?)(?:\s*[\.\,\!\?;]|$)'
            povz_matches = re.findall(povz_pattern, ln, re.IGNORECASE)
            for city_raw in povz_matches:
                target_cities.append(('повз', city_raw.strip()))
            
            # Process extracted target cities
            for direction_type, city_raw in target_cities:
                city_clean = city_raw.strip()
                city_norm = city_clean.lower()
                
                # Apply UA_CITY_NORMALIZE rules
                if city_norm in UA_CITY_NORMALIZE:
                    city_norm = UA_CITY_NORMALIZE[city_norm]
                
                # Try to get coordinates
                coords = CITY_COORDS.get(city_norm)
                if not coords and SETTLEMENTS_INDEX:
                    coords = SETTLEMENTS_INDEX.get(city_norm)
                if not coords:
                    coords = SETTLEMENT_FALLBACK.get(city_norm) if 'SETTLEMENT_FALLBACK' in globals() else None
                
                add_debug_log(f"Direction pattern '{direction_type}' found city: '{city_raw}' -> '{city_norm}' -> coords: {coords}", "direction_processing")
                
                if coords:
                    lat, lng = coords
                    threat_type, icon = classify(ln)
                    
                    # Create label showing direction
                    place_label = city_clean.title()
                    if direction_type == 'у напрямку':
                        place_label += f" (напрямок)"
                    elif direction_type == 'через':
                        place_label += f" (через)"
                    elif direction_type == 'повз':
                        place_label += f" (повз)"
                    
                    multi_city_tracks.append({
                        'id': f"{mid}_direction_{len(multi_city_tracks)+1}",
                        'place': place_label,
                        'lat': lat,
                        'lng': lng,
                        'threat_type': threat_type,
                        'text': clean_text(ln)[:500],
                        'date': date_str,
                        'channel': channel,
                        'marker_icon': icon,
                        'source_match': f'direction_{direction_type.replace(" ", "_")}',
                        'count': 1
                    })
                    add_debug_log(f"Created direction marker: {place_label} ({direction_type})", "direction_processing")
                else:
                    add_debug_log(f"No coordinates found for direction target: '{city_raw}' (normalized: '{city_norm}')", "direction_processing")
            
            # If we found any target cities with valid coordinates, skip general UAV processing
            if any(coords for _, coords in [(city_norm, CITY_COORDS.get(UA_CITY_NORMALIZE.get(city_raw.strip().lower(), city_raw.strip().lower()))) for _, city_raw in target_cities]):
                add_debug_log(f"Direction processing complete, skipping general UAV activity for line: '{ln}'", "direction_processing")
                continue
        
        # NEW: Create markers for general UAV activity messages (without specific direction)
        if 'бпла' in ln_lower or 'безпілотник' in ln_lower or 'дрон' in ln_lower:
            add_debug_log(f"UAV activity detected in line: '{ln}', oblast_hdr: '{oblast_hdr}'", "uav_processing")
            
            # CRITICAL: Check if message has specific directional patterns - if yes, skip general marker
            # Let the main parser handle "курсом на", "напрямок на", "у напрямку", "на [місто]" etc.
            has_directional_pattern = any(pattern in ln_lower for pattern in [
                'курсом на', 'курс на', 'напрямок на', 'напрямку на', 
                'ціль на', 'у напрямку', 'у бік', 'в бік', 'через', 'повз',
                'маневрує в районі', 'в районі', 'бпла на ', 'дрон на '
            ])
            
            # Check for emoji arrows BUT only if there's actual text (city name) after the arrow
            if '➡' in ln and not has_directional_pattern:
                # Extract text after arrow to see if there's a city name
                arrow_match = re.search(r'➡[️\s]*(.{3,})', ln)
                if arrow_match:
                    text_after_arrow = arrow_match.group(1).strip().strip('ㅤ️ ').strip()
                    # If there's meaningful text after arrow (not just punctuation/links), treat as directional
                    if text_after_arrow and len(text_after_arrow) > 1 and not text_after_arrow.startswith(('http', '[', '**', '➡')):
                        has_directional_pattern = True
            
            if has_directional_pattern:
                add_debug_log(f"SKIP general UAV marker - has directional pattern: '{ln}'", "uav_processing")
                # Don't create general marker - let main parser extract specific city
                continue
            
            # Check if we have a region and this is a UAV message
            if oblast_hdr:
                add_debug_log(f"Processing UAV with region context: '{oblast_hdr}'", "uav_processing")
                # Find the main city of the region to place the marker
                region_cities = {
                    'сумщина': 'суми',
                    'чернігівщина': 'чернігів',
                    'херсонщина': 'херсон',
                    'харківщина': 'харків',
                    'донеччина': 'краматорськ',  # safer than донецьк
                    'луганщина': 'сєвєродонецьк',
                    'запорожжя': 'запоріжжя',
                    'дніпропетровщина': 'дніпро',
                    'полтавщина': 'полтава',
                    'київщина': 'київ',
                    'львівщина': 'львів',
                    'івано-франківщина': 'івано-франківськ',
                    'тернопільщина': 'тернопіль',
                    'хмельниччина': 'хмельницький',
                    'рівненщина': 'рівне',
                    'волинщина': 'луцьк',
                    'житомирщина': 'житомир',
                    'вінниччина': 'вінниця',
                    'черкащина': 'черкаси',
                    'кіровоградщина': 'кропивницький',
                    'миколаївщина': 'миколаїв',
                    'одещина': 'одеса'
                }
                
                # Special coordinates for aviation threats over regions (e.g., aircraft over Black Sea for Odesa)
                region_aviation_coords = {
                    'одещина': (46.373528, 31.284023),  # Black Sea near Odesa for aviation threats
                    'одесщина': (46.373528, 31.284023),
                }
                
                region_city = region_cities.get(oblast_hdr)
                if region_city:
                    # Check if message refers to entire region rather than specific city
                    # Skip marker creation for some regional threats, but create for KAB/aviation bombs
                    genitive_form = oblast_hdr.replace('щина', 'щини')  # сумщина -> сумщини
                    dative_form = oblast_hdr.replace('щина', 'щині')    # сумщина -> сумщині
                    accusative_form = oblast_hdr + 'у'                  # сумщина -> сумщину
                    
                    is_regional_threat = any(regional_ref in ln_lower for regional_ref in [
                        f'на {oblast_hdr}', f'{accusative_form}', f'{genitive_form}', f'{dative_form}',
                        f'для {genitive_form}', f'по {dative_form}'
                    ])
                    
                    # For KAB/aviation bombs and aviation threats, always create marker even for regional threats
                    has_kab = any(kab_word in ln_lower for kab_word in ['каб', 'авіабомб', 'авиабомб'])
                    has_aviation_threat = any(avia_word in ln_lower for avia_word in [
                        'авіаційних засобів ураження', 'авіаційних засобів', 'застосування авіації',
                        'тактична авіація', 'тактичної авіації'
                    ])
                    
                    if is_regional_threat and not has_kab and not has_aviation_threat:
                        add_debug_log(f"Skipping regional threat marker - affects entire region: {oblast_hdr} (found: {[ref for ref in [f'на {oblast_hdr}', accusative_form, genitive_form, dative_form] if ref in ln_lower]})", "multi_region")
                        continue
                    
                    # Check if this is an aviation threat and use special coordinates if available
                    coords = None
                    if has_aviation_threat and oblast_hdr in region_aviation_coords:
                        coords = region_aviation_coords[oblast_hdr]
                        label = f"Авіація [{oblast_hdr.title()}]"
                        add_debug_log(f"Using aviation coordinates for {oblast_hdr}: {coords}", "aviation_region")
                    
                    # Otherwise, try to find coordinates for the region's main city
                    if not coords:
                        base_city = normalize_city_name(region_city)
                        base_city = UA_CITY_NORMALIZE.get(base_city, base_city)
                        coords = CITY_COORDS.get(base_city) or (SETTLEMENTS_INDEX.get(base_city) if SETTLEMENTS_INDEX else None)
                        label = base_city.title()
                        label += f" [{oblast_hdr.title()}]"
                    
                    if coords:
                        lat, lng = coords
                        
                        # Determine threat type based on message content using classify function
                        threat_type, icon = classify(ln)
                        # Keep shahed as default for UAV if classify doesn't return anything specific
                        if not threat_type:
                            threat_type = 'shahed'
                        
                        multi_city_tracks.append({
                            'id': f"{mid}_general_uav_{len(multi_city_tracks)+1}",
                            'place': label,
                            'lat': lat,
                            'lng': lng,
                            'threat_type': threat_type,
                            'text': clean_text(ln)[:500],
                            'date': date_str,
                            'channel': channel,
                            'marker_icon': icon,
                            'source_match': 'general_uav_activity',
                            'count': 1
                        })
                        add_debug_log(f"Created general UAV marker: {label} ({threat_type})", "multi_region")
                        add_debug_log(f"MARKER CREATION: oblast_hdr='{oblast_hdr}', region_city='{region_city}', coords=({lat}, {lng})", "marker_creation")
                        continue  # move to next line
        
        # NEW: Handle UAV messages without region but with city name
        ln_lower = ln.lower()
        if (not oblast_hdr) and ('бпла' in ln_lower or 'безпілотник' in ln_lower or 'дрон' in ln_lower or 'обстріл' in ln_lower or 'вибух' in ln_lower):
            # Try to extract city name from the message
            import re
            # Pattern for messages like "❗️ Синельникове — 1х БпЛА довкола" or "💥 Херсон — обстріл"
            city_match = re.search(r'[❗️⚠️🛸💥]*\s*([А-ЯІЇЄа-яіїєґ][А-Яа-яІіЇїЄєґ\-\'ʼ]{2,30}(?:ське|цьке|ський|ський район|ове|еве|ине|ино|івка|івськ|ськ|град|город)?)', ln)
            if city_match:
                city_name = city_match.group(1).strip()
                
                # Normalize city name
                base_city = normalize_city_name(city_name)
                base_city = UA_CITY_NORMALIZE.get(base_city, base_city)
                coords = CITY_COORDS.get(base_city) or (SETTLEMENTS_INDEX.get(base_city) if SETTLEMENTS_INDEX else None)
                
                if coords:
                    lat, lng = coords
                    label = base_city.title()
                    
                    # Determine threat type based on message content using classify function
                    threat_type, icon = classify(ln)
                    # Keep shahed as default for UAV if classify doesn't return anything specific
                    if not threat_type:
                        threat_type = 'shahed'
                        icon = 'icon_drone.svg'
                    
                    multi_city_tracks.append({
                        'id': f"{mid}_city_threat_{len(multi_city_tracks)+1}",
                        'place': label,
                        'lat': lat,
                        'lng': lng,
                        'threat_type': threat_type,
                        'text': clean_text(ln)[:500],
                        'date': date_str,
                        'channel': channel,
                        'marker_icon': icon,
                        'source_match': 'city_threat_activity',
                        'count': 1
                    })
                    add_debug_log(f"Created city threat marker: {label} ({threat_type})", "multi_region")
                    continue  # move to next line
        
        # --- NEW: БпЛА курсом на [city] pattern (e.g., "4х БпЛА курсом на Конотоп") ---
        # ВАЖЛИВО: Підтримка багатослівних назв міст (наприклад "Жовті Води")
        uav_course_city = None
        uav_course_count = 1
        # Pattern: "Nх БпЛА курсом на [city]" or "БпЛА курсом на [city]"
        # Захоплює назву міста до кінця рядка або до розділових знаків
        m_uav_course = re.search(r'(?:^|\b)(?:([0-9]+)[xх×]?\s*)?(?:бпла|шахед(?:и|ів)?|дрон(?:и)?)\s+курс(?:ом)?\s+на\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]+?)(?:\s*$|[,\.\!\?;])', ln, re.IGNORECASE)
        if m_uav_course:
            if m_uav_course.group(1):
                try:
                    uav_course_count = int(m_uav_course.group(1))
                except:
                    uav_course_count = 1
            uav_course_city = m_uav_course.group(2).strip()
            
            add_debug_log(f"UAV course pattern found: {uav_course_count}x БпЛА курсом на '{uav_course_city}'", "multi_region")
        
        if uav_course_city:
            candidate_cities = extract_course_targets(uav_course_city)
            add_debug_log(f"extract_course_targets('{uav_course_city}') returned: {candidate_cities}", "multi_region")
            per_marker_count = uav_course_count if len(candidate_cities) <= 1 else 1
            created_course_markers = False
            for dest_city in candidate_cities or [uav_course_city]:
                if not dest_city:
                    continue
                base_uav = normalize_city_name(dest_city)
                base_uav = UA_CITY_NORMALIZE.get(base_uav, base_uav)
                coords_uav = CITY_COORDS.get(base_uav) or (SETTLEMENTS_INDEX.get(base_uav) if SETTLEMENTS_INDEX else None)
                add_debug_log(f"Geocoding '{dest_city}' -> normalized: '{base_uav}' -> coords: {coords_uav}", "multi_region")
                
                # Try region-specific lookup if oblast_hdr is set
                if not coords_uav and oblast_hdr:
                    combo_uav = f"{base_uav} {oblast_hdr}"
                    coords_uav = CITY_COORDS.get(combo_uav) or (SETTLEMENTS_INDEX.get(combo_uav) if SETTLEMENTS_INDEX else None)
                    add_debug_log(f"Trying region combo: '{combo_uav}' -> {coords_uav}", "multi_region")
                
                if not coords_uav:
                    add_debug_log(f"No coords found for '{dest_city}' (normalized: '{base_uav}', oblast: '{oblast_hdr}')", "multi_region")
                    continue
                created_course_markers = True
                lat, lng = coords_uav
                label = UA_CITY_NORMALIZE.get(base_uav, base_uav).title()
                if per_marker_count > 1:
                    label += f" ({per_marker_count}x)"
                if oblast_hdr and oblast_hdr not in label.lower():
                    label += f" [{oblast_hdr.title()}]"
                
                multi_city_tracks.append({
                    'id': f"{mid}_mc{len(multi_city_tracks)+1}",
                    'place': label,
                    'lat': lat,
                    'lng': lng,
                    'threat_type': 'shahed',
                    'text': clean_text(ln)[:500],
                    'date': date_str,
                    'channel': channel,
                    'marker_icon': 'icon_drone.svg',
                    'source_match': 'multiline_uav_course',
                    'count': per_marker_count
                })
                add_debug_log(f"Created UAV course marker: {label}", "multi_region")
            if created_course_markers:
                continue  # move to next line
            else:
                base_uav = normalize_city_name(sanitize_course_destination(uav_course_city))
                add_debug_log(f"No coordinates found for UAV course city: '{uav_course_city}' (normalized: '{base_uav}')", "multi_region")
        
        # Continue processing other patterns even if UAV course didn't match
        # Don't skip the line completely
        
        # Пытаемся найти город и количество (например, "2х БпЛА курсом на Десну")
        import re
        # --- NEW: распознавание ракетных строк внутри многострочного блока ---
        # Примеры: "1 ракета на Холми", "2 ракети на Лубни", "3 ракеты на Лубни", "ракета на <місто>"
        rocket_city = None; rocket_count = 1
        mr = re.search(r'(?:^|\b)(?:([0-9]+)\s*)?(ракета|ракети|ракет)\s+на\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{2,40})', ln, re.IGNORECASE)
        if mr:
            if mr.group(1):
                try: rocket_count = int(mr.group(1))
                except: rocket_count = 1
            rocket_city = mr.group(3)
        if rocket_city:
            base_r = normalize_city_name(rocket_city)
            base_r = UA_CITY_NORMALIZE.get(base_r, base_r)
            coords_r = CITY_COORDS.get(base_r) or (SETTLEMENTS_INDEX.get(base_r) if SETTLEMENTS_INDEX else None)
            if not coords_r and oblast_hdr:
                combo_r = f"{base_r} {oblast_hdr}"
                coords_r = CITY_COORDS.get(combo_r) or (SETTLEMENTS_INDEX.get(combo_r) if SETTLEMENTS_INDEX else None)
            if coords_r:
                lat, lng = coords_r
                label = UA_CITY_NORMALIZE.get(base_r, base_r).title()
                if rocket_count > 1:
                    label += f" ({rocket_count})"
                if oblast_hdr and oblast_hdr not in label.lower():
                    label += f" [{oblast_hdr.title()}]"
                multi_city_tracks.append({
                    'id': f"{mid}_mc{len(multi_city_tracks)+1}", 'place': label, 'lat': lat, 'lng': lng,
                    'threat_type': 'rszv', 'text': clean_text(ln)[:500], 'date': date_str, 'channel': channel,
                    'marker_icon': 'icon_missile.svg', 'source_match': 'multiline_oblast_city_rocket', 'count': rocket_count
                })
                continue  # переходим к следующей строке (не пытаемся распознать как БпЛА)
        # --- NEW: группы крылатых ракет ("Група/Групи КР курсом на <город>") ---
        kr_city = None; kr_count = 1
        # Primary straightforward pattern for "Група/Групи КР курсом на <місто>"
        mkr = re.search(r'(?:^|\b)(?:([0-9]+)[xх×]?\s*)?груп[аи]\s+кр\b.*?курс(?:ом)?\s+на\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,40}?)(?=[,\.\!\?;]|$)', ln, re.IGNORECASE)
        if not mkr:
            # Tolerant pattern allowing missing leading "г" or space glitches / lost letters
            mkr = re.search(r'(?:^|\b)(?:([0-9]+)[xх×]?\s*)?(?:г)?руп[аи]\s*(?:к)?р\b.*?курс(?:ом)?\s+на\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,40}?)(?=[,\.\!\?;]|$)', ln, re.IGNORECASE)
        if not mkr and 'груп' in ln.lower() and 'курс' in ln.lower() and ' на ' in ln.lower():
            # Very loose fallback if 'КР' fragment dropped; capture after last 'на'
            after = ln.rsplit('на',1)[-1].strip()
            after = re.split(r'[,.!?:;]', after)[0].strip()
            if len(after) >= 3:
                class Dummy: pass
                mkr = Dummy(); mkr.group = lambda i: None if i==1 else after
        if mkr:
            try:
                log.info(f"KR_MATCH line='{ln}' groups={mkr.groups()}")
            except Exception:
                pass
            if mkr.group(1):
                try: kr_count = int(mkr.group(1))
                except: kr_count = 1
            kr_city = mkr.group(2)
        if kr_city:
            base_k = normalize_city_name(kr_city)
            base_k = UA_CITY_NORMALIZE.get(base_k, base_k)
            coords_k = CITY_COORDS.get(base_k) or (SETTLEMENTS_INDEX.get(base_k) if SETTLEMENTS_INDEX else None)
            if not coords_k and oblast_hdr:
                combo_k = f"{base_k} {oblast_hdr}"
                coords_k = CITY_COORDS.get(combo_k) or (SETTLEMENTS_INDEX.get(combo_k) if SETTLEMENTS_INDEX else None)
            if coords_k:
                lat, lng = coords_k
                label = UA_CITY_NORMALIZE.get(base_k, base_k).title()
                if kr_count > 1:
                    label += f" ({kr_count})"
                if oblast_hdr and oblast_hdr not in label.lower():
                    label += f" [{oblast_hdr.title()}]"
                multi_city_tracks.append({
                    'id': f"{mid}_mc{len(multi_city_tracks)+1}", 'place': label, 'lat': lat, 'lng': lng,
                    'threat_type': 'raketa', 'text': ln[:500], 'date': date_str, 'channel': channel,
                    'marker_icon': 'icon_balistic.svg', 'source_match': 'multiline_oblast_city_kr_group', 'count': kr_count
                })
                continue
        # Universal KR fallback (handles degraded OCR lines like '3х рупи  курсом на рилуки')
        low_ln = ln.lower()
        if ('курс' in low_ln and ' на ' in low_ln and ('груп' in low_ln or ' кр' in low_ln)):
            # Extract count if present at start or before 'груп'
            mcnt = re.search(r'^(\d+(?:-\d+)?)[xх×]?\s*', low_ln)
            count_guess = 1
            if mcnt:
                try: count_guess = int(mcnt.group(1))
                except: pass
            # Try after last 'на '
            parts = low_ln.rsplit(' на ', 1)
            if len(parts) == 2:
                cand = parts[1]
                cand = re.split(r'[\n,.!?:;]', cand)[0].strip()
                # strip residual non-letter chars
                cand_clean = re.sub(r"[^A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]", '', cand).strip()
                if len(cand_clean) >= 3:
                    base_f = normalize_city_name(cand_clean)
                    base_f = UA_CITY_NORMALIZE.get(base_f, base_f)
                    coords_f = CITY_COORDS.get(base_f) or (SETTLEMENTS_INDEX.get(base_f) if SETTLEMENTS_INDEX else None)
                    if not coords_f and oblast_hdr:
                        combo_f = f"{base_f} {oblast_hdr}"
                        coords_f = CITY_COORDS.get(combo_f) or (SETTLEMENTS_INDEX.get(combo_f) if SETTLEMENTS_INDEX else None)
                    # Fuzzy repair: if still not found, try restoring a potentially lost first letter
                    if not coords_f:
                        for pref in ['н','к','ч','п','г','с','в','б','д','м','т','л']:
                            test_base = pref + base_f
                            coords_try = CITY_COORDS.get(test_base) or (SETTLEMENTS_INDEX.get(test_base) if SETTLEMENTS_INDEX else None)
                            if not coords_try and oblast_hdr:
                                combo_try = f"{test_base} {oblast_hdr}"
                                coords_try = CITY_COORDS.get(combo_try) or (SETTLEMENTS_INDEX.get(combo_try) if SETTLEMENTS_INDEX else None)
                            if coords_try:
                                base_f = test_base
                                coords_f = coords_try
                                try: log.info(f"KR_FUZZ_REPAIR first_letter pref='{pref}' -> {base_f}")
                                except Exception: pass
                                break
                    if coords_f:
                        lat, lng = coords_f
                        label = UA_CITY_NORMALIZE.get(base_f, base_f).title()
                        if count_guess > 1:
                            label += f" ({count_guess})"
                        if oblast_hdr and oblast_hdr not in label.lower():
                            label += f" [{oblast_hdr.title()}]"
                        multi_city_tracks.append({
                            'id': f"{mid}_mc{len(multi_city_tracks)+1}", 'place': label, 'lat': lat, 'lng': lng,
                            'threat_type': 'raketa', 'text': ln[:500], 'date': date_str, 'channel': channel,
                            'marker_icon': 'icon_balistic.svg', 'source_match': 'multiline_oblast_city_kr_group_fallback2', 'count': count_guess
                        })
                        continue
        # Generic course fallback (any remaining 'курс' + ' на ' line not yet matched)
        if 'курс' in low_ln and ' на ' in low_ln and not any(tag in low_ln for tag in ['бпла','shahed']) and not any(mt['id'] == f"{mid}_mc{len(multi_city_tracks)+1}" for mt in multi_city_tracks):
            parts = low_ln.rsplit(' на ',1)
            if len(parts)==2:
                cand = re.split(r'[\n,.!?:;]', parts[1])[0].strip()
                cand = re.sub(r"[^A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]", '', cand)
                if len(cand) >= 3:
                    base_g = normalize_city_name(cand)
                    base_g = UA_CITY_NORMALIZE.get(base_g, base_g)
                    coords_g = CITY_COORDS.get(base_g) or (SETTLEMENTS_INDEX.get(base_g) if SETTLEMENTS_INDEX else None)
                    if not coords_g and oblast_hdr:
                        combo_g = f"{base_g} {oblast_hdr}"
                        coords_g = CITY_COORDS.get(combo_g) or (SETTLEMENTS_INDEX.get(combo_g) if SETTLEMENTS_INDEX else None)
                    # NEW: allow oblast center lookup if destination is a region (e.g. полтавщина / полтавщину)
                    if not coords_g and base_g in OBLAST_CENTERS:
                        coords_g = OBLAST_CENTERS[base_g]
                        try: log.info(f"GENERIC_COURSE_REGION dest='{base_g}' -> oblast center")
                        except Exception: pass
                    if not coords_g:
                        for pref in ['к','с','о','л','б','в','ж','т','я','у','р','н','п','г','ч']:
                            test = pref + base_g
                            coords_try = CITY_COORDS.get(test) or (SETTLEMENTS_INDEX.get(test) if SETTLEMENTS_INDEX else None)
                            if not coords_try and oblast_hdr:
                                combo_try = f"{test} {oblast_hdr}"
                                coords_try = CITY_COORDS.get(combo_try) or (SETTLEMENTS_INDEX.get(combo_try) if SETTLEMENTS_INDEX else None)
                            if coords_try:
                                base_g = test
                                coords_g = coords_try
                                try: log.info(f"GENERIC_FUZZ_CITY pref='{pref}' -> {base_g}")
                                except Exception: pass
                                break
                    if not coords_g:
                        for pref in ['н','к','ч','п','г','с','в','б','д','м','т','л']:
                            test_base = pref + base_g
                            coords_try = CITY_COORDS.get(test_base) or (SETTLEMENTS_INDEX.get(test_base) if SETTLEMENTS_INDEX else None)
                            if not coords_try and oblast_hdr:
                                combo_try = f"{test_base} {oblast_hdr}"
                                coords_try = CITY_COORDS.get(combo_try) or (SETTLEMENTS_INDEX.get(combo_try) if SETTLEMENTS_INDEX else None)
                            if coords_try:
                                base_g = test_base
                                coords_g = coords_try
                                try: log.info(f"GENERIC_COURSE_FUZZ pref='{pref}' -> {base_g}")
                                except Exception: pass
                                break
                    if coords_g:
                        lat, lng = coords_g
                        label = UA_CITY_NORMALIZE.get(base_g, base_g).title()
                        if oblast_hdr and oblast_hdr not in label.lower():
                            label += f" [{oblast_hdr.title()}]"
                        multi_city_tracks.append({
                            'id': f"{mid}_mc{len(multi_city_tracks)+1}", 'place': label, 'lat': lat, 'lng': lng,
                            'threat_type': 'raketa', 'text': ln[:500], 'date': date_str, 'channel': channel,
                            'marker_icon': 'icon_balistic.svg', 'source_match': 'multiline_oblast_city_course_generic', 'count': 1
                        })
                        continue
        # Fallback KR pattern if above failed but line mentions 'КР' and 'курс'
        if 'кр' in ln.lower() and 'курс' in ln.lower() and ' на ' in f" {ln.lower()} ":
            mkr2 = re.search(r'курс(?:ом)?\s+на\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,40}?)(?=[,\.\!\?;]|$)', ln, re.IGNORECASE)
            if mkr2:
                base_k2 = normalize_city_name(mkr2.group(1))
                base_k2 = UA_CITY_NORMALIZE.get(base_k2, base_k2)
                coords_k2 = CITY_COORDS.get(base_k2) or (SETTLEMENTS_INDEX.get(base_k2) if SETTLEMENTS_INDEX else None)
                if not coords_k2 and oblast_hdr:
                    combo_k2 = f"{base_k2} {oblast_hdr}"
                    coords_k2 = CITY_COORDS.get(combo_k2) or (SETTLEMENTS_INDEX.get(combo_k2) if SETTLEMENTS_INDEX else None)
                if not coords_k2:
                    for pref in ['н','к','ч','п','г','с','в','б','д','м','т','л']:
                        test_base = pref + base_k2
                        coords_try = CITY_COORDS.get(test_base) or (SETTLEMENTS_INDEX.get(test_base) if SETTLEMENTS_INDEX else None)
                        if not coords_try and oblast_hdr:
                            combo_try = f"{test_base} {oblast_hdr}"
                            coords_try = CITY_COORDS.get(combo_try) or (SETTLEMENTS_INDEX.get(combo_try) if SETTLEMENTS_INDEX else None)
                        if coords_try:
                            base_k2 = test_base
                            coords_k2 = coords_try
                            try: log.info(f"KR_FALLBACK_FUZZ pref='{pref}' -> {base_k2}")
                            except Exception: pass
                            break
                if coords_k2:
                    lat, lng = coords_k2
                    label = UA_CITY_NORMALIZE.get(base_k2, base_k2).title()
                    if oblast_hdr and oblast_hdr not in label.lower():
                        label += f" [{oblast_hdr.title()}]"
                    multi_city_tracks.append({
                        'id': f"{mid}_mc{len(multi_city_tracks)+1}", 'place': label, 'lat': lat, 'lng': lng,
                        'threat_type': 'raketa', 'text': ln[:500], 'date': date_str, 'channel': channel,
                        'marker_icon': 'icon_balistic.svg', 'source_match': 'multiline_oblast_city_kr_group_fallback', 'count': 1
                    })
                    continue
        # Разрешаем многословные названия (до 3 слов) до конца строки / знака препинания
        m = re.search(r'(\d+)[xх×]?\s*бпла.*?курс(?:ом)?\s+на\s+(?:н\.п\.?\s*)?([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,40}?)(?=[,\.\!\?;]|$)', ln, re.IGNORECASE)
        if m:
            count = int(m.group(1))
            city = m.group(2)
        else:
            # Дополнительно поддерживаем строки вида "7х БпЛА повз <місто> ..." или "БпЛА повз <місто>"
            m2 = re.search(r'бпла.*?курс(?:ом)?\s+на\s+(?:н\.п\.?\s*)?([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,40}?)(?=[,\.\!\?;]|$)', ln, re.IGNORECASE)
            if m2:
                count = 1
                city = m2.group(1)
            else:
                m3 = re.search(r'(\d+)[xх×]?\s*бпла.*?повз\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,40}?)(?=[,\.\!\?;]|$)', ln, re.IGNORECASE)
                if m3:
                    count = int(m3.group(1))
                    city = m3.group(2)
                else:
                    m4 = re.search(r'бпла.*?повз\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,40}?)(?=[,\.\!\?;]|$)', ln, re.IGNORECASE)
                    count = 1
                    city = m4.group(1) if m4 else None
        # --- NEW: Shahed lines inside multi-line block (e.g. '2 шахеди на Старий Салтів', '1 шахед на Мерефа / Борки') ---
        if not city:
            m_sha = re.search(r'^(?:([0-9]+)\s*[xх×]?\s*)?шахед(?:и|ів)?\s+на\s+(.+)$', ln.strip(), re.IGNORECASE)
            if m_sha:
                try:
                    scount = int(m_sha.group(1) or '1')
                except Exception:
                    scount = 1
                cities_part = m_sha.group(2)
                # Apply extract_course_targets to properly sanitize destinations (removes /район, etc.)
                raw_parts = extract_course_targets(cities_part)
                add_debug_log(f"Shahed pattern: '{cities_part}' -> sanitized targets: {raw_parts}", "multi_region")
                for ci in raw_parts:
                    c_raw = ci.strip().strip('.').strip()
                    if not c_raw or len(c_raw) < 2:
                        continue
                    cbase = normalize_city_name(c_raw)
                    cbase = UA_CITY_NORMALIZE.get(cbase, cbase)
                    coords_s = CITY_COORDS.get(cbase) or (SETTLEMENTS_INDEX.get(cbase) if SETTLEMENTS_INDEX else None)
                    add_debug_log(f"Shahed geocoding: '{ci}' -> normalized '{cbase}' -> coords {coords_s}", "multi_region")
                    if not coords_s and oblast_hdr:
                        combo_s = f"{cbase} {oblast_hdr}"
                        coords_s = CITY_COORDS.get(combo_s) or (SETTLEMENTS_INDEX.get(combo_s) if SETTLEMENTS_INDEX else None)
                    if not coords_s:
                        for pref in ['с','м','к','б','г','ч','н','п','т','в','л']:
                            test = pref + cbase
                            coords_try = CITY_COORDS.get(test) or (SETTLEMENTS_INDEX.get(test) if SETTLEMENTS_INDEX else None)
                            if not coords_try and oblast_hdr:
                                combo_try = f"{test} {oblast_hdr}"
                                coords_try = CITY_COORDS.get(combo_try) or (SETTLEMENTS_INDEX.get(combo_try) if SETTLEMENTS_INDEX else None)
                            if coords_try:
                                cbase = test; coords_s = coords_try; break
                    if not coords_s:
                        add_debug_log(f"No coords found for shahed dest '{ci}' (norm: '{cbase}')", "multi_region")
                        continue
                    lat, lng = coords_s
                    label = UA_CITY_NORMALIZE.get(cbase, cbase).title()
                    per_count = scount if len(raw_parts) == 1 else 1
                    if oblast_hdr and oblast_hdr not in label.lower():
                        label += f" [{oblast_hdr.title()}]"
                    
                    # Create multiple tracks for multiple shaheds
                    tracks_to_create = max(1, per_count)
                    for i in range(tracks_to_create):
                        track_label = label
                        if tracks_to_create > 1:
                            track_label += f" #{i+1}"
                        
                        # Add small coordinate offsets to prevent marker overlap
                        marker_lat = lat
                        marker_lng = lng
                        if tracks_to_create > 1:
                            # Create a chain pattern - drones one after another
                            offset_distance = 0.03  # ~3km offset between each drone
                            marker_lat += offset_distance * i
                            marker_lng += offset_distance * i * 0.5
                        
                        multi_city_tracks.append({
                            'id': f"{mid}_mc{len(multi_city_tracks)+1}", 'place': track_label, 'lat': marker_lat, 'lng': marker_lng,
                            'threat_type': 'shahed', 'text': clean_text(ln)[:500], 'date': date_str, 'channel': channel,
                            'marker_icon': 'icon_drone.svg', 'source_match': 'multiline_oblast_city_shahed', 'count': 1
                        })
                continue
        
        # --- NEW: Pattern "N на City1 N на City2..." (e.g. "Харківщина 1 на Вільшани 1 на Kov'яги 1 на Бірки") ---
        # Handles multiple "number + на + city" sequences in a single line WITHOUT repeating "БпЛА"
        # IMPORTANT: Pattern supports mixed Cyrillic/Latin city names (e.g. "Kov'яги")
        if re.search(r'(\d+)\s+на\s+[A-ZА-ЯІЇЄa-zа-яіїєґ\'\-]+', ln, re.IGNORECASE):
            # Find all "N на City" patterns in the line (supports mixed Cyrillic/Latin)
            multi_na_pattern = re.findall(r'(\d+)\s+на\s+([A-ZА-ЯІЇЄa-zа-яіїєґ\'\-]+(?:/[A-ZА-ЯІЇЄa-zа-яіїєґ\'\-]+)?)', ln, re.IGNORECASE)
            
            if len(multi_na_pattern) > 1:  # Multiple "N на City" patterns found - this is our case!
                add_debug_log(f"MULTI-NA pattern found {len(multi_na_pattern)} cities in line: '{ln}'", "multi_na")
                add_debug_log(f"MULTI-NA current region header (oblast_hdr): '{oblast_hdr}'", "multi_na")
                
                # Regional overrides for cities with duplicate names in different oblasts
                REGIONAL_CITY_COORDS = {
                    'харківщина': {
                        'вільшани': (50.177, 35.398),  # Вільшани, Харківська обл., Богодухівський район
                        'ковяги': (49.75, 36.12),       # Ков'яги, Харківська обл.
                        'березівка': (49.583, 36.450),  # Березівка, Харківська обл.
                    },
                    # Add more regional overrides as needed
                }
                
                for count_str, city_raw in multi_na_pattern:
                    count = int(count_str) if count_str.isdigit() else 1
                    city_name = city_raw.strip()
                    
                    # Normalize city name (handle Latin/Cyrillic mix)
                    city_norm = normalize_city_name(city_name)
                    city_norm = UA_CITY_NORMALIZE.get(city_norm, city_norm)
                    
                    # TRY 1: Regional override if oblast_hdr is set (e.g. "Харківщина:")
                    coords = None
                    if oblast_hdr and oblast_hdr in REGIONAL_CITY_COORDS:
                        region_coords = REGIONAL_CITY_COORDS[oblast_hdr]
                        coords = region_coords.get(city_norm)
                        if coords:
                            add_debug_log(f"  Multi-NA city: '{city_name}' ({count}x) -> norm: '{city_norm}' -> REGIONAL OVERRIDE coords: {coords} (oblast: {oblast_hdr})", "multi_na")
                    
                    # TRY 2: Default database lookup if no regional override
                    if not coords:
                        coords = CITY_COORDS.get(city_norm)
                        if coords:
                            add_debug_log(f"  Multi-NA city: '{city_name}' ({count}x) -> norm: '{city_norm}' -> DATABASE coords: {coords}", "multi_na")
                    
                    # TRY 3: Settlements index fallback
                    if not coords and SETTLEMENTS_INDEX:
                        coords = SETTLEMENTS_INDEX.get(city_norm)
                        if coords:
                            add_debug_log(f"  Multi-NA city: '{city_name}' ({count}x) -> norm: '{city_norm}' -> SETTLEMENTS coords: {coords}", "multi_na")
                    
                    if not coords:
                        add_debug_log(f"  WARNING: No coordinates for '{city_name}' (normalized: '{city_norm}', oblast: {oblast_hdr})", "multi_na")
                        continue
                    
                    if coords:
                        lat, lng = coords
                        threat_type, icon = classify(ln)
                        
                        # Create separate markers for each count
                        for i in range(count):
                            place_label = city_norm.title()
                            if count > 1:
                                place_label += f" #{i+1}"
                            
                            # Add offset for multiple drones at same location
                            marker_lat, marker_lng = lat, lng
                            if count > 1:
                                offset_distance = 0.03  # ~3km offset
                                marker_lat += offset_distance * i
                                marker_lng += offset_distance * i * 0.5
                            
                            multi_city_tracks.append({
                                'id': f"{mid}_multi_na_{len(multi_city_tracks)+1}",
                                'place': place_label,
                                'lat': marker_lat,
                                'lng': marker_lng,
                                'threat_type': threat_type,
                                'text': clean_text(ln)[:500],
                                'date': date_str,
                                'channel': channel,
                                'marker_icon': icon,
                                'source_match': 'multi_na_pattern',
                                'count': 1
                            })
                        add_debug_log(f"  Created {count} marker(s) for '{city_norm.title()}'", "multi_na")
                    else:
                        add_debug_log(f"  WARNING: No coordinates for '{city_name}' (normalized: '{city_norm}')", "multi_na")
                
                add_debug_log(f"Multi-NA pattern processed: {len(multi_city_tracks)} total markers created", "multi_na")
                continue  # Skip further processing of this line
        
        # --- NEW: Simple "X БпЛА на <city>" pattern (e.g. '1 БпЛА на Козелець', '2 БпЛА на Куликівку') ---
        # Also handle "Ціль на <city>" pattern for missile/rocket targets
        if not city:
            print(f"DEBUG: Checking simple БпЛА/Ціль pattern for line: '{ln}'")
            
            # Pattern 1: "Ціль на <city>" - rocket/missile target
            m_target = re.search(r'ціль\s+на\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,40}?)(?=\s|$|[,\.\!\?;\[])', ln, re.IGNORECASE)
            if m_target:
                city = m_target.group(1).strip()
                count = 1  # Default count for target
                print(f"DEBUG: Found 'Ціль на' pattern - city: '{city}'")
            # Pattern 2: "X БпЛА на <city>"
            elif re.search(r'(\d+)\s+бпла\s+на\s+', ln, re.IGNORECASE):
                m_simple = re.search(r'(\d+)\s+бпла\s+на\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,40}?)(?=\s|$|[,\.\!\?;])', ln, re.IGNORECASE)
                if m_simple:
                    try:
                        count = int(m_simple.group(1))
                    except Exception:
                        count = 1
                    city = m_simple.group(2).strip()
                    print(f"DEBUG: Found simple БпЛА pattern - count: {count}, city: '{city}'")
            # Pattern 3: "БпЛА на <city>" without count
            elif re.search(r'бпла\s+на\s+[A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,}', ln, re.IGNORECASE):
                # Fallback for "БпЛА на <city>" without count - handle cities with parentheses like "Кривий ріг (Дніпропетровщина)"
                m_simple_no_count = re.search(r'бпла\s+на\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,}?)(?:\s*\([^)]*\))?(?=\s*$|[,\.\!\?;])', ln, re.IGNORECASE)
                if m_simple_no_count:
                    count = 1
                    city = m_simple_no_count.group(1).strip()
                    print(f"DEBUG: Found simple БпЛА pattern (no count) - city: '{city}'")
        
        # --- NEW: Handle "X у напрямку City1, City2" pattern (e.g. "4 у напрямку Карлівки, Полтави") ---
        if not city:
            print(f"DEBUG: Checking 'X у напрямку' pattern for line: '{ln}'")
            m_naprymku = re.search(r'(\d+)\s+у\s+напрямку\s+([А-ЯІЇЄЁа-яіїєё\'\-\s,]{5,})(?=\s*$|[,\.\!\?;])', ln, re.IGNORECASE)
            if m_naprymku:
                try:
                    count = int(m_naprymku.group(1))
                except Exception:
                    count = 1
                cities_raw = m_naprymku.group(2).strip()
                print(f"DEBUG: Found 'у напрямку' pattern - count: {count}, cities: '{cities_raw}'")
                
                # Split cities by comma
                cities_list = [c.strip() for c in cities_raw.split(',') if c.strip()]
                for city_name in cities_list:
                    base = normalize_city_name(city_name)
                    base = UA_CITY_NORMALIZE.get(base, base)
                    coords = CITY_COORDS.get(base)
                    
                    # If not found, try to handle declensions (ending with -и, -ми, -у, etc)
                    if not coords and base:
                        if base.endswith('і') or base.endswith('и'):
                            base_nom = base[:-1] + 'а'  # карлівки -> карлівка
                            coords = CITY_COORDS.get(base_nom)
                        elif base.endswith('у'):
                            base_nom = base[:-1] + 'а'  # полтаву -> полтава  
                            coords = CITY_COORDS.get(base_nom)
                        elif base.endswith('ми'):
                            base_nom = base[:-2] + 'а'  # київми -> києва -> doesn't work, try other variants
                            coords = CITY_COORDS.get(base_nom)
                    
                    if coords:
                        lat, lng = coords
                        multi_city_tracks.append({
                            'id': f"{mid}_naprymku{len(multi_city_tracks)+1}", 'place': city_name.title(), 'lat': lat, 'lng': lng,
                            'threat_type': 'shahed', 'text': clean_text(ln)[:500], 'date': date_str, 'channel': channel,
                            'marker_icon': 'icon_drone.svg', 'source_match': 'naprymku_pattern', 'count': count
                        })
                        print(f"DEBUG: Added marker for '{city_name}' at {lat}, {lng}")
                if multi_city_tracks:
                    continue
                
        # --- NEW: Handle "X БпЛА City1 / City2" pattern (e.g. "2х БпЛА Гнідин / Бориспіль") ---
        if not city:
            print(f"DEBUG: Checking БпЛА city/city pattern for line: '{ln}'")
            m_cities = re.search(r'(\d+)х?\s+бпла\s+(?:на\s+)?([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,30}?)\s*/\s*([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,30}?)(?=\s|$|[,\.\!\?;])', ln, re.IGNORECASE)
            if m_cities:
                try:
                    count = int(m_cities.group(1))
                except Exception:
                    count = 1
                city1 = m_cities.group(2).strip()
                city2 = m_cities.group(3).strip()
                print(f"DEBUG: Found БпЛА city/city pattern - count: {count}, cities: '{city1}' / '{city2}'")
                
                # Process both cities separately
                for city_name in [city1, city2]:
                    base = normalize_city_name(city_name)
                    base = UA_CITY_NORMALIZE.get(base, base)
                    coords = CITY_COORDS.get(base)
                    if coords:
                        print(f"DEBUG: Creating БпЛА track for {city_name} at {coords}")
                        multi_city_tracks.append({
                            'lat': coords[0],
                            'lon': coords[1],
                            'name': city_name,
                            'type': 'БпЛА',
                            'time': date_str,
                            'id': mid,
                            'message': text[:100] + ('...' if len(text) > 100 else ''),
                            'channel': channel
                        })
                    else:
                        print(f"DEBUG: No coordinates found for {city_name} (base: {base})")
                
                # Set city to processed to prevent further processing
                city = f"{city1} / {city2}"
        # --- NEW: Handle "між X та Y" pattern (e.g. "між Корюківкою та Меною") ---
        if not city:
            m_between = re.search(r'між\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,30}?)\s+та\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,30}?)(?=\s|$|[,\.\!\?;])', ln, re.IGNORECASE)
            if m_between:
                city1 = m_between.group(1).strip()
                city2 = m_between.group(2).strip()
                # Try to geocode both cities and place marker at midpoint
                base1 = normalize_city_name(city1)
                base2 = normalize_city_name(city2)
                base1 = UA_CITY_NORMALIZE.get(base1, base1)
                base2 = UA_CITY_NORMALIZE.get(base2, base2)
                
                coords1 = CITY_COORDS.get(base1) or (SETTLEMENTS_INDEX.get(base1) if SETTLEMENTS_INDEX else None)
                coords2 = CITY_COORDS.get(base2) or (SETTLEMENTS_INDEX.get(base2) if SETTLEMENTS_INDEX else None)
                
                if not coords1 and oblast_hdr:
                    combo1 = f"{base1} {oblast_hdr}"
                    coords1 = CITY_COORDS.get(combo1) or (SETTLEMENTS_INDEX.get(combo1) if SETTLEMENTS_INDEX else None)
                if not coords2 and oblast_hdr:
                    combo2 = f"{base2} {oblast_hdr}"
                    coords2 = CITY_COORDS.get(combo2) or (SETTLEMENTS_INDEX.get(combo2) if SETTLEMENTS_INDEX else None)
                
                if coords1 and coords2:
                    # Place marker at midpoint
                    lat = (coords1[0] + coords2[0]) / 2
                    lng = (coords1[1] + coords2[1]) / 2
                    label = f"Між {base1.title()} та {base2.title()}"
                    if oblast_hdr and oblast_hdr not in label.lower():
                        label += f" [{oblast_hdr.title()}]"
                    
                    # Extract count from beginning of line if present
                    count_match = re.search(r'^(\d+(?:-\d+)?)\s*бпла', ln, re.IGNORECASE)
                    count = int(count_match.group(1)) if count_match else 1
                    
                    multi_city_tracks.append({
                        'id': f"{mid}_mc{len(multi_city_tracks)+1}", 'place': label, 'lat': lat, 'lng': lng,
                        'threat_type': 'shahed', 'text': clean_text(ln)[:500], 'date': date_str, 'channel': channel,
                        'marker_icon': 'icon_drone.svg', 'source_match': 'multiline_oblast_city_between', 'count': count
                    })
                    continue
        
        # --- NEW: Handle "неподалік X" pattern (e.g. "неподалік Ічні") ---
        if not city:
            m_near = re.search(r'неподалік\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,30}?)(?=\s|$|[,\.\!\?;])', ln, re.IGNORECASE)
            if m_near:
                city = m_near.group(1).strip()
                # Extract count from beginning of line if present
                count_match = re.search(r'^(\d+(?:-\d+)?)\s*бпла', ln, re.IGNORECASE)
                count = int(count_match.group(1)) if count_match else 1
        
        # --- NEW: Handle "в районі X" pattern (e.g. "в районі Конотопу") ---
        if not city:
            m_area = re.search(r'в\s+районі\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,30}?)(?=\s|$|[,\.\!\?;])', ln, re.IGNORECASE)
            if m_area:
                city = m_area.group(1).strip()
                # Extract count from beginning of line if present
                count_match = re.search(r'^(\d+(?:-\d+)?)\s*бпла', ln, re.IGNORECASE)
                count = int(count_match.group(1)) if count_match else 1
        
        if city:
            print(f"DEBUG: Processing city '{city}' with oblast_hdr '{oblast_hdr}' and count {count}")
            base = normalize_city_name(city)
            print(f"DEBUG: Normalized city name: '{base}'")
            # Простейшая нормализация винительного падежа -> именительный ("велику димерку" -> "велика димерка")
            if base.endswith('у димерку') and 'велик' in base:
                base = 'велика димерка'
            # Общая морфология: заменяем окончания "ку"->"ка", "ю"->"я" для последнего слова
            if base.endswith('ку '):
                base = base[:-3] + 'ка '
            elif base.endswith('ку'):
                base = base[:-2] + 'ка'
            if base.endswith('ю '):
                base = base[:-3] + 'я '
            elif base.endswith('ю'):
                base = base[:-1] + 'я'
            # Приводим многословные формы через UA_CITY_NORMALIZE если есть
            base = UA_CITY_NORMALIZE.get(base, base)
            if base == 'троєщину':
                base = 'троєщина'
                
            # Use enhanced coordinate lookup with Nominatim fallback and region context
            coords = get_coordinates_enhanced(base, region=oblast_hdr, context="БпЛА курсом на")
            
            print(f"DEBUG: Enhanced lookup for '{base}'" + (f" in {oblast_hdr}" if oblast_hdr else "") + f": {coords}")
            
            if not coords and oblast_hdr:
                # Legacy combo lookup as fallback
                combo = f"{base} {oblast_hdr}"
                print(f"DEBUG: Trying legacy combo lookup for '{combo}'")
                coords = CITY_COORDS.get(combo)
                if not coords and SETTLEMENTS_INDEX:
                    coords = SETTLEMENTS_INDEX.get(combo)
                print(f"DEBUG: Combo lookup result: {coords}")
            if not coords:
                print(f"DEBUG: Calling ensure_city_coords_with_message_context for '{base}' with oblast context '{oblast_hdr}'")
                # Try with full message context first to get oblast-specific coordinates
                context_message = f"{oblast_hdr} {original_text if 'original_text' in locals() else text}"
                coords = ensure_city_coords_with_message_context(base, context_message)
                if not coords:
                    print(f"DEBUG: Context-based lookup failed, trying standard ensure_city_coords for '{base}'")
                    coords = ensure_city_coords(base)
                print(f"DEBUG: ensure_city_coords result: {coords}")
            if coords:
                print(f"DEBUG: Found coords {coords} for city '{base}', creating track")
                # Handle both 2-tuple (lat, lng) and 3-tuple (lat, lng, approx_flag) returns
                if len(coords) == 3:
                    lat, lng, approx_flag = coords
                else:
                    lat, lng = coords
                    approx_flag = False
                threat_type, icon = 'shahed', 'icon_drone.svg'
                label = UA_CITY_NORMALIZE.get(base, base).title()
                if oblast_hdr and oblast_hdr not in label.lower():
                    label += f" [{oblast_hdr.title()}]"
                
                # Create multiple tracks for multiple drones instead of one track with count
                tracks_to_create = max(1, count)
                for i in range(tracks_to_create):
                    track_label = label
                    if tracks_to_create > 1:
                        track_label += f" #{i+1}"
                    
                    # Add small coordinate offsets to prevent marker overlap
                    marker_lat = lat
                    marker_lng = lng
                    if tracks_to_create > 1:
                        # Create a chain pattern - drones one after another
                        offset_distance = 0.03  # ~3km offset between each drone
                        marker_lat += offset_distance * i
                        marker_lng += offset_distance * i * 0.5
                    
                    print(f"DEBUG: Creating track {i+1}/{tracks_to_create} with label '{track_label}' at {marker_lat}, {marker_lng}")
                    multi_city_tracks.append({
                        'id': f"{mid}_mc{len(multi_city_tracks)+1}", 'place': track_label, 'lat': marker_lat, 'lng': marker_lng,
                        'threat_type': threat_type, 'text': clean_text(ln)[:500], 'date': date_str, 'channel': channel,
                        'marker_icon': icon, 'source_match': 'multiline_oblast_city', 'count': 1
                    })
            else:
                print(f"DEBUG: No coordinates found for city '{base}'")
    print(f"DEBUG: Multi-city tracks processing complete. Found {len(multi_city_tracks)} tracks")
    add_debug_log(f"Multi-region processing complete: {len(multi_city_tracks)} markers from {processed_lines_count} lines", "multi_region")
    
    if multi_city_tracks:
        print(f"DEBUG: Returning {len(multi_city_tracks)} multi-city tracks")
        add_debug_log(f"Returning {len(multi_city_tracks)} multi-city tracks: {[t['place'] for t in multi_city_tracks]}", "multi_region")
        # Combine with priority result if available
        if 'priority_result' in locals() and priority_result:
            combined_result = priority_result + multi_city_tracks
            add_debug_log(f"Combined priority result ({len(priority_result)}) with multi-city tracks ({len(multi_city_tracks)}) = {len(combined_result)} total", "priority_combine")
            return combined_result
        return multi_city_tracks
    else:
        # If no multi-city tracks were created, continue with main parsing logic
        # This allows regional direction messages like "БпЛА на сході Сумщини" to be processed by regional parser
        add_debug_log(f"No multi-city tracks created, continuing to main parser", "multi_region_fallback")
    # --- Detect and split multiple city targets in one message ---
    import re
    multi_city_tracks = []
    # 1. Patterns: 'на <город>', 'повз <город>'
    # Захватываем одно- или многословные названия после "на" / "повз" до знака препинания / конца строки
    city_patterns = re.findall(r'(?:на|повз)\s+([A-Za-zА-Яа-яЇїІіЄєҐґʼ`’\-\s]{3,40}?)(?=[,\.\n;:!\?]|$)', text.lower())
    # 2. Patterns: перечисление через запятую или слэш (например: "шишаки, глобине, ромодан" или "малин/гранітне")
    # Только если в сообщении нет явного одного города в начале
    city_enumerations = []
    for part in re.split(r'[\n\|]', text.lower()):
        # ищем перечисления через запятую
        if ',' in part:
            city_enumerations += [c.strip() for c in part.split(',') if len(c.strip()) > 2]
        # ищем перечисления через слэш
        if '/' in part:
            city_enumerations += [c.strip() for c in part.split('/') if len(c.strip()) > 2]
    # Объединяем все найденные города
    all_cities = set(city_patterns + city_enumerations)
    # Фильтруем по наличию в CITY_COORDS (или SETTLEMENTS_INDEX)
    found_cities = []
    def _resolve_city_candidate(raw: str):
        cand = raw.strip().lower()
        cand = re.sub(r'["“”«»\(\)\[\]]','', cand)
        
        # CRITICAL: Remove trailing geographic qualifiers (e.g., "Канів по межі з Київщиною" → "Канів")
        trailing_patterns = [
            r'\s+по\s+межі\s+з\s+.*$',
            r'\s+на\s+межі\s+з\s+.*$',
            r'\s+в\s+районі\s+.*$',
            r'\s+біля\s+кордону\s+.*$',
            r'\s+на\s+околицях\s+.*$',
            r'\s+поблизу\s+.*$',
        ]
        for pattern in trailing_patterns:
            cand = re.sub(pattern, '', cand).strip()
        
        cand = re.sub(r'\s+',' ', cand)
        # Пробуем от длинного к короткому (до 3 слов достаточно для наших случаев)
        words = cand.split()
        if not words:
            return None
        for ln in range(min(3, len(words)), 0, -1):
            sub = ' '.join(words[:ln])
            base = UA_CITY_NORMALIZE.get(sub, sub)
            if base in CITY_COORDS or (SETTLEMENTS_INDEX and base in SETTLEMENTS_INDEX):
                return base
            # Морфология окончания винительного/родительного последнего слова
            sub_mod = re.sub(r'у\b','а', sub)
            sub_mod = re.sub(r'ю\b','я', sub_mod)
            sub_mod = re.sub(r'ої\b','а', sub_mod)
            base2 = UA_CITY_NORMALIZE.get(sub_mod, sub_mod)
            if base2 in CITY_COORDS or (SETTLEMENTS_INDEX and base2 in SETTLEMENTS_INDEX):
                return base2
        return UA_CITY_NORMALIZE.get(cand, cand)
    for city in all_cities:
        norm = _resolve_city_candidate(city)
        if not norm:
            continue
        coords = CITY_COORDS.get(norm)
        if not coords and SETTLEMENTS_INDEX:
            coords = SETTLEMENTS_INDEX.get(norm)
        if coords:
            found_cities.append((norm, coords))
    # Если найдено 2 и более города — создаём отдельный маркер для каждого
    if len(found_cities) >= 2:
        threat_type, icon = 'shahed', 'icon_drone.svg'  # можно доработать auto-classify
        
        # Extract course information for Shahed threats
        course_info = None
        if threat_type == 'shahed':
            course_info = extract_shahed_course_info(original_text)
        
        for idx, (city, (lat, lng)) in enumerate(found_cities, 1):
            track = {
                'id': f"{mid}_mc{idx}", 'place': city.title(), 'lat': lat, 'lng': lng,
                'threat_type': threat_type, 'text': clean_text(original_text)[:500], 'date': date_str, 'channel': channel,
                'marker_icon': icon, 'source_match': 'multi_city_auto'
            }
            
            # Add course information if available
            if course_info:
                track.update({
                    'course_source': course_info.get('source_city'),
                    'course_target': course_info.get('target_city'),
                    'course_direction': course_info.get('course_direction'),
                    'course_type': course_info.get('course_type')
                })
            
            multi_city_tracks.append(track)
        if multi_city_tracks:
            return multi_city_tracks
    """Extract coordinates or try simple city geocoding (lightweight)."""
    original_text = text
    # ---------------- Global region (oblast) hint detection for universal settlement binding ----------------
    region_hint_global = None
    try:
        low_rt = original_text.lower()
        for obl_name in OBLAST_CENTERS.keys():
            if obl_name in low_rt:
                region_hint_global = obl_name  # first hit
                break
    except Exception:
        region_hint_global = None
    # Additional: detect section headers like "Сумщина:" "Полтавщина:" at line starts to set region hint
    if not region_hint_global:
        for line in original_text.split('\n'):
            l = line.strip().lower()
            if l.endswith(':'):
                base = l[:-1]
                if base in OBLAST_CENTERS:
                    region_hint_global = base
                    break

    def region_enhanced_coords(base_name: str, region_hint_override: str = None):
        """Resolve coordinates for a settlement name by weighted order (remote first):
        1) External geocode (region-qualified, then plain)
        2) Exact local datasets (CITY_COORDS, SETTLEMENTS_INDEX)
        3) Fuzzy approximate local match (Levenshtein-like via difflib)

        Rationale (user requirement): prefer freshest external resolution, fall back to local known list,
        and only then attempt approximate similarity mapping.
        """
        if not base_name:
            return None
        name_norm = UA_CITY_NORMALIZE.get(base_name, base_name).strip().lower()
        # --- 1. Remote geocode first ---
        region_for_query = region_hint_override or region_hint_global
        if region_for_query:
            canon = REGION_GEOCODE_CANON.get(region_for_query)
            if canon:
                region_for_query = canon
        # Region-qualified
        if OPENCAGE_API_KEY and region_for_query:
            try:
                combo = f"{name_norm} {region_for_query}".replace('  ', ' ').strip()
                c = geocode_opencage(combo)
                if c and 43.0 <= c[0] <= 53.8 and 20.0 <= c[1] <= 42.0:
                    return c
            except Exception:
                pass
        # Plain name remote
        if OPENCAGE_API_KEY:
            try:
                c = geocode_opencage(name_norm)
                if c and 43.0 <= c[0] <= 53.8 and 20.0 <= c[1] <= 42.0:
                    return c
            except Exception:
                pass
        # --- 2. Exact local datasets ---
        coord = CITY_COORDS.get(name_norm)
        if not coord and SETTLEMENTS_INDEX:
            coord = SETTLEMENTS_INDEX.get(name_norm)
        # Explicit settlement fallback (manual corrections for mis-geocoded small places)
        if not coord:
            coord = SETTLEMENT_FALLBACK.get(name_norm)
        if coord:
            return coord
        # --- 3. Fuzzy approximate search (only if not found) ---
        try:
            if SETTLEMENTS_INDEX:
                import difflib
                # Choose candidate list limited for performance
                names = list(SETTLEMENTS_INDEX.keys())
                # High cutoff to avoid bad matches
                best = difflib.get_close_matches(name_norm, names, n=1, cutoff=0.86)
                if best:
                    b = best[0]
                    return SETTLEMENTS_INDEX.get(b)
        except Exception:
            pass
        return None
    # ---- Fundraising / donation solicitation handling ----
    # Previous behavior: fully suppressed entire message if donation links found (blocked napramok multi-line threat posts with footer links)
    # New behavior: If donation lines present BUT the message also contains threat indicators, strip only the donation lines and continue parsing.
    low_full = original_text.lower()
    DONATION_KEYS = [
        'монобанк','monobank','mono.bank','privat24','приват24','реквізит','реквизит','донат','donat','iban','paypal','patreon','send.monobank.ua','jar/','банка: http','карта(','карта(monobank)','карта(privat24)','підтримати канал'
    ]
    donation_present = any(k in low_full for k in DONATION_KEYS) or re.search(r'\b\d{16}\b', low_full)
    # Pure subscription / invite promo suppression (no threats, mostly t.me invite links + short call to action)
    if not any(w in low_full for w in ['бпла','дрон','шахед','shahed','ракета','каб','артил','града','смерч','ураган','mlrs','iskander','s-300','s300','border','trivoga','тривога','повітряна тривога']) and \
       low_full.count('t.me/') >= 1 and len(re.sub(r'\s+',' ', low_full)) < 260 and \
       len([ln for ln in low_full.splitlines() if ln.strip()]) <= 6:
        if all(tok not in low_full for tok in ['загроза','укритт','alert','launch','start','вильот','вихід','пуски','air','strike']):
            return None
    if donation_present:
        # Threat keyword heuristic (lightweight; don't rely on later THREAT_KEYS definition yet)
        threat_tokens = ['бпла','дрон','шахед','shahed','geran','ракета','ракети','missile','iskander','s-300','s300','каб','артил','града','смерч','ураган','mlrs']
        has_threat_word = any(tok in low_full for tok in threat_tokens)
        if has_threat_word:
            # НЕ удаляем строки с донатами если есть угрозы - просто продолжаем парсинг
            log.debug(f"mid={mid} donation_present but has_threats - continuing without stripping")
            # text остается без изменений
        else:
            return [{
                'id': str(mid), 'place': None, 'lat': None, 'lng': None,
                'threat_type': None, 'text': original_text[:500], 'date': date_str, 'channel': channel,
                'list_only': True, 'suppress': True, 'suppress_reason': 'donation_only'
            }]
    # --- Universal link stripping (any clickable invite / http) ---
    def _strip_links(s: str) -> str:
        if not s:
            return s
        # markdown links [text](url)
        # handle bold inside brackets [**Text**](url) by stripping ** first
        s = re.sub(r'\*\*','', s)
        s = re.sub(r'\[([^\]]{0,80})\]\((https?://|t\.me/)[^\)]+\)', lambda m: (m.group(1) or '').strip(), s, flags=re.IGNORECASE)
        # bare urls
        s = re.sub(r'(https?://\S+|t\.me/\S+)', '', s, flags=re.IGNORECASE)
        # collapse whitespace and drop empty lines
        cleaned = []
        for ln in s.splitlines():
            ln2 = ln.strip()
            if not ln2:
                continue
            # pure decoration (arrows, bullets) or subscribe call to action lines
            if re.fullmatch(r'[>➡→\-\s·•]*', ln2):
                continue
            # remove any line that is just a subscribe CTA or starts with arrow+subscribe
            if re.search(r'(підписатись|підписатися|підписатися|подписаться|подпишись|subscribe)', ln2, re.IGNORECASE):
                continue
            # remove arrow+subscribe pattern specifically
            if re.search(r'[➡→>]\s*підписатися', ln2, re.IGNORECASE):
                continue
            cleaned.append(ln2)
        return '\n'.join(cleaned)
    new_text = _strip_links(text)
    if new_text != text:
        text = new_text
    new_orig = _strip_links(original_text)
    if new_orig != original_text:
        original_text = new_orig
    # --- Explicit launch site detection (multi-line). Create one marker per detected launch location.
    low_work = text.lower()
    if ('пуск' in low_work or 'пуски' in low_work or '+ пуски' in low_work):
        # find quoted or dash-separated site tokens: «Name», "Name", or after 'з ' preposition
        sites_found = set()
        # Quoted tokens
        for m in re.findall(r'«([^»]{2,40})»', text):
            sites_found.add(m.strip().lower())
        for m in re.findall(r'"([^"\n]{2,40})"', text):
            sites_found.add(m.strip().lower())
        # Phrases after 'з ' (from) up to comma
        for m in re.findall(r'з\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-]{2,40})', low_work):
            sites_found.add(m.strip().lower())
        # tokens after 'аеродрому' or 'аэродрома' inside quotes
        for m in re.findall(r'аеродром[ау]\s+«([^»]{2,40})»', low_work):
            sites_found.add(m.strip().lower())
        for m in re.findall(r'аэродром[ау]\s+«([^»]{2,40})»', low_work):
            sites_found.add(m.strip().lower())
        tracks = []
        threat_type = 'pusk'
        icon = 'pusk.png'
        idx = 0
        for raw_site in sites_found:
            norm_key = raw_site.replace(' — ','-').replace(' – ','-').replace('—','-').replace('–','-')
            norm_key = norm_key.replace('  ',' ').strip()
            base_variants = [norm_key, norm_key.replace('полігон ','').replace('полигон ','')]
            coord = None
            chosen_name = raw_site
            for bv in base_variants:
                if bv in LAUNCH_SITES:
                    coord = LAUNCH_SITES[bv]
                    chosen_name = bv
                    break
            if not coord:
                continue
            idx += 1
            lat,lng = coord
            tracks.append({
                'id': f"{mid}_l{idx}", 'place': chosen_name.title(), 'lat': lat, 'lng': lng,
                'threat_type': threat_type, 'text': original_text[:500], 'date': date_str, 'channel': channel,
                'marker_icon': icon, 'source_match': 'launch_site'
            })
        if tracks:
            return tracks
    # ---- Daily / periodic situation summary ("ситуація станом на HH:MM" + sectional bullets) ----
    # User request: do NOT create map markers for such aggregated status reports.
    # Heuristics: phrase "ситуація станом" (uk) or "ситуация на" (ru), OR presence of 2+ bullet headers like "• авіація", "• бпла", "• флот" in same message.
    bullet_headers = 0
    for hdr in ['• авіація', '• авиа', '• бпла', '• дро', '• флот', '• кораб', '• ракети', '• ракеты']:
        if hdr in low_full:
            bullet_headers += 1
    if re.search(r'ситуац[ія][яi]\s+станом', low_full) or re.search(r'ситуац[ия]\s+на\s+\d{1,2}:\d{2}', low_full) or bullet_headers >= 2:
        # User clarified: completely skip (no site display at all)
        return [{
            'id': str(mid), 'place': None, 'lat': None, 'lng': None,
            'threat_type': None, 'text': original_text[:800], 'date': date_str, 'channel': channel,
            'list_only': True, 'summary': True, 'suppress': True
        }]
    # ---- Imprecise directional-only messages (no exact city location) suppression ----
    # User request: messages that only state relative / directional movement without a clear city position
    # Examples: "групи ... рухаються північніше X у напрямку Y"; "... курс західний (місто)"; region-only with direction
    # Allow cases with explicit target form "курс на <city>" (precise intent) or patterns we already map like 'повз <city>' or multi-city slash/comma lists.
    def _has_threat_local(txt: str):
        l = txt.lower()
        return any(k in l for k in ['бпла','дрон','шахед','shahed','geran','ракета','ракети','missile'])
    lower_all = original_text.lower()
    if _has_threat_local(lower_all):
        directional_course = 'курс' in lower_all and any(w in lower_all for w in ['північ','півден','схід','захід']) and not re.search(r'курс(?:ом)?\s+на\s+[A-Za-zА-Яа-яЇїІіЄєҐґ\-]{3,}', lower_all)
        relative_dir_tokens = any(tok in lower_all for tok in ['північніше','південніше','східніше','західніше'])
        # Multi-city list heuristic (comma or slash separated multiple city tokens at start)
        multi_city_pattern = r"^[^\n]{0,120}?([A-Za-zА-Яа-яЇїІіЄєҐґ'`’ʼ\-]{3,}\s*,\s*){1,}[A-Za-zА-Яа-яЇїІіЄєҐґ'`’ʼ\-]{3,}"
        multi_city_enumeration = bool(re.match(multi_city_pattern, lower_all)) or ('/' in lower_all)
        has_pass_near = 'повз ' in lower_all
        if (directional_course or relative_dir_tokens) and not has_pass_near and not multi_city_enumeration:
            return [{
                'id': str(mid), 'place': None, 'lat': None, 'lng': None,
                'threat_type': None, 'text': original_text[:500], 'date': date_str, 'channel': channel,
                'list_only': True, 'suppress': True, 'suppress_reason': 'imprecise_direction_only'
            }]
    # Не удаляем полностью "Повітряна тривога" теперь: нужно показывать в списке событий.
    # Сохраняем текст как есть для event list.
    # Убираем markdown * _ ` и базовые эмодзи-иконки в начале строк
    text = re.sub(r'[\*`_]+', '', text)
    # Удаляем ведущие эмодзи/иконки перед словами
    text = re.sub(r'^[\W_]+', '', text)
    # Общий набор ключевых слов угроз
    THREAT_KEYS = ['бпла','дрон','шахед','shahed','geran','ракета','ракети','missile','iskander','s-300','s300','каб','артил','града','смерч','ураган','mlrs','avia','авіа','авиа','бомба','високошвидкісн']
    def has_threat(txt: str):
        l = txt.lower()
        return any(k in l for k in THREAT_KEYS)
    
    # PRIORITY: Structured messages with regional headers (e.g., "Область:\n city details")
    if not _disable_multiline and has_threat(original_text):
        import re as _struct_re
        # Look for pattern: "RegionName:\n threats with cities"
        region_header_pattern = r'^([А-Яа-яЇїІіЄєҐґ]+щина):\s*$'
        text_lines = original_text.split('\n')
        
        structured_sections = []
        current_region = None
        current_threats = []
        
        for line in text_lines:
            line = line.strip()
            if not line or 'підписатися' in line.lower():
                continue
                
            # Check if line is a region header
            region_match = _struct_re.match(region_header_pattern, line)
            if region_match:
                # Save previous section
                if current_region and current_threats:
                    structured_sections.append((current_region, current_threats))
                # Start new section
                current_region = region_match.group(1)
                current_threats = []
            elif current_region and ('шахед' in line.lower() or 'бпла' in line.lower()):
                # This is a threat line under current region
                current_threats.append(line)
        
        # Don't forget last section
        if current_region and current_threats:
            structured_sections.append((current_region, current_threats))
        
        # Process structured sections if we found any
        if len(structured_sections) >= 2:
            add_debug_log(f"STRUCTURED REGIONS: Found {len(structured_sections)} regions with threats", "structured_regions")
            
            all_structured_tracks = []
            for region_name, threat_lines in structured_sections:
                add_debug_log(f"Processing region {region_name} with {len(threat_lines)} threats", "structured_region_detail")
                
                for threat_line in threat_lines:
                    # Process each threat line with region context
                    region_context_text = f"{region_name}:\n{threat_line}"
                    line_tracks = process_message(region_context_text, f"{mid}_{region_name}_{len(all_structured_tracks)}", 
                                                date_str, channel, _disable_multiline=True)
                    if line_tracks:
                        all_structured_tracks.extend(line_tracks)
                        add_debug_log(f"Region {region_name} threat '{threat_line[:50]}...' produced {len(line_tracks)} tracks", "structured_threat_result")
            
            if all_structured_tracks:
                add_debug_log(f"Structured processing complete: {len(all_structured_tracks)} total tracks", "structured_complete")
                return all_structured_tracks
    
    # NEW: Handle UAV messages with "через [city]" and "повз [city]" patterns - BEFORE trajectory_phrase  
    try:
        lorig = text.lower()
        if 'бпла' in lorig and ('через' in lorig or 'повз' in lorig):
            threats = []
            
            # Extract cities from "через [city1], [city2]" pattern
            import re as _re_route
            route_pattern = r'через\s+([А-ЯІЇЄЁа-яіїєё\s\',\-]+?)(?:\s*\.\s+|$)'
            route_matches = _re_route.findall(route_pattern, text, re.IGNORECASE)
            
            for route_match in route_matches:
                # Split by comma to get individual cities
                cities_raw = [c.strip() for c in route_match.split(',') if c.strip()]
                
                for city_raw in cities_raw:
                    city_clean = city_raw.strip().strip('.,')
                    city_norm = clean_text(city_clean).lower()
                    
                    # Apply normalization rules
                    if city_norm in UA_CITY_NORMALIZE:
                        city_norm = UA_CITY_NORMALIZE[city_norm]
                    
                    # Try to get coordinates
                    coords = region_enhanced_coords(city_norm)
                    if not coords:
                        coords = ensure_city_coords(city_norm)
                    
                    if coords:
                        # Handle different coordinate formats
                        if isinstance(coords, tuple) and len(coords) >= 2:
                            lat, lng = coords[0], coords[1]
                        else:
                            continue
                        
                        threat_type, icon = classify(text)
                        
                        # Extract count from text context (look for patterns like "15х БпЛА через")
                        count = 1
                        count_match = _re_route.search(rf'(\d+)[xх×]?\s*бпла.*?через.*?{re.escape(city_clean)}', text, re.IGNORECASE)
                        if count_match:
                            count = int(count_match.group(1))
                        
                        threats.append({
                            'id': f"{mid}_route_{len(threats)}",
                            'place': city_clean.title(),
                            'lat': lat,
                            'lng': lng,
                            'threat_type': threat_type,
                            'text': f"Через {city_clean.title()} (з повідомлення про маршрут)",
                            'date': date_str,
                            'channel': channel,
                            'marker_icon': icon,
                            'source_match': f'route_via_{count}x',
                            'count': count
                        })
                        
                        add_debug_log(f"Route via: {city_clean} ({count}x) -> {coords}", "route_via")
            
            # Extract cities from "повз [city]" pattern
            past_pattern = r'повз\s+([А-ЯІЇЄЁа-яіїєё\s\',\-]+?)(?:\s*\.\s*|$)'
            past_matches = _re_route.findall(past_pattern, text, re.IGNORECASE)
            
            for past_match in past_matches:
                city_clean = past_match.strip().strip('.,')
                city_norm = clean_text(city_clean).lower()
                
                # Apply normalization rules
                if city_norm in UA_CITY_NORMALIZE:
                    city_norm = UA_CITY_NORMALIZE[city_norm]
                
                # Try to get coordinates
                coords = region_enhanced_coords(city_norm)
                if not coords:
                    coords = ensure_city_coords_with_message_context(city_norm, text)
                
                # Fallback: try accusative case normalization (e.g., "олександрію" -> "олександрія")
                if not coords and city_norm.endswith('ію'):
                    accusative_fallback = city_norm[:-2] + 'ія'
                    coords = region_enhanced_coords(accusative_fallback)
                    if not coords:
                        coords = ensure_city_coords_with_message_context(accusative_fallback, text)
                    if coords:
                        city_norm = accusative_fallback
                        city_clean = accusative_fallback.title()  # Use normalized name for display
                
                if coords:
                    # Handle different coordinate formats
                        if isinstance(coords, tuple) and len(coords) >= 2:
                            lat, lng = coords[0], coords[1]
                        else:
                            continue
                        
                        threat_type, icon = classify(text)
                        
                        # Extract count from text context (look for patterns like "4х БпЛА повз")
                        count = 1
                        count_match = _re_route.search(rf'(\d+)[xх×]?\s*бпла.*?повз.*?{re.escape(city_clean)}', text, re.IGNORECASE)
                        if count_match:
                            count = int(count_match.group(1))
                    
                        threats.append({
                            'id': f"{mid}_past_{len(threats)}",
                            'place': city_clean.title(),
                            'lat': lat,
                            'lng': lng,
                            'threat_type': threat_type,
                            'text': f"Повз {city_clean.title()} (з повідомлення про маршрут)",
                            'date': date_str,
                            'channel': channel,
                            'marker_icon': icon,
                            'source_match': f'route_past_{count}x',
                            'count': count
                        })
                        
                        add_debug_log(f"Route past: {city_clean} ({count}x) -> {coords}", "route_past")
            
            if threats:
                return threats
            else:
                pass
                
    except Exception:
        pass
    
    # --- Trajectory phrase pattern: "з дніпропетровщини через харківщину у напрямку полтавщини" ---
    # We map region stems to canonical OBLAST_CENTERS keys (simplistic stem matching).
    lower_full = text.lower()
    if has_threat(lower_full) and ' через ' in lower_full and (' у напрямку ' in lower_full or ' напрямку ' in lower_full or ' в напрямку ' in lower_full):
        # Extract sequence tokens after prepositions з/із/від -> start, через -> middle(s), напрямку -> target
        # Very heuristic; splits by key words.
        try:
            norm = re.sub(r'\s+', ' ', lower_full)
            norm = norm.replace('із ', 'з ').replace('від ', 'з ')
            if ' через ' in norm:
                front, after = norm.split(' через ', 1)
                start_token = front.split(' з ')[-1].strip()
                target_part = None; mid_part = ''
                for marker in [' у напрямку ', ' в напрямку ', ' напрямку ']:
                    if marker in after:
                        mid_part, target_part = after.split(marker, 1)
                        break
                if target_part:
                    mid_token = mid_part.strip().split('.')[0]
                    target_token = target_part.strip().split('.')[0]
                    def region_center(token: str):
                        token = token.strip()
                        for k,(lat,lng) in OBLAST_CENTERS.items():
                            if token.startswith(k.split()[0][:6]) or token in k:
                                return (k,(lat,lng))
                        return None
                    seq = []
                    for tk in [start_token, mid_token, target_token]:
                        rc = region_center(tk)
                        if rc and (not seq or seq[-1][0] != rc[0]):
                            seq.append(rc)
                    if len(seq) >= 2:
                        threat_type, icon = classify(text)
                        tracks = []
                        for idx,(name,(lat,lng)) in enumerate(seq,1):
                            base = name.split()[0].title()
                            tracks.append({
                                'id': f"{mid}_t{idx}", 'place': base, 'lat': lat, 'lng': lng,
                                'threat_type': threat_type, 'text': original_text[:500], 'date': date_str, 'channel': channel,
                                'marker_icon': icon, 'source_match': 'trajectory_phrase'
                            })
                        return tracks
        except Exception:
            pass
    # direct coordinates pattern
    # --- Direction with parenthetical specific settlement e.g. "у напрямку білгород-дністровського району одещини (затока)" ---
    if has_threat(lower_full) and 'у напрямку' in lower_full and '(' in lower_full and ')' in lower_full:
        # capture last parenthetical token (short) that is a known settlement
        try:
            paren_tokens = re.findall(r'\(([a-zа-яіїєґ\-\s]{3,})\)', lower_full)
            if paren_tokens:
                candidate = paren_tokens[-1].strip().lower()
                # trim descriptors like 'смт ' , 'с.' etc
                candidate = re.sub(r'^(смт|с\.|м\.|місто|селище)\s+','', candidate)
                norm = UA_CITY_NORMALIZE.get(candidate, candidate)
                coords = CITY_COORDS.get(norm)
                if not coords and SETTLEMENTS_INDEX:
                    coords = SETTLEMENTS_INDEX.get(norm)
                if not coords:
                    coords = SETTLEMENT_FALLBACK.get(norm)
                log.debug(f"parenthetical_dir detect mid={mid} candidate={candidate} norm={norm} found={bool(coords)}")
                if coords:
                    lat,lng = coords
                    threat_type, icon = classify(text)
                    return [{
                        'id': f"{mid}_dirp", 'place': norm.title(), 'lat': lat, 'lng': lng,
                        'threat_type': threat_type, 'text': original_text[:500], 'date': date_str, 'channel': channel,
                        'marker_icon': icon, 'source_match': 'direction_parenthetical'
                    }]
        except Exception:
            pass
    # --- Region-level shelling threat (e.g. "Харківська обл. Загроза обстрілу прикордонних територій") ---
    try:
        if re.search(r'(загроза обстрілу|угроза обстрела)', lower_full):
            # attempt to match any oblast token present
            region_hit = None
            for reg_key in OBLAST_CENTERS.keys():
                if reg_key in lower_full:
                    region_hit = reg_key
                    log.debug(f"region_shelling candidate mid={mid} match={reg_key}")
                    break
            if region_hit:
                # Only emit if we haven't already returned a more specific structure earlier (heuristic: continue)
                lat, lng = OBLAST_CENTERS[region_hit]
                threat_type, icon = classify(text)
                # Enforce obstril icon for shelling phrasing even if classify changed in future
                if re.search(r'(загроза обстрілу|угроза обстрела|обстріл|обстрел)', lower_full):
                    threat_type = 'artillery'; icon = 'obstril.png'
                border_shell = bool(re.search(r'прикордон|пригранич', lower_full))
                place_label = region_hit
                if border_shell:
                    place_label += ' (прикордоння)'
                log.debug(f"region_shelling emit mid={mid} region={region_hit} border={border_shell}")
                return [{
                    'id': f"{mid}_region_shell", 'place': place_label, 'lat': lat, 'lng': lng,
                    'threat_type': threat_type, 'text': original_text[:500], 'date': date_str, 'channel': channel,
                    'marker_icon': icon, 'source_match': 'region_shelling', 'border_shelling': border_shell
                }]
    except Exception:
        pass
    # Special handling for KAB threats with regional mentions (e.g., "Загроза КАБ для прифронтових громад Сумщини")
    kab_region_match = re.search(r'(каб|авіабомб|авиабомб|авіаційних.*бомб|керован.*бомб)[^\.]*?(сумщин[иіа]|харківщин[иіа]|чернігівщин[иіа]|полтавщин[иіа])', text.lower())
    if kab_region_match:
        region_mention = kab_region_match.group(2)
        # Convert genitive/dative to nominative
        if 'сумщин' in region_mention:
            region_key = 'сумщина'
        elif 'харківщин' in region_mention:
            region_key = 'харківщина'
        elif 'чернігівщин' in region_mention:
            region_key = 'чернігівщина'
        elif 'полтавщин' in region_mention:
            region_key = 'полтавщина'
        else:
            region_key = None
            
        if region_key and region_key in OBLAST_CENTERS:
            lat, lng = OBLAST_CENTERS[region_key]
            # For KAB threats, offset coordinates slightly from city center to avoid implying direct city impact
            if region_key == 'сумщина':
                lat += 0.1  # Move north of Sumy city
                lng -= 0.1  # Move west of Sumy city
            elif region_key == 'харківщина':
                lat += 0.1  # Move north of Kharkiv city
                lng -= 0.1  # Move west of Kharkiv city
            add_debug_log(f"Creating KAB regional threat marker for {region_key}: lat={lat}, lng={lng}", "kab_regional")
            return [{
                'id': f"{mid}_kab_regional", 'place': region_key.title(), 'lat': lat, 'lng': lng,
                'threat_type': 'raketa', 'text': original_text[:500], 'date': date_str, 'channel': channel,
                'marker_icon': 'icon_balistic.svg', 'source_match': 'kab_regional_threat'
            }]
    
    # SPECIAL: Handle multi-regional UAV messages (like the user's example)
    def handle_multi_regional_uav():
        """Handle messages with multiple regional UAV threats listed separately"""
        threats = []
        text_lines = text.split('\n')
        
        # Check if this looks like a multi-regional UAV message
        region_count = 0
        uav_count = 0
        for line in text_lines:
            line_lower = line.lower().strip()
            if not line_lower:
                continue
                
            # Count regions mentioned
            if any(region in line_lower for region in ['щина:', 'область:', 'край:']):
                region_count += 1
            
            # Count UAV mentions
            if 'бпла' in line_lower and ('курс' in line_lower or 'на ' in line_lower):
                uav_count += 1
        
        # If we have multiple regions and multiple UAV mentions, process each line
        if region_count >= 2 and uav_count >= 3:
            add_debug_log(f"MULTI-REGIONAL UAV MESSAGE: {region_count} regions, {uav_count} UAVs", "multi_regional")
            
            for line in text_lines:
                line_stripped = line.strip()
                if not line_stripped or ':' in line_stripped[:20]:  # Skip region headers
                    continue
                
                line_lower = line_stripped.lower()
                
                # Look for UAV course patterns
                if 'бпла' in line_lower and ('курс' in line_lower or ' на ' in line_lower):
                    # Extract city name from patterns like "БпЛА курсом на Конотоп" or "2х БпЛА курсом на Велику Димерку"
                    patterns = [
                        r'(\d+(?:-\d+)?)?[xх×]?\s*бпла\s+курсом?\s+на\s+([А-ЯІЇЄЁа-яіїєё\'\-\s]+?)(?:\s*$|\s*[,\.\!\?\|])',
                        r'бпла\s+курсом?\s+на\s+([А-ЯІЇЄЁа-яіїєё\'\-\s]+?)(?:\s*$|\s*[,\.\!\?\|])',
                        r'(\d+(?:-\d+)?)?[xх×]?\s*бпла\s+на\s+([А-ЯІЇЄЁа-яіїєё\'\-\s]+?)(?:\s*$|\s*[,\.\!\?\|])'
                    ]
                    
                    for pattern in patterns:
                        matches = re.finditer(pattern, line_stripped, re.IGNORECASE)
                        for match in matches:
                            if len(match.groups()) == 2:
                                count_str, city_raw = match.groups()
                            else:
                                count_str = None
                                city_raw = match.group(1)
                            
                            if not city_raw:
                                continue
                                
                            # Clean and normalize city name
                            city_clean = city_raw.strip()
                            city_norm = clean_text(city_clean).lower()
                            
                            # Apply normalization rules
                            if city_norm in UA_CITY_NORMALIZE:
                                city_norm = UA_CITY_NORMALIZE[city_norm]
                            
                            # Try to get coordinates
                            coords = region_enhanced_coords(city_norm)
                            if not coords:
                                coords = ensure_city_coords(city_norm)
                            
                            if coords:
                                lat, lng = coords
                                threat_type, icon = classify(text)
                                
                                # Extract count if present
                                uav_count_num = 1
                                if count_str and count_str.isdigit():
                                    uav_count_num = int(count_str)
                                
                                threat_id = f"{mid}_multi_{len(threats)}"
                                threats.append({
                                    'id': threat_id,
                                    'place': city_clean.title(),
                                    'lat': lat,
                                    'lng': lng,
                                    'threat_type': threat_type,
                                    'text': f"{line_stripped} (з багаторегіонального повідомлення)",
                                    'date': date_str,
                                    'channel': channel,
                                    'marker_icon': icon,
                                    'source_match': f'multi_regional_uav_{uav_count_num}x',
                                    'count': uav_count_num
                                })
                                
                                add_debug_log(f"Multi-regional UAV: {city_clean} ({uav_count_num}x) -> {coords}", "multi_regional")
                            else:
                                add_debug_log(f"Multi-regional UAV: No coords for {city_clean}", "multi_regional")
        
        return threats

    # SPECIAL: Handle single UAV course mentions in regular messages
    def handle_single_uav_courses():
        """Handle UAV course mentions like '4х БпЛА курсом на Добротвір' in regular alert messages"""
        threats = []
        
        # Look for UAV course patterns in the entire message
        patterns = [
            r'(\d+(?:-\d+)?)?[xх×]?\s*бпла\s+курсом?\s+на\s+([А-ЯІЇЄЁа-яіїєё\'\-\s]+?)(?:\s*$|\s*[,\.\!\?\|\(])',
            r'бпла\s+курсом?\s+на\s+([А-ЯІЇЄЁа-яіїєё\'\-\s]+?)(?:\s*$|\s*[,\.\!\?\|\(])',
            r'(\d+(?:-\d+)?)?[xх×]?\s*бпла\s+на\s+([А-ЯІЇЄЁа-яіїєё\'\-\s]+?)(?:\s*$|\s*[,\.\!\?\|\(])'
        ]
        
        for pattern in patterns:
            matches = re.finditer(pattern, text, re.IGNORECASE)
            for match in matches:
                if len(match.groups()) == 2:
                    count_str, city_raw = match.groups()
                else:
                    count_str = None
                    city_raw = match.group(1)
                
                if not city_raw:
                    continue
                    
                # Clean and normalize city name
                city_clean = city_raw.strip()
                city_norm = clean_text(city_clean).lower()
                
                # Apply normalization rules
                if city_norm in UA_CITY_NORMALIZE:
                    city_norm = UA_CITY_NORMALIZE[city_norm]
                
                # Try to get coordinates
                coords = region_enhanced_coords(city_norm)
                if not coords:
                    coords = ensure_city_coords(city_norm)
                
                if coords:
                    lat, lng = coords[:2]
                    threat_type, icon = classify(text)
                    
                    # Extract count if present
                    uav_count_num = 1
                    if count_str and count_str.isdigit():
                        uav_count_num = int(count_str)
                    
                    threat_id = f"{mid}_uav_course_{len(threats)}"
                    threats.append({
                        'id': threat_id,
                        'place': city_clean.title(),
                        'lat': lat,
                        'lng': lng,
                        'threat_type': threat_type,
                        'text': f"БпЛА курсом на {city_clean} ({uav_count_num}x)",
                        'date': date_str,
                        'channel': channel,
                        'marker_icon': icon,
                        'source_match': f'single_uav_course_{uav_count_num}x',
                        'count': uav_count_num
                    })
                    
                    add_debug_log(f"Single UAV course: {city_clean} ({uav_count_num}x) -> {coords}", "single_uav")
                else:
                    add_debug_log(f"Single UAV course: No coords for {city_clean}", "single_uav")
        
        # ALSO: Extract cities from emoji structure in the same text 
        # Pattern for "| 🛸 Город (Область)"
        emoji_pattern = r'\|\s*🛸\s*([А-ЯІЇЄЁа-яіїєё\'\-\s]+?)\s*\([^)]*обл[^)]*\)'
        emoji_matches = re.finditer(emoji_pattern, text, re.IGNORECASE)
        
        for match in emoji_matches:
            city_raw = match.group(1).strip()
            if not city_raw or len(city_raw) < 2:
                continue
                
            city_norm = clean_text(city_raw).lower()
            if city_norm in UA_CITY_NORMALIZE:
                city_norm = UA_CITY_NORMALIZE[city_norm]
            
            coords = region_enhanced_coords(city_norm)
            if not coords:
                coords = ensure_city_coords(city_norm)
            
            if coords:
                lat, lng = coords[:2]
                threat_type, icon = classify(text)
                
                threat_id = f"{mid}_emoji_struct_{len(threats)}"
                threats.append({
                    'id': threat_id,
                    'place': city_raw.title(),
                    'lat': lat,
                    'lng': lng,
                    'threat_type': threat_type,
                    'text': f"Загроза в {city_raw}",
                    'date': date_str,
                    'channel': channel,
                    'marker_icon': icon,
                    'source_match': 'emoji_structure',
                    'count': 1
                })
                
                add_debug_log(f"Emoji structure: {city_raw} -> {coords}", "emoji_struct")
            else:
                add_debug_log(f"Emoji structure: No coords for {city_raw}", "emoji_struct")
        
        return threats

    # Check for single UAV course mentions first (before multi-regional check)
    single_uav_threats = handle_single_uav_courses()
    if single_uav_threats:
        add_debug_log(f"SINGLE UAV COURSES: Found {len(single_uav_threats)} threats", "single_uav")
        # Continue processing to also get regular location markers
        # Don't return early - we want both UAV course markers AND location markers

    # Check for multi-regional UAV messages
    if multi_regional_flag:
        multi_regional_threats = handle_multi_regional_uav()
        if multi_regional_threats:
            add_debug_log(f"MULTI-REGIONAL UAV: Found {len(multi_regional_threats)} threats", "multi_regional")
            return multi_regional_threats

    # Southeast-wide tactical aviation activity (no specific settlement): place a synthetic marker off SE border.
    se_phrase = lower if 'lower' in locals() else original_text.lower()
    if ('тактичн' in se_phrase or 'авіаці' in se_phrase or 'авиац' in se_phrase) and ('південно-східн' in se_phrase or 'південно східн' in se_phrase or 'юго-восточ' in se_phrase or 'південного-сходу' in se_phrase):
        # Approx point in Azov Sea off SE (between Mariupol & Berdyansk) to avoid implying exact impact
        lat, lng = 46.5, 37.5
        return [{
            'id': f"{mid}_se", 'place': 'Південно-східний напрямок', 'lat': lat, 'lng': lng,
            'threat_type': 'avia', 'text': original_text[:500], 'date': date_str, 'channel': channel,
            'marker_icon': 'avia.png', 'source_match': 'southeast_aviation'
        }]
    # North-east tactical aviation activity - coordinates on Russian territory before Ukraine border
    # Aviation threats come FROM Russia, so marker should be in Russia
    # SKIP if this is a multi-threat message (handled separately above)
    if ('тактичн' in se_phrase or 'авіаці' in se_phrase or 'авиац' in se_phrase) and (
        'північно-східн' in se_phrase or 'північно східн' in se_phrase or 'северо-восточ' in se_phrase or 'північного-сходу' in se_phrase
    ) and not ('🛬' in original_text and '🛸' in original_text):
        # Coordinates on Russian territory (Belgorod area) - aviation source location
        lat, lng = 51.0, 36.5  # Near Belgorod, Russia (before Ukraine border)
        return [{
            'id': f"{mid}_ne", 'place': 'Північно-східний напрямок', 'lat': lat, 'lng': lng,
            'threat_type': 'avia', 'text': original_text[:500], 'date': date_str, 'channel': channel,
            'marker_icon': 'avia.png', 'source_match': 'northeast_aviation'
        }]
    m = re.search(r'(\d{1,2}\.\d+),(\d{1,3}\.\d+)', text)
    if m:
        lat_val = safe_float(m.group(1))
        lng_val = safe_float(m.group(2))
        if lat_val is not None and lng_val is not None and validate_ukraine_coords(lat_val, lng_val):
            threat_type, icon = classify(text)
            return [{
                'id': str(mid), 'place': 'Unknown', 'lat': lat_val, 'lng': lng_val,
                'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
                'marker_icon': icon
            }]
    # Alarm cancellation always list-only
    if re.search(r'відбій\s+тривог|отбой\s+тревог', original_text.lower()):
        return [{
            'id': str(mid), 'place': None, 'lat': None, 'lng': None,
            'threat_type': 'alarm_cancel', 'text': original_text[:500], 'date': date_str, 'channel': channel,
            'marker_icon': 'vidboi.png', 'list_only': True
        }]
    lower = text.lower()
    # Specialized single-line pattern: direction from one oblast toward another (e.g. 'бпла ... курсом на полтавщину')
    import re as _re_one
    m_dir_oblast = _re_one.search(r'бпла[^\n]*курс(?:ом)?\s+на\s+([a-zа-яїієґ\-]+щин[ауі])', lower)
    if m_dir_oblast:
        dest = m_dir_oblast.group(1)
        # normalize accusative -> nominative
        dest_norm = dest.replace('щину','щина').replace('щини','щина')
        if dest_norm in OBLAST_CENTERS:
            dest_lat, dest_lng = OBLAST_CENTERS[dest_norm]

            def _region_key_from_stem(stem: str):
                for key in OBLAST_CENTERS.keys():
                    if stem and stem in key:
                        return key
                return None

            def _resolve_location_token(token: str):
                if not token:
                    return None
                cleaned = token.strip(" .,:;!?\n\t'`\"-»«")
                if not cleaned:
                    return None
                cleaned = ' '.join(cleaned.split())
                variants = [cleaned]
                def _add_variant(val: str):
                    v = val.strip()
                    if v and v not in variants:
                        variants.append(v)
                suffix_map = {
                    'щину': 'щина', 'щини': 'щина', 'щині': 'щина',
                    ' область': ' область', ' обл.': ' область', ' обл': ' область'
                }
                for suffix, repl in suffix_map.items():
                    if cleaned.endswith(suffix):
                        _add_variant(cleaned[:-len(suffix)] + repl)
                loc_endings = [('і','ь'),('і','а'),('і','я'),('ї','я'),('ю','я'),('у','а')]
                for ending, replacement in loc_endings:
                    if cleaned.endswith(ending):
                        _add_variant(cleaned[:-len(ending)] + replacement)
                for variant in list(variants):
                    normalized = UA_CITY_NORMALIZE.get(variant, variant)
                    if normalized in OBLAST_CENTERS:
                        plat, plng = OBLAST_CENTERS[normalized]
                        return {'label': normalized.split()[0].title(), 'lat': plat, 'lng': plng}
                    if normalized in CITY_TO_OBLAST:
                        stem = CITY_TO_OBLAST[normalized]
                        reg_key = _region_key_from_stem(stem)
                        if reg_key:
                            plat, plng = OBLAST_CENTERS[reg_key]
                            return {'label': reg_key.split()[0].title(), 'lat': plat, 'lng': plng}
                    if normalized in CITY_COORDS:
                        plat, plng = CITY_COORDS[normalized]
                        return {'label': normalized.title(), 'lat': plat, 'lng': plng}
                return None

            prefix = lower[:m_dir_oblast.start()]
            source_candidate = None
            src_pattern = _re_one.compile(r'(?:на|у|в|із|зі|з)\s+([a-zа-яїієґ\-\'ʼ`\s]{3,40})')
            for sm in src_pattern.finditer(prefix):
                resolved = _resolve_location_token(sm.group(1))
                if resolved:
                    source_candidate = resolved
            if not source_candidate:
                header_match = _re_one.match(r'^\s*([a-zа-яїієґ\-\'ʼ`\s]{3,})[:—-]', lower)
                if header_match:
                    resolved = _resolve_location_token(header_match.group(1))
                    if resolved:
                        # Skip if header is just an oblast/region marker (not a specific city)
                        # When destination is also an oblast, this indicates region-level info without specific location
                        header_text = header_match.group(1).strip()
                        header_normalized = LOCATIVE_NORMALIZE.get(header_text, header_text)
                        is_region_header = (
                            header_normalized in OBLAST_CENTERS or
                            header_normalized in CITY_TO_OBLAST or
                            'область' in header_normalized or 'обл' in header_normalized or
                            header_text.endswith(('щина', 'щині', 'щину', 'щиною'))
                        )
                        dest_is_oblast = dest_norm in OBLAST_CENTERS
                        # Only use header as source if it's a specific city OR if destination is a city (not oblast)
                        if not (is_region_header and dest_is_oblast):
                            source_candidate = resolved
            if source_candidate:
                src_lat, src_lng = source_candidate['lat'], source_candidate['lng']
                dest_label = dest_norm.split()[0].title()

                def _direction_token(dlat: float, dlng: float):
                    if abs(dlat) < 1e-6 and abs(dlng) < 1e-6:
                        return None
                    if abs(dlat) > abs(dlng) * 1.4:
                        return 'n' if dlat > 0 else 's'
                    if abs(dlng) > abs(dlat) * 1.4:
                        return 'e' if dlng > 0 else 'w'
                    if dlat >= 0 and dlng >= 0:
                        return 'ne'
                    if dlat >= 0 and dlng < 0:
                        return 'nw'
                    if dlat < 0 and dlng >= 0:
                        return 'se'
                    return 'sw'

                dir_token = _direction_token(dest_lat - src_lat, dest_lng - src_lng)
                arrow_label_map = {
                    'n': 'півночі', 's': 'півдня', 'e': 'сходу', 'w': 'заходу',
                    'ne': 'північного сходу', 'nw': 'північного заходу',
                    'se': 'південного сходу', 'sw': 'південного заходу'
                }
                course_direction_map = {
                    'n': 'північ', 's': 'південь', 'e': 'схід', 'w': 'захід',
                    'ne': 'північний схід', 'nw': 'північний захід',
                    'se': 'південний схід', 'sw': 'південний захід'
                }
                arrow_label = arrow_label_map.get(dir_token, '')
                course_direction_text = course_direction_map.get(dir_token, dest_label)

                place_name = f"{source_candidate['label']} → {dest_label}"
                if arrow_label:
                    place_name += f" ←{arrow_label}"

                trajectory = {
                    'start': [src_lat, src_lng],
                    'end': [dest_lat, dest_lng],
                    'source': source_candidate['label'],
                    'target': dest_label,
                    'kind': 'singleline_region_course'
                }

                threat_type, icon = classify(original_text)
                return [{
                    'id': f"{mid}_dir_oblast", 'place': place_name, 'lat': src_lat, 'lng': src_lng,
                    'threat_type': threat_type, 'text': original_text[:500], 'date': date_str, 'channel': channel,
                    'marker_icon': icon, 'source_match': 'singleline_region_course', 'trajectory': trajectory,
                    'course_source': source_candidate['label'], 'course_target': dest_label,
                    'course_direction': f"курс на {course_direction_text}", 'course_type': 'region_to_region'
                }]

            return [{
                'id': f"{mid}_dir_oblast", 'place': dest_norm.title(), 'lat': dest_lat, 'lng': dest_lng,
                'threat_type': 'uav', 'text': original_text[:500], 'date': date_str, 'channel': channel,
                'marker_icon': 'icon_drone.svg', 'source_match': 'singleline_oblast_course'
            }]
    # Extract drone / shahed count pattern (e.g. "7х бпла", "6x дронів", "10 х бпла") early so later branches can reuse
    drone_count = None
    m_count = re.search(r'(\b\d{1,3})\s*[xх]\s*(?:бпла|дрон|дрони|шахед|шахеди|шахедів)', lower)
    if m_count:
        try:
            drone_count = int(m_count.group(1))
        except ValueError:
            drone_count = None
    # Normalize some genitive forms ("дніпропетровської" -> base) to capture multiple oblasts in one message
    GENITIVE_NORMALIZE = {
        'дніпропетровської': 'дніпропетровська область',
        'днепропетровской': 'дніпропетровська область',
        'чернігівської': 'чернігівська обл.',
        'черниговской': 'чернігівська обл.',
        'сумської': 'сумська область',
        'сумской': 'сумська область',
        'харківської': 'харківська обл.',
        'харьковской': 'харківська обл.'
    }
    for gform, base_form in GENITIVE_NORMALIZE.items():
        if gform in lower:
            lower = lower.replace(gform, base_form)
    # Locative / prepositional oblast & region endings -> base ("дніпропетровщині" -> "дніпропетровщина")
    LOCATIVE_NORMALIZE = {
        'дніпропетровщині': 'дніпропетровщина',
        'донеччині': 'донеччина',
        'сумщині': 'сумщина',
        'харківщині': 'харківщина',
        'чернігівщині': 'чернігівщина',
        'миколаївщині': 'миколаївщина',
        'херсонщині': 'херсонщина',
        'запоріжжі': 'запоріжжя'
    }
    for lform, base_form in LOCATIVE_NORMALIZE.items():
        if lform in lower:
            lower = lower.replace(lform, base_form)
    # City genitive -> nominative (subset) for settlement detection
    CITY_GENITIVE = [
        ('харкова','харків'), ('києва','київ'), ('львова','львів'), ('одеси','одеса'), ('дніпра','дніпро')
    ]
    for gform, base in CITY_GENITIVE:
        if gform in lower:
            lower = lower.replace(gform, base)
    # Normalize some accusative oblast forms to nominative for matching
    lower = lower.replace('донеччину','донеччина').replace('сумщину','сумщина')
    text = lower  # downstream logic mostly uses lower-case comparisons
    # Санітизація дублювань типу "область області" -> залишаємо один раз
    text = re.sub(r'(область|обл\.)\s+област[іи]', r'\1', text)

    # --- Simple sanitization of formatting noise (bold asterisks, stray stars) ---
    # Keeps Ukrainian characters while removing leading/trailing markup like ** or * around segments
    if '**' in text or '*' in text:
        # remove isolated asterisks not part of words
        text = re.sub(r'\*+', '', text)

    # --- Early explicit pattern: "<RaionName> район (<Oblast ...>)" (e.g. "Запорізький район (Запорізька обл.)") ---
    # Sometimes such messages were slipping through as raw because the pre-parenthesis token ended with 'район'.
    m_raion_oblast = re.search(r'([A-Za-zА-Яа-яЇїІіЄєҐґ\-]{4,})\s+район\s*\(([^)]*обл[^)]*)\)', text)
    if m_raion_oblast:
        raion_token = m_raion_oblast.group(1).strip().lower()
        # Normalize morphological endings similar to later norm_raion logic
        raion_base = re.sub(r'(ському|ского|ського|ский|ськiй|ськой|ським|ском)$', 'ський', raion_token)
        if raion_base in RAION_FALLBACK:
            lat, lng = RAION_FALLBACK[raion_base]
            threat_type, icon = classify(original_text if 'original_text' in locals() else text)
            # Maintain active raion alarm state
            if threat_type == 'alarm':
                RAION_ALARMS[raion_base] = {'place': f"{raion_base.title()} район", 'lat': lat, 'lng': lng, 'since': time.time()}
            elif threat_type == 'alarm_cancel':
                RAION_ALARMS.pop(raion_base, None)
            return [{
                'id': str(mid), 'place': f"{raion_base.title()} район", 'lat': lat, 'lng': lng,
                'threat_type': threat_type, 'text': (original_text if 'original_text' in locals() else text)[:500],
                'date': date_str, 'channel': channel, 'marker_icon': icon, 'source_match': 'raion_oblast_combo'
            }]
        else:
            log.debug(f"raion_oblast primary matched token={raion_token} base={raion_base} no coords")
    else:
        # Secondary heuristic fallback if formatting (emoji / markup) broke regex
        if 'район (' in text and ' обл' in text and has_threat(text):
            try:
                prefix = text.split('район (',1)[0]
                cand = prefix.strip().split()[-1].lower()
                cand_base = re.sub(r'(ському|ского|ського|ский|ськiй|ськой|ським|ском)$', 'ський', cand)
                if cand_base in RAION_FALLBACK:
                    lat,lng = RAION_FALLBACK[cand_base]
                    threat_type, icon = classify(original_text if 'original_text' in locals() else text)
                    log.debug(f"raion_oblast secondary emit cand={cand} base={cand_base}")
                    return [{
                        'id': str(mid), 'place': f"{cand_base.title()} район", 'lat': lat, 'lng': lng,
                        'threat_type': threat_type, 'text': (original_text if 'original_text' in locals() else text)[:500],
                        'date': date_str, 'channel': channel, 'marker_icon': icon, 'source_match': 'raion_oblast_secondary'
                    }]
                else:
                    log.debug(f"raion_oblast secondary no coords cand={cand} base={cand_base}")
            except Exception as _e:
                log.debug(f"raion_oblast secondary error={_e}")

    # --- Russian strategic aviation suppression ---
    def _is_russian_strategic_aviation(t: str) -> bool:
        """Suppress messages about Russian strategic aviation (Tu-95, etc.) from Russian airbases"""
        t_lower = t.lower()
        
        # Check for Russian strategic bombers
        russian_bombers = ['ту-95', 'tu-95', 'ту-160', 'tu-160', 'ту-22', 'tu-22']
        has_bomber = any(bomber in t_lower for bomber in russian_bombers)
        
        # Check for Russian airbases and regions
        russian_airbases = ['енгельс', 'engels', 'энгельс', 'саратов', 'рязань', 'муром', 'украінка', 'українка']
        has_russian_airbase = any(airbase in t_lower for airbase in russian_airbases)
        
        # Check for Russian regions/areas
        russian_regions = ['саратовській області', 'саратовской области', 'тульській області', 'рязанській області']
        has_russian_region = any(region in t_lower for region in russian_regions)
        
        # Check for terms indicating Russian territory/airbases
        russian_territory_terms = ['аеродрома', 'аэродрома', 'з аеродрому', 'с аэродрома', 'мета вильоту невідома', 'цель вылета неизвестна']
        has_russian_territory = any(term in t_lower for term in russian_territory_terms)
        
        # Check for generic relocation/transfer terms without specific threats
        relocation_terms = ['передислокація', 'передислокация', 'переліт', 'перелет', 'відмічено', 'отмечено']
        has_relocation = any(term in t_lower for term in relocation_terms)
        
        # Suppress if it's about Russian bombers from Russian territory
        if has_bomber and (has_russian_airbase or has_russian_territory or has_russian_region):
            return True
            
        # Suppress relocation/transfer messages between Russian airbases
        if has_relocation and has_bomber and (has_russian_airbase or has_russian_region):
            return True
            
        # Also suppress general strategic aviation reports without specific Ukrainian targets
        if ('борт' in t_lower or 'борти' in t_lower) and ('мета вильоту невідома' in t_lower or 'цель вылета неизвестна' in t_lower):
            return True
            
        return False

    # --- General warning suppression ---

    if _is_russian_strategic_aviation(text):
        return None
        
    if _is_general_warning_without_location(text):
        return None

    # --- Western border drone reconnaissance suppression ---
    def _is_western_border_reconnaissance(t: str) -> bool:
        """Suppress messages about drones crossing western borders (Hungary, etc.) - not related to Russian threats"""
        t_lower = t.lower()
        
        # Check for western border crossing indicators
        border_crossing_terms = [
            'перетнув державний кордон', 'пересек государственную границу',
            'перетнув кордон', 'пересек границу',
            'з боку угорщини', 'со стороны венгрии',
            'з території угорщини', 'с территории венгрии'
        ]
        has_border_crossing = any(term in t_lower for term in border_crossing_terms)
        
        # Check for western regions (primarily Zakarpattya)
        western_regions = ['закарпатт', 'закарпать', 'ужгород', 'мукачев']
        has_western_region = any(region in t_lower for region in western_regions)
        
        # Check for reconnaissance/monitoring context (not combat threats)
        recon_terms = ['радари зсу', 'радары всу', 'зафіксували проліт', 'зафиксировали пролет', 'стежити за обстановкою', 'следить за обстановкой']
        has_recon_context = any(term in t_lower for term in recon_terms)
        
        # Suppress if it's about western border reconnaissance
        if has_border_crossing and has_western_region:
            return True
            
        # Also suppress general monitoring messages about western regions
        if has_western_region and has_recon_context and ('дрон' in t_lower or 'бпла' in t_lower):
            return True
            
        return False

    if _is_western_border_reconnaissance(text):
        return None

    # --- Aggregate / statistical summary suppression ---
    def _is_aggregate_summary(t: str) -> bool:
        # Situation report override: if starts with 'обстановка' we evaluate full logic first (word 'загроза' inside shouldn't unblock)
        starts_obst = t.startswith('обстановка')
        # Do not suppress if explicit real-time warning words present (unless it's a structured situation report)
        if not starts_obst and any(w in t for w in ['загроза','перейдіть в укриття','укриття!']):
            return False
        verbs = ['збито/подавлено','збито / подавлено','збито-подавлено','збито','подавлено','знищено']
        context = ['станом на','за попередніми даними','у ніч на','повітряний напад','протиповітряною обороною','протиповітряна оборона','підрозділи реб','мобільні вогневі групи','обстановка']
        objects_re = re.compile(r'\b\d{1,3}[\-–]?(ма|)?\s*(ворожих|)\s*(бпла|shahed|дрон(?:ів|и)?|ракет|ракети)')
        verb_hit = any(v in t for v in verbs)
        ctx_hits = sum(1 for c in context if c in t)
        obj_hit = bool(objects_re.search(t))
        # Strong aggregate if all three categories present OR multiple context + objects
        if (verb_hit and obj_hit and ctx_hits >= 1) or (ctx_hits >= 2 and obj_hit):
            return True
        # Long multiline with origins list and many commas plus 'типу shahed'
        if 'типу shahed' in t and t.count('\n') >= 2 and obj_hit:
            return True
        # Situation report structure: starts with 'обстановка станом на' or begins with 'обстановка' and multiple category lines (— стратегічна авіація, — бпла, — флот)
        if starts_obst:
            dash_lines = sum(1 for line in t.split('\n') if line.strip().startswith('—'))
            if dash_lines >= 2:
                return True
        return False
    if _is_aggregate_summary(text):
        return None

    # --- Pattern: City (Oblast ...) e.g. "Павлоград (Дніпропетровська обл.)" ---
    bracket_city = re.search(r'([A-Za-zА-Яа-яЇїІіЄєҐґ\-]{3,})\s*\(([^)]+)\)', text)
    if bracket_city:
        raw_city = bracket_city.group(1).strip().lower()
        raw_inside = bracket_city.group(2).lower()
        # Особый случай: "дніпропетровська область (павлоградський р-н)" -> ставим Павлоград
        if ('область' in raw_city or 'обл' in raw_city) and ('павлоград' in raw_inside):
            pav_key = 'павлоградський'
            if pav_key in RAION_FALLBACK:
                lat,lng = RAION_FALLBACK[pav_key]
                threat_type, icon = classify(text)
                return [{
                    'id': str(mid), 'place': 'Павлоградський район', 'lat': lat, 'lng': lng,
                    'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
                    'marker_icon': icon, 'source_match': 'oblast_raion_combo'
                }]
        # Пропускаем случаи вида "<область> (<район ...>)" чтобы не трактовать слово 'область' как город
        if raw_city in {'область','обл','обл.'} or raw_city.endswith('область'):
            bracket_city = None
    if bracket_city and raw_city != 'район':
            norm_city = UA_CITY_NORMALIZE.get(raw_city, raw_city)
            # Initial local attempt (static minimal list)
            coords = CITY_COORDS.get(norm_city)
            # Region hint extraction
            region_hint = None
            if any(tok in raw_inside for tok in ['обл', 'область']):
                region_hint = raw_inside.strip()
            # 1) Explicit override for (city, region) if provided
            if region_hint:
                override_key = (norm_city, region_hint)
                if override_key in OBLAST_CITY_OVERRIDES:
                    coords = OBLAST_CITY_OVERRIDES[override_key]
            # 2) If we have region hint and NO coords yet, attempt region-qualified geocode first (priority to enforce oblast binding)
            region_combo_tried = False
            if not coords and region_hint and OPENCAGE_API_KEY:
                combo_query = f"{norm_city} {region_hint}".replace('  ',' ').strip()
                try:
                    refined = geocode_opencage(combo_query)
                    if refined:
                        coords = refined
                    region_combo_tried = True
                except Exception:
                    pass
            # 3) Attempt city alone geocode only if still no coords
            if not coords and OPENCAGE_API_KEY:
                try:
                    coords = geocode_opencage(norm_city)
                except Exception:
                    pass
            # 4) If region hint exists and we got coords from plain city geocode but city is potentially duplicated across oblasts,
            # try region-qualified geocode as refinement (unless already tried).
            if region_hint and OPENCAGE_API_KEY and not region_combo_tried and coords and norm_city in ['борова','миколаївка','николаевка']:
                try:
                    combo_query = f"{norm_city} {region_hint}".replace('  ',' ').strip()
                    refined2 = geocode_opencage(combo_query)
                    if refined2:
                        coords = refined2
                except Exception:
                    pass
            # Ambiguous manual mapping fallback (if still no coords or mismatch with region)
            if region_hint:
                # derive stem like 'харківськ', 'львівськ'
                rh_low = region_hint.lower()
                # choose first word containing 'харків' etc
                region_key = None
                for stem in ['харків','львів','київ','дніпропетров','полтав','сум','черніг','волин','запор','одес','микола','черка','житом','хмельниць','рівн','івано','терноп','ужгород','кропив','луган','донець','чернівц']:
                    if stem in rh_low:
                        region_key = stem
                        break
                AMBIGUOUS_CITY_REGION = {
                    ('золочів','харків'): (50.2788, 36.3644),  # Zolochiv Kharkiv oblast
                    ('золочів','львів'): (49.8078, 24.9002),   # Zolochiv Lviv oblast
                }
                if region_key:
                    key = (norm_city, region_key)
                    mapped = AMBIGUOUS_CITY_REGION.get(key)
                    if mapped:
                        coords = mapped
            if coords:
                lat,lng = coords
                threat_type, icon = classify(text)
                return [{
                    'id': str(mid), 'place': norm_city.title(), 'lat': lat, 'lng': lng,
                    'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
                    'marker_icon': icon, 'source_match': 'bracket_city'
                }]

    # --- Multi-segment / enumerated lines (1. 2. 3.) region extraction ---
    # Разбиваем по переносам, собираем упоминания нескольких областей; создаём отдельные маркеры
    
    # PRIORITY: Detect trajectory patterns BEFORE multi-region processing
    # Pattern: "з [source_region] на [target_region(s)]" - trajectory, not multi-target
    trajectory_pattern = r'(\d+(?:-\d+)?)?\s*шахед[іївыиє]*\s+з\s+([а-яіїєґ]+(щин|ччин)[ауиі])\s+на\s+([а-яіїєґ/]+(щин|ччин)[ауиіу])'
    trajectory_match = re.search(trajectory_pattern, text.lower(), re.IGNORECASE)
    
    if trajectory_match:
        count_str = trajectory_match.group(1)
        source_region = trajectory_match.group(2)
        target_regions = trajectory_match.group(4)
        
        print(f"DEBUG: Trajectory detected - {count_str or ''}шахедів з {source_region} на {target_regions}")
        
        # For trajectory messages, we should NOT create markers in region centers
        # This represents movement through airspace, not attacks on specific locations
        # Options:
        # 1. Don't create any markers (trajectory only)
        # 2. Create trajectory line visualization 
        # 3. Create border crossing markers
        
        # For now, suppress markers for pure trajectory messages
        print(f"DEBUG: Suppressing region markers for trajectory message")
        return None
    
    region_hits = []  # list of (display_name, (lat,lng), snippet)
    # Treat semicolons as separators like newlines for multi-segment parsing
    seg_text = text.replace(';', '\n')
    lines = [ln.strip() for ln in seg_text.split('\n') if ln.strip()]
    # Pre-flag launch site style multi-line posts to avoid RAW fallback – treat each line with a launch phrase as separate pseudo-track (no coords yet)
    launch_mode = any(ln.lower().startswith('відмічені пуски') or ln.lower().startswith('+ пуски') for ln in lines)
    for ln in lines:
        ln_low = ln.lower()
        local_regions = []
        for name, coords in OBLAST_CENTERS.items():
            if name in ln_low:
                local_regions.append((name, coords))
        # если в строке более 1— сохраняем все, иначе одну
        for (rn, rc) in local_regions:
            region_hits.append((rn.title(), rc, ln[:180]))
    # Якщо знайшли >=2 регіональних маркери в різних пунктах списку — формуємо множинні треки
    if len(region_hits) >= 2 and not launch_mode:
        # ВИДАЛЕНО перевірку course_line_present - тепер завжди дозволяємо region markers + course parsing
        if True:  # завжди виконуємо блок регіональних маркерів
            # Пропускаем если нет ни одного упоминания угрозы вообще
            if not has_threat(text):
                return None
            threat_type, icon = classify(text)
            tracks = []
            # deduplicate by name
            seen_names = set()
            # Directional offset helper
            def directional_offset(rlabel: str, lat: float, lng: float):
                base = rlabel.lower().split()[0]
                full = text  # already lower
                # detect "на схід <base>", "схід <base>", etc., but ignore origins "з південного сходу" for that base
                # We only tag if phrase contains base key AFTER direction (targeting side), not originating "з <dir> ..." alone.
                directions = [
                    ('схід', 'east', (0.0, 0.9)),
                    ('захід', 'west', (0.0, -0.9)),
                    ('північ', 'north', (0.7, 0.0)),
                    ('південь', 'south', (-0.7, 0.0))
                ]
                applied = None
                for word, code, (dlat, dlng) in directions:
                    patterns = [f"на {word} {base}", f" {word} {base}"]
                    if any(pat in full for pat in patterns) and f"з {word}" not in full:
                        applied = (code, dlat, dlng)
                        break
                if not applied:
                    return lat, lng, rlabel
                _, dlat, dlng = applied
                nlat = max(43.0, min(53.5, lat + dlat))
                nlng = max(21.0, min(41.0, lng + dlng))
                human = {'east':'схід','west':'захід','north':'північ','south':'південь'}[applied[0]]
                return nlat, nlng, f"{rlabel} ({human})"
            for idx, (rname, (lat,lng), snippet) in enumerate(region_hits, 1):
                if rname in seen_names: continue
                seen_names.add(rname)
                adj_lat, adj_lng, adj_label = directional_offset(rname, lat, lng)
                tracks.append({
                    'id': f"{mid}_{idx}", 'place': adj_label, 'lat': adj_lat, 'lng': adj_lng,
                    'threat_type': threat_type, 'text': snippet[:500], 'date': date_str, 'channel': channel,
                    'marker_icon': icon, 'source_match': 'region_multi'
                })
            if tracks:
                return tracks

    # --- Single border oblast KAB launch: place marker at predefined border point ---
    if len(region_hits) == 1 and 'каб' in lower and ('пуск' in lower or 'пуски' in lower):
        rname, (olat, olng), snippet = region_hits[0]
        # базовые ключи для соответствия
        key = rname.lower()
        BORDER_POINTS = {
            'донеччина': (48.20, 37.90),
            'донецька область': (48.20, 37.90),
            'сумщина': (51.30, 34.40),
            'сумська область': (51.30, 34.40),
            'чернігівщина': (51.75, 31.60),
            'чернігівська обл.': (51.75, 31.60),
            'харківщина': (50.25, 36.85),
            'харківська обл.': (50.25, 36.85),
            'луганщина': (48.90, 39.40),
            'луганська область': (48.90, 39.40),
            'запорізька обл.': (47.55, 35.60),
            'херсонська обл.': (46.65, 32.60)
        }
        # нормализация ключа (удаляем регистр / лишние пробелы)
        k_simple = key.replace('’','').replace("'",'').strip()
        # попытка прямого поиска
        coord = None
        for bk, bcoord in BORDER_POINTS.items():
            if bk in k_simple:
                coord = bcoord
                break
        if coord:
            threat_type, icon = classify(text)
            return [{
                'id': str(mid), 'place': rname + ' (кордон)', 'lat': coord[0], 'lng': coord[1],
                'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
                'marker_icon': icon, 'source_match': 'border_kab'
            }]

    # --- Pattern: multiple shaheds with counts / directions / near-pass ("повз") ---
    # Handles composite direction phrases (південного сходу -> південний схід, північно-захід тощо)
    # Examples: "14 шахедів ... 3 на Покровське з півдня, 9 на Петропавлівку з південного сходу, 2 на Шахтарське з півдня"
    #           "16 шахедів ... 2 повз Терентівку на північ, 6 на Юріївку з півдня, 7 повз Межову північно-захід" etc.
    if 'шахед' in lower and ((' на ' in lower) or (' повз ' in lower)):
        segs = re.split(r'[\n,⚠;]+', lower)
        found = []
        # Direction phrases may appear after 'з', 'зі', 'із', 'на'. Capture full tail then normalize.
        pat_on = re.compile(r'(\d{1,2})\s+на\s+([a-zа-яіїєґ\-ʼ\']{3,})(?:у|а|е)?(?:\s+((?:з|зі|із|на)\s+[a-zа-яіїєґ\-\s]+))?')
        pat_povz = re.compile(r'(\d{1,2})\s+повз\s+([a-zа-яіїєґ\-ʼ\']{3,})(?:у|а|е)?(?:\s+(?:на\s+)?([a-zа-яіїєґ\-\s]+))?')
        def normalize_direction(raw_dir: str) -> str:
            if not raw_dir:
                return ''
            d = raw_dir.lower().strip()
            # remove leading prepositions
            d = re.sub(r'^(з|зі|із|на|від)\s+', '', d)
            d = d.replace('–','-')
            # unify hyphen variants to space-separated tokens
            d = d.replace('-', ' ')
            d = re.sub(r'\s+', ' ', d).strip()
            # morphological endings -> base cardinal forms
            repl = [
                (r'південного сходу', 'південний схід'),
                (r'північного сходу', 'північний схід'),
                (r'південного заходу', 'південний захід'),
                (r'північного заходу', 'північний захід'),
                (r'півдня', 'південь'),
                (r'півночі', 'північ'),
                (r'сходу', 'схід'),
                (r'заходу', 'захід')
            ]
            for pat, rep in repl:
                d = re.sub(pat, rep, d)
            # collapse duplicate words
            parts = []
            seen = set()
            for tok in d.split():
                if tok in seen:
                    continue
                seen.add(tok)
                parts.append(tok)
            return ' '.join(parts)
        for seg in segs:
            # Strip common trailing separators (colon, semicolon, space, slash, backslash)
            s = seg.strip(':; /\\')
            if not s or s.isdigit():
                continue
            matches = []
            matches.extend(list(pat_on.finditer(s)))
            matches.extend(list(pat_povz.finditer(s)))
            for m in matches:
                cnt = int(m.group(1))
                place_token = (m.group(2) or '').strip("-'ʼ")
                raw_dir = ''
                # pat_on group(3); pat_povz group(3)
                if len(m.groups()) >= 3:
                    raw_dir = (m.group(3) or '').strip()
                direction = normalize_direction(raw_dir)
                place_token = place_token.replace('ʼ',"'")
                variants = {place_token}
                # heuristic nominative recovery
                if place_token.endswith('ку'): variants.add(place_token[:-2]+'ка')
                if place_token.endswith('ву'): variants.add(place_token[:-2]+'ва')
                if place_token.endswith('ову'): variants.add(place_token[:-3]+'ова')
                if place_token.endswith('ю'):
                    variants.add(place_token[:-1]+'я'); variants.add(place_token[:-1]+'а')
                if place_token.endswith('у'): variants.add(place_token[:-1]+'а')
                if place_token.endswith('ому'):
                    variants.add(place_token[:-3]+'е'); variants.add(place_token[:-3])
                matched_coord = None; matched_name = None
                for var in variants:
                    if var in CITY_COORDS:
                        matched_coord = CITY_COORDS[var]; matched_name = var; break
                if matched_coord:
                    plat, plng = matched_coord
                    found.append((matched_name, plat, plng, cnt, direction, s[:160]))
        if found:
            threat_type, icon = classify(text)
            tracks = []
            for idx,(p, plat, plng, cnt, direction, snippet) in enumerate(found,1):
                base_label = f"{p.title()} ({cnt})"
                if direction:
                    base_label += f" ←{direction}"
                tracks.append({
                    'id': f"{mid}_s{idx}", 'place': base_label, 'lat': plat, 'lng': plng,
                    'threat_type': threat_type, 'text': snippet[:500], 'date': date_str, 'channel': channel,
                    'marker_icon': icon, 'source_match': 'multi_shah_ed', 'count': cnt
                })
            if found and not tracks:
                log.debug(f"multi_shah_ed matched segments but no tracks mid={mid} raw={found}")
            if tracks:
                log.debug(f"multi_shah_ed tracks mid={mid} -> {[t['place'] for t in tracks]}")
                return tracks

    # --- Per-line UAV course / area city targeting ("БпЛА курсом на <місто>", "8х БпЛА в районі <міста>", "БпЛА на <місто>") ---
    # Triggered when region multi list suppressed earlier due to presence of course lines or simple "на" pattern.
    if 'бпла' in lower and ('курс' in lower or 'в районі' in lower or 'в напрямку' in lower or 'в бік' in lower or 'від' in lower or 'околиц' in lower or 'сектор' in lower or 'бпла на ' in lower or (re.search(r'\d+\s*[xх×]?\s*бпла\s+на\s+', lower))):
        add_debug_log(f"UAV course parser triggered for message length: {len(text)} chars", "uav_course")
        
        # --- EARLY CHECK: Black Sea aquatory (e.g. "курсом на Миколаїв з акваторії Чорного моря" or "15 шахедів з моря на Ізмаїл") ---
        # Must check BEFORE "курсом на" parser to prevent placing marker on target city
        is_black_sea = (('акватор' in lower or 'акваторії' in lower) and ('чорного моря' in lower or 'чорне море' in lower or 'чорному морі' in lower)) or \
                       ('з моря' in lower and ('курс' in lower or 'на ' in lower)) or \
                       ('з чорного моря' in lower)
        
        if is_black_sea:
            # Extract target region/direction if mentioned
            m_target = re.search(r'курс(?:ом)?\s+на\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-]{3,})', lower)
            m_direction = re.search(r'на\s+(північ|південь|схід|захід|північний\s+схід|північний\s+захід|південний\s+схід|південний\s+захід)', lower)
            m_region = re.search(r'(одещин|одеськ|миколаїв|херсон)', lower)
            
            target_info = None
            sea_lat, sea_lng = 45.3, 30.7  # Default: northern Black Sea central coords
            
            # Adjust position based on direction/region
            if m_direction:
                direction = m_direction.group(1)
                if 'південь' in direction:
                    sea_lat = 45.0  # Further south
                elif 'північ' in direction:
                    sea_lat = 45.6  # Further north
                if 'схід' in direction:
                    sea_lng = 31.2  # Further east
                elif 'захід' in direction:
                    sea_lng = 30.2  # Further west
            
            if m_region:
                region_name = m_region.group(1)
                if 'одещин' in region_name or 'одеськ' in region_name:
                    # South of Odesa region - in the sea 50km offshore
                    sea_lat, sea_lng = 45.7, 30.7
                    target_info = 'Одещини'
                elif 'миколаїв' in region_name:
                    sea_lat, sea_lng = 45.9, 31.4
                    target_info = 'Миколаївщини'
                elif 'херсон' in region_name:
                    sea_lat, sea_lng = 45.7, 32.5
                    target_info = 'Херсонщини'
            
            if m_target:
                tc = m_target.group(1).lower()
                tc = UA_CITY_NORMALIZE.get(tc, tc)
                target_info = tc.title()
            
            threat_type, icon = classify(text)
            place_label = 'Акваторія Чорного моря'
            if target_info:
                place_label += f' (на {target_info})'
            
            # Try to find target city coordinates for trajectory
            target_coords = None
            if m_target:
                tc_normalized = m_target.group(1).lower()
                tc_normalized = UA_CITY_NORMALIZE.get(tc_normalized, tc_normalized)
                if tc_normalized in CITY_COORDS:
                    target_coords = CITY_COORDS[tc_normalized]
            
            result = {
                'id': str(mid), 'place': place_label, 'lat': sea_lat, 'lng': sea_lng,
                'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
                'marker_icon': icon, 'source_match': 'black_sea_course'
            }
            
            # Add trajectory data if we have target coordinates
            if target_coords:
                result['trajectory'] = {
                    'start': [sea_lat, sea_lng],
                    'end': list(target_coords),
                    'target': target_info
                }
            
            return [result]
        
        original_text_norm = re.sub(r'(?i)(\b[А-Яа-яЇїІіЄєҐґ\-]{3,}(?:щина|область|обл\.)):(?!\s*\n)', r'\1:\n', original_text)
        lines_with_region = []
        current_region_hdr = None
        for raw_ln in original_text_norm.splitlines():
            ln_stripped = raw_ln.strip()
            if not ln_stripped:
                continue
            low_ln = ln_stripped.lower()
            # Allow region header if line ends with ':' even if preceded by emoji or bullets
            if low_ln.endswith(':'):
                # remove leading emojis/symbols
                cleaned_hdr = re.sub(r'^[^a-zа-яіїєґ]+','', low_ln[:-1])
                base_hdr = cleaned_hdr.strip()
                log.debug(f"mid={mid} region_header_check: '{low_ln}' -> cleaned: '{base_hdr}' -> found: {base_hdr in OBLAST_CENTERS}")
                if base_hdr in OBLAST_CENTERS:
                    current_region_hdr = base_hdr
                    log.debug(f"mid={mid} region_header_set: '{base_hdr}'")
                continue
            # split by semicolons; also break on pattern like " 2х БпЛА курсом" inside the same segment later
            subparts = [p.strip() for p in re.split(r'[;]+', ln_stripped) if p.strip()]
            for part in subparts:
                lines_with_region.append((part, current_region_hdr))
        # Further split segments that contain multiple "БпЛА курс" phrases glued together
        multi_start_re = re.compile(r'(?:\d+\s*[xх×]?\s*)?бпла\s*курс', re.IGNORECASE)
        expanded = []
        for part, region_hdr in lines_with_region:
            low_part = part.lower()
            starts = [m.start() for m in multi_start_re.finditer(low_part)]
            if len(starts) <= 1:
                expanded.append((part, region_hdr))
                continue
            for idx, s in enumerate(starts):
                seg_start = s
                seg_end = starts[idx+1] if idx+1 < len(starts) else len(low_part)
                segment = part[seg_start:seg_end].strip()
                if segment:
                    expanded.append((segment, region_hdr))
        if expanded:
            lines_with_region = expanded
        course_tracks = []
        pat_count_course = re.compile(r'^(\d+(?:-\d+)?)\s*[xх×]?\s*бпла(?:\s+пролетіли)?.*?курс(?:ом)?\s+на\s+(?:н\.п\.?\s*)?([A-Za-zА-Яа-яЇїІіЄєҐґ\-’ʼ`\s]{3,40}?)(?=[,\.\n;:!\?]|$)', re.IGNORECASE)
        pat_course = re.compile(r'бпла(?:\s+пролетіли)?.*?курс(?:ом)?\s+на\s+(?:н\.п\.?\s*)?([A-Za-zА-Яа-яЇїІіЄєҐґ\-’ʼ`\s]{3,40}?)(?=[,\.\n;:!\?]|$)', re.IGNORECASE)
        pat_area = re.compile(r'(\d+(?:-\d+)?)?[xх×]?\s*бпла\s+(?:.*?\s+)?в\s+районі\s+(?:н\.п\.?\s*)?([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,60}?)(?=[,\.\n;:!\?]|$)', re.IGNORECASE)  # Fixed: added н.п. support
        pat_napramku = re.compile(r'(\d+(?:-\d+)?)?[xх×]?\s*бпла\s+[➡️⬆️⬇️⬅️↗️↘️↙️↖️]*\s*(?:в|у)\s+напрямку\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,40}?)(?=[,\.\n;:!\?]|$)', re.IGNORECASE)
        pat_sektor = re.compile(r'(\d+(?:-\d+)?)?[xх×]?\s*бпла\s+в\s+секторі\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,40}?)(?=[,\.\n;:!\?]|$)', re.IGNORECASE)
        pat_simple_na = re.compile(r'(\d+(?:-\d+)?)?[xх×]?\s*бпла\s+на\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,40}?)(?=[,\.\n;:!\?]|$)', re.IGNORECASE)
        pat_complex_napramku = re.compile(r'(\d+(?:-\d+)?)?[xх×]?\s*бпла\s+на/через\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,40}?)\s+в\s+напрямку\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,40}?)(?=[,\.\n;:!\?]|$)', re.IGNORECASE)
        pat_napramku_ta = re.compile(r'(\d+(?:-\d+)?)?[xх×]?\s*бпла\s+(?:в|у)\s+напрямку\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,40}?)\s+та\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,40}?)(?=[,\.\n;:!\?]|$)', re.IGNORECASE)
        pat_okolytsi = re.compile(r'(\d+(?:-\d+)?)?[xх×]?\s*бпла\s+на\s+околицях\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,40}?)(?=[,\.\n;:!\?]|$)', re.IGNORECASE)
        pat_vid_do = re.compile(r'(\d+(?:-\d+)?)?[xх×]?\s*бпла\s+від\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,40}?)\s+до\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,40}?)(?=[,\.\n;:!\?]|$)', re.IGNORECASE)
        pat_vik = re.compile(r'(\d+(?:-\d+)?)?[xх×]?\s*бпла\s+[➡️⬆️⬇️⬅️↗️↘️↙️↖️]*\s*(?:в|у)\s+бік\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-\'ʼ`\s]{3,40}?)(?=[,\.\n;:!\?]|$)', re.IGNORECASE)
        if re.search(r'бпла.*?курс(?:ом)?\s+на\s+кіпт[ії]', lower):
            coords = SETTLEMENT_FALLBACK.get('кіпті')
            if coords:
                lat, lng = coords
                threat_type, icon = classify(original_text)
                return [{
                    'id': f"{mid}_kipti_course", 'place': 'Кіпті', 'lat': lat, 'lng': lng,
                    'threat_type': threat_type, 'text': original_text[:500], 'date': date_str, 'channel': channel,
                    'marker_icon': icon, 'source_match': 'course_kipti'
                }]
        def norm_city_token(tok: str) -> str:
            t = tok.lower().strip(" .,'’ʼ`-:")
            t = t.replace("'", "'")  # Normalize curly quotes
            if t.endswith('ку'): t = t[:-2] + 'ка'
            elif t.endswith('ву'): t = t[:-2] + 'ва'
            elif t.endswith('ову'): t = t[:-3] + 'ова'
            elif t.endswith('ю'): t = t[:-1] + 'я'
            elif t.endswith('у'): t = t[:-1] + 'а'
            if t.startswith('нову '):
                t = 'нова ' + t[5:]
            t = t.replace('водолагу','водолога')
            return t
        
        # Pattern to extract oblast from parentheses like "(Полтавська обл.)" or "(Харківська область)"
        pat_oblast_in_parens = re.compile(r'\(([А-Яа-яЇїІіЄєҐґ\-]+)\s*обл\.?\)?', re.IGNORECASE)
        
        for ln, region_hdr in lines_with_region:
            ln_low = ln.lower()
            if 'бпла' not in ln_low:
                continue
            
            # PRIORITY: Extract oblast from parentheses in the line itself (e.g., "Семенівку (Полтавська обл.)")
            # This overrides the region header from channel
            line_oblast_match = pat_oblast_in_parens.search(ln)
            if line_oblast_match:
                oblast_name = line_oblast_match.group(1).lower()
                # Map to standard oblast name
                oblast_map = {
                    'полтавськ': 'полтавщина', 'полтавська': 'полтавщина',
                    'харківськ': 'харківщина', 'харківська': 'харківщина',
                    'чернігівськ': 'чернігівщина', 'чернігівська': 'чернігівщина',
                    'сумськ': 'сумщина', 'сумська': 'сумщина',
                    'київськ': 'київщина', 'київська': 'київщина',
                    'одеськ': 'одещина', 'одеська': 'одещина',
                    'миколаївськ': 'миколаївщина', 'миколаївська': 'миколаївщина',
                    'херсонськ': 'херсонщина', 'херсонська': 'херсонщина',
                    'запорізьк': 'запорізька', 'запорізька': 'запорізька',
                    'дніпропетровськ': 'дніпропетровщина', 'дніпропетровська': 'дніпропетровщина',
                    'донецьк': 'донецька', 'донецька': 'донецька',
                    'луганськ': 'луганська', 'луганська': 'луганська',
                    'черкаськ': 'черкащина', 'черкаська': 'черкащина',
                    'житомирськ': 'житомирщина', 'житомирська': 'житомирщина',
                    'вінницьк': 'вінниччина', 'вінницька': 'вінниччина',
                    'рівненськ': 'рівненщина', 'рівненська': 'рівненщина',
                    'волинськ': 'волинь', 'волинська': 'волинь',
                    'львівськ': 'львівщина', 'львівська': 'львівщина',
                    'тернопільськ': 'тернопільщина', 'тернопільська': 'тернопільщина',
                    'хмельницьк': 'хмельниччина', 'хмельницька': 'хмельниччина',
                    'івано-франківськ': 'івано-франківщина', 'івано-франківська': 'івано-франківщина',
                    'закарпатськ': 'закарпаття', 'закарпатська': 'закарпаття',
                    'чернівецьк': 'чернівецька', 'чернівецька': 'чернівецька',
                    'кіровоградськ': 'кіровоградщина', 'кіровоградська': 'кіровоградщина',
                }
                for key, val in oblast_map.items():
                    if oblast_name.startswith(key):
                        region_hdr = val
                        log.info(f"mid={mid} OVERRIDE region_hdr from line: '{oblast_name}' -> '{region_hdr}'")
                        break
            
            add_debug_log(f"Processing UAV line: '{ln[:100]}...' (region: {region_hdr})", "uav_course")
            
            # Check for complex pattern "на/через X в напрямку Y" first
            m_complex = pat_complex_napramku.search(ln_low)
            if m_complex:
                count = int(m_complex.group(1)) if m_complex.group(1) else 1
                city1 = m_complex.group(2)  # через це місто
                city2 = m_complex.group(3)  # в напрямку цього міста
                
                # Process both cities
                for city_raw in [city1, city2]:
                    multi_norm = _resolve_city_candidate(city_raw)
                    base = norm_city_token(multi_norm)
                    coords = CITY_COORDS.get(base) or (SETTLEMENTS_INDEX.get(base) if SETTLEMENTS_INDEX else None)
                    if not coords:
                        try:
                            coords = region_enhanced_coords(base, region_hint_override=region_hdr)
                        except Exception:
                            coords = None
                    # Try Nominatim API if still no coordinates
                    if not coords and NOMINATIM_AVAILABLE:
                        try:
                            nominatim_coords = get_coordinates_nominatim(base, region=region_hdr)
                            if nominatim_coords:
                                coords = nominatim_coords
                                CITY_COORDS[base] = coords
                        except Exception:
                            pass
                    if coords:
                        lat, lng = coords
                        threat_type, icon = classify(text)
                        for i in range(1, count+1):
                            label = base.title()
                            if count > 1:
                                label += f" ({i}/{count})"
                            if region_hdr and region_hdr not in label.lower():
                                label += f" [{region_hdr.title()}]"
                            course_tracks.append({
                                'id': f"{mid}_complex_{base}_{i}", 'place': label, 'lat': lat, 'lng': lng,
                                'threat_type': threat_type, 'text': ln[:500], 'date': date_str, 'channel': channel,
                                'marker_icon': icon, 'source_match': 'uav_complex', 'count': 1
                            })
                continue  # Skip to next line
            
            # Check for "від X до Y" pattern (trajectory)
            m_vid_do = pat_vid_do.search(ln_low)
            if m_vid_do:
                count = int(m_vid_do.group(1)) if m_vid_do.group(1) else 1
                city1 = m_vid_do.group(2)  # від цього міста
                city2 = m_vid_do.group(3)  # до цього міста
                
                # Process both cities
                for city_raw in [city1, city2]:
                    multi_norm = _resolve_city_candidate(city_raw)
                    base = norm_city_token(multi_norm)
                    coords = CITY_COORDS.get(base) or (SETTLEMENTS_INDEX.get(base) if SETTLEMENTS_INDEX else None)
                    if not coords:
                        try:
                            coords = region_enhanced_coords(base, region_hint_override=region_hdr)
                        except Exception:
                            coords = None
                    if not coords and NOMINATIM_AVAILABLE:
                        try:
                            nominatim_coords = get_coordinates_nominatim(base, region=region_hdr)
                            if nominatim_coords:
                                coords = nominatim_coords
                                CITY_COORDS[base] = coords
                        except Exception:
                            pass
                    if coords:
                        lat, lng = coords
                        threat_type, icon = classify(text)
                        for i in range(1, count+1):
                            label = base.title()
                            if count > 1:
                                label += f" ({i}/{count})"
                            if region_hdr and region_hdr not in label.lower():
                                label += f" [{region_hdr.title()}]"
                            course_tracks.append({
                                'id': f"{mid}_viddo_{base}_{i}", 'place': label, 'lat': lat, 'lng': lng,
                                'threat_type': threat_type, 'text': ln[:500], 'date': date_str, 'channel': channel,
                                'marker_icon': icon, 'source_match': 'uav_vid_do', 'count': 1
                            })
                continue
            
            # Check for "в напрямку X та Y" pattern (multiple cities)
            m_ta = pat_napramku_ta.search(ln_low)
            if m_ta:
                count = int(m_ta.group(1)) if m_ta.group(1) else 1
                city1 = m_ta.group(2)
                city2 = m_ta.group(3)
                
                # Process both cities
                for city_raw in [city1, city2]:
                    multi_norm = _resolve_city_candidate(city_raw)
                    base = norm_city_token(multi_norm)
                    coords = CITY_COORDS.get(base) or (SETTLEMENTS_INDEX.get(base) if SETTLEMENTS_INDEX else None)
                    if not coords:
                        try:
                            coords = region_enhanced_coords(base, region_hint_override=region_hdr)
                        except Exception:
                            coords = None
                    if not coords and NOMINATIM_AVAILABLE:
                        try:
                            nominatim_coords = get_coordinates_nominatim(base, region=region_hdr)
                            if nominatim_coords:
                                coords = nominatim_coords
                                CITY_COORDS[base] = coords
                        except Exception:
                            pass
                    if coords:
                        lat, lng = coords
                        threat_type, icon = classify(text)
                        for i in range(1, count+1):
                            label = base.title()
                            if count > 1:
                                label += f" ({i}/{count})"
                            if region_hdr and region_hdr not in label.lower():
                                label += f" [{region_hdr.title()}]"
                            course_tracks.append({
                                'id': f"{mid}_ta_{base}_{i}", 'place': label, 'lat': lat, 'lng': lng,
                                'threat_type': threat_type, 'text': ln[:500], 'date': date_str, 'channel': channel,
                                'marker_icon': icon, 'source_match': 'uav_ta', 'count': 1
                            })
                continue
            
            count = None; city = None; approx_flag = False
            m1 = pat_count_course.search(ln_low)
            if m1:
                count = int(m1.group(1)); city = m1.group(2)
            else:
                m2 = pat_area.search(ln_low)
                if m2:
                    if m2.group(1):
                        count = int(m2.group(1))
                    city = m2.group(2)
                else:
                    m3 = pat_napramku.search(ln_low)
                    if m3:
                        if m3.group(1):
                            count = int(m3.group(1))
                        city = m3.group(2)
                    else:
                        m3_sektor = pat_sektor.search(ln_low)
                        if m3_sektor:
                            if m3_sektor.group(1):
                                count = int(m3_sektor.group(1))
                            city = m3_sektor.group(2)
                        else:
                            m4 = pat_course.search(ln_low)
                            if m4:
                                city = m4.group(1)
                            else:
                                m5 = pat_okolytsi.search(ln_low)
                                if m5:
                                    if m5.group(1):
                                        count = int(m5.group(1))
                                    city = m5.group(2)
                                else:
                                    m6 = pat_simple_na.search(ln_low)
                                    if m6:
                                        if m6.group(1):
                                            count = int(m6.group(1))
                                        city = m6.group(2)
                                    else:
                                        m7 = pat_vik.search(ln_low)
                                        if m7:
                                            if m7.group(1):
                                                count = int(m7.group(1))
                                            city = m7.group(2)
            if not city:
                add_debug_log("No city found in UAV line", "uav_course")
                continue
            add_debug_log(f"Found city '{city}' in UAV line", "uav_course")
            multi_norm = _resolve_city_candidate(city)
            base = norm_city_token(multi_norm)
            add_debug_log(f"City normalized to '{base}'", "uav_course")
            
            # FILTER: Skip oblast/region names (e.g., "БпЛА на Дніпропетровщині" should be regional threat, not city marker)
            oblast_suffixes = ['щина', 'щині', 'область', 'обл']
            if any(base.endswith(suffix) for suffix in oblast_suffixes):
                add_debug_log(f"Skipping oblast name '{base}' - this is a regional threat, not a city target", "uav_course")
                continue
            
            # PRIORITY: Try region-specific variant first (e.g., "шевченкове(миколаївська)" for "шевченкове" with region_hdr="миколаївщина")
            coords = None
            if region_hdr:
                # Try variant with region suffix
                region_variant = f"{base}({region_hdr})"
                coords = CITY_COORDS.get(region_variant)
                if coords:
                    add_debug_log(f"Found region-specific coordinates for '{region_variant}': {coords}", "uav_course")
            
            # Fallback to base name without region
            if not coords:
                coords = CITY_COORDS.get(base) or (SETTLEMENTS_INDEX.get(base) if SETTLEMENTS_INDEX else None)
                add_debug_log(f"Coordinates lookup for '{base}': {coords}", "uav_course")
            if not coords:
                try:
                    coords = region_enhanced_coords(base, region_hint_override=region_hdr)
                except Exception:
                    coords = None
            # Try Nominatim API if still no coordinates
            if not coords and NOMINATIM_AVAILABLE:
                try:
                    add_debug_log(f"Trying Nominatim API for city '{base}'", "uav_course")
                    nominatim_coords = get_coordinates_nominatim(base, region=region_hdr)
                    if nominatim_coords:
                        coords = nominatim_coords
                        CITY_COORDS[base] = coords  # Cache for future use
                        add_debug_log(f"Nominatim found coordinates for '{base}': {coords}", "uav_course")
                except Exception as e:
                    add_debug_log(f"Nominatim API error for '{base}': {e}", "uav_course")
            if not coords:
                # Fallback: if we have a region header, place placeholder near its oblast center with slight jitter
                if region_hdr and region_hdr in OBLAST_CENTERS:
                    rlat, rlng = OBLAST_CENTERS[region_hdr]
                    # deterministic jitter based on hash of city token
                    h = abs(hash(base)) % 1000 / 1000.0
                    lat = max(43.0, min(53.5, rlat + (h - 0.5) * 0.4))
                    lng = max(21.0, min(41.0, rlng + (h - 0.5) * 0.6))
                    coords = (lat, lng)
                    approx_flag = True
                else:
                    # skip THIS city but continue processing other cities
                    add_debug_log(f"Skipping unrecognized city '{base}' - no coordinates and no region context", "uav_course")
                    continue
            if base not in CITY_COORDS:
                CITY_COORDS[base] = coords
            lat, lng = coords
            threat_type, icon = classify(text)
            # Generate individual markers per drone for progressive map loading
            total = count or 1
            for i in range(1, total+1):
                label = base.title()
                if total > 1:
                    label += f" ({i}/{total})"
                if region_hdr and region_hdr not in label.lower():
                    label += f" [{region_hdr.title()}]"
                if approx_flag:
                    label += ' ~'
                course_tracks.append({
                    'id': f"{mid}_c{len(course_tracks)+1}", 'place': label, 'lat': lat, 'lng': lng,
                    'threat_type': threat_type, 'text': ln[:500], 'date': date_str, 'channel': channel,
                    'marker_icon': icon, 'source_match': 'course_city_unit', 'count': 1
                })
                add_debug_log(f"Created course track for '{label}' at {lat}, {lng}", "uav_course")
        add_debug_log(f"Total course tracks generated: {len(course_tracks)}", "uav_course")
        log.debug(f"mid={mid} course_tracks_generated: {len(course_tracks)} tracks")
        if course_tracks:
            return course_tracks
        # Salvage fallback: large multi-line message with many 'бпла курсом' but parser produced nothing
        try:
            ll_full = text.lower()
            if course_tracks == [] and ll_full.count('бпла') >= 5 and ll_full.count('курс') >= 5:
                pat_salv = re.compile(r'(?:\d+\s*[xх×]?\s*)?бпла[^\n]{0,60}?курс(?:ом)?\s+на\s+([a-zа-яіїєґ\-ʼ"“”\'`\s]{3,40})', re.IGNORECASE)
                raw_hits = [m.group(1).strip() for m in pat_salv.finditer(ll_full)]
                uniq = []
                for h in raw_hits:
                    if h and h not in uniq:
                        uniq.append(h)
                salvage_tracks = []
                for idx, token in enumerate(uniq, 1):
                    base_tok = _resolve_city_candidate(token)
                    base_tok = norm_city_token(base_tok)
                    coords = CITY_COORDS.get(base_tok) or (SETTLEMENTS_INDEX.get(base_tok) if SETTLEMENTS_INDEX else None)
                    if not coords:
                        continue
                    lat, lng = coords
                    threat_type, icon = classify(text)
                    salvage_tracks.append({
                        'id': f"{mid}_sf{idx}", 'place': base_tok.title(), 'lat': lat, 'lng': lng,
                        'threat_type': threat_type, 'text': token[:120], 'date': date_str, 'channel': channel,
                        'marker_icon': icon, 'source_match': 'salvage_course_multi'
                    })
                if salvage_tracks:
                    log.debug(f"salvage_course_multi generated {len(salvage_tracks)} tracks mid={mid}")
                    return salvage_tracks
        except Exception as _e_salv:
            log.debug(f'salvage fallback error mid={mid}: {_e_salv}')

    # --- Generic multi-line UAV near-pass counts (e.g. "5х бпла повз Барвінкове") ---
    if 'бпла' in lower and 'повз' in lower and re.search(r'\d+[xх]\s*бпла', lower):
        lines_near = [ln.strip() for ln in lower.split('\n') if ln.strip()]
        near_tracks = []
        pat_near = re.compile(r'(\d+)[xх]\s*бпла[^\n]*?повз\s+([a-zа-яіїєґ\-ʼ\']{3,})')
        for ln in lines_near:
            m = pat_near.search(ln)
            if not m:
                continue
            cnt = int(m.group(1))
            place = (m.group(2) or '').strip("-'ʼ")
            variants = {place}
            if place.endswith('е'): variants.add(place[:-1])
            if place.endswith('ю'):
                variants.add(place[:-1]+'я'); variants.add(place[:-1]+'а')
            if place.endswith('у'):
                variants.add(place[:-1]+'а')
            if place.endswith('ому'):
                variants.add(place[:-3])
            if place.endswith('ове'):
                variants.add(place[:-2]+'’я')  # crude alt
            matched=None; mname=None
            for v in variants:
                if v in CITY_COORDS:
                    matched=CITY_COORDS[v]; mname=v; break
            if not matched and SETTLEMENTS_INDEX:
                for v in variants:
                    if v in SETTLEMENTS_INDEX:
                        matched=SETTLEMENTS_INDEX[v]; mname=v; break
            if not matched:
                # OpenCage fallback
                try:
                    for v in variants:
                        oc = region_enhanced_coords(v)
                        if oc:
                            matched=oc; mname=v; break
                except Exception:
                    matched=None
            if matched:
                if mname not in CITY_COORDS:
                    CITY_COORDS[mname]=matched
                lat,lng = matched
                threat_type, icon = classify(text)
                near_tracks.append({
                    'id': f"{mid}_n{len(near_tracks)+1}", 'place': f"{mname.title()} ({cnt})", 'lat': lat, 'lng': lng,
                    'threat_type': threat_type, 'text': ln[:500], 'date': date_str, 'channel': channel,
                    'marker_icon': icon, 'source_match': 'uav_near_pass', 'count': cnt
                })
        if near_tracks:
            return near_tracks

    # --- Late parenthetical specific settlement fallback (e.g. direction to oblast but (затока)) ---
    if has_threat(original_text.lower()) and '(' in original_text and ')' in original_text:
        p_tokens = re.findall(r'\(([A-Za-zА-Яа-яЇїІіЄєҐґ\-\s]{3,})\)', original_text.lower())
        if p_tokens:
            cand = p_tokens[-1].strip()
            cand = re.sub(r'^(смт|с\.|м\.|місто|селище)\s+','', cand)
            base_cand = UA_CITY_NORMALIZE.get(cand, cand)
            coords = CITY_COORDS.get(base_cand) or SETTLEMENTS_INDEX.get(base_cand)
            log.debug(f"late_parenthetical mid={mid} cand={cand} base={base_cand} found={bool(coords)}")
            if coords:
                lat,lng = coords
                threat_type, icon = classify(original_text)
                return [{
                    'id': str(mid), 'place': base_cand.title(), 'lat': lat, 'lng': lng,
                    'threat_type': threat_type, 'text': original_text[:500], 'date': date_str, 'channel': channel,
                    'marker_icon': icon, 'source_match': 'late_parenthetical'
                }]

    # --- Settlement matching using external dataset (if provided) (single first match) ---
    if not region_hits:
        # 1) Multi-list form: "Новгород-сіверський, Шостка, Короп, Кролевець - уважно по БПЛА"
        # support both hyphen - and en dash – between list and tail
        dash_idx = None
        for dch in [' - ', ' – ', '- ', '– ']:
            if dch in lower:
                dash_idx = lower.index(dch)
                break
        if ('уважно' in lower or 'по бпла' in lower or 'бпла' in lower) and (',' in lower) and dash_idx is not None:
            left = lower[:dash_idx]
            right = lower[dash_idx+1:]
            if any(k in right for k in ['бпла','дрон','шахед','uav']):
                raw_places = [p.strip() for p in left.split(',') if p.strip()]
                tracks = []
                threat_type, icon = classify(text)
                seen = set()
                for idx, rp in enumerate(raw_places,1):
                    key = rp.replace('й,','й').strip()
                    coords = region_enhanced_coords(key)
                    if coords and key not in seen:
                        seen.add(key)
                        lat,lng = coords
                        tracks.append({
                            'id': f"{mid}_m{idx}", 'place': key.title(), 'lat': lat, 'lng': lng,
                            'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
                            'marker_icon': icon, 'source_match': 'multi_settlement'
                        })
                if tracks:
                    return tracks
        # 2) Single settlement search (fallback) with word-boundary and specificity prioritization
        if SETTLEMENTS_INDEX:
            cand_hits = []
            text_len = len(lower)
            for name in SETTLEMENTS_ORDERED:
                start = 0
                while True:
                    idx = lower.find(name, start)
                    if idx == -1:
                        break
                    before_ok = (idx == 0) or not lower[idx-1].isalnum()
                    after_idx = idx + len(name)
                    after_ok = (after_idx == text_len) or not lower[after_idx].isalnum()
                    if before_ok and after_ok:
                        cand_hits.append(name)
                        break  # only need first occurrence
                    start = idx + 1
            if cand_hits:
                # Prefer longer names; deprioritize generic oblast centers when more specific present
                def score(n: str):
                    base_penalty = -5 if n in ['суми'] and len(cand_hits) > 1 else 0
                    return (len(n) + base_penalty)
                cand_hits.sort(key=score, reverse=True)
                chosen = cand_hits[0]
                lat, lng = SETTLEMENTS_INDEX[chosen]
                threat_type, icon = classify(text)
                return [{
                    'id': str(mid), 'place': chosen.title(), 'lat': lat, 'lng': lng,
                    'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
                    'marker_icon': icon,
                    'source_match': 'settlement'
                }]

    # --- Raion (district) detection ---
    # Ищем конструкции вида "Покровський район", а также множественные "Конотопський та Сумський районы".
    def norm_raion(token: str):
        t = token.lower().strip('- ')
        # унификация дефисов
        t = t.replace('–','-')
        # морфологические окончания -> базовая форма -ський
        t = re.sub(r'(ському|ского|ського|ский|ськiй|ськой|ським|ском)$','ський', t)
        return t
    raion_matches = []
    # множественное 'райони'
    plural_pattern = re.compile(r'([А-ЯA-ZЇІЄҐЁа-яa-zїієґё,\-\s]{4,}?)райони', re.IGNORECASE)
    for pm in plural_pattern.finditer(text):
        segment = pm.group(1)
        # разделяем по 'та' или запятым
        parts = re.split(r'\s+та\s+|,', segment)
        for p in parts:
            cand = p.strip()
            if not cand:
                continue
            # берём последнее слово (Конотопський)
            last = cand.split()[-1]
            base = norm_raion(last)
            if base in RAION_FALLBACK:
                raion_matches.append((base, RAION_FALLBACK[base]))
    # одиночное 'район' (любой падеж: район, району, районом, района)
    raion_pattern = re.compile(r'([А-ЯA-ZЇІЄҐЁа-яa-zїієґё\-]{4,})\s+район(?:у|ом|а)?', re.IGNORECASE)
    for m_r in raion_pattern.finditer(text):
        base = norm_raion(m_r.group(1))
        if base in RAION_FALLBACK:
            raion_matches.append((base, RAION_FALLBACK[base]))
    # Аббревиатура "р-н" (у т.ч. варианты "р-н.", "рн", "р-н," )
    raion_abbrev_pattern = re.compile(r'([А-ЯA-ZЇІЄҐЁа-яa-zїієґё\-]{4,})\s+р\s*[-–]?\s*н\.?', re.IGNORECASE)
    for m_ra in raion_abbrev_pattern.finditer(text):
        base = norm_raion(m_ra.group(1))
        if base in RAION_FALLBACK:
            raion_matches.append((base, RAION_FALLBACK[base]))
    if raion_matches:
        threat_type, icon = classify(text)
        tracks = []
        seen = set()
        for idx,(name,(lat,lng)) in enumerate(raion_matches,1):
            # For some districts, show the main city name instead of district name
            district_to_city_mapping = {
                'павлоградський': 'Павлоград',
                'білоцерківський': 'Біла Церква',
                'кременчуцький': 'Кременчук',
                'миколаївський': 'Миколаїв',
                'дніпровський': 'Дніпро'
            }
            
            if name.lower() in district_to_city_mapping:
                title = district_to_city_mapping[name.lower()]
            else:
                title = f"{name.title()} район"
            if title in seen: continue
            seen.add(title)
            # Maintain alarm overlay state
            if threat_type == 'alarm':
                RAION_ALARMS[name] = {'place': title, 'lat': lat, 'lng': lng, 'since': time.time()}
            elif threat_type == 'alarm_cancel':
                RAION_ALARMS.pop(name, None)
            tracks.append({
                'id': f"{mid}_d{idx}", 'place': title, 'lat': lat, 'lng': lng,
                'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
                'marker_icon': icon, 'source_match': 'raion'
            })
        if tracks:
            log.debug(f"RAION_MATCH mid={mid} -> {[t['place'] for t in tracks]}")
            return tracks

    # --- Hromada detection (e.g., "Хотінська територіальна громада") ---
    hromada_pattern = re.compile(r'([А-ЯA-ZЇІЄҐЁа-яa-zїієґё\-]{4,})\s+територіал(?:ьна|ьної)?\s+громада', re.IGNORECASE)
    hromada_matches = []
    for m_h in hromada_pattern.finditer(text):
        token = m_h.group(1).lower()
        # normalize adjective endings to 'ська'
        base = re.sub(r'(ської|ской|ська|ской)$', 'ська', token)
        if base in HROMADA_FALLBACK:
            hromada_matches.append((base, HROMADA_FALLBACK[base]))
    if hromada_matches:
        threat_type, icon = classify(text)
        tracks = []
        seen = set()
        for idx,(name,(lat,lng)) in enumerate(hromada_matches,1):
            title = f"{name.title()} територіальна громада"
            if title in seen: continue
            seen.add(title)
            tracks.append({
                'id': f"{mid}_h{idx}", 'place': title, 'lat': lat, 'lng': lng,
                'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
                'marker_icon': icon, 'source_match': 'hromada'
            })
        if tracks:
            return tracks

    # --- Slash separated settlements PRIORITY (moved earlier so it can't be overridden by region logic) ---
    lower_full_for_slash = text.lower()
    if '/' in lower_full_for_slash and ('бпла' in lower_full_for_slash or 'дрон' in lower_full_for_slash) and any(x in lower_full_for_slash for x in ['х бпла','x бпла',' бпла']):
        # take portion before first dash (— or -) which usually separates counts/other text
        left_part = re.split(r'[—-]', lower_full_for_slash, 1)[0]
        # Remove trailing count token like "5х бпла" from left part to isolate pure settlements
        left_part = re.sub(r'\b\d+[xх]\s*бпла.*$', '', left_part).strip()
        parts = [p.strip() for p in re.split(r'/|\\', left_part) if p.strip()]
        found = []
        # Derive a region stem from any well-known city token to bias geocoding of other parts
        inferred_region = None
        for p in parts:
            base_inf = UA_CITY_NORMALIZE.get(p, p)
            if base_inf in CITY_TO_OBLAST:
                inferred_region = CITY_TO_OBLAST[base_inf]
                break
        for p in parts:
            base = UA_CITY_NORMALIZE.get(p, p)
            coords = CITY_COORDS.get(base)
            if not coords and SETTLEMENTS_INDEX:
                coords = SETTLEMENTS_INDEX.get(base)
            if not coords:
                # If we have inferred region stem, attempt region-qualified geocode first
                if inferred_region and OPENCAGE_API_KEY:
                    oblast_variants = [
                        f"{base} {inferred_region}щина",
                        f"{base} {inferred_region}ська область",
                        f"{base} {inferred_region}ская область"
                    ]
                    for q in oblast_variants:
                        try:
                            coords = geocode_opencage(q)
                            if coords:
                                break
                        except Exception:
                            pass
                if not coords:
                    try:
                        coords = region_enhanced_coords(base)
                    except Exception:
                        coords = None
            if coords:
                found.append((base.title(), coords))
        if found:
            threat_type, icon = classify(text)
            tracks = []
            for idx,(nm,(lat,lng)) in enumerate(found,1):
                if 'курс захід' in lower_full_for_slash:
                    lng -= 0.4
                tracks.append({
                    'id': f"{mid}_s{idx}", 'place': nm, 'lat': lat, 'lng': lng,
                    'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
                    'marker_icon': icon, 'source_match': 'slash_combo', 'count': drone_count
                })
            if tracks:
                try:
                    log.debug(f"SLASH_COMBO mid={mid} parts={parts} tracks={[(t['place'], t['lat'], t['lng']) for t in tracks]}")
                except Exception:
                    pass
            if tracks:
                return tracks

    # --- Black Sea aquatory: place marker in sea, not on target city (e.g. "в акваторії чорного моря, курсом на одесу" or "з моря на Ізмаїл") ---
    lower_sea = text.lower()
    is_black_sea = (('акватор' in lower_sea or 'акваторії' in lower_sea) and ('чорного моря' in lower_sea or 'чорне море' in lower_sea or 'чорному морі' in lower_sea)) or \
                   ('з моря' in lower_sea and ('курс' in lower_sea or 'на ' in lower_sea)) or \
                   ('з чорного моря' in lower_sea)
    
    if is_black_sea:
        # Extract target region/direction if mentioned
        m_target = re.search(r'курс(?:ом)?\s+на\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-]{3,})', lower_sea)
        m_direction = re.search(r'на\s+(північ|південь|схід|захід|північний\s+схід|північний\s+захід|південний\s+схід|південний\s+захід)', lower_sea)
        m_region = re.search(r'(одещин|одеськ|миколаїв|херсон)', lower_sea)
        
        target_info = None
        sea_lat, sea_lng = 45.3, 30.7  # Default: northern Black Sea central coords
        
        # Adjust position based on direction/region
        if m_direction:
            direction = m_direction.group(1)
            if 'південь' in direction:
                sea_lat = 45.0  # Further south
            elif 'північ' in direction:
                sea_lat = 45.6  # Further north
            if 'схід' in direction:
                sea_lng = 31.2  # Further east
            elif 'захід' in direction:
                sea_lng = 30.2  # Further west
        
        if m_region:
            region_name = m_region.group(1)
            if 'одещин' in region_name or 'одеськ' in region_name:
                # South of Odesa region - in the sea 50km offshore
                sea_lat, sea_lng = 45.7, 30.7
                target_info = 'Одещини'
            elif 'миколаїв' in region_name:
                sea_lat, sea_lng = 45.9, 31.4
                target_info = 'Миколаївщини'
            elif 'херсон' in region_name:
                sea_lat, sea_lng = 45.7, 32.5
                target_info = 'Херсонщини'
        
        if m_target:
            tc = m_target.group(1).lower()
            tc = UA_CITY_NORMALIZE.get(tc, tc)
            target_info = tc.title()
        
        threat_type, icon = classify(text)
        place_label = 'Акваторія Чорного моря'
        if target_info:
            place_label += f' (на {target_info})'
        
        # Try to find target city coordinates for trajectory
        target_coords = None
        if m_target:
            tc_normalized = m_target.group(1).lower()
            tc_normalized = UA_CITY_NORMALIZE.get(tc_normalized, tc_normalized)
            if tc_normalized in CITY_COORDS:
                target_coords = CITY_COORDS[tc_normalized]
        
        result = {
            'id': str(mid), 'place': place_label, 'lat': sea_lat, 'lng': sea_lng,
            'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
            'marker_icon': icon, 'source_match': 'black_sea_course'
        }
        
        # Add trajectory data if we have target coordinates
        if target_coords:
            result['trajectory'] = {
                'start': [sea_lat, sea_lng],
                'end': list(target_coords),
                'target': target_info
            }
        
        return [result]

    # --- Bilhorod-Dnistrovskyi coastal UAV patrol ("вздовж узбережжя Білгород-Дністровського району") ---
    if (('узбереж' in lower_sea or 'вздовж узбереж' in lower_sea) and
        ('білгород-дністровського' in lower_sea or 'белгород-днестровского' in lower_sea) and
        ('бпла' in lower_sea or 'дрон' in lower_sea)):
        # Base approximate city coordinate; push 0.22° south into sea
        city_lat, city_lng = 46.186, 30.345
        lat = city_lat - 0.22
        lng = city_lng
        threat_type, icon = classify(text)
        return [{
            'id': str(mid), 'place': 'Узбережжя Білгород-Дністровського р-ну', 'lat': lat, 'lng': lng,
            'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
            'marker_icon': icon, 'source_match': 'bilhorod_dnistrovskyi_coast'
        }]

    # --- "повз <city>" (passing near) with optional direction target "у напрямку <city>" ---
    lower_pass = text.lower()
    pass_near_detected = False
    if 'повз ' in lower_pass and ('бпла' in lower_pass or 'дрон' in lower_pass):
        pass_match = re.search(r"повз\s+([A-Za-zА-Яа-яЇїІіЄєҐґ'’ʼ`\-]{3,})", lower_pass)
        dir_match = re.search(r"напрямку\s+([A-Za-zА-Яа-яЇїІіЄєҐґ'’ʼ`\-]{3,})(?:\s+([A-Za-zА-Яа-яЇїІіЄєҐґ'’ʼ`\-]{3,}))?", lower_pass)
        places = []
        def norm_c(s: str):
            if not s: return None
            s = s.strip().lower().strip(".,:;()!?")
            s = UA_CITY_NORMALIZE.get(s, s)
            # Morphological heuristics: convert common Ukrainian/Russian case endings to nominative
            candidates = [s]
            if s.endswith('у') and len(s) > 4:
                candidates.append(s[:-1] + 'а')
            if s.endswith('ю') and len(s) > 4:
                candidates.append(s[:-1] + 'я')
            if s.endswith('и') and len(s) > 4:
                candidates.append(s[:-1] + 'а')
            if s.endswith('ої') and len(s) > 5:
                candidates.append(s[:-2] + 'а')
            if s.endswith('оїї') and len(s) > 6:
                candidates.append(s[:-3] + 'а')
            for cand in candidates:
                if region_enhanced_coords(cand):
                    return cand
            return s
        if pass_match:
            c1 = norm_c(pass_match.group(1))
            if c1:
                coords1 = region_enhanced_coords(c1)
                if coords1:
                    places.append((c1.title(), coords1, 'pass_near'))
        if dir_match:
            c2_first = norm_c(dir_match.group(1))
            c2_second_raw = dir_match.group(2)
            full_phrase = None
            if c2_first and c2_second_raw:
                c2_second = norm_c(c2_second_raw)
                cand_phrase = f"{c2_first} {c2_second}".strip()
                if cand_phrase in CITY_COORDS or (SETTLEMENTS_INDEX and cand_phrase in SETTLEMENTS_INDEX):
                    full_phrase = cand_phrase
            c2_key = full_phrase or c2_first
            if c2_key and c2_key != (places[0][0].lower() if places else None):
                coords2 = region_enhanced_coords(c2_key)
                if coords2:
                    places.append((c2_key.title(), coords2, 'direction_target'))
        if places:
            threat_type, icon = classify(text)
            out_tracks = []
            for idx,(nm,(lat,lng),tag) in enumerate(places,1):
                out_tracks.append({
                    'id': f"{mid}_pv{idx}", 'place': nm, 'lat': lat, 'lng': lng,
                    'threat_type': threat_type, 'text': text[:500], 'date': date_str,
                    'channel': channel, 'marker_icon': icon, 'source_match': tag, 'count': drone_count
                })
            if out_tracks:
                pass_near_detected = True
                return out_tracks

    # --- Pattern: "рухалися на <city1>, змінили курс на <city2>" ---
    lower_course_change = text.lower()
    if 'змінили курс на' in lower_course_change and ('рухал' in lower_course_change or 'рухались' in lower_course_change or 'рухалися' in lower_course_change):
        m_to = re.search(r'змінили\s+курс\s+на\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-]{3,})', lower_course_change)
        m_from = re.search(r'рухал(?:ися|ись|и|ась)?\s+на\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-]{3,})', lower_course_change)
        places = []
        def norm_simple(s):
            if not s: return None
            s = s.strip().lower().strip(".,:;()!")
            return UA_CITY_NORMALIZE.get(s, s)
        if m_from:
            c_from = norm_simple(m_from.group(1))
            coords_from = region_enhanced_coords(c_from)
            if coords_from:
                places.append((c_from.title(), coords_from, 'course_from'))
        if m_to:
            c_to = norm_simple(m_to.group(1))
            coords_to = region_enhanced_coords(c_to)
            if coords_to:
                # avoid duplicate if same
                if not any(p[0].lower()==c_to for p in places):
                    places.append((c_to.title(), coords_to, 'course_changed_to'))
        if places:
            threat_type, icon = classify(text)
            out = []
            for idx,(name,(lat,lng),tag) in enumerate(places,1):
                out.append({
                    'id': f"{mid}_cc{idx}", 'place': name, 'lat': lat, 'lng': lng,
                    'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
                    'marker_icon': icon, 'source_match': tag
                })
            if out:
                return out

    # --- Relative direction near a city: "північніше кам'янського у напрямку кременчука" ---
    rel_dir_lower = text.lower()
    if any(k in rel_dir_lower for k in ['північніше','південніше','східніше','західніше']) and ('бпла' in rel_dir_lower or 'дрон' in rel_dir_lower):
        # Allow letters plus apostrophes/hyphen
        m_rel = re.search(r"(північніше|південніше|східніше|західніше)\s+([A-Za-zА-Яа-яЇїІіЄєҐґ'`’ʼ\-]{4,})", rel_dir_lower)
        target_dir = re.search(r'напрямку\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-]{3,})', rel_dir_lower)
        if m_rel:
            dir_word = m_rel.group(1)
            raw_city = m_rel.group(2).strip(".,:;()!?")
            def norm_rel_city(s):
                s = s.lower()
                # нормализация окончаний родительного падежа '-ського' -> 'ське'
                if s.endswith('ського'):
                    s = s[:-6] + 'ське'
                if s.endswith('ого') and len(s) > 5:
                    s = s[:-3] + 'о'
                return UA_CITY_NORMALIZE.get(s, s)
            base_city = norm_rel_city(raw_city)
            coords_base = region_enhanced_coords(base_city)
            coords_target = None
            target_name = None
            if target_dir:
                tn = target_dir.group(1).lower().strip('.:,;()!?')
                tn = UA_CITY_NORMALIZE.get(tn, tn)
                coords_target = region_enhanced_coords(tn)
                target_name = tn
            if coords_base:
                lat_b, lng_b = coords_base
                # offset ~0.35 deg lat/long depending on direction
                lat_off, lng_off = 0,0
                if 'північ' in dir_word: lat_off = 0.35
                elif 'півден' in dir_word: lat_off = -0.35
                elif 'східн' in dir_word: lng_off = 0.55
                elif 'західн' in dir_word: lng_off = -0.55
                rel_lat, rel_lng = lat_b + lat_off, lng_b + lng_off
                threat_type, icon = classify(text)
                tracks = [{
                    'id': f"{mid}_rel1", 'place': base_city.title(), 'lat': rel_lat, 'lng': rel_lng,
                    'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
                    'marker_icon': icon, 'source_match': 'relative_dir'
                }]
                if coords_target:
                    tracks.append({
                        'id': f"{mid}_rel2", 'place': target_name.title(), 'lat': coords_target[0], 'lng': coords_target[1],
                        'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
                        'marker_icon': icon, 'source_match': 'direction_target'
                    })
                return tracks

    # --- Parenthetical course city e.g. "курс західний (кременчук)" ---
    if 'курс' in lower and '(' in lower and ')' in lower and ('бпла' in lower or 'дрон' in lower):
        m_par = re.search(r'курс[^()]{0,30}\(([A-Za-zА-Яа-яЇїІіЄєҐґ\-]{3,})\)', lower)
        if m_par:
            pc = m_par.group(1).lower()
            pc = UA_CITY_NORMALIZE.get(pc, pc)
            coords = region_enhanced_coords(pc)
            if coords:
                threat_type, icon = classify(text)
                return [{
                    'id': f"{mid}_pc", 'place': pc.title(), 'lat': coords[0], 'lng': coords[1],
                    'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
                    'marker_icon': icon, 'source_match': 'course_parenthetical'
                }]

    # --- Comma separated settlements followed by threat keyword (e.g. "Обухівка, Курилівка, Петриківка увага БПЛА") ---
    lower_commas = text.lower()
    if 'бпла' in lower_commas and ',' in lower_commas:
        # Identify first threat keyword position
        threat_kw_idx = None
        for kw in ['увага','проліт','пролёт','уважно','уважно.','уважно,']:
            pos = lower_commas.find(kw)
            if pos != -1:
                threat_kw_idx = pos
                break
        if threat_kw_idx is not None:
            left_seg = lower_commas[:threat_kw_idx]
            # quick guard to ensure segment not too long
            if 3 <= len(left_seg) <= 180:
                cand_parts = [p.strip() for p in left_seg.split(',') if p.strip()]
                found = []
                for cand in cand_parts:
                    # normalize basic endings (remove trailing punctuation)
                    base = cand.strip(" .!?:;()[]'`’ʼ")
                    if len(base) < 3:
                        continue
                    norm = UA_CITY_NORMALIZE.get(base, base)
                    coords = region_enhanced_coords(norm)
                    if coords:
                        found.append((norm.title(), coords))
                if found:
                    threat_type, icon = classify(text)
                    tracks = []
                    seenp = set()
                    for idx,(nm,(lat,lng)) in enumerate(found,1):
                        if nm in seenp: continue
                        seenp.add(nm)
                        tracks.append({
                            'id': f"{mid}_m{idx}", 'place': nm, 'lat': lat, 'lng': lng,
                            'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
                            'marker_icon': icon, 'source_match': 'multi_settlement_comma', 'count': drone_count
                        })
                    if tracks:
                        return tracks

    # --- PRIORITY: Direction patterns (у напрямку, через, повз) - BEFORE region boundary logic ---
    try:
        import re as _re_direction
        
        if has_threat(text) and any(pattern in text.lower() for pattern in ['у напрямку', 'через', 'повз']):
            direction_targets = []
            
            # Pattern 1: "у напрямку [city], [oblast]"
            naprym_pattern = r'у\s+напрямку\s+([А-Яа-яЇїІіЄєҐґ\'\-\s]+?)(?:\s*,\s*([А-Яа-яЇїІіЄєҐґ\'\-\s]*області?))?(?:[\.\,\!\?;]|$)'
            naprym_matches = _re_direction.findall(naprym_pattern, text, _re_direction.IGNORECASE)
            for city_raw, oblast_raw in naprym_matches:
                direction_targets.append(('у напрямку', city_raw.strip(), oblast_raw.strip() if oblast_raw else ''))
            
            # Process direction targets
            for direction_type, city_raw, oblast_raw in direction_targets:
                if direction_type == 'у напрямку':
                    city_norm = city_raw.lower().replace('\u02bc',"'").replace('ʼ',"'").replace("'","'").replace('`',"'")
                    city_norm = re.sub(r'\s+',' ', city_norm).strip()
                    
                    # Try exact lookup
                    coords = CITY_COORDS.get(city_norm)
                    if not coords:
                        # Try normalized lookup
                        city_base = UA_CITY_NORMALIZE.get(city_norm, city_norm)
                        coords = CITY_COORDS.get(city_base)
                    
                    if coords:
                        lat, lng = coords
                        threat_type, icon = classify(text)
                        
                        # Extract drone count
                        import re as _re_count
                        count_match = _re_count.search(r'(\d+)\s*[хx]?\s*(?:бпла|дрон|шахед)', text.lower())
                        drone_count = int(count_match.group(1)) if count_match else 1
                        
                        add_debug_log(f"PRIORITY: Direction target found - {city_norm} -> {coords}", "direction_priority")
                        return [{
                            'id': str(mid), 'place': city_raw.title(), 'lat': lat, 'lng': lng,
                            'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
                            'marker_icon': icon, 'source_match': 'direction_target_priority', 'count': drone_count
                        }]
                    else:
                        add_debug_log(f"PRIORITY: Direction target not found - {city_norm}", "direction_priority")
    except Exception as e:
        add_debug_log(f"Direction priority processing error: {e}", "direction_priority")

    # PRIORITY: Various Shahed patterns - Process before region boundary logic
    try:
        import re as _re_shahed
        all_shahed_tracks = []
        
        # Pattern 1: "N шахедів біля [city]" or "N шахедів біля [city1]/[city2]"
        bilya_pattern = r'(\d+)\s+шахед[а-яіїєёыийї]*\s+біля\s+([А-Яа-яЏїІіЄєҐґ\'\-\s\/]+?)(?:\s+та\s+район)?(?:\s+на\s+[А-Яа-яЇїІіЄєҐґ\'\-\s]+)?(?:[\.\,\!\?;]|$)'
        bilya_matches = _re_shahed.findall(bilya_pattern, text, _re_shahed.IGNORECASE)
        
        # Pattern 2: "N шахед на [city]"
        na_pattern = r'(\d+)\s+шахед[а-яіїєёыийї]*\s+на\s+([А-Яа-яЇїІіЄєҐґ\'\-\s]+?)(?:[\.\,\!\?;]|$)'
        na_matches = _re_shahed.findall(na_pattern, text, _re_shahed.IGNORECASE)
        
        # Pattern 3: "N шахедів з боку [city]"
        z_boku_pattern = r'(\d+)\s+шахед[а-яіїєёыийї]*\s+з\s+боку\s+([А-Яа-яЇїІіЄєҐґ\'\-\s]+?)(?:[\.\,\!\?;]|$)'
        z_boku_matches = _re_shahed.findall(z_boku_pattern, text, _re_shahed.IGNORECASE)
        
        # Pattern 4: "N шахедів через [city1]/[city2]" - multiple cities
        cherez_multi_pattern = r'(\d+)\s+шахед[а-яіїєёыийї]*\s+через\s+([А-Яа-яЇїІіЄєҐґ\'\-\s\/]+?)(?:\s+район)?(?:\s+на\s+[А-Яа-яЇїІіЄєҐґ\'\-\s]+)?(?:[\.\,\!\?;]|$)'
        cherez_matches = _re_shahed.findall(cherez_multi_pattern, text, _re_shahed.IGNORECASE)
        
        all_patterns = [
            (bilya_matches, 'bilya'),
            (na_matches, 'na'), 
            (z_boku_matches, 'z_boku'),
            (cherez_matches, 'cherez')
        ]
        
        for matches, pattern_type in all_patterns:
            for count_str, city_raw in matches:
                # Handle multiple cities separated by /
                cities = [c.strip() for c in city_raw.split('/')]
                
                for city_part in cities:
                    city_norm = city_part.lower().replace('\u02bc',"'").replace('ʼ',"'").replace("'","'").replace('`',"'")
                    city_norm = re.sub(r'\s+',' ', city_norm).strip()
                    
                    # Special handling for "[city] на [region]" patterns
                    region_match = re.match(r'^(.+?)\s+на\s+([а-яіїє]+щині?|[а-яіїє]+ській?\s+обл?\.?|[а-яіїє]+ській?\s+області?)$', city_norm)
                    if region_match:
                        city_norm = region_match.group(1).strip()
                        region_hint = region_match.group(2).strip()
                        # Use full message context for resolution
                        coords = ensure_city_coords_with_message_context(city_norm, text)
                        if coords:
                            lat, lng, approx = coords
                            add_debug_log(f"SHAHED: Regional pattern found - {city_norm} на {region_hint} -> ({lat}, {lng})", "shahed_regional")
                            
                            result_entry = {
                                'id': f"{mid}_sha_{len(threats)+1}",
                                'place': f"{city_part.title()}",
                                'lat': lat, 'lng': lng,
                                'type': 'shahed', 'count': int(count_str),
                                'timestamp': date_str, 'channel': channel
                            }
                            threats.append(result_entry)
                            continue  # Skip regular processing for this city
                    
                    # Apply normalization rules for accusative/genitive cases
                    original_norm = city_norm
                    if city_norm in UA_CITY_NORMALIZE:
                        city_norm = UA_CITY_NORMALIZE[city_norm]
                    
                    # Try accusative endings for cities like "миколаєва" -> "миколаїв", "полтави" -> "полтава"
                    if not (city_norm in CITY_COORDS or region_enhanced_coords(city_norm)):
                        # Try various ending transformations
                        variants = [city_norm]
                        if city_norm.endswith('а'):
                            variants.extend([city_norm[:-1] + 'ів', city_norm[:-1] + 'і'])
                        elif city_norm.endswith('и'):
                            variants.extend([city_norm[:-1] + 'а', city_norm[:-1] + 'я'])
                        elif city_norm.endswith('у'):
                            variants.extend([city_norm[:-1] + 'п', city_norm[:-1] + 'к'])
                        
                        for variant in variants:
                            if variant in CITY_COORDS or region_enhanced_coords(variant):
                                city_norm = variant
                                break
                    
                    # Try to get coordinates
                    coords = region_enhanced_coords(city_norm)
                    if not coords:
                        context_result = ensure_city_coords_with_message_context(city_norm, text)
                        if context_result:
                            coords = context_result[:2]  # Take only lat, lng
                    
                    if coords:
                        lat, lng = coords
                        threat_type, icon = classify(text)
                        count = int(count_str) if count_str.isdigit() else 1
                        
                        # Create multiple tracks for multiple drones
                        tracks_to_create = max(1, count)
                        for i in range(tracks_to_create):
                            track_label = city_part.title()
                            if tracks_to_create > 1:
                                track_label += f" #{i+1}"
                            
                            # Add small coordinate offsets to prevent marker overlap
                            marker_lat = lat
                            marker_lng = lng
                            if tracks_to_create > 1:
                                # Create a chain pattern - drones one after another
                                offset_distance = 0.03  # ~3km offset between each drone
                                marker_lat += offset_distance * i
                                marker_lng += offset_distance * i * 0.5
                                
                            all_shahed_tracks.append({
                                'id': f"{mid}_{pattern_type}_{len(all_shahed_tracks)}", 
                                'place': track_label, 
                                'lat': marker_lat, 
                                'lng': marker_lng,
                                'threat_type': threat_type, 
                                'text': text[:500], 
                                'date': date_str, 
                                'channel': channel,
                                'marker_icon': icon, 
                                'source_match': f'{pattern_type}_shahed_priority', 
                                'count': 1
                            })
                        add_debug_log(f"SHAHED {pattern_type.upper()}: {city_norm} ({count}x) -> {coords}", f"shahed_{pattern_type}")
        
        if all_shahed_tracks:
            return all_shahed_tracks
    except Exception as e:
        add_debug_log(f"Shahed patterns processing error: {e}", "shahed_priority")

    # Region boundary logic (fallback single or midpoint for exactly two)
    matched_regions = []
    for name, coords in OBLAST_CENTERS.items():
        if name in lower:
            matched_regions.append((name, coords))
    if matched_regions:
        # НОВОЕ: Проверка контекстного геокодинга перед региональными маркерами
        if CONTEXT_GEOCODER_AVAILABLE:
            context_result = get_coordinates_context_aware(text)
            if context_result:
                lat, lng, target_city = context_result
                threat_type, icon = classify(text)
                
                print(f"DEBUG Context-aware geocoding: Found primary target '{target_city}' at ({lat}, {lng})")
                
                return [{
                    'id': str(mid), 'place': target_city.title(), 'lat': lat, 'lng': lng,
                    'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
                    'marker_icon': icon, 'source_match': 'context_aware_geocoding', 'count': 1
                }]
        
        # Если только области упомянуты и нет ключей угроз, пропускаем.
        # Дополнительная защита: иногда в messages.json могли сохраниться старые записи без угроз.
        if not has_threat(text):
            # чистый список областей? (только названия + двоеточия/пробелы/переводы строк)
            stripped = re.sub(r'[\s:]+', ' ', text.lower()).strip()
            only_regions = all(rn in OBLAST_CENTERS for rn in stripped.split() if rn)
            if only_regions or len(text) < 120:
                return None
        # --- Направления внутри области (північно-західний / південно-західний и т.п.) ---
        def detect_direction(lower_txt: str):
            # Support full adjectives with endings (-ний / -ня / -ньому) by searching stems
            if 'північно-захід' in lower_txt or 'північно-західн' in lower_txt: return 'nw'
            if 'південно-захід' in lower_txt or 'південно-західн' in lower_txt: return 'sw'
            if 'північно-схід' in lower_txt or 'північно-східн' in lower_txt: return 'ne'
            if 'південно-схід' in lower_txt or 'південно-східн' in lower_txt: return 'se'
            # Single directions (allow stems 'північн', 'південн')
            if re.search(r'\bпівніч(?!о-с)(?:н\w*)?\b', lower_txt): return 'n'
            if re.search(r'\bпівденн?\w*\b', lower_txt): return 's'
            if re.search(r'\bсхідн?\w*\b', lower_txt): return 'e'
            if re.search(r'\bзахідн?\w*\b', lower_txt): return 'w'
            return None
        direction_code = None
    if len(matched_regions) == 1 and not raion_matches and not pass_near_detected:
            direction_code = detect_direction(lower)
            # If message also contains course info referencing cities/slash – skip region-level marker to allow city parsing later
            course_words = (' курс ' in lower or lower.startswith('курс '))
            # Treat city present only if it appears as a standalone word (to avoid 'дніпро' inside 'дніпропетровщини')
            has_city_token = False
            try:
                import re as _re_ct
                for c_name in CITY_COORDS.keys():
                    if _re_ct.search(r'\b'+_re_ct.escape(c_name)+r'\b', lower):
                        has_city_token = True; break
            except Exception:
                has_city_token = any(c in lower for c in CITY_COORDS.keys())
            has_slash_combo = '/' in lower
            if direction_code and not (course_words and (has_city_token or has_slash_combo)):
                # ---- Special: sector course pattern inside region directional message ----
                # e.g. "курс(ом) в бік сектору перещепине - губиниха"
                sector_match = re.search(r'курс(?:ом)?\s+в\s+бік\s+сектору\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-]{3,})(?:\s*[-–]\s*([A-Za-zА-Яа-яЇїІіЄєҐґ\-]{3,}))?', lower)
                if sector_match:
                    c1 = sector_match.group(1)
                    c2 = sector_match.group(2)
                    def norm_city(n):
                        if not n: return None
                        n = n.strip().lower()
                        n = re.sub(r'["`ʼ’\'.,:;()]+', '', n)
                        return UA_CITY_NORMALIZE.get(n, n)
                    c1n = norm_city(c1)
                    c2n = norm_city(c2) if c2 else None
                    coords1 = CITY_COORDS.get(c1n) or (SETTLEMENTS_INDEX.get(c1n) if SETTLEMENTS_INDEX else None)
                    coords2 = CITY_COORDS.get(c2n) or (SETTLEMENTS_INDEX.get(c2n) if (c2n and SETTLEMENTS_INDEX) else None)
                    if coords1 or coords2:
                        if coords1 and coords2:
                            lat_o = (coords1[0]+coords2[0])/2
                            lng_o = (coords1[1]+coords2[1])/2
                            place_label = f"{c1n.title()} - {c2n.title()} (сектор)"
                        else:
                            (lat_o,lng_o) = coords1 or coords2
                            place_label = (c1n or c2n).title()
                        threat_type, icon = classify(text)
                        return [{
                            'id': str(mid), 'place': place_label, 'lat': lat_o, 'lng': lng_o,
                            'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
                            'marker_icon': icon, 'source_match': 'course_sector', 'count': drone_count
                        }]
                (reg_name, (base_lat, base_lng)) = matched_regions[0]
                
                # Define offset function for coordinate calculations
                def offset(lat, lng, code):
                    # Уменьшенные дельты для более точного позиционирования в пределах области
                    # (широта ~111 км, долгота * cos(lat))
                    import math
                    lat_step = 0.35  # Примерно 35-40 км вместо 60 км
                    lng_step = 0.55 / max(0.2, abs(math.cos(math.radians(lat))))  # Примерно 35-40 км
                    if code == 'n': return lat+lat_step, lng
                    if code == 's': return lat-lat_step, lng
                    if code == 'e': return lat, lng+lng_step
                    if code == 'w': return lat, lng-lng_step
                    # диагонали немного меньше по каждой оси
                    lat_diag = lat_step * 0.8
                    lng_diag = lng_step * 0.8
                    if code == 'ne': return lat+lat_diag, lng+lng_diag
                    if code == 'nw': return lat+lat_diag, lng-lng_diag
                    if code == 'se': return lat-lat_diag, lng+lng_diag
                    if code == 'sw': return lat-lat_diag, lng-lng_diag
                    return lat, lng
                
                # SPECIAL: Handle messages with start position + course direction
                # e.g. "на півночі тернопільщини ➡️ курсом на південно-західний напрямок"
                start_direction = None
                course_direction = None
                
                # Detect start position (на півночі/півдні/сході/заході)
                if re.search(r'\bна\s+півночі\b', lower) or re.search(r'\bпівнічн\w+\s+частин\w*\b', lower):
                    start_direction = 'n'
                elif re.search(r'\bна\s+півдні\b', lower) or re.search(r'\bпівденн\w+\s+частин\w*\b', lower):
                    start_direction = 's'
                elif re.search(r'\bна\s+сході\b', lower) or re.search(r'\bсхідн\w+\s+частин\w*\b', lower):
                    start_direction = 'e'
                elif re.search(r'\bна\s+заході\b', lower) or re.search(r'\bзахідн\w+\s+частин\w*\b', lower):
                    start_direction = 'w'
                
                # Detect course direction (курсом на направление)
                # Support patterns: "курсом на", "рух на", "продовжує рух на", "прямують на", "в напрямку"
                has_direction_keyword = ('курс' in lower and 'напрямок' in lower) or ('➡' in lower or '→' in lower) or \
                                       ('рух' in lower and 'на' in lower) or ('прямують' in lower and 'на' in lower) or \
                                       ('продовжує' in lower and ('рух' in lower or 'на' in lower)) or \
                                       ('в' in lower and ('напрямку' in lower or 'напрямок' in lower or 'напрям' in lower))
                
                if has_direction_keyword:
                    if 'північно-західн' in lower or 'північно-захід' in lower:
                        course_direction = 'nw'
                    elif 'південно-західн' in lower or 'південно-захід' in lower:
                        course_direction = 'sw'
                    elif 'північно-східн' in lower or 'північно-схід' in lower:
                        course_direction = 'ne'
                    elif 'південно-східн' in lower or 'південно-схід' in lower:
                        course_direction = 'se'
                    # Single directions in course - support "курсом на", "рух на", "в [напрямок] напрямку"
                    elif re.search(r'(курс\w*|рух|прямують|продовжує)\s+(на\s+)?північ', lower) or re.search(r'в\s+північн\w*\s+напрям', lower):
                        course_direction = 'n'
                    elif re.search(r'(курс\w*|рух|прямують|продовжує)\s+(на\s+)?південь|півд', lower) or re.search(r'в\s+півден\w*\s+напрям', lower):
                        course_direction = 's'
                    elif re.search(r'(курс\w*|рух|прямують|продовжує)\s+(на\s+)?схід', lower) or re.search(r'в\s+східн\w*\s+напрям', lower):
                        course_direction = 'e'
                    elif re.search(r'(курс\w*|рух|прямують|продовжує)\s+(на\s+)?захід', lower) or re.search(r'в\s+захід\w*\s+напрям', lower):
                        course_direction = 'w'
                
                # If we have both start position and course direction, apply them sequentially
                if start_direction and course_direction:
                    # First offset: move to start position within region
                    lat_start, lng_start = offset(base_lat, base_lng, start_direction)
                    # Second offset: apply course direction from start position  
                    lat_final, lng_final = offset(lat_start, lng_start, course_direction)
                    
                    # Create descriptive label with arrow for trajectory visualization
                    start_labels = {'n':'півночі', 's':'півдні', 'e':'сході', 'w':'заході'}
                    course_labels = {
                        'n':'північ', 's':'південь', 'e':'схід', 'w':'захід',
                        'ne':'північний схід', 'nw':'північний захід', 
                        'se':'південний схід', 'sw':'південний захід'
                    }
                    # Direction labels for arrow (Ukrainian names compatible with frontend)
                    arrow_labels = {
                        'n':'північ', 's':'півдня', 'e':'сходу', 'w':'заходу',
                        'ne':'північного сходу', 'nw':'північного заходу',
                        'se':'південного сходу', 'sw':'південного заходу'
                    }
                    start_label = start_labels.get(start_direction, 'області')
                    course_label = course_labels.get(course_direction, 'напрямок')
                    arrow_label = arrow_labels.get(course_direction, '')
                    base_disp = reg_name.split()[0].title()
                    
                    # Add arrow to place name for trajectory visualization in frontend
                    place_name = f"{base_disp} (з {start_label})"
                    if arrow_label:
                        place_name += f" ←{arrow_label}"
                    
                    trajectory = {
                        'start': [lat_start, lng_start],
                        'end': [lat_final, lng_final],
                        'source': base_disp,
                        'target': course_label,
                        'kind': 'region_start_course'
                    }

                    threat_type, icon = classify(text)
                    return [{
                        'id': str(mid), 'place': place_name, 
                        'lat': lat_final, 'lng': lng_final,
                        'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
                        'marker_icon': icon, 'source_match': 'region_start_course', 'count': drone_count,
                        'trajectory': trajectory,
                        'course_direction': f"курс на {course_label}",
                        'course_source': base_disp,
                        'course_target': course_label,
                        'course_type': 'region_start_course'
                    }]
                
                # If only course_direction (no start position), use it as the direction
                if course_direction and not start_direction:
                    direction_code = course_direction
                
                # смещение ~50-70 км в сторону указанного направления (fallback for single direction)
                lat_o, lng_o = offset(base_lat, base_lng, direction_code)
                threat_type, icon = classify(text)
                dir_label_map = {
                    'n':'північна частина', 's':'південна частина', 'e':'східна частина', 'w':'західна частина',
                    'ne':'північно-східна частина', 'nw':'північно-західна частина',
                    'se':'південно-східна частина', 'sw':'південно-західна частина'
                }
                # Direction labels for arrow (Ukrainian names compatible with frontend)
                arrow_labels = {
                    'n':'північ', 's':'півдня', 'e':'сходу', 'w':'заходу',
                    'ne':'північного сходу', 'nw':'північного заходу',
                    'se':'південного сходу', 'sw':'південного заходу'
                }
                dir_phrase = dir_label_map.get(direction_code, 'частина')
                arrow_label = arrow_labels.get(direction_code, '')
                base_disp = reg_name.split()[0].title()
                
                # Add arrow to place name for trajectory visualization
                place_name = f"{base_disp} ({dir_phrase})"
                if arrow_label:
                    place_name += f" ←{arrow_label}"
                
                return [{
                    'id': str(mid), 'place': place_name, 'lat': lat_o, 'lng': lng_o,
                    'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
                    'marker_icon': icon, 'source_match': 'region_direction', 'count': drone_count
                }]
            # если нет направления — продолжаем анализ (ищем конкретные цели типа "курс на <місто>")
    # Midpoint for explicit course between two regions (e.g. "... на запоріжжі курсом на дніпропетровщину")
    if len(matched_regions) == 2 and ('курс' in lower or '➡' in lower or '→' in lower) and (' на ' in lower):
            # ensure we really reference both regions in a course sense: one mentioned before 'курс' and the other after 'курс' / arrow
            parts_course = re.split(r'курс|➡|→', lower, 1)
            if len(parts_course) == 2:
                before, after_part = parts_course
                r1, r2 = matched_regions[0], matched_regions[1]
                bnames = [r1[0].split()[0].lower(), r2[0].split()[0].lower()]
                # If both region stems appear across the split segments, build midpoint
                cond_split = (any(n[:5] in before for n in bnames) and any(n[:5] in after_part for n in bnames))
                # Fallback heuristic: pattern 'на <region1>' earlier then arrow/"курс" then 'на <region2>'
                if not cond_split:
                    # Extract simple region stems from OBLAST_CENTERS keys
                    stems = ['запоріж','запор', 'дніпропетров','дніпропет']
                    if any(st in lower for st in stems):
                        if re.search(r'на\s+запоріж', lower) and re.search(r'на\s+дніпропетров', lower):
                            cond_split = True
                if cond_split:
                    (n1,(a1,b1)), (n2,(a2,b2)) = matched_regions

                    def region_variants(name: str):
                        base = name.split()[0].lower()
                        variants = {base}
                        cleaned = base.replace('область', '').replace('області', '').strip()
                        if cleaned:
                            variants.add(cleaned)
                        if cleaned.endswith('ська'):
                            stem = cleaned[:-4]
                            variants.update({stem + 'щина', stem + 'щини', stem + 'щин', stem})
                        elif cleaned.endswith('ської'):
                            stem = cleaned[:-5]
                            variants.update({stem + 'щина', stem + 'щини', stem + 'щин', stem})
                        return [v for v in variants if v]

                    def segment_has(segment: str, name: str) -> bool:
                        for variant in region_variants(name):
                            if variant in segment:
                                return True
                        return False

                    def region_position(full_text: str, name: str) -> int:
                        positions = []
                        for variant in region_variants(name):
                            idx = full_text.find(variant)
                            if idx != -1:
                                positions.append(idx)
                        return min(positions) if positions else 10**6

                    # Determine source and target based on message structure
                    source_entry = matched_regions[0]
                    target_entry = matched_regions[1]
                    before_region = next((entry for entry in matched_regions if segment_has(before, entry[0])), None)
                    after_region = next((entry for entry in matched_regions if segment_has(after_part, entry[0])), None)

                    if before_region and after_region and before_region != after_region:
                        source_entry = before_region
                        target_entry = after_region
                    elif before_region and not after_region:
                        source_entry = before_region
                        target_entry = next(entry for entry in matched_regions if entry != source_entry)
                    elif after_region and not before_region:
                        target_entry = after_region
                        source_entry = next(entry for entry in matched_regions if entry != target_entry)
                    else:
                        # fallback to textual order
                        ordered = sorted(matched_regions, key=lambda entry: region_position(lower, entry[0]))
                        if len(ordered) == 2 and ordered[0] != ordered[1]:
                            source_entry, target_entry = ordered[0], ordered[1]

                    (source_name, (src_lat, src_lng)) = source_entry
                    (target_name, (tgt_lat, tgt_lng)) = target_entry

                    source_region = source_name.split()[0].title()
                    target_region = target_name.split()[0].title()

                    def offset(lat, lng, code):
                        import math
                        lat_step = 0.35
                        lng_step = 0.55 / max(0.2, abs(math.cos(math.radians(lat))))
                        if code == 'n': return lat+lat_step, lng
                        if code == 's': return lat-lat_step, lng
                        if code == 'e': return lat, lng+lng_step
                        if code == 'w': return lat, lng-lng_step
                        lat_diag = lat_step * 0.8
                        lng_diag = lng_step * 0.8
                        if code == 'ne': return lat+lat_diag, lng+lng_diag
                        if code == 'nw': return lat+lat_diag, lng-lng_diag
                        if code == 'se': return lat-lat_diag, lng+lng_diag
                        if code == 'sw': return lat-lat_diag, lng-lng_diag
                        return lat, lng

                    def detect_region_direction(text_block: str, region_label: str):
                        base = region_label.split()[0].lower()
                        region_variants = [base]
                        if base.endswith('ська'):
                            region_variants.append(base[:-4] + 'щині')
                            region_variants.append(base[:-4] + 'щини')
                            region_variants.append(base[:-4] + 'щина')
                        tokens = {
                            'північ': 'n',
                            'півден': 's',
                            'схід': 'e',
                            'захід': 'w'
                        }
                        for variant in region_variants:
                            for needle, code in tokens.items():
                                pattern = rf'(?:на|у|в)\s+{needle}\w*\s+(?:частин\w*\s+)?{variant}'
                                if re.search(pattern, text_block):
                                    return code
                        return None

                    source_lat_adj, source_lng_adj = src_lat, src_lng
                    source_direction_hint = detect_region_direction(lower, source_name)
                    if source_direction_hint:
                        source_lat_adj, source_lng_adj = offset(source_lat_adj, source_lng_adj, source_direction_hint)

                    # Calculate direction from source to target for arrow labels
                    dlat = tgt_lat - src_lat
                    dlng = tgt_lng - src_lng

                    def direction_token(dy: float, dx: float):
                        if abs(dy) < 1e-6 and abs(dx) < 1e-6:
                            return None
                        if abs(dy) > abs(dx) * 1.4:
                            return 'n' if dy > 0 else 's'
                        if abs(dx) > abs(dy) * 1.4:
                            return 'e' if dx > 0 else 'w'
                        if dy >= 0 and dx >= 0:
                            return 'ne'
                        if dy >= 0 and dx < 0:
                            return 'nw'
                        if dy < 0 and dx >= 0:
                            return 'se'
                        return 'sw'

                    dir_token = direction_token(dlat, dlng)
                    arrow_label_map = {
                        'n': 'півночі', 's': 'півдня', 'e': 'сходу', 'w': 'заходу',
                        'ne': 'північного сходу', 'nw': 'північного заходу',
                        'se': 'південного сходу', 'sw': 'південного заходу'
                    }
                    course_label_map = {
                        'n': 'північ', 's': 'південь', 'e': 'схід', 'w': 'захід',
                        'ne': "північний схід", 'nw': "північний захід",
                        'se': "південний схід", 'sw': "південний захід"
                    }
                    arrow_direction = arrow_label_map.get(dir_token, '')
                    course_direction_text = course_label_map.get(dir_token)

                    # Position marker at the (optionally offset) source to avoid teleporting to the target city
                    lat = source_lat_adj
                    lng = source_lng_adj

                    # Create place name with arrow for trajectory visualization
                    place_name = f"{source_region} → {target_region}"
                    if arrow_direction:
                        place_name += f" ←{arrow_direction}"

                    trajectory = {
                        'start': [lat, lng],
                        'end': [tgt_lat, tgt_lng],
                        'target': target_region,
                        'source': source_region,
                        'kind': 'region_course'
                    }

                    threat_type, icon = classify(text)
                    result = {
                        'id': str(mid), 'place': place_name, 'lat': lat, 'lng': lng,
                        'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
                        'marker_icon': icon, 'source_match': 'region_course_trajectory', 'count': drone_count,
                        'trajectory': trajectory,
                        'course_source': source_region,
                        'course_target': target_region,
                        'course_type': 'region_to_region'
                    }
                    if course_direction_text:
                        result['course_direction'] = f"курс на {course_direction_text}"
                    else:
                        result['course_direction'] = f"курс на {target_region}"
                    return [result]

    if len(matched_regions) == 2 and any(w in lower for w in ['межі','межу','межа','между','границі','граница']):
            (n1,(a1,b1)), (n2,(a2,b2)) = matched_regions
            lat = (a1+a2)/2; lng = (b1+b2)/2
            threat_type, icon = classify(text)
            return [{
                'id': str(mid), 'place': f"Межа {n1.split()[0].title()}/{n2.split()[0].title()}" , 'lat': lat, 'lng': lng,
                'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
                'marker_icon': icon, 'count': drone_count
            }]
    else:
            # If message contains explicit course targets (parsed later), don't emit plain region markers
            course_target_hint = False
            for ln in text.split('\n'):
                ll = ln.lower()
                if 'бпла' in ll and 'курс' in ll and re.search(r'курс(?:ом)?\s+(?:на|в|у)\s+[A-Za-zА-Яа-яЇїІіЄєҐґ\-]{3,}', ll):
                    course_target_hint = True
                    break
            if not course_target_hint:
                threat_type, icon = classify(text)
                
                # Extract course information for Shahed threats
                course_info = None
                if threat_type == 'shahed':
                    course_info = extract_shahed_course_info(original_text or text)
                
                tracks = []
                seen = set()
                for idx,(n1,(lat,lng)) in enumerate(matched_regions,1):
                    base = n1.split()[0].title()
                    if base in seen: continue
                    seen.add(base)
                    
                    track = {
                        'id': f"{mid}_r{idx}", 'place': base, 'lat': lat, 'lng': lng,
                        'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
                        'marker_icon': icon, 'source_match': 'region_multi_simple', 'count': drone_count
                    }
                    
                    # Add course information if available
                    if course_info:
                        track.update({
                            'course_source': course_info.get('source_city'),
                            'course_target': course_info.get('target_city'),
                            'course_direction': course_info.get('course_direction'),
                            'course_type': course_info.get('course_type')
                        })
                    
                    tracks.append(track)
                if tracks:
                    return tracks
    # City fallback scan (ensure whole-word style match to avoid false hits inside oblast words, e.g. 'дніпро' in 'дніпропетровщина')
    for city in UA_CITIES:
        if re.search(r'(?<![a-zа-яїієґ])' + re.escape(city) + r'(?![a-zа-яїієґ])', lower):
            norm = UA_CITY_NORMALIZE.get(city, city)
            # City fallback: attempt region-qualified first
            coords = None
            if region_hint_global and OPENCAGE_API_KEY:
                coords = geocode_opencage(f"{norm} {region_hint_global}")
            if not coords:
                coords = region_enhanced_coords(norm)
            # If областной контекст уже определён (matched_regions) ограничим города той же области
            if matched_regions:
                # берем первый stem области
                stem = None
                for (rn, _c) in matched_regions:
                    for s in ['харків','львів','київ','дніпропетров','полтав','сум','черніг','волин','запор','одес','микола','черка','житом','хмельниць','рівн','івано','терноп','ужгород','кропив','луган','донець','чернівц']:
                        if s in rn:
                            stem = s; break
                    if stem: break
                if stem and norm in CITY_TO_OBLAST and CITY_TO_OBLAST[norm] != stem:
                    continue
            if coords:
                lat, lng = coords
                threat_type, icon = classify(text)
                return [{
                    'id': str(mid), 'place': norm.title(), 'lat': lat, 'lng': lng,
                    'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
                    'marker_icon': icon, 'count': drone_count
                }]
            # if city found but no coords even in fallback, continue scanning others (no break)
    # --- Slash separated settlements with drone count (e.g. "дніпро / самар — 6х бпла ... курс західний") ---
    if '/' in lower and ('бпла' in lower or 'дрон' in lower) and any(x in lower for x in ['х бпла','x бпла',' бпла']):
        left_part = lower.split('—')[0].split('-',1)[0]
        parts = [p.strip() for p in re.split(r'/|\\', left_part) if p.strip()]
        found = []
        for p in parts:
            if p in CITY_COORDS:
                found.append((p.title(), CITY_COORDS[p]))
        if found:
            threat_type, icon = classify(text)
            tracks = []
            for idx,(nm,(lat,lng)) in enumerate(found,1):
                # If course west mentioned, offset west a bit
                if 'курс захід' in lower or 'курс запад' in lower:
                    lng -= 0.4
                tracks.append({
                    'id': f"{mid}_s{idx}", 'place': nm, 'lat': lat, 'lng': lng,
                    'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
                    'marker_icon': icon, 'source_match': 'slash_combo'
                })
            if tracks:
                return tracks
    # --- Single city with westward course ("курс західний") adjust marker to west to avoid mistaken northern region offsets ---
    if 'курс захід' in lower and 'бпла' in lower:
        for c in CITY_COORDS.keys():
            if c in lower:
                lat,lng = CITY_COORDS[c]
                threat_type, icon = classify(text)
                return [{
                    'id': str(mid), 'place': c.title(), 'lat': lat, 'lng': lng - 0.4,
                    'threat_type': threat_type, 'text': text[:500], 'date': date_str, 'channel': channel,
                    'marker_icon': icon, 'source_match': 'course_west'
                }]
    # --- Drone course target parsing (e.g. "БпЛА курсом на Ніжин") ---
    def _normalize_course_city(w: str):
        # Preserve internal single space for multi-word (e.g. "липова долина") before stripping punctuation
        w = re.sub(r'\s+', ' ', w.strip().lower())
        # Remove punctuation but keep spaces and hyphen
        w = re.sub(r'["`ʼ’\'.,:;()]+', '', w)
        # Allow letters, spaces, hyphen
        w = re.sub(r'[^a-zа-яїієґё\- ]', '', w)
        # Accusative to nominative heuristic for each word (handles phrases like 'велику багачку', 'липову долину')
        parts = [p for p in w.split(' ') if p]
        norm_parts = []
        for p in parts:
            base = p
            # Common feminine accusative endings -> nominative
            if len(base) > 4 and base.endswith(('у','ю')):
                base = base[:-1] + 'а'
            # Handle '-у/ю' endings for multi-word second element 'долину' -> 'долина'
            if len(base) > 5 and base.endswith('ину'):
                base = base[:-2] + 'на'
            # Special handling for oblast names ending in 'щину' -> 'щина'
            if len(base) > 6 and base.endswith('щину'):
                base = base[:-1] + 'а'
            norm_parts.append(base)
        w = ' '.join(norm_parts)
        # Apply explicit manual normalization map last (covers irregular)
        if w in UA_CITY_NORMALIZE:
            w = UA_CITY_NORMALIZE[w]
        return w
    course_matches = []
    # Ищем каждую строку с шаблоном
    for line in text.split('\n'):
        line_low = line.lower()
        if 'бпла' in line_low and 'курс' in line_low and (' на ' in line_low or ' в ' in line_low or ' у ' in line_low):
            # Capture one or two words as target, allowing hyphens and apostrophes
            m = re.search(r'курс(?:ом)?\s+(?:на|в|у)\s+([A-Za-zА-Яа-яЇїІіЄєҐґ\-]{3,}(?:\s+[A-Za-zА-Яа-яЇїІіЄєҐґ\-]{3,})?)', line, flags=re.IGNORECASE)
            if m:
                raw_city = m.group(1)
                norm_city = _normalize_course_city(raw_city)
                if norm_city:
                    # If the captured target looks like an oblast (region) name (e.g. 'дніпропетровщина', 'черкаська область'),
                    # we intentionally SKIP adding a precise course target marker to avoid falsely placing it at the oblast's capital city.
                    # User requirement: phrases like 'курс(ом) на Дніпропетровщину' must NOT create a marker right in 'Дніпро'.
                    # Check both nominative and accusative forms (щина/щину)
                    if re.search(r'(щина|щину|область)$', norm_city) or re.search(r'(щина|щину|область)$', raw_city.lower()):
                        log.debug(f'skip course_target oblast_only={norm_city} raw={raw_city} mid={mid}')
                        continue
                    coords = region_enhanced_coords(norm_city)
                    if not coords:
                        log.debug(f'course_target_lookup miss city={norm_city} mid={mid} line={line.strip()[:120]!r} region_hint={region_hint_global}')
                        coords = ensure_city_coords(norm_city)
                        # Try context-based lookup if standard lookup fails
                        if not coords:
                            context_result = ensure_city_coords_with_message_context(norm_city, text)
                            if context_result:
                                coords = context_result[:2]  # Take only lat, lng
                    # Oblast stem disambiguation: if global hint exists and known expected stem differs, re-query with region-qualified geocode
                    if coords and region_hint_global and norm_city in CITY_TO_OBLAST:
                        expected_stem = CITY_TO_OBLAST[norm_city]
                        if expected_stem != region_hint_global[:len(expected_stem)]:
                            # attempt region-qualified geocode with expected stem to refine
                            if OPENCAGE_API_KEY:
                                try:
                                    region_phrase = None
                                    # derive full oblast phrase from stem heuristically (simple mapping subset)
                                    stem_map = {
                                        'сум': 'сумська область', 'полтав': 'полтавська область', 'дніпропетров': 'дніпропетровська область',
                                        'харків': 'харківська область'
                                    }
                                    region_phrase = stem_map.get(expected_stem)
                                    if region_phrase:
                                        refined = geocode_opencage(f"{norm_city} {region_phrase}")
                                        if refined:
                                            coords = refined
                                except Exception:
                                    pass
                    if coords:
                        log.debug(f'course_target_match city={norm_city} coords={coords} region_hint={region_hint_global} mid={mid}')
                    # If still no coords AND we have a region hint + OpenCage, try region-qualified query directly for multi-word ambiguous city
                    if not coords and region_hint_global and OPENCAGE_API_KEY:
                        try:
                            refined2 = geocode_opencage(f"{norm_city} {region_hint_global}")
                            if refined2:
                                coords = refined2
                        except Exception:
                            pass
                    if coords:
                        # Extract line-specific drone count if present (e.g. "4х БпЛА")
                        line_count = None
                        m_lc = re.search(r'(\b\d{1,3})\s*[xх]\s*бпла', line_low)
                        if m_lc:
                            try:
                                line_count = int(m_lc.group(1))
                            except Exception:
                                line_count = None
                        # Ensure coords is a tuple of exactly 2 elements (lat, lng)
                        if len(coords) >= 2:
                            coords = coords[:2]
                        course_matches.append((norm_city.title(), coords, line[:200], line_count))
    if course_matches:
        threat_type, icon = classify(text)
        tracks = []
        seen_places = set()
        for idx,(name,(lat,lng),snippet,line_count) in enumerate(course_matches,1):
            if name in seen_places: continue
            seen_places.add(name)
            
            # Extract Shahed course information if this is a Shahed threat
            course_info = None
            if threat_type == 'shahed':
                course_info = extract_shahed_course_info(original_text or text)
            
            # Determine how many tracks to create
            count = line_count if line_count else drone_count
            tracks_to_create = max(1, count if count else 1)
            
            # Create multiple tracks for multiple drones
            for i in range(tracks_to_create):
                track_name = name
                if tracks_to_create > 1:
                    track_name += f" #{i+1}"
                
                # Add small coordinate offsets to prevent marker overlap
                marker_lat = lat
                marker_lng = lng
                if tracks_to_create > 1:
                    # Create a chain pattern - drones one after another
                    offset_distance = 0.03  # ~3km offset between each drone
                    marker_lat += offset_distance * i
                    marker_lng += offset_distance * i * 0.5
                
                track = {
                    'id': f"{mid}_c{idx}_{i+1}", 'place': track_name, 'lat': marker_lat, 'lng': marker_lng,
                    'threat_type': threat_type, 'text': snippet[:500], 'date': date_str, 'channel': channel,
                    'marker_icon': icon, 'source_match': 'course_target', 'count': 1
                }
                
                # Add course information if available
                if course_info:
                    track.update({
                        'course_source': course_info.get('source_city'),
                        'course_target': course_info.get('target_city'),
                        'course_direction': course_info.get('course_direction'),
                        'course_type': course_info.get('course_type')
                    })
                
                tracks.append(track)
        if tracks:
            return tracks
    
    # Логируем длинные сообщения, которые не сгенерировали треков
    try:
        if text and len(text) > 1000:
            print(f"DEBUG: LONG MESSAGE NO TRACKS - mid={mid}, length={len(text)}, preview: {text[:200]}...")
            # Проверим наличие ключевых слов
            lower_check = text.lower()
            keywords = {'бпла': lower_check.count('бпла'), 'шахед': lower_check.count('шахед'), 
                       'курс': lower_check.count('курс'), 'район': lower_check.count('район')}
            print(f"DEBUG: Long message keywords: {keywords}")
    except Exception:
        pass
    
    # Final check: if we found single UAV threats earlier but no other tracks, return the UAV threats
    if 'single_uav_threats' in locals() and single_uav_threats:
        add_debug_log(f"FINAL: Returning single UAV threats only: {len(single_uav_threats)}", "final_single_uav")
        return single_uav_threats
    
    return None

async def fetch_loop():
    log.info('fetch_loop() started')
    if not client:
        log.warning('Telegram client not configured; skipping fetch loop.')
        return
    log.info('fetch_loop: client exists, proceeding')
    async def ensure_connected():
        log.info('ensure_connected() called')
        if client.is_connected():
            log.info('Client already connected')
            auth_status = await client.is_user_authorized()
            log.info(f'Authorization status: {auth_status}')
            return auth_status
        try:
            log.info('Connecting client...')
            await client.connect()
            log.info('Client connected successfully')
            # If bot token provided and not authorized yet, try bot login
            if BOT_TOKEN and not await client.is_user_authorized():
                try:
                    log.info('Trying bot token login...')
                    await client.start(bot_token=BOT_TOKEN)
                except Exception as be:
                    log.error(f'Bot start failed: {be}')
            auth_status = await client.is_user_authorized()
            log.info(f'Final authorization status: {auth_status}')
            if not auth_status:
                log.error('Not authorized. Use /auth/start & /auth/complete to login or set TELEGRAM_SESSION.')
                return False
            return True
        except AuthKeyDuplicatedError:
            log.error('AuthKeyDuplicatedError: duplicate session. Provide new TELEGRAM_SESSION or re-auth.')
            return False
        except AuthKeyUnregisteredError:
            log.error('AuthKeyUnregisteredError: Session invalid/expired. Re-auth needed.')
            return False
        except FloodWaitError as fe:
            wait = int(getattr(fe, 'seconds', 60))
            log.warning(f'FloodWait: sleeping {wait}s before reconnect.')
            await asyncio.sleep(wait)
            return False
        except Exception as e:
            log.warning(f'ensure_connected error: {e}')
            return False

    if not await ensure_connected():
        AUTH_STATUS.update({'authorized': False, 'reason': 'not_authorized_initial'})
        await asyncio.sleep(180)
        return
    else:
        AUTH_STATUS.update({'authorized': True, 'reason': 'ok'})
    tz = pytz.timezone('Europe/Kyiv')
    processed = {m.get('id') for m in load_messages()}
    all_data = load_messages()
    # -------- Initial backfill (last BACKFILL_MINUTES, default 50) --------
    try:
        backfill_minutes = int(os.getenv('BACKFILL_MINUTES', '50'))
    except ValueError:
        backfill_minutes = 50
    # SPEED FIX: Limit backfill messages per channel (was 400, now 100)
    try:
        backfill_limit = int(os.getenv('BACKFILL_LIMIT', '100'))
    except ValueError:
        backfill_limit = 100
    backfill_cutoff = datetime.now(tz) - timedelta(minutes=backfill_minutes)
    if backfill_minutes > 0:
        log.info(f'Starting FAST backfill for last {backfill_minutes} minutes (limit {backfill_limit} per channel, NO geocoding)...')
        # Track backfill progress
        BACKFILL_STATUS['in_progress'] = True
        BACKFILL_STATUS['started_at'] = datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')
        BACKFILL_STATUS['channels_total'] = len([c for c in CHANNELS if c.strip()])
        BACKFILL_STATUS['channels_done'] = 0
        BACKFILL_STATUS['messages_processed'] = 0
        
        total_backfilled = 0
        for ch in CHANNELS:
            ch_strip = ch.strip()
            if not ch_strip:
                continue
            BACKFILL_STATUS['current_channel'] = ch_strip
            print(f"DEBUG: Processing backfill for channel: {ch_strip}")
            fetched = 0
            try:
                if not await ensure_connected():
                    log.warning('Disconnected during backfill; aborting backfill early.')
                    break
                async for msg in client.iter_messages(ch_strip, limit=backfill_limit):  # SPEED FIX: reduced from 400
                    if not msg.text:
                        continue
                    dt = msg.date.astimezone(tz)
                    if dt < backfill_cutoff:
                        break  # older than needed
                    if msg.id in processed:
                        continue
                    # Check for ballistic threat messages (backfill - don't add to chat)
                    update_ballistic_state(msg.text, is_realtime=False)
                    
                    # SPEED FIX: Skip heavy geocoding during backfill - store raw, process later
                    # This makes backfill instant instead of 30+ minutes
                    all_data.append({
                        'id': str(msg.id),
                        'place': None,
                        'lat': None,
                        'lng': None,
                        'threat_type': 'shahed',  # default, will be updated on reparse
                        'text': msg.text[:500],
                        'date': dt.strftime('%Y-%m-%d %H:%M:%S'),
                        'channel': ch_strip,
                        'pending_geo': True  # Flag for lazy geocoding in /data
                    })
                    processed.add(msg.id)
                    fetched += 1
                    BACKFILL_STATUS['messages_processed'] += 1
                if fetched:
                    total_backfilled += fetched
                    log.info(f'Backfilled {fetched} raw messages from {ch_strip}')
                BACKFILL_STATUS['channels_done'] += 1
            except Exception as e:
                log.warning(f'Backfill error {ch_strip}: {e}')
                BACKFILL_STATUS['channels_done'] += 1
    if backfill_minutes > 0:
        # Mark backfill complete
        BACKFILL_STATUS['in_progress'] = False
        BACKFILL_STATUS['current_channel'] = None
        if total_backfilled:
            save_messages(all_data)
            log.info(f'Backfill saved: {total_backfilled} raw messages (geocoding deferred to /data)')
        log.info('Backfill completed.')
    while True:
        new_tracks = []
        for ch in CHANNELS:
            ch = ch.strip()
            if not ch:
                continue
            if ch in INVALID_CHANNELS:
                log.debug(f'Skip invalid channel {ch}')
                continue
            msgs_seen = 0
            msgs_recent_window = 0
            geo_added = 0
            try:
                if not await ensure_connected():
                    # If session invalid we stop loop gracefully
                    if not client.is_connected():
                        log.error('Stopping live loop due to lost/invalid session.')
                        AUTH_STATUS.update({'authorized': False, 'reason': 'lost_session'})
                        return
                log.debug(f'Polling channel {ch} (last processed count={len(processed)})')
                async for msg in client.iter_messages(ch, limit=20):
                    msgs_seen += 1
                    if not msg.text:
                        continue
                    if msg.id in processed:
                        continue
                    dt = msg.date.astimezone(tz)
                    if dt < datetime.now(tz) - timedelta(minutes=30):
                        # Older than live window
                        continue
                    msgs_recent_window += 1
                    # Check for ballistic threat messages (realtime - add to chat)
                    update_ballistic_state(msg.text, is_realtime=True)
                    # Add other important messages to chat
                    add_telegram_message_to_chat(msg.text, is_realtime=True)
                    tracks = process_message(msg.text, msg.id, dt.strftime('%Y-%m-%d %H:%M:%S'), ch)
                    
                    # Send push notification for threat messages (КАБи, ракети, БПЛА)
                    msg_lower = msg.text.lower()
                    if any(kw in msg_lower for kw in ['каб', 'ракет', 'балістичн', 'бпла', 'дрон', 'шахед', 'вибух']):
                        # Extract location from message (usually first part before threat description)
                        location = ''
                        if '(' in msg.text and ')' in msg.text:
                            # Format: "Харків (Харківська обл.) Загроза..."
                            location = msg.text.split(')')[0] + ')'
                        elif tracks and tracks[0].get('place'):
                            location = tracks[0]['place']
                        
                        if location:
                            # Pass FULL message text - function will extract threat part
                            send_telegram_threat_notification(msg.text, location, str(msg.id))
                    
                    if tracks:
                        merged_any = False
                        appended = []
                        for t in tracks:
                            if t.get('place'):
                                t['place'] = ensure_ua_place(t['place'])
                            merged, ref = maybe_merge_track(all_data, t)
                            if merged:
                                merged_any = True
                            else:
                                new_tracks.append(t)
                                appended.append(t)
                        geo_added += 1
                        processed.add(msg.id)
                        if merged_any and not appended:
                            log.info(f'Merged live track(s) {ch} #{msg.id} (no new marker).')
                        else:
                            log.info(f'Added track from {ch} #{msg.id} (+{len(appended)} new, merged={merged_any})')
                    else:
                        # Store raw if enabled to allow later reprocessing / debugging (e.g., napramok multi-line posts)
                        if ALWAYS_STORE_RAW:
                            all_data.append({
                                'id': str(msg.id), 'place': None, 'lat': None, 'lng': None,
                                'threat_type': None, 'text': msg.text[:800], 'date': dt.strftime('%Y-%m-%d %H:%M:%S'),
                                'channel': ch, 'pending_geo': True
                            })
                            processed.add(msg.id)
                        log.debug(f'Live skip (no geo): {ch} #{msg.id} {msg.text[:80]!r}')
            except AuthKeyDuplicatedError:
                log.error('AuthKeyDuplicatedError during live fetch. Ending loop until session replaced.')
                AUTH_STATUS.update({'authorized': False, 'reason': 'authkey_duplicated'})
                return
            except FloodWaitError as fe:
                wait = int(getattr(fe, 'seconds', 60))
                log.warning(f'FloodWait while reading {ch}: sleep {wait}s')
                await asyncio.sleep(wait)
            # Generic RPC errors will be caught by broad Exception if specific class not available
            except Exception as e:
                msg = str(e)
                log.warning(f'Error reading {ch}: {msg}')
                # Auto-mark invalid entity errors to skip future attempts this runtime
                markers = ['Cannot find any entity', 'CHANNEL_PRIVATE', 'USERNAME_NOT_OCCUPIED', 'TOPIC_DELETED']
                if any(mk in msg for mk in markers):
                    INVALID_CHANNELS.add(ch)
                    log.warning(f'Marking channel {ch} as invalid; will skip further reads this session.')
            finally:
                # Post-channel diagnostics to help debug silent channels like 'napramok'
                log.debug(
                    f'Channel diag {ch}: iter_messages_seen={msgs_seen}, recent_window={msgs_recent_window}, geo_added={geo_added}, invalid={ch in INVALID_CHANNELS}'
                )
                if msgs_seen == 0:
                    log.warning(f'Channel {ch} returned no messages this cycle (possible resolution/access issue).')
                elif msgs_recent_window == 0:
                    log.debug(f'Channel {ch} had messages but none within last 30m window.')
                elif geo_added == 0:
                    log.debug(f'Channel {ch} had {msgs_recent_window} recent messages but none produced geo tracks.')
        if new_tracks:
            # Append truly new tracks (merges already applied in-place)
            all_data.extend(new_tracks)
            save_messages(all_data)
            try:
                broadcast_new(new_tracks)
            except Exception as e:
                log.debug(f'SSE broadcast failed: {e}')
        else:
            # If only merges happened (no brand-new tracks), still persist periodically
            save_messages(all_data)
        await asyncio.sleep(45)  # Check every 45 seconds (CPU optimized)

def start_fetch_thread():
    global FETCH_THREAD_STARTED
    log.info('start_fetch_thread() called')
    if not client:
        log.warning('start_fetch_thread: client is None')
        return
    if FETCH_THREAD_STARTED:
        log.info('start_fetch_thread: already started')
        return
    log.info('start_fetch_thread: starting new thread')
    FETCH_THREAD_STARTED = True
    loop = asyncio.new_event_loop()
    def runner():
        log.info('fetch_thread runner started')
        if FETCH_START_DELAY > 0:
            log.info(f'Delaying Telegram fetch start for {FETCH_START_DELAY}s (FETCH_START_DELAY).')
            time.sleep(FETCH_START_DELAY)
        asyncio.set_event_loop(loop)
        try:
            log.info('About to call fetch_loop()')
            loop.run_until_complete(fetch_loop())
        except AuthKeyDuplicatedError:
            AUTH_STATUS.update({'authorized': False, 'reason': 'authkey_duplicated_runner'})
            log.error('Fetch loop stopped: duplicated auth key.')
        except Exception as e:
            AUTH_STATUS.update({'authorized': False, 'reason': f'crash:{e.__class__.__name__}'})
            log.error(f'Fetch loop crashed: {e}')
        finally:
            FETCH_THREAD_STARTED = False
            log.info('fetch_thread runner finished')
    threading.Thread(target=runner, daemon=True).start()
    log.info('start_fetch_thread: thread started successfully')

def replace_client(new_session: str):
    global client, session_str
    session_str = new_session
    try:
        if client:
            try:
                # Telethon has disconnect
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                loop.run_until_complete(client.disconnect())
            except Exception:
                pass
    finally:
        client = TelegramClient(StringSession(new_session), API_ID, API_HASH)
        AUTH_STATUS.update({'authorized': True, 'reason': 'replaced_session'})
        start_fetch_thread()

# ----------------- Session watcher (auto reload new_session.txt) -----------------
SESSION_WATCH_FILE = os.getenv('SESSION_WATCH_FILE', 'new_session.txt')
SESSION_WATCH_INTERVAL = int(os.getenv('SESSION_WATCH_INTERVAL', '60'))  # CPU optimized: 60s instead of 20s
_watch_thread_started = False
_last_session_file_mtime = 0

def start_session_watcher():
    global _watch_thread_started, _last_session_file_mtime
    if _watch_thread_started:
        return
    _watch_thread_started = True
    def _watch():
        global _last_session_file_mtime, session_str
        while True:
            try:
                if os.path.exists(SESSION_WATCH_FILE):
                    mt = os.path.getmtime(SESSION_WATCH_FILE)
                    if mt != _last_session_file_mtime:
                        _last_session_file_mtime = mt
                        with open(SESSION_WATCH_FILE,'r',encoding='utf-8') as f:
                            new_s = f.read().strip()
                        if new_s and new_s != session_str:
                            log.info('Session watcher: detected updated session file, reloading...')
                            replace_client(new_s)
                # If we are unauthorized due to duplicate key, keep looking for replacement
                if AUTH_STATUS.get('reason','').startswith('authkey_duplicated') and not client.is_connected():
                    # just a hint in logs every few cycles
                    if int(time.time()) % (SESSION_WATCH_INTERVAL*3) == 0:
                        log.info('Waiting for new session (AuthKeyDuplicatedError). Generate via /auth endpoints.')
            except Exception as e:
                log.debug(f'Session watcher error: {e}')
            time.sleep(SESSION_WATCH_INTERVAL)
    threading.Thread(target=_watch, daemon=True).start()

@app.route('/google2848d36b38653ede.html')
def google_verification():
    """Google Search Console verification file"""
    return send_from_directory('static', 'google2848d36b38653ede.html')

@app.route('/new')
def index_new():
    """New UI - SVG map from ukrainealarm.com with districts"""
    response = render_template('index_map.html')
    resp = app.response_class(response)
    resp.headers['Cache-Control'] = 'public, max-age=300'
    return resp

@app.route('/old')
def index_old():
    """Old TopoJSON map (has artifacts)"""
    response = render_template('index_new.html')
    resp = app.response_class(response)
    resp.headers['Cache-Control'] = 'public, max-age=300'
    return resp

@app.route('/shahed-map')
@app.route('/shahed')
@app.route('/drones')
def shahed_map():
    """Shahed map landing page"""
    return render_template('shahed_map.html')

# Redirects for icons requested without /static/ prefix
@app.route('/icon_missile.svg')
def icon_missile_redirect():
    return redirect('/static/icon_missile.svg', code=301)

@app.route('/icon_balistic.svg')
def icon_balistic_redirect():
    return redirect('/static/icon_balistic.svg', code=301)

@app.route('/icon_drone.svg')
def icon_drone_redirect():
    return redirect('/static/icon_drone.svg', code=301)

@app.route('/favicon.ico')
def favicon():
    return redirect('/static/icons/favicon-32x32.png', code=301)

# SEO: Bot detection patterns for prerender
SEO_BOT_PATTERNS = [
    'googlebot', 'bingbot', 'yandex', 'baiduspider', 'facebookexternalhit',
    'twitterbot', 'rogerbot', 'linkedinbot', 'embedly', 'quora link preview',
    'showyoubot', 'outbrain', 'pinterest', 'slackbot', 'vkshare', 'w3c_validator',
    'whatsapp', 'telegram', 'applebot', 'duckduckbot'
]

def is_seo_bot(user_agent):
    """Check if request is from SEO bot/crawler"""
    if not user_agent:
        return False
    ua_lower = user_agent.lower()
    return any(bot in ua_lower for bot in SEO_BOT_PATTERNS)

@app.route('/')
def index():
    """Main page - Карта тривог України онлайн"""
    user_agent = request.headers.get('User-Agent', '')
    
    # SEO: Detect crawlers and serve optimized response
    if is_seo_bot(user_agent):
        # For bots: add extra SEO headers and potentially serve prerendered content
        response = render_template('index_index.html')
        resp = app.response_class(response)
        resp.headers['Cache-Control'] = 'public, max-age=3600'  # 1 hour for bots
        resp.headers['X-Robots-Tag'] = 'index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1'
        resp.headers['Link'] = '<https://neptun.in.ua/>; rel="canonical"'
        # Mark as bot request for debugging
        resp.headers['X-Bot-Detected'] = 'true'
        return resp
    
    # BANDWIDTH OPTIMIZATION: Add caching headers for main page
    response = render_template('index_index.html')
    resp = app.response_class(response)
    resp.headers['Cache-Control'] = 'public, max-age=300'  # 5 minutes cache
    resp.headers['ETag'] = f'index-{int(time.time() // 300)}'
    # SEO Headers for search engines
    resp.headers['X-Robots-Tag'] = 'index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1'
    resp.headers['Link'] = '<https://neptun.in.ua/>; rel="canonical"'
    return resp

# SEO: Regional pages for each oblast
REGIONS_SEO = {
    'kyiv': {'name': 'Київська область', 'name_gen': 'Київської області', 'city': 'Київ'},
    'kharkiv': {'name': 'Харківська область', 'name_gen': 'Харківської області', 'city': 'Харків'},
    'odesa': {'name': 'Одеська область', 'name_gen': 'Одеської області', 'city': 'Одеса'},
    'dnipro': {'name': 'Дніпропетровська область', 'name_gen': 'Дніпропетровської області', 'city': 'Дніпро'},
    'lviv': {'name': 'Львівська область', 'name_gen': 'Львівської області', 'city': 'Львів'},
    'zaporizhzhia': {'name': 'Запорізька область', 'name_gen': 'Запорізької області', 'city': 'Запоріжжя'},
    'vinnytsia': {'name': 'Вінницька область', 'name_gen': 'Вінницької області', 'city': 'Вінниця'},
    'poltava': {'name': 'Полтавська область', 'name_gen': 'Полтавської області', 'city': 'Полтава'},
    'chernihiv': {'name': 'Чернігівська область', 'name_gen': 'Чернігівської області', 'city': 'Чернігів'},
    'sumy': {'name': 'Сумська область', 'name_gen': 'Сумської області', 'city': 'Суми'},
    'mykolaiv': {'name': 'Миколаївська область', 'name_gen': 'Миколаївської області', 'city': 'Миколаїв'},
    'kherson': {'name': 'Херсонська область', 'name_gen': 'Херсонської області', 'city': 'Херсон'},
    'zhytomyr': {'name': 'Житомирська область', 'name_gen': 'Житомирської області', 'city': 'Житомир'},
    'cherkasy': {'name': 'Черкаська область', 'name_gen': 'Черкаської області', 'city': 'Черкаси'},
    'rivne': {'name': 'Рівненська область', 'name_gen': 'Рівненської області', 'city': 'Рівне'},
    'khmelnytskyi': {'name': 'Хмельницька область', 'name_gen': 'Хмельницької області', 'city': 'Хмельницький'},
    'volyn': {'name': 'Волинська область', 'name_gen': 'Волинської області', 'city': 'Луцьк'},
    'ternopil': {'name': 'Тернопільська область', 'name_gen': 'Тернопільської області', 'city': 'Тернопіль'},
    'ivano-frankivsk': {'name': 'Івано-Франківська область', 'name_gen': 'Івано-Франківської області', 'city': 'Івано-Франківськ'},
    'chernivtsi': {'name': 'Чернівецька область', 'name_gen': 'Чернівецької області', 'city': 'Чернівці'},
    'zakarpattia': {'name': 'Закарпатська область', 'name_gen': 'Закарпатської області', 'city': 'Ужгород'},
    'kirovohrad': {'name': 'Кіровоградська область', 'name_gen': 'Кіровоградської області', 'city': 'Кропивницький'},
    'donetsk': {'name': 'Донецька область', 'name_gen': 'Донецької області', 'city': 'Донецьк'},
    'luhansk': {'name': 'Луганська область', 'name_gen': 'Луганської області', 'city': 'Луганськ'},
}

@app.route('/region/<region_slug>')
def region_page(region_slug):
    """SEO page for each region - helps with regional search queries"""
    region = REGIONS_SEO.get(region_slug)
    if not region:
        return render_template('index_index.html'), 404
    
    return render_template('region.html', 
                          region_slug=region_slug,
                          region_name=region['name'],
                          region_name_gen=region['name_gen'],
                          region_city=region['city'])

@app.route('/admin/subscription/<subscription_id>/approve', methods=['POST'])
def admin_approve_subscription(subscription_id):
    """Manually approve a subscription (for bank transfer payments)"""
    if not _require_secret(request):
        return jsonify({'error': 'Forbidden'}), 403
    
    if os.path.exists(COMMERCIAL_SUBSCRIPTIONS_FILE):
        try:
            with open(COMMERCIAL_SUBSCRIPTIONS_FILE, 'r', encoding='utf-8') as f:
                subscriptions = json.load(f)
            
            # Find and approve subscription
            for sub in subscriptions:
                if sub['id'] == subscription_id:
                    sub['status'] = 'paid'
                    sub['manual_approval'] = True
                    sub['approved_at'] = datetime.now(pytz.timezone('Europe/Kiev')).isoformat()
                    
                    # Send confirmation email
                    if MAIL_ENABLED:
                        try:
                            send_subscription_email(sub)
                        except Exception as e:
                            print(f"❌ Email sending failed: {e}")
                    
                    break
            
            # Save updated subscriptions
            with open(COMMERCIAL_SUBSCRIPTIONS_FILE, 'w', encoding='utf-8') as f:
                json.dump(subscriptions, f, ensure_ascii=False, indent=2)
            
            return jsonify({'success': True, 'message': 'Subscription approved'})
            
        except Exception as e:
            print(f"❌ Failed to approve subscription: {e}")
            return jsonify({'error': str(e)}), 500
    
    return jsonify({'error': 'Subscription not found'}), 404

@app.route('/map-only')
def map_only():
    """Map-only view - new SVG map for embedding in mobile apps (iOS/Android WebView)"""
    response = render_template('index_map.html')
    resp = app.response_class(response)
    resp.headers['Cache-Control'] = 'public, max-age=300'  # 5 minutes cache
    resp.headers['X-Frame-Options'] = 'ALLOWALL'  # Allow embedding in iframes/WebView
    resp.headers['Access-Control-Allow-Origin'] = '*'  # Allow cross-origin requests
    return resp

@app.route('/map-old')
def map_old():
    """Old Leaflet map view (map_only.html)"""
    response = render_template('map_only.html')
    resp = app.response_class(response)
    resp.headers['Cache-Control'] = 'public, max-age=300'  # 5 minutes cache
    resp.headers['X-Frame-Options'] = 'ALLOWALL'  # Allow embedding in iframes/WebView
    resp.headers['Access-Control-Allow-Origin'] = '*'  # Allow cross-origin requests
    return resp

@app.route('/map-embed')
def map_embed():
    """Map with world mask (dimming) for mobile apps embedding"""
    response = render_template('map_embed.html')
    resp = app.response_class(response)
    resp.headers['Cache-Control'] = 'public, max-age=300'  # 5 minutes cache
    resp.headers['X-Frame-Options'] = 'ALLOWALL'  # Allow embedding in iframes/WebView
    resp.headers['Access-Control-Allow-Origin'] = '*'  # Allow cross-origin requests
    return resp

@app.route('/svg')
def index_svg():
    """SVG map - redirect to main page"""
    from flask import redirect
    return redirect('/', code=301)

@app.route('/about')
def about():
    """About NEPTUN project page"""
    response = render_template('about.html')
    resp = app.response_class(response)
    resp.headers['Cache-Control'] = 'public, max-age=3600'  # 1 hour cache
    return resp

@app.route('/analytics')
def analytics():
    """Analytics and statistics page with original content analysis"""
    response = render_template('analytics.html')
    resp = app.response_class(response)
    resp.headers['Cache-Control'] = 'public, max-age=300'  # 5 minutes cache
    return resp

@app.route('/community')
@app.route('/telegram')
@app.route('/join')
def redirect_telegram():
    """Redirect to Telegram community"""
    page_name = request.path.lstrip('/')
    user_ip = request.headers.get('X-Forwarded-For', request.remote_addr)
    user_agent = request.headers.get('User-Agent', '')
    track_redirect_visit(page_name, user_ip, user_agent)
    return render_template('redirect.html')

@app.route('/channel')
@app.route('/group')
@app.route('/chat')
def redirect_telegram2():
    """Redirect to Telegram channel"""
    page_name = request.path.lstrip('/')
    user_ip = request.headers.get('X-Forwarded-For', request.remote_addr)
    user_agent = request.headers.get('User-Agent', '')
    track_redirect_visit(page_name, user_ip, user_agent)
    return render_template('redirect2.html')

@app.route('/news')
@app.route('/updates')
@app.route('/alerts')
def redirect_telegram3():
    """Redirect to Telegram alerts channel"""
    page_name = request.path.lstrip('/')
    user_ip = request.headers.get('X-Forwarded-For', request.remote_addr)
    user_agent = request.headers.get('User-Agent', '')
    track_redirect_visit(page_name, user_ip, user_agent)
    return render_template('redirect3.html')

@app.route('/track_redirect_click', methods=['POST'])
def track_redirect_click():
    """Track button click on redirect page"""
    try:
        data = request.get_json() or {}
        page_name = data.get('page', 'unknown')
        user_ip = request.headers.get('X-Forwarded-For', request.remote_addr)
        user_agent = request.headers.get('User-Agent', '')
        
        # Track as click (we'll add a suffix to differentiate)
        track_redirect_visit(f"{page_name}_click", user_ip, user_agent)
        
        return jsonify({'status': 'ok'})
    except Exception as e:
        log.warning(f"Failed to track redirect click: {e}")
        return jsonify({'status': 'error', 'message': str(e)}), 500

@app.route('/faq')
def faq():
    """Frequently Asked Questions page"""
    response = render_template('faq.html')
    resp = app.response_class(response)
    resp.headers['Cache-Control'] = 'public, max-age=3600'  # 1 hour cache
    return resp

@app.route('/privacy')
def privacy():
    """Privacy Policy page"""
    response = render_template('privacy.html')
    resp = app.response_class(response)
    resp.headers['Cache-Control'] = 'public, max-age=86400'  # 24 hours cache
    return resp

@app.route('/terms')
def terms():
    """Terms of Service page"""
    response = render_template('terms.html')
    resp = app.response_class(response)
    resp.headers['Cache-Control'] = 'public, max-age=86400'  # 24 hours cache
    return resp

@app.route('/contact')
def contact():
    """Contact page"""
    response = render_template('contact.html')
    resp = app.response_class(response)
    resp.headers['Cache-Control'] = 'public, max-age=86400'  # 24 hours cache
    return resp

# Address database for blackout schedules with subgroups
# Format: group can be "1.1", "1.2", "2.1", "2.2", "3.1", "3.2" etc.
# TODO: Replace with real database and API integration
BLACKOUT_ADDRESSES = {
    # Kyiv - all subgroups across different districts
    'київ хрещатик': {'group': '1.1', 'city': 'Київ', 'oblast': 'Київська', 'provider': 'ДТЕК Київські електромережі'},
    'київ вулиця хрещатик': {'group': '1.1', 'city': 'Київ', 'oblast': 'Київська', 'provider': 'ДТЕК Київські електромережі'},
    'київ майдан': {'group': '1.2', 'city': 'Київ', 'oblast': 'Київська', 'provider': 'ДТЕК Київські електромережі'},
    'київ печерськ': {'group': '2.1', 'city': 'Київ', 'oblast': 'Київська', 'provider': 'ДТЕК Київські електромережі'},
    'київ поділ': {'group': '2.2', 'city': 'Київ', 'oblast': 'Київська', 'provider': 'ДТЕК Київські електромережі'},
    'київ шевченківський': {'group': '3.1', 'city': 'Київ', 'oblast': 'Київська', 'provider': 'ДТЕК Київські електромережі'},
    'київ оболонь': {'group': '3.2', 'city': 'Київ', 'oblast': 'Київська', 'provider': 'ДТЕК Київські електромережі'},
    'київ троєщина': {'group': '1.1', 'city': 'Київ', 'oblast': 'Київська', 'provider': 'ДТЕК Київські електромережі'},
    'київ позняки': {'group': '2.1', 'city': 'Київ', 'oblast': 'Київська', 'provider': 'ДТЕК Київські електромережі'},
    'київ дарниця': {'group': '3.1', 'city': 'Київ', 'oblast': 'Київська', 'provider': 'ДТЕК Київські електромережі'},
    'київ лівобережна': {'group': '2.2', 'city': 'Київ', 'oblast': 'Київська', 'provider': 'ДТЕК Київські електромережі'},
    'київ академмістечко': {'group': '3.2', 'city': 'Київ', 'oblast': 'Київська', 'provider': 'ДТЕК Київські електромережі'},
    'київ теремки': {'group': '1.2', 'city': 'Київ', 'oblast': 'Київська', 'provider': 'ДТЕК Київські електромережі'},
    'київ вишневе': {'group': '2.1', 'city': 'Київ', 'oblast': 'Київська', 'provider': 'ДТЕК Київські електромережі'},
    'київ бориспіль': {'group': '1.1', 'city': 'Бориспіль', 'oblast': 'Київська', 'provider': 'ДТЕК Київські електромережі'},
    
    # Odesa - all subgroups
    'одеса дерибасівська': {'group': '1.1', 'city': 'Одеса', 'oblast': 'Одеська', 'provider': 'ДТЕК Одеські електромережі'},
    'одеса приморський': {'group': '1.2', 'city': 'Одеса', 'oblast': 'Одеська', 'provider': 'ДТЕК Одеські електромережі'},
    'одеса центр': {'group': '2.1', 'city': 'Одеса', 'oblast': 'Одеська', 'provider': 'ДТЕК Одеські електромережі'},
    'одеса аркадія': {'group': '2.2', 'city': 'Одеса', 'oblast': 'Одеська', 'provider': 'ДТЕК Одеські електромережі'},
    'одеса таїрова': {'group': '3.1', 'city': 'Одеса', 'oblast': 'Одеська', 'provider': 'ДТЕК Одеські електромережі'},
    'одеса котовського': {'group': '3.2', 'city': 'Одеса', 'oblast': 'Одеська', 'provider': 'ДТЕК Одеські електромережі'},
    'одеса молдаванка': {'group': '1.1', 'city': 'Одеса', 'oblast': 'Одеська', 'provider': 'ДТЕК Одеські електромережі'},
    'одеса пересипь': {'group': '2.1', 'city': 'Одеса', 'oblast': 'Одеська', 'provider': 'ДТЕК Одеські електромережі'},
    'одеса суворовський': {'group': '3.1', 'city': 'Одеса', 'oblast': 'Одеська', 'provider': 'ДТЕК Одеські електромережі'},
    'одеса чорноморка': {'group': '1.2', 'city': 'Одеса', 'oblast': 'Одеська', 'provider': 'ДТЕК Одеські електромережі'},
    
    # Kharkiv - all subgroups
    'харків сумська': {'group': '1.1', 'city': 'Харків', 'oblast': 'Харківська', 'provider': 'ДТЕК Східенерго'},
    'харків центр': {'group': '1.2', 'city': 'Харків', 'oblast': 'Харківська', 'provider': 'ДТЕК Східенерго'},
    'харків салтівка': {'group': '2.1', 'city': 'Харків', 'oblast': 'Харківська', 'provider': 'ДТЕК Східенерго'},
    'харків нагірний': {'group': '2.2', 'city': 'Харків', 'oblast': 'Харківська', 'provider': 'ДТЕК Східенерго'},
    'харків холодна гора': {'group': '3.1', 'city': 'Харків', 'oblast': 'Харківська', 'provider': 'ДТЕК Східенерго'},
    'харків павлове поле': {'group': '3.2', 'city': 'Харків', 'oblast': 'Харківська', 'provider': 'ДТЕК Східенерго'},
    'харків московський': {'group': '1.1', 'city': 'Харків', 'oblast': 'Харківська', 'provider': 'ДТЕК Східенерго'},
    'харків індустріальний': {'group': '2.1', 'city': 'Харків', 'oblast': 'Харківська', 'provider': 'ДТЕК Східенерго'},
    'харків київський': {'group': '1.2', 'city': 'Харків', 'oblast': 'Харківська', 'provider': 'ДТЕК Східенерго'},
    
    # Dnipro - all subgroups
    'дніпро центр': {'group': '1.1', 'city': 'Дніпро', 'oblast': 'Дніпропетровська', 'provider': 'ДТЕК Дніпровські електромережі'},
    'дніпро гагаріна': {'group': '1.2', 'city': 'Дніпро', 'oblast': 'Дніпропетровська', 'provider': 'ДТЕК Дніпровські електромережі'},
    'дніпро нагірний': {'group': '2.1', 'city': 'Дніпро', 'oblast': 'Дніпропетровська', 'provider': 'ДТЕК Дніпровські електромережі'},
    'дніпро проспект': {'group': '2.2', 'city': 'Дніпро', 'oblast': 'Дніпропетровська', 'provider': 'ДТЕК Дніпровські електромережі'},
    'дніпро придніпровськ': {'group': '3.1', 'city': 'Дніпро', 'oblast': 'Дніпропетровська', 'provider': 'ДТЕК Дніпровські електромережі'},
    'дніпро новокодацький': {'group': '3.2', 'city': 'Дніпро', 'oblast': 'Дніпропетровська', 'provider': 'ДТЕК Дніпровські електромережі'},
    'дніпро соборний': {'group': '1.1', 'city': 'Дніпро', 'oblast': 'Дніпропетровська', 'provider': 'ДТЕК Дніпровські електромережі'},
    'дніпро амур': {'group': '2.1', 'city': 'Дніпро', 'oblast': 'Дніпропетровська', 'provider': 'ДТЕК Дніпровські електромережі'},
    
    # Lviv - all subgroups
    'львів центр': {'group': '1.1', 'city': 'Львів', 'oblast': 'Львівська', 'provider': 'Львівобленерго'},
    'львів площа ринок': {'group': '1.2', 'city': 'Львів', 'oblast': 'Львівська', 'provider': 'Львівобленерго'},
    'львів франка': {'group': '2.1', 'city': 'Львів', 'oblast': 'Львівська', 'provider': 'Львівобленерго'},
    'львів сихів': {'group': '2.2', 'city': 'Львів', 'oblast': 'Львівська', 'provider': 'Львівобленерго'},
    'львів личаківська': {'group': '3.1', 'city': 'Львів', 'oblast': 'Львівська', 'provider': 'Львівобленерго'},
    'львів сихівська': {'group': '3.2', 'city': 'Львів', 'oblast': 'Львівська', 'provider': 'Львівобленерго'},
    'львів залізничний': {'group': '1.1', 'city': 'Львів', 'oblast': 'Львівська', 'provider': 'Львівобленерго'},
    'львів шевченківський': {'group': '2.1', 'city': 'Львів', 'oblast': 'Львівська', 'provider': 'Львівобленерго'},
    
    # Zaporizhzhia - all subgroups
    'запоріжжя центр': {'group': '1.1', 'city': 'Запоріжжя', 'oblast': 'Запорізька', 'provider': 'ДТЕК Запорізькі електромережі'},
    'запоріжжя проспект': {'group': '1.2', 'city': 'Запоріжжя', 'oblast': 'Запорізька', 'provider': 'ДТЕК Запорізькі електромережі'},
    'запоріжжя хортицький': {'group': '2.1', 'city': 'Запоріжжя', 'oblast': 'Запорізька', 'provider': 'ДТЕК Запорізькі електромережі'},
    'запоріжжя шевченківський': {'group': '2.2', 'city': 'Запоріжжя', 'oblast': 'Запорізька', 'provider': 'ДТЕК Запорізькі електромережі'},
    'запоріжжя заводський': {'group': '3.1', 'city': 'Запоріжжя', 'oblast': 'Запорізька', 'provider': 'ДТЕК Запорізькі електромережі'},
    'запоріжжя дніпровський': {'group': '3.2', 'city': 'Запоріжжя', 'oblast': 'Запорізька', 'provider': 'ДТЕК Запорізькі електромережі'},
    
    # Vinnytsia - all subgroups
    'вінниця центр': {'group': '1.1', 'city': 'Вінниця', 'oblast': 'Вінницька', 'provider': 'Вінницяобленерго'},
    'вінниця соборна': {'group': '1.2', 'city': 'Вінниця', 'oblast': 'Вінницька', 'provider': 'Вінницяобленерго'},
    'вінниця хмельницьке': {'group': '2.1', 'city': 'Вінниця', 'oblast': 'Вінницька', 'provider': 'Вінницяобленерго'},
    'вінниця вишенька': {'group': '2.2', 'city': 'Вінниця', 'oblast': 'Вінницька', 'provider': 'Вінницяобленерго'},
    'вінниця замостя': {'group': '3.1', 'city': 'Вінниця', 'oblast': 'Вінницька', 'provider': 'Вінницяобленерго'},
    
    # Poltava - all subgroups
    'полтава центр': {'group': '1.1', 'city': 'Полтава', 'oblast': 'Полтавська', 'provider': 'Полтаваобленерго'},
    'полтава соборності': {'group': '1.2', 'city': 'Полтава', 'oblast': 'Полтавська', 'provider': 'Полтаваобленерго'},
    'полтава київський': {'group': '2.1', 'city': 'Полтава', 'oblast': 'Полтавська', 'provider': 'Полтаваобленерго'},
    'полтава подільський': {'group': '2.2', 'city': 'Полтава', 'oblast': 'Полтавська', 'provider': 'Полтаваобленерго'},
    
    # Chernihiv - all subgroups
    'чернігів центр': {'group': '1.1', 'city': 'Чернігів', 'oblast': 'Чернігівська', 'provider': 'Чернігівобленерго'},
    'чернігів мира': {'group': '1.2', 'city': 'Чернігів', 'oblast': 'Чернігівська', 'provider': 'Чернігівобленерго'},
    'чернігів деснянський': {'group': '2.1', 'city': 'Чернігів', 'oblast': 'Чернігівська', 'provider': 'Чернігівобленерго'},
    
    # Zhytomyr - all subgroups
    'житомир центр': {'group': '1.1', 'city': 'Житомир', 'oblast': 'Житомирська', 'provider': 'Житомиробленерго'},
    'житомир київська': {'group': '1.2', 'city': 'Житомир', 'oblast': 'Житомирська', 'provider': 'Житомиробленерго'},
    'житомир богунія': {'group': '2.1', 'city': 'Житомир', 'oblast': 'Житомирська', 'provider': 'Житомиробленерго'},
    'житомир корольовський': {'group': '2.2', 'city': 'Житомир', 'oblast': 'Житомирська', 'provider': 'Житомиробленерго'},
    
    # Cherkasy - all subgroups
    'черкаси центр': {'group': '1.1', 'city': 'Черкаси', 'oblast': 'Черкаська', 'provider': 'Черкасиобленерго'},
    'черкаси соборна': {'group': '1.2', 'city': 'Черкаси', 'oblast': 'Черкаська', 'provider': 'Черкасиобленерgo'},
    'черкаси придніпровський': {'group': '2.1', 'city': 'Черкаси', 'oblast': 'Черкаська', 'provider': 'Черкасиобленерго'},
    
    # Sumy - all subgroups
    'суми центр': {'group': '1.1', 'city': 'Суми', 'oblast': 'Сумська', 'provider': 'Сумиобленерго'},
    'суми соборна': {'group': '1.2', 'city': 'Суми', 'oblast': 'Сумська', 'provider': 'Сумиобленерго'},
    'суми ковпаківський': {'group': '2.1', 'city': 'Суми', 'oblast': 'Сумська', 'provider': 'Сумиобленерго'},
    
    # Khmelnytskyi - all subgroups
    'хмельницький центр': {'group': '1.1', 'city': 'Хмельницький', 'oblast': 'Хмельницька', 'provider': 'Хмельницькобленерго'},
    'хмельницький проспект': {'group': '1.2', 'city': 'Хмельницький', 'oblast': 'Хмельницька', 'provider': 'Хмельницькобленерго'},
    'хмельницький загоцька': {'group': '2.1', 'city': 'Хмельницький', 'oblast': 'Хмельницька', 'provider': 'Хмельницькобленерго'},
    
    # Rivne - all subgroups
    'рівне центр': {'group': '1.1', 'city': 'Рівне', 'oblast': 'Рівненська', 'provider': 'Рівненобленерго'},
    'рівне соборна': {'group': '1.2', 'city': 'Рівне', 'oblast': 'Рівненська', 'provider': 'Рівненобленерго'},
    'рівне північний': {'group': '2.1', 'city': 'Рівне', 'oblast': 'Рівненська', 'provider': 'Рівненобленерго'},
    
    # Ivano-Frankivsk - all subgroups
    'івано-франківськ центр': {'group': '1.1', 'city': 'Івано-Франківськ', 'oblast': 'Івано-Франківська', 'provider': 'Прикарпаттяобленерго'},
    'івано-франківськ незалежності': {'group': '1.2', 'city': 'Івано-Франківськ', 'oblast': 'Івано-Франківська', 'provider': 'Прикарпаттяобленерго'},
    'івано-франківськ пасічна': {'group': '2.1', 'city': 'Івано-Франківськ', 'oblast': 'Івано-Франківська', 'provider': 'Прикарпаттяобленерго'},
    
    # Ternopil - all subgroups
    'тернопіль центр': {'group': '1.1', 'city': 'Тернопіль', 'oblast': 'Тернопільська', 'provider': 'Тернопільобленерго'},
    'тернопіль руська': {'group': '1.2', 'city': 'Тернопіль', 'oblast': 'Тернопільська', 'provider': 'Тернопільобленерго'},
    'тернопіль східний': {'group': '2.1', 'city': 'Тернопіль', 'oblast': 'Тернопільська', 'provider': 'Тернопільобленерго'},
    
    # Lutsk - all subgroups
    'луцьк центр': {'group': '1.1', 'city': 'Луцьк', 'oblast': 'Волинська', 'provider': 'Волиньобленерго'},
    'луцьк волі': {'group': '1.2', 'city': 'Луцьк', 'oblast': 'Волинська', 'provider': 'Волиньобленерго'},
    'луцьк вокзальна': {'group': '2.1', 'city': 'Луцьк', 'oblast': 'Волинська', 'provider': 'Волиньобленерго'},
    
    # Chernivtsi - all subgroups
    'чернівці центр': {'group': '1.1', 'city': 'Чернівці', 'oblast': 'Чернівецька', 'provider': 'Чернівціобленерго'},
    'чернівці головна': {'group': '1.2', 'city': 'Чернівці', 'oblast': 'Чернівецька', 'provider': 'Чернівціобленерго'},
    'чернівці садгора': {'group': '2.1', 'city': 'Чернівці', 'oblast': 'Чернівецька', 'provider': 'Чернівціобленерго'},
    
    # Uzhhorod - all subgroups
    'ужгород центр': {'group': '1.1', 'city': 'Ужгород', 'oblast': 'Закарпатська', 'provider': 'Закарпаттяобленерго'},
    'ужгород корзо': {'group': '1.2', 'city': 'Ужгород', 'oblast': 'Закарпатська', 'provider': 'Закарпаттяобленерго'},
    'ужгород боздош': {'group': '2.1', 'city': 'Ужгород', 'oblast': 'Закарпатська', 'provider': 'Закарпаттяобленерго'},
    
    # Kropyvnytskyi (Kirovohrad) - all subgroups
    'кропивницький центр': {'group': '1.1', 'city': 'Кропивницький', 'oblast': 'Кіровоградська', 'provider': 'Кіровоградобленерго'},
    'кропивницький велика перспективна': {'group': '1.2', 'city': 'Кропивницький', 'oblast': 'Кіровоградська', 'provider': 'Кіровоградобленерго'},
    'кропивницький фортечний': {'group': '2.1', 'city': 'Кропивницький', 'oblast': 'Кіровоградська', 'provider': 'Кіровоградобленерго'},
    
    # Mykolaiv - all subgroups
    'миколаїв центр': {'group': '1.1', 'city': 'Миколаїв', 'oblast': 'Миколаївська', 'provider': 'Миколаївобленерго'},
    'миколаїв соборна': {'group': '1.2', 'city': 'Миколаїв', 'oblast': 'Миколаївська', 'provider': 'Миколаївобленерго'},
    'миколаїв інгульський': {'group': '2.1', 'city': 'Миколаїв', 'oblast': 'Миколаївська', 'provider': 'Миколаївобленерго'},
    'миколаїв корабельний': {'group': '2.2', 'city': 'Миколаїв', 'oblast': 'Миколаївська', 'provider': 'Миколаївобленерго'},
    
    # Kherson - all subgroups
    'херсон центр': {'group': '1.1', 'city': 'Херсон', 'oblast': 'Херсонська', 'provider': 'Херсонобленерго'},
    'херсон ушакова': {'group': '1.2', 'city': 'Херсон', 'oblast': 'Херсонська', 'provider': 'Херсонобленерго'},
    'херсон дніпровський': {'group': '2.1', 'city': 'Херсон', 'oblast': 'Херсонська', 'provider': 'Херсонобленерго'},
    
    # Mariupol (DTEK Donetsk region)
    'маріуполь центр': {'group': '1.1', 'city': 'Маріуполь', 'oblast': 'Донецька', 'provider': 'ДТЕК Донецькі електромережі'},
    'маріуполь лівобережний': {'group': '2.1', 'city': 'Маріуполь', 'oblast': 'Донецька', 'provider': 'ДТЕК Донецькі електромережі'},
    
    # Kremenchuk - all subgroups
    'кременчук центр': {'group': '1.1', 'city': 'Кременчук', 'oblast': 'Полтавська', 'provider': 'Полтаваобленерго'},
    'кременчук київська': {'group': '1.2', 'city': 'Кременчук', 'oblast': 'Полтавська', 'provider': 'Полтаваобленерго'},
    'кременчук автозаводський': {'group': '2.1', 'city': 'Кременчук', 'oblast': 'Полтавська', 'provider': 'Полтаваобленерго'},
}

# Merge with extended database if available
if UKRAINE_ADDRESSES_DB:
    BLACKOUT_ADDRESSES.update(UKRAINE_ADDRESSES_DB)
    print(f"INFO: Merged addresses database, total: {len(BLACKOUT_ADDRESSES)} addresses")

# Blackout schedules by group and subgroup
# Format: group "1.1", "1.2", "2.1", "2.2", "3.1", "3.2"
# Each subgroup has different timing within main group
# TODO: Fetch from real APIs (DTEK, Ukrenergo)
BLACKOUT_SCHEDULES = {
    # Group 1 subgroups
    '1.1': [
        {'time': '00:00 - 04:00', 'label': 'Електропостачання', 'status': 'normal'},
        {'time': '04:00 - 08:00', 'label': 'Можливе відключення', 'status': 'normal'},
        {'time': '08:00 - 12:00', 'label': 'Електропостачання', 'status': 'normal'},
        {'time': '12:00 - 16:00', 'label': 'Активне відключення', 'status': 'active'},
        {'time': '16:00 - 20:00', 'label': 'Електропостачання', 'status': 'normal'},
        {'time': '20:00 - 24:00', 'label': 'Можливе відключення', 'status': 'upcoming'},
    ],
    '1.2': [
        {'time': '00:00 - 04:00', 'label': 'Можливе відключення', 'status': 'upcoming'},
        {'time': '04:00 - 08:00', 'label': 'Електропостачання', 'status': 'normal'},
        {'time': '08:00 - 12:00', 'label': 'Можливе відключення', 'status': 'normal'},
        {'time': '12:00 - 16:00', 'label': 'Електропостачання', 'status': 'normal'},
        {'time': '16:00 - 20:00', 'label': 'Активне відключення', 'status': 'active'},
        {'time': '20:00 - 24:00', 'label': 'Електропостачання', 'status': 'normal'},
    ],
    
    # Group 2 subgroups
    '2.1': [
        {'time': '00:00 - 04:00', 'label': 'Електропостачання', 'status': 'normal'},
        {'time': '04:00 - 08:00', 'label': 'Можливе відключення', 'status': 'normal'},
        {'time': '08:00 - 12:00', 'label': 'Електропостачання', 'status': 'normal'},
        {'time': '12:00 - 16:00', 'label': 'Можливе відключення', 'status': 'normal'},
        {'time': '16:00 - 20:00', 'label': 'Активне відключення', 'status': 'active'},
        {'time': '20:00 - 24:00', 'label': 'Електропостачання', 'status': 'normal'},
    ],
    '2.2': [
        {'time': '00:00 - 04:00', 'label': 'Можливе відключення', 'status': 'normal'},
        {'time': '04:00 - 08:00', 'label': 'Електропостачання', 'status': 'normal'},
        {'time': '08:00 - 12:00', 'label': 'Активне відключення', 'status': 'active'},
        {'time': '12:00 - 16:00', 'label': 'Електропостачання', 'status': 'normal'},
        {'time': '16:00 - 20:00', 'label': 'Можливе відключення', 'status': 'upcoming'},
        {'time': '20:00 - 24:00', 'label': 'Електропостачання', 'status': 'normal'},
    ],
    
    # Group 3 subgroups
    '3.1': [
        {'time': '00:00 - 04:00', 'label': 'Можливе відключення', 'status': 'upcoming'},
        {'time': '04:00 - 08:00', 'label': 'Електропостачання', 'status': 'normal'},
        {'time': '08:00 - 12:00', 'label': 'Можливе відключення', 'status': 'normal'},
        {'time': '12:00 - 16:00', 'label': 'Електропостачання', 'status': 'normal'},
        {'time': '16:00 - 20:00', 'label': 'Активне відключення', 'status': 'active'},
        {'time': '20:00 - 24:00', 'label': 'Електропостачання', 'status': 'normal'},
    ],
    '3.2': [
        {'time': '00:00 - 04:00', 'label': 'Електропостачання', 'status': 'normal'},
        {'time': '04:00 - 08:00', 'label': 'Можливе відключення', 'status': 'normal'},
        {'time': '08:00 - 12:00', 'label': 'Електропостачання', 'status': 'normal'},
        {'time': '12:00 - 16:00', 'label': 'Можливе відключення', 'status': 'upcoming'},
        {'time': '16:00 - 20:00', 'label': 'Електропостачання', 'status': 'normal'},
        {'time': '20:00 - 24:00', 'label': 'Активне відключення', 'status': 'active'},
    ],
    
    # Fallback for old integer groups (backward compatibility)
    1: [
        {'time': '06:00 - 10:00', 'label': 'Можливе відключення', 'status': 'normal'},
        {'time': '10:00 - 14:00', 'label': 'Електропостачання', 'status': 'normal'},
        {'time': '14:00 - 18:00', 'label': 'Активне відключення', 'status': 'active'},
        {'time': '18:00 - 22:00', 'label': 'Електропостачання', 'status': 'normal'},
        {'time': '22:00 - 02:00', 'label': 'Можливе відключення', 'status': 'upcoming'},
    ],
    2: [
        {'time': '08:00 - 12:00', 'label': 'Електропостачання', 'status': 'normal'},
        {'time': '12:00 - 16:00', 'label': 'Можливе відключення', 'status': 'upcoming'},
        {'time': '16:00 - 20:00', 'label': 'Активне відключення', 'status': 'active'},
        {'time': '20:00 - 00:00', 'label': 'Електропостачання', 'status': 'normal'},
        {'time': '00:00 - 04:00', 'label': 'Можливе відключення', 'status': 'normal'},
    ],
    3: [
        {'time': '04:00 - 08:00', 'label': 'Можливе відключення', 'status': 'normal'},
        {'time': '08:00 - 12:00', 'label': 'Активне відключення', 'status': 'active'},
        {'time': '12:00 - 16:00', 'label': 'Електропостачання', 'status': 'normal'},
        {'time': '16:00 - 20:00', 'label': 'Можливе відключення', 'status': 'upcoming'},
        {'time': '20:00 - 00:00', 'label': 'Електропостачання', 'status': 'normal'},
    ],
}

@app.route('/api/search_cities')
def search_cities():
    """Get all cities and addresses for autocomplete"""
    try:
        # Collect unique cities
        cities_set = set()
        addresses_list = []
        
        for address_key, data in BLACKOUT_ADDRESSES.items():
            city = data.get('city', '')
            if city:
                cities_set.add(city)
            
            # Parse address_key to extract street and building
            # Format: "city street" or "city street building"
            parts = address_key.split()
            if len(parts) >= 2:
                street = ' '.join(parts[1:])
                addresses_list.append({
                    'city': city,
                    'street': street,
                    'building': '',  # Can be extracted if needed
                    'group': data.get('group', ''),
                    'oblast': data.get('oblast', ''),
                    'provider': data.get('provider', '')
                })
        
        # Convert cities set to sorted list
        cities_list = sorted(list(cities_set))
        
        return jsonify({
            'cities': cities_list,
            'addresses': addresses_list[:200]  # Limit for performance
        })
        
    except Exception as e:
        print(f"ERROR in search_cities: {str(e)}")
        return jsonify({
            'cities': UKRAINE_CITIES if UKRAINE_CITIES else [],
            'addresses': []
        })


@app.route('/api/all_cities_with_queues')
def get_all_cities_with_queues():
    """Get all cities with their queues for the schedule grid"""
    try:
        # Group addresses by city and queue
        cities_data = {}
        
        for address_key, data in BLACKOUT_ADDRESSES.items():
            city = data.get('city', '')
            oblast = data.get('oblast', '')
            queue = data.get('group', '')
            provider = data.get('provider', '')
            
            if not city:
                continue
            
            # Create city key
            city_key = f"{city}, {oblast}"
            
            if city_key not in cities_data:
                cities_data[city_key] = {
                    'city': city,
                    'oblast': oblast,
                    'provider': provider,
                    'queues': set()
                }
            
            if queue:
                cities_data[city_key]['queues'].add(queue)
        
        # Convert to list and format
        result = []
        for city_key, data in cities_data.items():
            queues_list = sorted(list(data['queues']))
            
            # Determine current hour for status
            current_hour = datetime.now(pytz.timezone('Europe/Kiev')).hour
            
            # Check if any queue has active blackout now
            has_active_blackout = False
            active_queues = []
            
            for queue in queues_list:
                schedule = BLACKOUT_SCHEDULES.get(queue, [])
                for slot in schedule:
                    if slot.get('status') == 'active':
                        # Parse time range
                        time_range = slot.get('time', '')
                        if ' - ' in time_range:
                            start_time = time_range.split(' - ')[0]
                            start_hour = int(start_time.split(':')[0])
                            end_hour = (start_hour + 4) % 24
                            
                            if start_hour <= current_hour < end_hour or (end_hour < start_hour and (current_hour >= start_hour or current_hour < end_hour)):
                                has_active_blackout = True
                                active_queues.append(queue)
            
            # Determine status
            if has_active_blackout:
                status = 'active'
                status_text = f"Відключення черг: {', '.join(active_queues)}"
            elif len(queues_list) > 0:
                status = 'warning'
                status_text = f"Черги: {', '.join(queues_list)}"
            else:
                status = 'stable'
                status_text = "Стабільно"
            
            result.append({
                'city': data['city'],
                'oblast': data['oblast'],
                'provider': data['provider'],
                'queues': queues_list,
                'status': status,
                'statusText': status_text,
                'queuesCount': len(queues_list)
            })
        
        # Sort by city name
        result.sort(key=lambda x: x['city'])
        
        return jsonify({
            'success': True,
            'cities': result,
            'total': len(result)
        })
        
    except Exception as e:
        log.error(f"Error in get_all_cities_with_queues: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/get_schedule')
def get_schedule():
    """Get blackout schedule for a specific address using YASNO API with fallback"""
    city = request.args.get('city', '').strip()
    street = request.args.get('street', '').strip()
    building = request.args.get('building', '').strip()
    group = request.args.get('group', '').strip()
    refresh = request.args.get('refresh', '').lower() in ('true', '1', 'yes')
    
    if not city:
        return jsonify({'error': 'Місто обов\'язкове для заповнення'}), 400
    
    # Try YASNO API first (for Kyiv and Dnipro)
    try:
        from yasno_api import yasno_api
        
        region = yasno_api.city_to_region(city)
        if region:
            # Clear cache if refresh requested
            if refresh:
                yasno_api._cache = None
                yasno_api._cache_time = None
                log.info(f"Forced refresh for {city}")
            
            # YASNO supports this city - get schedule with force refresh if needed
            data = yasno_api._get_data(force_refresh=refresh)
            if not data:
                log.warning(f"YASNO API returned no data for {city}")
            
            result = yasno_api.get_schedule_for_address(city, group if group else None)
            
            if result.get('found'):
                return jsonify({
                    'found': True,
                    'address': f"{city}, {street} {building}".strip() if street else city,
                    'city': city,
                    'region': result.get('region'),
                    'group': group or result.get('available_groups', ['1.1'])[0],
                    'provider': 'YASNO (DTEK)',
                    'source': 'yasno_api',
                    'is_blackout': result.get('is_blackout', False),
                    'status': result.get('status', 'unknown'),
                    'status_type': result.get('status_type', 'UNKNOWN'),
                    'schedule': result.get('schedule', []),
                    'schedule_tomorrow': result.get('schedule_tomorrow', []),
                    'raw_schedule': result.get('raw_schedule', []),
                    'raw_schedule_tomorrow': result.get('raw_schedule_tomorrow', []),
                    'next_blackout_hour': result.get('next_blackout_hour'),
                    'next_power_on_hour': result.get('next_power_on_hour'),
                    'available_groups': result.get('available_groups', yasno_api.AVAILABLE_GROUPS),
                    'last_update': result.get('last_update'),
                    # Emergency/schedule status
                    'emergency_mode': result.get('emergency_mode', False),
                    'schedules_active': result.get('schedules_active', True),
                    'emergency_message': result.get('emergency_message', ''),
                    'has_definite_outages': result.get('has_definite_outages', False),
                    'has_possible_outages': result.get('has_possible_outages', False),
                    # For notifications
                    'status_changed': result.get('status_changed', False),
                    'power_turned_on': result.get('power_turned_on', False),
                    'power_turned_off': result.get('power_turned_off', False),
                })
            else:
                log.warning(f"YASNO API returned no data for {city}")
    except ImportError:
        log.warning("YASNO API module not available")
    except Exception as e:
        log.error(f"YASNO API error: {e}")
    
    # Fallback to static data for other cities
    return get_schedule_fallback(city, street, building)


def get_schedule_fallback(city, street, building):
    """Fallback method using static data if API client is unavailable"""
    city_lower = city.lower()
    street_lower = street.lower() if street else ''
    
    # Try to find matching address in static database
    best_match = None
    best_match_data = None
    best_score = 0
    
    for address_key, data in BLACKOUT_ADDRESSES.items():
        key_parts = address_key.split()
        key_city = key_parts[0] if len(key_parts) > 0 else ''
        key_street = ' '.join(key_parts[1:]) if len(key_parts) > 1 else ''
        
        score = 0
        if city_lower in key_city or key_city in city_lower:
            score += 2
        if street_lower and (street_lower in key_street or key_street in street_lower):
            score += 2
        
        if score > best_score:
            best_score = score
            best_match = address_key
            best_match_data = data
    
    if not best_match_data or best_score < 2:
        return jsonify({'error': f'Адресу не знайдено для {city}. Спробуйте інше місто або вулицю.'}), 404
    
    # Reconstruct readable address
    parts = best_match.split()
    city_name = parts[0].capitalize()
    street_name = ' '.join(parts[1:]).capitalize() if len(parts) > 1 else ''
    readable_address = f'{city_name}'
    if street_name:
        readable_address += f', {street_name}'
    if building:
        readable_address += f', {building}'
    
    # Get schedule for the group
    group = best_match_data['group']
    schedule = BLACKOUT_SCHEDULES.get(group, [])
    
    return jsonify({
        'address': readable_address,
        'city': best_match_data['city'],
        'oblast': best_match_data['oblast'],
        'group': group,
        'provider': best_match_data['provider'],
        'schedule': schedule
    })


@app.route('/api/live_schedules')
def get_live_schedules():
    """Get schedules - returns static data"""
    try:
        return jsonify({
            'success': True,
            'schedules': BLACKOUT_SCHEDULES,
            'last_update': None,
            'source': 'static'
        })
    except Exception as e:
        log.error(f"Error in get_live_schedules: {e}")
        return jsonify({
            'error': 'Помилка отримання графіків'
        }), 500


@app.route('/api/schedule_status')
def get_schedule_status():
    """Get status of schedule data"""
    try:
        return jsonify({
            'available': True,
            'last_update': None,
            'cache_valid': True,
            'source': 'static',
            'message': 'Використовуються статичні дані'
        })
    except Exception as e:
        log.error(f"Error in get_schedule_status: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/api/force_update', methods=['POST'])
def force_schedule_update():
    """Force update - not available with static data"""
    return jsonify({
        'success': False,
        'message': 'Автооновлення недоступне, використовуються статичні дані'
    }), 503


# ==================== AI ROUTE MANAGEMENT API ====================

@app.route('/api/routes/predict', methods=['POST'])
def api_predict_route():
    """
    AI predicts most likely route based on source region.
    
    POST JSON: {source_region: "одеська", current_position: [lat, lng], message: "optional text"}
    Returns: {predicted_targets: [...], waypoints: [...], confidence: 0.85, reasoning: "..."}
    """
    try:
        data = request.get_json() or {}
        source_region = data.get('source_region', '')
        current_position = data.get('current_position')
        message_text = data.get('message', '')
        
        if not source_region:
            return jsonify({'error': 'source_region required'}), 400
        
        prediction = predict_route_with_ai(source_region, current_position, message_text)
        return jsonify(prediction)
        
    except Exception as e:
        print(f"ERROR in api_predict_route: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/api/routes/patterns', methods=['GET'])
def api_get_route_patterns():
    """Get all stored route patterns"""
    try:
        patterns = _load_route_patterns()
        return jsonify({
            'patterns': patterns.get('patterns', {}),
            'total_historical': len(patterns.get('historical_routes', [])),
            'ai_corrections_pending': len(patterns.get('ai_corrections', [])),
            'last_updated': patterns.get('last_updated')
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/routes/patterns', methods=['POST'])
def api_update_route_pattern():
    """
    Update or create a route pattern.
    
    POST JSON: {
        pattern_id: "south_to_kyiv",
        name: "Південь → Київ",
        source_regions: ["одеська", "миколаївська"],
        target_regions: ["київська"],
        waypoints: ["вінницька"],
        confidence: 0.85,
        avg_speed_kmh: 120
    }
    """
    try:
        data = request.get_json() or {}
        pattern_id = data.get('pattern_id')
        
        if not pattern_id:
            return jsonify({'error': 'pattern_id required'}), 400
        
        patterns = _load_route_patterns()
        
        if 'patterns' not in patterns:
            patterns['patterns'] = {}
        
        # Update or create pattern
        if pattern_id in patterns['patterns']:
            patterns['patterns'][pattern_id].update(data)
        else:
            patterns['patterns'][pattern_id] = data
        
        _save_route_patterns()
        
        return jsonify({'status': 'ok', 'pattern_id': pattern_id})
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/routes/correct', methods=['POST'])
def api_correct_route():
    """
    AI corrects a route prediction.
    Called when actual route differs from prediction.
    
    POST JSON: {
        route_id: "marker_123",
        actual_target: "харківська",
        actual_waypoints: ["полтавська"],
        notes: "Змінив курс на схід"
    }
    """
    try:
        data = request.get_json() or {}
        route_id = data.get('route_id')
        
        if not route_id:
            return jsonify({'error': 'route_id required'}), 400
        
        result = ai_correct_route(route_id, {
            'actual_target': data.get('actual_target'),
            'actual_waypoints': data.get('actual_waypoints', []),
            'notes': data.get('notes', '')
        })
        
        return jsonify(result)
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/routes/record', methods=['POST'])
def api_record_route():
    """
    Record an observed route for pattern learning.
    
    POST JSON: {
        source_region: "одеська",
        target_region: "київська",
        waypoints: ["вінницька", "черкаська"],
        threat_type: "shahed"
    }
    """
    try:
        data = request.get_json() or {}
        
        update_route_pattern_with_ai(data, data.get('target_region'))
        
        return jsonify({'status': 'ok', 'message': 'Route recorded'})
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/routes/ai-analyze', methods=['POST'])
def api_ai_analyze_routes():
    """
    Trigger AI analysis of historical routes to suggest pattern updates.
    """
    try:
        if not GROQ_ENABLED:
            return jsonify({'error': 'AI not enabled'}), 503
        
        patterns = _load_route_patterns()
        
        if len(patterns.get('historical_routes', [])) < 5:
            return jsonify({'error': 'Need at least 5 historical routes for analysis'}), 400
        
        _ai_analyze_patterns_for_update(patterns)
        _save_route_patterns()
        
        # Return latest AI suggestions
        suggestions = patterns.get('ai_corrections', [])
        latest = suggestions[-1] if suggestions else None
        
        return jsonify({
            'status': 'ok',
            'latest_analysis': latest
        })
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/routes/history', methods=['GET'])
def api_get_route_history():
    """Get recent historical routes"""
    try:
        patterns = _load_route_patterns()
        limit = request.args.get('limit', 20, type=int)
        
        history = patterns.get('historical_routes', [])[-limit:]
        
        return jsonify({
            'routes': history,
            'total': len(patterns.get('historical_routes', []))
        })
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/ai/threat-analysis', methods=['POST'])
def api_ai_threat_analysis():
    """
    Advanced AI threat analysis endpoint.
    
    Request body:
    {
        "active_threats": [...],  // List of current threats
        "region": "...",          // Optional: specific region to assess
        "message": "..."          // Optional: latest message text
    }
    
    Returns comprehensive threat analysis.
    """
    try:
        data = request.get_json() or {}
        active_threats = data.get('active_threats', [])
        region = data.get('region')
        message = data.get('message')
        
        result = {}
        
        # Analyze attack pattern
        patterns = _load_route_patterns()
        attack_analysis = analyze_attack_pattern(active_threats, patterns)
        result['attack_pattern'] = attack_analysis
        
        # Detect decoys
        if active_threats:
            threats_with_decoy = detect_decoy_threats(active_threats.copy())
            result['decoy_analysis'] = {
                'threats': threats_with_decoy,
                'high_decoy_count': sum(1 for t in threats_with_decoy if t.get('decoy_probability', 0) > 0.3)
            }
        
        # Prioritize threats
        if active_threats:
            prioritized = prioritize_threats(active_threats.copy())
            result['priority_ranking'] = [
                {
                    'name': t.get('name', t.get('target', 'Unknown')),
                    'type': t.get('type', t.get('threat_type')),
                    'priority_score': t.get('priority_score', 0)
                }
                for t in prioritized[:5]
            ]
        
        # Regional assessment
        if region:
            result['regional_assessment'] = get_regional_threat_assessment(region, active_threats)
        
        # Prediction accuracy stats
        result['prediction_stats'] = get_prediction_accuracy_stats()
        
        # Temporal context
        result['temporal_context'] = get_temporal_factors()
        
        return jsonify(result)
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/ai/predict-target', methods=['POST'])
def api_ai_predict_target():
    """
    AI-powered target prediction endpoint.
    
    Request body:
    {
        "source_region": "одеська",
        "source_coords": [46.4, 30.7],  // Optional
        "threat_type": "shahed",
        "message": "...",  // Optional: message text
        "top_n": 5  // Optional: number of predictions
    }
    """
    try:
        data = request.get_json() or {}
        source_region = data.get('source_region', '')
        source_coords = data.get('source_coords')
        threat_type = data.get('threat_type', 'shahed')
        message = data.get('message', '')
        top_n = data.get('top_n', 5)
        
        if source_coords:
            source_coords = tuple(source_coords)
        
        prediction = predict_multiple_targets_with_ai(
            source_region=source_region,
            source_coords=source_coords,
            threat_type=threat_type,
            message_text=message,
            top_n=top_n
        )
        
        # Add confidence intervals
        for target in prediction.get('targets', []):
            ci = calculate_confidence_interval(
                target['probability'],
                sample_size=20  # Based on historical data
            )
            target['confidence_interval'] = ci
        
        return jsonify(prediction)
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/ai/learn', methods=['POST'])
def api_ai_learn_outcome():
    """
    Record attack outcome for learning.
    
    Request body:
    {
        "attack_id": "...",
        "actual_targets": ["Київ", "Харків"],
        "predicted_targets": [...],
        "threat_type": "shahed",
        "source_region": "одеська",
        "timestamp": "2024-01-15T03:30:00"
    }
    """
    try:
        data = request.get_json() or {}
        
        attack_id = data.get('attack_id', f"attack_{int(time.time())}")
        actual_targets = data.get('actual_targets', [])
        predicted_targets = data.get('predicted_targets', [])
        threat_type = data.get('threat_type', 'unknown')
        source_region = data.get('source_region', '')
        timestamp = data.get('timestamp')
        
        if not actual_targets:
            return jsonify({'error': 'actual_targets required'}), 400
        
        result = learn_from_attack_outcome(
            attack_id=attack_id,
            actual_targets=actual_targets,
            predicted_targets=predicted_targets,
            threat_type=threat_type,
            source_region=source_region,
            timestamp=timestamp
        )
        
        return jsonify(result)
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/ai/accuracy', methods=['GET'])
def api_ai_accuracy_stats():
    """Get AI prediction accuracy statistics"""
    try:
        stats = get_prediction_accuracy_stats()
        return jsonify(stats)
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/geocode/smart', methods=['POST'])
def api_smart_geocode():
    """
    Smart geocoding endpoint with AI disambiguation.
    
    Request body:
    {
        "city": "Михайлівка",
        "region": "запорізька",  // optional
        "message": "БпЛА з Криму...",  // optional context
        "source_region": "чорне море"  // optional
    }
    """
    try:
        data = request.get_json() or {}
        city = data.get('city', '')
        region = data.get('region')
        message = data.get('message')
        source_region = data.get('source_region')
        
        if not city:
            return jsonify({'error': 'city required'}), 400
        
        coords = smart_geocode(city, region, message, source_region)
        
        if coords:
            return jsonify({
                'city': city,
                'coords': list(coords),
                'lat': coords[0],
                'lng': coords[1],
                'found': True
            })
        else:
            return jsonify({
                'city': city,
                'found': False,
                'suggestions': []
            })
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/geocode/batch', methods=['POST'])
def api_batch_geocode():
    """
    Batch geocoding endpoint.
    
    Request body:
    {
        "locations": [
            {"city": "Михайлівка", "region": "запорізька"},
            {"city": "Суми"}
        ],
        "message": "...",  // optional context
        "source_region": "..."  // optional
    }
    """
    try:
        data = request.get_json() or {}
        locations = data.get('locations', [])
        message = data.get('message')
        source_region = data.get('source_region')
        
        if not locations:
            return jsonify({'error': 'locations required'}), 400
        
        if len(locations) > 50:
            return jsonify({'error': 'max 50 locations per request'}), 400
        
        results = batch_geocode(locations, message, source_region)
        
        return jsonify({
            'results': results,
            'total': len(results),
            'resolved': sum(1 for r in results if r.get('resolved'))
        })
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/geocode/learn', methods=['POST'])
def api_geocode_learn():
    """
    Learn from geocoding correction.
    
    Request body:
    {
        "query": "михайлівка",
        "coords": [47.123, 35.456],
        "oblast": "Запорізька область"
    }
    """
    try:
        data = request.get_json() or {}
        query = data.get('query', '')
        coords = data.get('coords', [])
        oblast = data.get('oblast')
        
        if not query or len(coords) != 2:
            return jsonify({'error': 'query and coords [lat, lng] required'}), 400
        
        learn_geocode_correction(query, tuple(coords), oblast, source='api')
        
        return jsonify({'status': 'ok', 'learned': query})
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/geocode/stats', methods=['GET'])
def api_geocode_stats():
    """Get geocoding statistics"""
    try:
        stats = get_geocode_stats()
        
        # Add Nominatim stats if available
        if NOMINATIM_AVAILABLE:
            try:
                from nominatim_geocoder import get_cache_stats
                stats['nominatim'] = get_cache_stats()
            except:
                pass
        
        return jsonify(stats)
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/geocode/disambiguate', methods=['POST'])
def api_disambiguate_city():
    """
    Disambiguate city that exists in multiple oblasts.
    
    Request body:
    {
        "city": "Михайлівка",
        "message": "БпЛА з Криму курсом на...",  // context
        "source_region": "чорне море"
    }
    """
    try:
        data = request.get_json() or {}
        city = data.get('city', '')
        message = data.get('message')
        source_region = data.get('source_region')
        context_region = data.get('context_region')
        
        if not city:
            return jsonify({'error': 'city required'}), 400
        
        # Check if city is ambiguous
        city_lower = normalize_city_name(city)
        if city_lower not in AMBIGUOUS_CITIES:
            return jsonify({
                'city': city,
                'ambiguous': False,
                'resolved_oblast': None
            })
        
        possible_oblasts = AMBIGUOUS_CITIES[city_lower]
        resolved = disambiguate_city(city, context_region, source_region, message)
        
        return jsonify({
            'city': city,
            'ambiguous': True,
            'possible_oblasts': possible_oblasts,
            'resolved_oblast': resolved,
            'confidence': 0.8 if resolved else 0.3
        })
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/geocode/normalize', methods=['POST'])
def api_normalize_city():
    """
    Normalize city name (fix typos, aliases, case forms).
    
    Request body:
    {
        "city": "Суму",
        "cities": ["Суму", "Полтаву", "Харкова"]  // batch mode
    }
    """
    try:
        data = request.get_json() or {}
        city = data.get('city')
        cities = data.get('cities', [])
        
        if city:
            normalized = normalize_city_name(city)
            return jsonify({
                'original': city,
                'normalized': normalized,
                'changed': city.lower() != normalized
            })
        elif cities:
            results = []
            for c in cities[:100]:  # Limit to 100
                norm = normalize_city_name(c)
                results.append({
                    'original': c,
                    'normalized': norm,
                    'changed': c.lower() != norm
                })
            return jsonify({'results': results})
        else:
            return jsonify({'error': 'city or cities required'}), 400
    
    except Exception as e:
        return jsonify({'error': str(e)}), 500


# ==================== END AI GEOCODING API ====================


# ==================== END AI ROUTE MANAGEMENT API ====================


@app.route('/locate')
def locate_place():
    """Search for a city/settlement and return coordinates or suggestions"""
    query = request.args.get('q', '').strip()
    
    if not query:
        return jsonify({'status': 'error', 'message': 'No query provided'})
    
    # Clean query from region suffixes before searching
    query_clean = query
    for suffix in [' область', ' Область', 'область', 'Область', 'ська область', 'цька область']:
        if suffix in query_clean:
            query_clean = query_clean.split(suffix)[0].strip()
            break
    
    query_lower = query_clean.lower()
    
    # First, try exact match in CITY_COORDS
    if query_lower in CITY_COORDS:
        lat, lng = CITY_COORDS[query_lower]
        return jsonify({
            'status': 'ok',
            'name': query.title(),
            'lat': lat,
            'lng': lng,
            'source': 'city_coords'
        })
    
    # Try exact match in SETTLEMENTS_INDEX
    if query_lower in SETTLEMENTS_INDEX:
        lat, lng = SETTLEMENTS_INDEX[query_lower]
        return jsonify({
            'status': 'ok',
            'name': query.title(),
            'lat': lat,
            'lng': lng,
            'source': 'settlements'
        })
    
    # Try exact match in UKRAINE_ADDRESSES_DB (extract city names)
    if UKRAINE_ADDRESSES_DB:
        for key, value in UKRAINE_ADDRESSES_DB.items():
            city_name = value.get('city', '').lower()
            if city_name == query_lower:
                # Use CITY_COORDS or SETTLEMENTS_INDEX for this city
                if city_name in CITY_COORDS:
                    lat, lng = CITY_COORDS[city_name]
                    return jsonify({
                        'status': 'ok',
                        'name': value.get('city'),
                        'lat': lat,
                        'lng': lng,
                        'source': 'addresses_db'
                    })
    
    # Try normalized version with UA_CITY_NORMALIZE
    if query_lower in UA_CITY_NORMALIZE:
        normalized = UA_CITY_NORMALIZE[query_lower]
        if normalized in CITY_COORDS:
            lat, lng = CITY_COORDS[normalized]
            return jsonify({
                'status': 'ok',
                'name': normalized.title(),
                'lat': lat,
                'lng': lng,
                'source': 'normalized'
            })
        if normalized in SETTLEMENTS_INDEX:
            lat, lng = SETTLEMENTS_INDEX[normalized]
            return jsonify({
                'status': 'ok',
                'name': normalized.title(),
                'lat': lat,
                'lng': lng,
                'source': 'normalized'
            })
    
    # Try API sources for exact match (используем 3 API параллельно)
    api_results = []
    
    # 1. Nominatim API (добавляем Ukraine в строку запроса)
    try:
        import requests
        nominatim_url = 'https://nominatim.openstreetmap.org/search'
        params = {
            'q': f'{query}, Ukraine',
            'format': 'json',
            'limit': 1,
            'accept-language': 'uk'
        }
        headers = {
            'User-Agent': 'NeptunAlarmMap/1.0 (https://neptun-alarm.onrender.com)'
        }
        
        response = requests.get(nominatim_url, params=params, headers=headers, timeout=3)
        if response.ok:
            results = response.json()
            if isinstance(results, list) and len(results) > 0:
                result = results[0]
                if isinstance(result, dict):
                    lat_val = safe_float(result.get('lat'))
                    lng_val = safe_float(result.get('lon'))
                    if lat_val is not None and lng_val is not None and validate_ukraine_coords(lat_val, lng_val):
                        api_results.append({
                            'name': result.get('display_name', query).split(',')[0],
                            'lat': lat_val,
                            'lng': lng_val,
                            'source': 'nominatim'
                        })
    except Exception as e:
        log.warning(f'Nominatim exact match error: {e}')
    
    # 2. Photon API (самый быстрый и надёжный для украинских сел)
    try:
        photon_url = 'https://photon.komoot.io/api/'
        params = {
            'q': query,
            'limit': 1
        }
        
        response = requests.get(photon_url, params=params, timeout=3)
        if response.ok:
            data = response.json()
            features = data.get('features', [])
            if features and len(features) > 0:
                feature = features[0]
                props = feature.get('properties', {}) if isinstance(feature, dict) else {}
                coords = feature.get('geometry', {}).get('coordinates', []) if isinstance(feature, dict) else []
                if coords and len(coords) >= 2 and (props.get('country') == 'Україна' or props.get('country') == 'Ukraine'):
                    lng_val = safe_float(coords[0])
                    lat_val = safe_float(coords[1])
                    if lat_val is not None and lng_val is not None and validate_ukraine_coords(lat_val, lng_val):
                        api_results.append({
                            'name': props.get('name', query),
                            'lat': lat_val,
                            'lng': lng_val,
                            'source': 'photon'
                        })
    except Exception as e:
        log.warning(f'Photon exact match error: {e}')
    
    # 3. GeoNames API отключён (требует регистрацию, demo лимит исчерпан)
    # Photon + Nominatim дают полное покрытие всех украинских населённых пунктов
    
    # Если хотя бы один API вернул результат, используем его
    if api_results:
        # Приоритет: Photon (самый точный для украинских сел) > Nominatim
        for source_priority in ['photon', 'nominatim']:
            for result in api_results:
                if result['source'] == source_priority:
                    return jsonify({
                        'status': 'ok',
                        'name': result['name'],
                        'lat': result['lat'],
                        'lng': result['lng'],
                        'source': result['source']
                    })
    
    # If no exact match, return suggestions (prefix/substring match)
    suggestions = set()
    
    # Search in CITY_COORDS first (priority)
    for city_name in CITY_COORDS.keys():
        if query_lower in city_name:
            suggestions.add(city_name.title())
            if len(suggestions) >= 50:
                break
    
    # Then search in SETTLEMENTS_INDEX
    if len(suggestions) < 50:
        for settlement_name in SETTLEMENTS_INDEX.keys():
            city_title = settlement_name.title()
            if query_lower in settlement_name:
                suggestions.add(city_title)
                if len(suggestions) >= 100:
                    break
    
    # Also search in UKRAINE_ADDRESSES_DB cities
    if len(suggestions) < 100 and UKRAINE_ADDRESSES_DB:
        cities_from_db = set()
        for value in UKRAINE_ADDRESSES_DB.values():
            city_name = value.get('city', '').strip()
            if city_name and query_lower in city_name.lower():
                cities_from_db.add(city_name)
        suggestions.update(cities_from_db)
    
    # Add UKRAINE_CITIES if available
    if len(suggestions) < 100 and UKRAINE_CITIES:
        for city in UKRAINE_CITIES:
            if query_lower in city.lower():
                suggestions.add(city)
    
    # ВСЕГДА используем несколько API для максимальной полноты поиска
    api_suggestions = set()
    
    # 1. Photon API (быстрее чем Nominatim, использует OpenStreetMap данные)
    try:
        import requests
        photon_url = 'https://photon.komoot.io/api/'
        params = {
            'q': query,
            'limit': 20
        }
        
        response = requests.get(photon_url, params=params, timeout=3)
        if response.ok:
            data = response.json()
            for feature in data.get('features', []):
                props = feature.get('properties', {})
                name = props.get('name', '')
                country = props.get('country', '')
                if country == 'Україна' and name:
                    api_suggestions.add(name)
    except Exception as e:
        log.warning(f'Photon API error: {e}')
    
    # 2. Nominatim API (OpenStreetMap)
    try:
        import requests
        nominatim_url = 'https://nominatim.openstreetmap.org/search'
        params = {
            'q': f'{query}, Ukraine',
            'format': 'json',
            'limit': 30,
            'accept-language': 'uk',
            'addressdetails': 1
        }
        headers = {
            'User-Agent': 'NeptunAlarmMap/1.0 (https://neptun-alarm.onrender.com)'
        }
        
        response = requests.get(nominatim_url, params=params, headers=headers, timeout=4)
        if response.ok:
            results = response.json()
            for result in results:
                # Пробуем разные поля для названия
                name = None
                address = result.get('address', {})
                
                # Приоритет полям
                for field in ['village', 'town', 'city', 'hamlet', 'suburb', 'municipality']:
                    if field in address:
                        name = address[field]
                        break
                
                if not name:
                    display_name = result.get('display_name', '')
                    if display_name:
                        name = display_name.split(',')[0]
                
                if name:
                    api_suggestions.add(name)
    except Exception as e:
        log.warning(f'Nominatim API error: {e}')
    
    # 3. GeoNames API отключён (требует регистрацию, demo лимит 20к/день исчерпан)
    # Photon + Nominatim дают полное покрытие всех украинских населённых пунктов
    
    # Объединяем локальные и API результаты
    suggestions.update(api_suggestions)
    
    # Sort and limit
    suggestions_list = sorted(list(suggestions), key=lambda x: (len(x), x))[:50]
    
    if suggestions_list:
        return jsonify({
            'status': 'suggest',
            'matches': suggestions_list
        })
    
    # No matches found
    return jsonify({
        'status': 'not_found',
        'message': f'Не знайдено: {query}'
    })


def _prune_comments():
    # keep only last COMMENTS_MAX comments
    global COMMENTS
    if len(COMMENTS) > COMMENTS_MAX:
        COMMENTS = COMMENTS[-COMMENTS_MAX:]

@app.route('/comments', methods=['GET','POST'])
def comments_endpoint():
    """GET returns recent anonymous comments. POST inserts a new one persistently.

    Persistence strategy:
      - Store each comment into SQLite (comments table) with epoch for ordering.
      - Maintain small in-memory tail cache to avoid DB hit storms on rapid polling.
      - On GET always fetch from DB (limit) for durability across redeploys.
    """
    if request.method == 'POST':
        try:
            data = request.get_json(force=True, silent=True) or {}
        except Exception:
            data = {}
        text = (data.get('text') or '').strip()
        if not text:
            return jsonify({'ok': False, 'error': 'empty'}), 400
        reply_to = (data.get('reply_to') or '').strip() or None
        if reply_to and not re.fullmatch(r'[0-9a-fA-F]{6,20}', reply_to):
            reply_to = None  # sanitize unexpected format
        # rudimentary spam / flooding throttles (per-IP simple memory window)
        ip = request.headers.get('X-Forwarded-For', request.remote_addr) or 'unknown'
        now_ts = time.time()
        # simple rate tracker: store recent post times per IP in a module-level dict
        rt = getattr(app, '_comment_rate', None)
        if rt is None:
            rt = {}
            setattr(app, '_comment_rate', rt)
        arr = rt.get(ip, [])
        # drop entries older than 60s
        arr = [t for t in arr if now_ts - t < 60]
        if len(arr) >= 8:  # max 8 comments per minute per IP
            return jsonify({'ok': False, 'error': 'rate_limited'}), 429
        arr.append(now_ts)
        rt[ip] = arr
        # basic length clamp
        if len(text) > 800:
            text = text[:800]
        item = {
            'id': uuid.uuid4().hex[:10],
            'text': text,
            'ts': datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S'),
            'epoch': now_ts,
            'reply_to': reply_to
        }
        cache_item = {k: item[k] for k in ('id','text','ts')}
        if reply_to:
            cache_item['reply_to'] = reply_to
        COMMENTS.append(cache_item)  # store subset in memory cache
        _prune_comments()
        # persist
        save_comment_record(item)
        resp_item = {k: item[k] for k in ('id','text','ts')}
        if reply_to:
            resp_item['reply_to'] = reply_to
        return jsonify({'ok': True, 'item': resp_item})
    # GET
    limit = 80
    rows = load_recent_comments(limit=limit)
    if not rows and COMMENTS:  # fallback to cache if DB query unexpectedly empty
        rows = COMMENTS[-limit:]
    return jsonify({'ok': True, 'items': rows})

@app.route('/comments/react', methods=['POST'])
def comment_react_endpoint():
    """Toggle emoji reactions on comments."""
    try:
        data = request.get_json(force=True, silent=True) or {}
    except Exception:
        return jsonify({'ok': False, 'error': 'invalid_json'}), 400
    
    comment_id = (data.get('comment_id') or '').strip()
    emoji = (data.get('emoji') or '').strip()
    
    # Validation
    if not comment_id or not emoji:
        return jsonify({'ok': False, 'error': 'missing_params'}), 400
        
    # Validate emoji is in allowed list
    allowed_emojis = ['👍', '❤️', '🔥', '😢', '😡', '😂', '👎']
    if emoji not in allowed_emojis:
        return jsonify({'ok': False, 'error': 'invalid_emoji'}), 400
    
    # Get user IP for uniqueness
    ip = request.headers.get('X-Forwarded-For', request.remote_addr) or 'unknown'
    
    # Rate limiting: max 20 reactions per minute per IP
    now_ts = time.time()
    rt = getattr(app, '_reaction_rate', None)
    if rt is None:
        rt = {}
        setattr(app, '_reaction_rate', rt)
    
    arr = rt.get(ip, [])
    arr = [t for t in arr if now_ts - t < 60]  # Keep last 60 seconds
    if len(arr) >= 20:
        return jsonify({'ok': False, 'error': 'rate_limited'}), 429
    arr.append(now_ts)
    rt[ip] = arr
    
    # Toggle reaction
    result = toggle_comment_reaction(comment_id, emoji, ip)
    
    if result['action'] == 'error':
        return jsonify({'ok': False, 'error': 'server_error'}), 500
    
    return jsonify({
        'ok': True, 
        'action': result['action'],
        'reactions': result['reactions']
    })

@app.route('/active_alarms')
def active_alarms_endpoint():
    """Return current active oblast & raion air alarms (for polygon styling)."""
    
    # Rate limit отключен: все пользователи имеют свободный доступ
    
    try:
        now_ep = time.time()
        cutoff = now_ep - APP_ALARM_TTL_MINUTES*60
        for dct in (ACTIVE_OBLAST_ALARMS, ACTIVE_RAION_ALARMS):
            for k in list(dct.keys()):
                if dct[k]['last'] < cutoff:
                    dct.pop(k, None)
        obl_list = []
        for k,v in ACTIVE_OBLAST_ALARMS.items():
            base = k.lower()
            pcode = OBLAST_PCODE.get(base)
            obl_list.append({'name': k, 'since': v['since'], **({'pcode':pcode} if pcode else {})})
        return jsonify({
            'oblasts': obl_list,
            'raions': [{'name': k, 'since': v['since']} for k,v in ACTIVE_RAION_ALARMS.items()],
            'ttl_minutes': APP_ALARM_TTL_MINUTES
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/alarms_stats')
@protected_endpoint(is_heavy=False)  # PROTECTION: Rate limiting
def alarms_stats():
    """Return recent alarm events history (start/cancel/expire) with optional query params:
    ?level=oblast|raion  ?name=<substring>  ?minutes=<window>  ?limit=N
    """
    # ===========================================================================
    # HARDENED /alarms_stats ENDPOINT  
    # BEFORE: Could request up to 2000 items with 720 min window
    # AFTER:  Max 500 items, max 360 min (6h) window
    # ===========================================================================
    MAX_LIMIT = 500      # HARD LIMIT (was 2000)
    MAX_MINUTES = 360    # HARD LIMIT: 6 hours (was 720 = 12h)
    
    level_f = request.args.get('level')
    name_sub = (request.args.get('name') or '').lower().strip()
    minutes = min(MAX_MINUTES, max(1, int(request.args.get('minutes', '360'))))  # Cap at 6h
    limit = min(MAX_LIMIT, max(1, int(request.args.get('limit', '200'))))  # Cap at 500
    
    cutoff = time.time() - minutes*60
    rows = []
    try:
        with _visits_db_conn() as conn:
            q = "SELECT level,name,event,ts FROM alarm_events WHERE ts >= ?"
            params = [cutoff]
            if level_f in ('oblast','raion'):
                q += " AND level = ?"; params.append(level_f)
            if name_sub:
                q += " AND LOWER(name) LIKE ?"; params.append(f"%{name_sub}%")
            q += " ORDER BY ts DESC LIMIT ?"; params.append(limit)
            cur = conn.execute(q, tuple(params))
            for level,name,event,tsv in cur.fetchall():
                rows.append({'level': level, 'name': name, 'event': event, 'ts': tsv})
    except Exception as e:
        return jsonify({'error': str(e)}), 500
    return jsonify({'items': rows, 'count': len(rows), 'window_minutes': minutes})

@app.route('/data')
@protected_endpoint(is_heavy=True)  # PROTECTION: Rate limit + concurrency control
def data():
    global FALLBACK_REPARSE_CACHE, MAX_REPARSE_CACHE_SIZE
    
    # ===========================================================================
    # HARDENED /data ENDPOINT - Prevents 23GB+ traffic spikes
    # HIGH-LOAD OPTIMIZED: Added in-memory caching
    # ===========================================================================
    
    # HIGH-LOAD: Check memory cache first (5 second TTL)
    cache_key = f'data_{MONITOR_PERIOD_MINUTES}'
    cached = RESPONSE_CACHE.get(cache_key)
    if cached:
        # Still check ETag for 304
        client_etag = request.headers.get('If-None-Match')
        if client_etag and cached.get('etag') == client_etag:
            return Response(status=304, headers={'Cache-Control': 'public, max-age=5'})
        
        response = jsonify(cached['data'])
        response.headers['Cache-Control'] = 'public, max-age=5'
        response.headers['X-Cache'] = 'HIT'
        if cached.get('etag'):
            response.headers['ETag'] = cached['etag']
        return response
    
    # PROTECTION: Hard limits to prevent memory/bandwidth exhaustion
    MAX_TRACKS = 200       # HARD LIMIT: max tracks per response (was unlimited)
    MAX_EVENTS = 100       # HARD LIMIT: max events per response (was unlimited)
    MAX_RESPONSE_MB = 2    # HARD LIMIT: max response size in MB
    
    # BANDWIDTH OPTIMIZATION: Add aggressive caching headers  
    response_headers = {
        'Cache-Control': 'public, max-age=5',  # Reduced to match memory cache
        'ETag': f'data-{int(time.time() // 5)}',  # Cache for 5 seconds
        'Vary': 'Accept-Encoding'
    }
    
    # Check if client has cached version (saves bandwidth)
    client_etag = request.headers.get('If-None-Match')
    if client_etag == response_headers['ETag']:
        return Response(status=304, headers=response_headers)
    
    # Use global configured MONITOR_PERIOD_MINUTES from admin panel
    # URL parameter timeRange is ignored - only admin can control this
    time_range = MONITOR_PERIOD_MINUTES
    # Validate range (should be 1-360 as set by admin, but apply safety limits)
    time_range = max(1, min(time_range, 360))
    
    print(f"[DEBUG] /data endpoint called with timeRange={request.args.get('timeRange')}, MONITOR_PERIOD_MINUTES={MONITOR_PERIOD_MINUTES}, using time_range={time_range}")
    messages = load_messages()
    print(f"[DEBUG] Loaded {len(messages)} total messages")
    tz = pytz.timezone('Europe/Kyiv')
    now = datetime.now(tz).replace(tzinfo=None)
    
    # For AI TTL, we need to check each message individually
    # But first do a pre-filter to avoid checking very old messages
    max_possible_ttl = 240  # 4 hours - max possible TTL for any threat type
    min_time_prefilter = now - timedelta(minutes=max_possible_ttl)
    
    # Fallback to fixed time if AI TTL is disabled
    min_time = now - timedelta(minutes=time_range)
    manual_cutoff = now - timedelta(minutes=max(time_range, MANUAL_MARKER_WINDOW_MINUTES))
    
    print(f"[DEBUG] Filtering messages since {min_time} (last {time_range} minutes), AI_TTL_ENABLED={AI_TTL_ENABLED}")
    hidden = set(load_hidden())
    out = []  # geo tracks
    events = []  # list-only (alarms, cancellations, other non-geo informational)
    ai_ttl_stats = {'shown': 0, 'hidden': 0, 'reasons': {}}
    
    for m in messages:
        try:
            dt = datetime.strptime(m.get('date',''), '%Y-%m-%d %H:%M:%S')
        except Exception:
            continue
        
        manual_marker = bool(m.get('manual'))
        
        # === AI TTL LOGIC ===
        # Check if message should be visible using AI-calculated TTL
        if AI_TTL_ENABLED and not manual_marker:
            # Pre-filter: skip messages older than max possible TTL
            if dt < min_time_prefilter:
                continue
            
            # Calculate individual marker TTL
            visibility = should_marker_be_visible(m, now)
            
            if not visibility['visible']:
                ai_ttl_stats['hidden'] += 1
                reason = visibility.get('ttl_info', {}).get('reason', 'unknown')
                ai_ttl_stats['reasons'][reason] = ai_ttl_stats['reasons'].get(reason, 0) + 1
                continue
            
            # Add TTL info to marker for frontend display
            if visibility.get('ttl_info'):
                m['ai_ttl'] = {
                    'remaining_minutes': visibility.get('remaining_minutes', 0),
                    'reason': visibility['ttl_info'].get('reason', ''),
                    'status': visibility['ttl_info'].get('status', 'active'),
                    'threat_type_detected': visibility['ttl_info'].get('threat_type_detected', '')
                }
            ai_ttl_stats['shown'] += 1
            # Continue to marker processing below
        
        # === FALLBACK LOGIC ===
        # If AI TTL is disabled, use fixed time
        elif not AI_TTL_ENABLED:
            if not (dt >= min_time or (manual_marker and dt >= manual_cutoff)):
                continue
        else:
            # AI TTL was enabled but marker was already processed above, continue
            continue
        
        # === MARKER PROCESSING (shared for both AI TTL and fallback) ===
        # Fallback reparse: if message lacks geo but contains course pattern, try to derive markers now
        txt_low = (m.get('text') or '').lower()
        msg_id = m.get('id')
            
        # Skip multi-regional UAV messages - they're already handled by immediate processing
        text_full = m.get('text') or ''
        text_lines = text_full.split('\n')
        region_count = sum(1 for line in text_lines if any(region in line.lower() for region in ['щина:', 'щина]', 'область:', 'край:']) or (
            'щина' in line.lower() and line.lower().strip().endswith(':')
        ))
        uav_count = sum(1 for line in text_lines if 'бпла' in line.lower() and ('курс' in line.lower() or 'на ' in line.lower()))
        
        # Process ALL messages without coordinates through process_message()
        if (not m.get('lat')) and (not m.get('lng')):
            # Skip if this is a multi-regional UAV message (already processed immediately)
            if region_count >= 2 and uav_count >= 3:
                add_debug_log(f"Skipping fallback reparse for multi-regional UAV message ID {msg_id}", "reparse")
                continue
                
            # Check if we've already reparsed this message to avoid duplicate processing
            if msg_id in FALLBACK_REPARSE_CACHE:
                add_debug_log(f"Skipping fallback reparse for message ID {msg_id} - already processed", "reparse")
                continue
            
            try:
                # Add to cache to prevent future reprocessing
                FALLBACK_REPARSE_CACHE.add(msg_id)
                # Limit cache size to prevent memory growth
                if len(FALLBACK_REPARSE_CACHE) > MAX_REPARSE_CACHE_SIZE:
                    # Remove oldest half of the cache (approximate LRU)
                    cache_list = list(FALLBACK_REPARSE_CACHE)
                    FALLBACK_REPARSE_CACHE = set(cache_list[len(cache_list)//2:])
                
                add_debug_log(f"Fallback reparse for message ID {msg_id} - first time processing", "reparse")
                reparsed = process_message(m.get('text') or '', m.get('id'), m.get('date'), m.get('channel') or m.get('source') or '')
                if isinstance(reparsed, list) and reparsed:
                    reparsed_any = False
                    for t in reparsed:
                        if t.get('list_only'):
                            if not t.get('suppress'):
                                events.append(t)
                                reparsed_any = True
                            continue
                        try:
                            lat_r = round(float(t.get('lat')), 3)
                            lng_r = round(float(t.get('lng')), 3)
                        except Exception:
                            continue
                        text_r = (t.get('text') or '')
                        source_r = t.get('channel') or t.get('source') or ''
                        marker_key_r = f"{lat_r},{lng_r}|{text_r}|{source_r}"
                        if marker_key_r in hidden:
                            continue
                        out.append(t)
                        reparsed_any = True
                    # Skip adding original as event if we produced tracks or list-only entries
                    if reparsed_any:
                        continue
            except Exception:
                pass
        # list-only (no coordinates) -> push into events list if not suppressed
        if m.get('list_only'):
            if not m.get('suppress'):
                events.append(m)
            continue  # skip trying to interpret as marker
        # build marker key similar to frontend hide logic (rounded lat/lng + text + source/channel)
        try:
            lat = round(float(m.get('lat')), 3)
            lng = round(float(m.get('lng')), 3)
        except Exception:
            continue  # not a proper geo marker
        text = (m.get('text') or '')
        source = m.get('source') or m.get('channel') or ''
        marker_key = f"{lat},{lng}|{text}|{source}"
        if marker_key in hidden:
            continue
        # Backward compatibility: allow prefix match (text truncated when stored) for same lat,lng,source
        base_prefix = f"{lat},{lng}|"
        if not any(h.startswith(base_prefix) for h in hidden if '|' in h):
            pass
        else:
            # iterate candidates with same coords and source, compare text prefix
            skip = False
            for h in hidden:
                if not h.startswith(base_prefix):
                    continue
                try:
                    _, htext, hsource = h.split('|',2)
                except ValueError:
                    continue
                if hsource == source and text.startswith(htext):
                    skip = True
                    break
            if skip:
                continue
        # Фильтр: удаляем региональные метки без явных слов угроз (могли сохраниться старыми версиями логики)
        low_txt = text.lower()
        if m.get('source_match','').startswith('region') and not any(k in low_txt for k in ['бпла','дрон','шахед','shahed','geran','ракета','ракети','missile','iskander','s-300','s300','каб','артил','града','смерч','ураган','mlrs','avia','авіа','авиа','бомба']):
            continue
        out.append(m)

    
    # Log AI TTL statistics
    if AI_TTL_ENABLED and (ai_ttl_stats['shown'] > 0 or ai_ttl_stats['hidden'] > 0):
        print(f"[AI TTL] Shown: {ai_ttl_stats['shown']}, Hidden by TTL: {ai_ttl_stats['hidden']}")
        if ai_ttl_stats['reasons']:
            for reason, count in list(ai_ttl_stats['reasons'].items())[:3]:
                print(f"[AI TTL]   - {reason}: {count}")
    
    # === THREAT TRACKER: Update from alarms and get active threats ===
    try:
        # Check alarm state and update threats
        if _alarm_all_cache.get('data'):
            check_alarms_and_update_threats()
        
        # Cleanup old threats
        THREAT_TRACKER.cleanup_old_threats(max_age_hours=4)
        
        # Get active tracked threats
        active_threats = THREAT_TRACKER.get_all_active_threats()
        threat_info = {
            'count': len(active_threats),
            'by_type': {},
            'by_region': {}
        }
        for t in active_threats:
            tt = t.get('threat_type', 'unknown')
            threat_info['by_type'][tt] = threat_info['by_type'].get(tt, 0) + t.get('quantity_remaining', 1)
            for r in t.get('regions', []):
                threat_info['by_region'][r] = threat_info['by_region'].get(r, 0) + 1
    except Exception as e:
        print(f"[THREAT TRACKER] Error in /data: {e}")
        threat_info = None
    
    # Sort events by time desc (latest first) like markers implicitly (messages stored chronological)
    try:
        events.sort(key=lambda x: x.get('date',''), reverse=True)
    except Exception:
        pass
    
    # ===========================================================================
    # PROTECTION: Apply hard limits to prevent bandwidth/memory exhaustion
    # ===========================================================================
    total_tracks = len(out)
    total_events = len(events)
    
    # HARD LIMIT: Truncate tracks (newest first - reverse since messages are chronological)
    if len(out) > MAX_TRACKS:
        out = out[-MAX_TRACKS:]  # Keep newest tracks
        print(f"[BANDWIDTH PROTECTION] Truncated tracks: {total_tracks} -> {MAX_TRACKS}")
    
    # HARD LIMIT: Truncate events
    if len(events) > MAX_EVENTS:
        events = events[:MAX_EVENTS]  # Already sorted newest first
        print(f"[BANDWIDTH PROTECTION] Truncated events: {total_events} -> {MAX_EVENTS}")
    
    print(f"[DEBUG] Returning {len(out)} tracks and {len(events)} events (limits: {MAX_TRACKS}/{MAX_EVENTS})")
    
    # Replace old shahed.png with new icon_drone.svg for backward compatibility
    for track in out:
        if track.get('marker_icon') == 'shahed.png':
            track['marker_icon'] = 'icon_drone.svg'
    
    # DEBUG: Count tracks with trajectories
    traj_count = sum(1 for t in out if t.get('trajectory'))
    if traj_count > 0:
        print(f"[DEBUG] /data response has {traj_count} tracks with trajectories")
    
    # Build response with metadata about truncation
    response_data = {
        'tracks': out,
        'events': events,
        'all_sources': CHANNELS,
        'trajectories': [],
        # Ballistic threat state from Telegram
        'ballistic_threat': {
            'active': BALLISTIC_THREAT_ACTIVE,
            'region': BALLISTIC_THREAT_REGION,
            'timestamp': BALLISTIC_THREAT_TIMESTAMP,
        },
        # Smart threat tracking info
        'threat_tracking': threat_info,
        # AI TTL stats
        'ai_ttl': {
            'enabled': AI_TTL_ENABLED,
            'stats': ai_ttl_stats if AI_TTL_ENABLED else None
        },
        # Metadata for clients to know if data was truncated
        '_meta': {
            'tracks_total': total_tracks,
            'tracks_returned': len(out),
            'tracks_truncated': total_tracks > MAX_TRACKS,
            'events_total': total_events,
            'events_returned': len(events),
            'events_truncated': total_events > MAX_EVENTS,
            'time_range_minutes': time_range,
        }
    }
    
    # PROTECTION: Final response size check
    response_json = json.dumps(response_data, separators=(',', ':'))
    response_size = len(response_json.encode('utf-8'))
    
    if response_size > MAX_RESPONSE_MB * 1024 * 1024:
        # Emergency truncation - should rarely happen with above limits
        print(f"[BANDWIDTH EMERGENCY] Response too large: {response_size / 1024 / 1024:.2f}MB > {MAX_RESPONSE_MB}MB")
        response_data['tracks'] = out[:50]
        response_data['events'] = events[:25]
        response_data['_meta']['emergency_truncated'] = True
        response_json = json.dumps(response_data, separators=(',', ':'))
    
    # HIGH-LOAD: Cache the response for 5 seconds
    RESPONSE_CACHE.set(cache_key, {
        'data': response_data,
        'etag': response_headers.get('ETag')
    }, ttl=5)
    
    resp = Response(response_json, mimetype='application/json')
    # Add aggressive caching headers to reduce bandwidth
    resp.headers.update(response_headers)
    resp.headers['X-Cache'] = 'MISS'
    return resp

@app.route('/channels')
def list_channels():
    return jsonify({'channels': CHANNELS, 'invalid': list(INVALID_CHANNELS)})

@app.route('/debug_parse', methods=['POST'])
def debug_parse():
    """Ad-hoc debugging endpoint to inspect parser output for a stored message or raw text.

    POST JSON:
      {"id": <message_id>}  -> reparse stored message text
      or
      {"text": "raw message text", "channel": "optional", "date": "YYYY-MM-DD HH:MM:SS"}

    Response: { ok: bool, source: 'stored'|'raw', message: {...original message fields subset...}, tracks: [...], count: N }
    """
    try:
        payload = request.get_json(force=True, silent=True) or {}
    except Exception:
        try:
            payload = request.get_json(silent=True) or {}
        except Exception:
            payload = {}
    mid = payload.get('id')
    raw_text = payload.get('text')
    # Allow base64-encoded text to avoid client console encoding corruption
    if not raw_text:
        b64_txt = payload.get('b64') or payload.get('b64_text') or None
        if b64_txt:
            try:
                import base64
                raw_text = base64.b64decode(b64_txt).decode('utf-8', errors='replace')
            except Exception:
                raw_text = ''
    channel = payload.get('channel') or ''
    date_str = payload.get('date') or datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')
    src = 'raw'
    if mid and not raw_text:
        # look up stored messages
        try:
            for m in load_messages():
                if str(m.get('id')) == str(mid):
                    raw_text = m.get('text') or ''
                    channel = m.get('channel') or m.get('source') or channel
                    date_str = m.get('date') or date_str
                    src = 'stored'
                    break
        except Exception:
            pass
    if not raw_text:
        return jsonify({'ok': False, 'error': 'no_text_provided'}), 400
    try:
        tracks = process_message(raw_text, str(mid) if mid else 'debug', date_str, channel)
    except Exception as e:
        return jsonify({'ok': False, 'error': f'parse_error: {e}'}), 500
    return jsonify({
        'ok': True,
        'source': src,
        'message': {
            'id': mid,
            'channel': channel,
            'date': date_str,
            'text': raw_text[:2000]
        },
        'count': len(tracks) if isinstance(tracks, list) else 0,
        'tracks': tracks if isinstance(tracks, list) else []
    })

@app.route('/api/visitor_count')
def visitor_count():
    """API endpoint to get total visitor count from database."""
    try:
        import sqlite3
        conn = sqlite3.connect('visits.db')
        cursor = conn.cursor()
        
        # Get total unique visitors
        cursor.execute('SELECT COUNT(DISTINCT ip) FROM visits')
        total_visitors = cursor.fetchone()[0]
        
        conn.close()
        
        return str(total_visitors), 200, {
            'Content-Type': 'text/plain',
            'Cache-Control': 'public, max-age=10',
            'Access-Control-Allow-Origin': '*'
        }
    except Exception as e:
        print(f"[ERROR] Failed to get visitor count: {e}")
        return "0", 200, {'Content-Type': 'text/plain'}

@app.route('/api/android_visitor_count')
def android_visitor_count():
    """API endpoint to get Android app visitor count."""
    try:
        import sqlite3
        conn = sqlite3.connect('visits.db')
        cursor = conn.cursor()
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS app_visits (
                device_id TEXT PRIMARY KEY,
                platform TEXT,
                ip TEXT,
                last_seen DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        cursor.execute('SELECT COUNT(*) FROM app_visits WHERE platform = ?', ('android',))
        android_visitors = cursor.fetchone()[0] or 0
        
        conn.close()
        
        return str(android_visitors), 200, {
            'Content-Type': 'text/plain',
            'Cache-Control': 'public, max-age=10',
            'Access-Control-Allow-Origin': '*'
        }
    except Exception as e:
        print(f"[ERROR] Failed to get Android visitor count: {e}")
        return "0", 200, {'Content-Type': 'text/plain'}

@app.route('/api/track_android_visit', methods=['POST'])
def track_android_visit():
    """Track Android app visitor."""
    try:
        import sqlite3
        payload = request.get_json(silent=True) or {}
        client_ip = request.environ.get('HTTP_X_FORWARDED_FOR', request.remote_addr)
        device_id = str(payload.get('device_id') or '').strip() or client_ip
        platform_hint = payload.get('platform') or 'android'
        ua = request.headers.get('User-Agent', '')
        platform_label = _normalize_platform(platform_hint, ua)
        
        conn = sqlite3.connect('visits.db')
        cursor = conn.cursor()
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS app_visits (
                device_id TEXT PRIMARY KEY,
                platform TEXT,
                ip TEXT,
                last_seen DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        cursor.execute('''
            INSERT INTO app_visits (device_id, platform, ip, last_seen)
            VALUES (?, ?, ?, CURRENT_TIMESTAMP)
            ON CONFLICT(device_id) DO UPDATE SET
                platform=excluded.platform,
                ip=excluded.ip,
                last_seen=CURRENT_TIMESTAMP
        ''', (device_id, platform_label, client_ip))
        
        conn.commit()
        conn.close()
        
        return jsonify({'ok': True, 'platform': platform_label}), 200
    except Exception as e:
        print(f"[ERROR] Failed to track Android visit: {e}")
        return jsonify({'ok': False}), 500

@app.route('/api/events')
@protected_endpoint(is_heavy=False)  # PROTECTION: Rate limiting
def get_events():
    """Get recent air alarm events from Telegram."""
    # ===========================================================================
    # HARDENED /api/events ENDPOINT
    # BEFORE: Processed ALL messages without limit
    # AFTER:  Process last 500 messages max, return 100 events max
    # ===========================================================================
    MAX_PROCESS_MESSAGES = 500  # HARD LIMIT: max messages to scan
    MAX_RETURN_EVENTS = 100     # HARD LIMIT: max events to return
    
    try:
        messages = load_messages()
        events = []
        
        # PROTECTION: Only process last 500 messages (was: ALL messages)
        for msg in messages[-MAX_PROCESS_MESSAGES:]:
            if not isinstance(msg, dict):
                continue
                
            text = msg.get('text', '').strip()
            channel = msg.get('channel', '')
            timestamp = msg.get('time', '')
            
            # Detect alarm type by emoji or text
            emoji = None
            status = None
            
            if '🚨' in text or 'Повітряна тривога' in text:
                emoji = '🚨'
                status = 'Повітряна тривога'
            elif '🟢' in text or 'Відбій тривоги' in text or 'відбій тривоги' in text:
                emoji = '🟢'
                status = 'Відбій тривоги'
            else:
                continue
            
            # Extract region from multiple formats:
            # Format 1: "**🚨 Дніпропетровська область**"
            # Format 2: "**🚨 Харківський район (Харківська обл.)**"
            region = ''
            
            if '**' in text:
                parts = text.split('**')
                for part in parts:
                    part = part.strip()
                    # Look for parts containing emoji
                    if '🚨' in part or '🟢' in part:
                        # Remove emoji and clean up
                        region = part.replace('🚨', '').replace('🟢', '').strip()
                        break
            
            # Fallback: extract from first line
            if not region and text:
                first_line = text.split('\n')[0].strip()
                # Remove markdown and emojis
                region = first_line.replace('**', '').replace('🚨', '').replace('🟢', '').strip()
                # Remove common phrases
                region = region.replace('Повітряна тривога.', '').replace('Прямуйте в укриття!', '').strip()
                region = region.replace('Відбій тривоги.', '').replace('Будьте обережні!', '').strip()
            
            # Skip if no region found
            if not region:
                continue
            
            events.append({
                'timestamp': timestamp,
                'channel': channel,
                'emoji': emoji,
                'region': region,
                'status': status,
                'text': text[:200]  # First 200 chars
            })
        
        # Sort by timestamp (newest first) and return last 100 events
        # This ensures stable results regardless of message order in file
        events.reverse()
        
        # PROTECTION: Hard limit on returned events
        returned_events = events[:MAX_RETURN_EVENTS]
        
        response = jsonify(returned_events)
        response.headers['Cache-Control'] = 'public, max-age=30'
        response.headers['Access-Control-Allow-Origin'] = '*'
        return response
        
    except Exception as e:
        print(f"[ERROR] /api/events failed: {e}")
        return jsonify([]), 500

@app.route('/api/messages')
@protected_endpoint(is_heavy=False)  # PROTECTION: Rate limiting
def get_messages():
    """Get recent alarm messages with coordinates for mobile apps."""
    # ===========================================================================
    # HARDENED /api/messages ENDPOINT - HIGH LOAD OPTIMIZED
    # Uses response cache to avoid reprocessing on every request
    # ===========================================================================
    
    # Check cache first (30 second TTL)
    cache_key = 'api_messages'
    cached = RESPONSE_CACHE.get(cache_key)
    if cached:
        response = jsonify(cached)
        response.headers['Cache-Control'] = 'public, max-age=30'
        response.headers['X-Cache'] = 'HIT'
        return response
    
    MAX_MESSAGES = 100  # HARD LIMIT: max messages per request (was 200)
    
    try:
        messages = load_messages()
        result_messages = []
        
        # PROTECTION: Reduced from 200 to 100 messages max
        for msg in messages[-MAX_MESSAGES:]:
            if not isinstance(msg, dict):
                continue
            
            text = msg.get('text', '').strip()
            
            # Detect alarm type
            alarm_type = 'Тривога'
            if 'БпЛА' in text or 'дрон' in text:
                alarm_type = 'БпЛА/Дрони'
            elif 'ракет' in text or 'балістич' in text:
                alarm_type = 'Ракетна загроза'
            elif 'Повітряна тривога' in text:
                alarm_type = 'Повітряна тривога'
            
            # Try to extract location and coordinates
            location = ''
            latitude = 48.3794  # Default: center of Ukraine
            longitude = 31.1656
            
            # Extract region/city from text
            if '**' in text:
                parts = text.split('**')
                for part in parts:
                    part = part.strip()
                    if '🚨' in part or '🟢' in part or 'область' in part.lower():
                        location = part.replace('🚨', '').replace('🟢', '').strip()
                        break
            
            # If no location found, try first line
            if not location and text:
                first_line = text.split('\n')[0].strip()
                location = first_line.replace('**', '').replace('🚨', '').replace('🟢', '').strip()[:100]
            
            # Try to get coordinates from UKRAINE_ADDRESSES_DB
            if location:
                location_lower = location.lower()
                for city_name, coords in UKRAINE_ADDRESSES_DB.items():
                    if city_name.lower() in location_lower or location_lower in city_name.lower():
                        latitude = coords['lat']
                        longitude = coords['lon']
                        if not location:
                            location = city_name
                        break
            
            # Get timestamp in Kyiv time
            import pytz
            kyiv_tz = pytz.timezone('Europe/Kiev')
            msg_time = msg.get('time', '') or msg.get('timestamp', '') or msg.get('date', '')
            
            # If no timestamp from message, use current time
            if not msg_time:
                msg_time = datetime.now(kyiv_tz).strftime('%d.%m.%Y %H:%M')
            else:
                # Try to parse and convert to Kyiv time if needed
                try:
                    # If it's a string, keep it as is (assuming it's already formatted)
                    if not isinstance(msg_time, str):
                        dt = datetime.fromtimestamp(msg_time, tz=pytz.UTC)
                        msg_time = dt.astimezone(kyiv_tz).strftime('%d.%m.%Y %H:%M')
                except:
                    # Fallback to original or current time
                    if isinstance(msg_time, str):
                        pass  # Keep original string
                    else:
                        msg_time = datetime.now(kyiv_tz).strftime('%d.%m.%Y %H:%M')
            
            result_messages.append({
                'type': alarm_type,
                'location': location or 'Україна',
                'timestamp': msg_time,
                'text': text[:300],  # First 300 chars
                'latitude': latitude,
                'longitude': longitude,
                'channel': msg.get('channel', ''),
            })
        
        # Sort by timestamp (newest first)
        result_messages.sort(key=lambda x: x.get('timestamp', ''), reverse=True)
        
        # Cache the result
        result_data = {
            'messages': result_messages,
            'count': len(result_messages),
            'timestamp': datetime.now().isoformat()
        }
        RESPONSE_CACHE.set(cache_key, result_data, ttl=30)
        
        response = jsonify(result_data)
        response.headers['Cache-Control'] = 'public, max-age=30'
        response.headers['Access-Control-Allow-Origin'] = '*'
        response.headers['X-Cache'] = 'MISS'
        return response
        
    except Exception as e:
        print(f"[ERROR] /api/messages failed: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({'messages': [], 'count': 0, 'error': str(e)}), 500

# ==================== ALARM STATUS API (для AlarmTimerWidget) ====================
_active_alarms_cache = {}  # region -> {active: bool, start_time: str, type: str}

@app.route('/api/alarm-status')
@protected_endpoint(is_heavy=False)  # PROTECTION: Rate limiting
def get_alarm_status():
    """Get current alarm status for regions - used by AlarmTimerWidget."""
    
    # HIGH-LOAD: Check cache first (15 second TTL)
    cache_key = 'api_alarm_status'
    cached = RESPONSE_CACHE.get(cache_key)
    if cached:
        response = jsonify(cached)
        response.headers['Cache-Control'] = 'public, max-age=15'
        response.headers['X-Cache'] = 'HIT'
        return response
    
    MAX_MESSAGES_TO_SCAN = 100  # HARD LIMIT
    
    try:
        messages = load_messages()
        alerts = {}
        
        # Process last 100 messages to find active alarms
        for msg in messages[-MAX_MESSAGES_TO_SCAN:]:
            if not isinstance(msg, dict):
                continue
            
            text = msg.get('text', '').lower()
            location = ''
            
            # Extract region from location field or text
            if '**' in msg.get('text', ''):
                parts = msg.get('text', '').split('**')
                for part in parts:
                    part = part.strip()
                    if 'область' in part.lower() or 'обл' in part.lower():
                        location = part.replace('🚨', '').replace('🟢', '').strip()
                        break
            
            if not location:
                location = msg.get('location', msg.get('text', '')[:50])
            
            # Get timestamp
            timestamp = msg.get('time', '') or msg.get('timestamp', '') or datetime.now().isoformat()
            
            # Determine if this is alarm start or end
            is_all_clear = 'відбій' in text
            is_alarm = 'тривога' in text or 'бпла' in text or 'дрон' in text or 'ракет' in text
            
            # Determine alarm type
            alarm_type = 'Повітряна тривога'
            if 'бпла' in text or 'дрон' in text:
                alarm_type = 'БпЛА/Дрони'
            elif 'ракет' in text or 'балістичн' in text:
                alarm_type = 'Ракетна загроза'
            
            if location:
                # Clean up location name
                region_key = location.replace('🚨', '').replace('🟢', '').strip()[:50]
                
                if is_all_clear:
                    alerts[region_key] = {
                        'active': False,
                        'start_time': None,
                        'type': None,
                        'end_time': timestamp
                    }
                elif is_alarm:
                    # Only set if not already active or if this is newer
                    if region_key not in alerts or not alerts[region_key].get('active'):
                        alerts[region_key] = {
                            'active': True,
                            'start_time': timestamp,
                            'type': alarm_type,
                            'end_time': None
                        }
        
        result_data = {
            'alerts': alerts,
            'timestamp': datetime.now().isoformat(),
            'count': sum(1 for a in alerts.values() if a.get('active'))
        }
        RESPONSE_CACHE.set(cache_key, result_data, ttl=15)
        
        response = jsonify(result_data)
        response.headers['Cache-Control'] = 'public, max-age=15'
        response.headers['Access-Control-Allow-Origin'] = '*'
        response.headers['X-Cache'] = 'MISS'
        return response
        
    except Exception as e:
        print(f"[ERROR] /api/alarm-status failed: {e}")
        return jsonify({'alerts': {}, 'error': str(e)}), 500

# ==================== ALARM HISTORY API (для AlarmHistoryPage) ====================
@app.route('/api/alarm-history')
@protected_endpoint(is_heavy=True)  # PROTECTION: This can be heavy with large date ranges
def get_alarm_history():
    """Get alarm history for statistics - used by AlarmHistoryPage."""
    # ===========================================================================
    # HARDENED /api/alarm-history ENDPOINT
    # BEFORE: Could scan unlimited messages with days=365
    # AFTER:  Max 7 days lookback, max 200 results
    # ===========================================================================
    MAX_DAYS = 7       # HARD LIMIT: max days to look back (was unlimited)
    MAX_RESULTS = 200  # HARD LIMIT: max results to return (was 500)
    
    try:
        region = request.args.get('region', '')
        days = min(MAX_DAYS, max(1, int(request.args.get('days', 7))))  # PROTECTION: Cap at 7 days
        
        messages = load_messages()
        history = []
        
        # Calculate date cutoff
        cutoff_date = datetime.now() - timedelta(days=days)
        
        for msg in messages:
            if not isinstance(msg, dict):
                continue
            
            text = msg.get('text', '').lower()
            
            # Skip if not alarm-related
            if not any(kw in text for kw in ['тривога', 'відбій', 'бпла', 'дрон', 'ракет']):
                continue
            
            # Get timestamp
            timestamp_str = msg.get('time', '') or msg.get('timestamp', '')
            try:
                # Try to parse timestamp
                if timestamp_str:
                    # Handle various formats
                    for fmt in ['%Y-%m-%d %H:%M:%S', '%d.%m.%Y %H:%M', '%Y-%m-%dT%H:%M:%S']:
                        try:
                            timestamp = datetime.strptime(timestamp_str[:19], fmt)
                            break
                        except:
                            continue
                    else:
                        timestamp = datetime.now()
                else:
                    timestamp = datetime.now()
                
                # Skip if too old
                if timestamp < cutoff_date:
                    continue
                    
            except:
                continue
            
            # Extract location
            location = msg.get('location', '')
            if not location and '**' in msg.get('text', ''):
                parts = msg.get('text', '').split('**')
                for part in parts:
                    if 'область' in part.lower():
                        location = part.strip()
                        break
            
            # Filter by region if specified
            if region and region.lower() not in location.lower():
                continue
            
            # Determine alarm type
            is_start = 'тривога' in text and 'відбій' not in text
            alarm_type = 'air_raid'
            if 'бпла' in text or 'дрон' in text:
                alarm_type = 'drone'
            elif 'ракет' in text:
                alarm_type = 'missile'
            
            history.append({
                'start_time': timestamp.isoformat(),
                'end_time': None,  # Would need to match with відбій
                'type': alarm_type,
                'region': location[:50],
                'is_start': is_start,
                'duration_minutes': 30  # Estimate
            })
        
        # Sort by time
        history.sort(key=lambda x: x['start_time'], reverse=True)
        
        # PROTECTION: Hard limit on results
        returned_history = history[:MAX_RESULTS]
        
        response = jsonify({
            'history': returned_history,
            'count': len(returned_history),
            'total_count': len(history),
            'truncated': len(history) > MAX_RESULTS,
            'region': region,
            'days': days,
            'timestamp': datetime.now().isoformat()
        })
        response.headers['Cache-Control'] = 'public, max-age=60'
        response.headers['Access-Control-Allow-Origin'] = '*'
        return response
        
    except Exception as e:
        print(f"[ERROR] /api/alarm-history failed: {e}")
        return jsonify({'history': [], 'error': str(e)}), 500

# ==================== FAMILY SAFETY API (для FamilySafetyTab) ====================
# Using family_store (FamilyStore class) for persistent storage

@app.route('/api/family/status', methods=['POST'])
def get_family_status():
    """Get safety status for family members by their codes."""
    try:
        data = request.get_json() or {}
        codes = data.get('codes', [])
        
        statuses = family_store.get_statuses(codes)
        
        response = jsonify({'statuses': statuses, 'timestamp': datetime.now().isoformat()})
        response.headers['Access-Control-Allow-Origin'] = '*'
        return response
        
    except Exception as e:
        print(f"[ERROR] /api/family/status failed: {e}")
        return jsonify({'statuses': {}, 'error': str(e)}), 500

@app.route('/api/family/update', methods=['POST'])
def update_family_status():
    """Update safety status for a family member."""
    try:
        data = request.get_json() or {}
        code = (data.get('code', '') or '').upper()
        is_safe = data.get('is_safe', False)
        name = data.get('name', '')
        fcm_token = data.get('fcm_token')
        device_id = data.get('device_id')
        
        if not code or len(code) < 4:
            return jsonify({'success': False, 'error': 'Invalid code'}), 400
        
        family_store.update_status(code, is_safe, name, fcm_token, device_id)
        
        response = jsonify({'success': True, 'code': code, 'is_safe': is_safe})
        response.headers['Access-Control-Allow-Origin'] = '*'
        return response
        
    except Exception as e:
        print(f"[ERROR] /api/family/update failed: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/family/register-token', methods=['POST'])
def register_family_fcm_token():
    """Register FCM token for family member to receive SOS notifications."""
    try:
        data = request.get_json() or {}
        code = (data.get('code', '') or '').upper()
        fcm_token = data.get('fcm_token')
        device_id = data.get('device_id')
        
        if not code or len(code) < 4:
            return jsonify({'success': False, 'error': 'Invalid code'}), 400
        if not fcm_token:
            return jsonify({'success': False, 'error': 'Missing FCM token'}), 400
        
        family_store.register_fcm_token(code, fcm_token, device_id)
        
        response = jsonify({'success': True, 'code': code})
        response.headers['Access-Control-Allow-Origin'] = '*'
        return response
        
    except Exception as e:
        print(f"[ERROR] /api/family/register-token failed: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/family/sos', methods=['POST'])
def send_family_sos():
    """Send SOS signal to family members via push notification."""
    try:
        data = request.get_json() or {}
        code = (data.get('code', '') or '').upper()
        family_codes = data.get('family_codes', [])
        sender_name = data.get('name', '')
        location = data.get('location')  # Optional: {lat, lng, address}
        
        print(f"[SOS] === SOS REQUEST RECEIVED ===")
        print(f"[SOS] Sender code: {code}")
        print(f"[SOS] Sender name: {sender_name}")
        print(f"[SOS] Family codes to notify: {family_codes}")
        
        if not code:
            return jsonify({'success': False, 'error': 'Invalid code'}), 400
        
        # Get tokens to notify and mark sender as needing help
        sos_data = family_store.send_sos(code, family_codes)
        tokens_to_notify = sos_data.get('tokens_to_notify', [])
        
        print(f"[SOS] Found {len(tokens_to_notify)} family members with FCM tokens")
        for t in tokens_to_notify:
            print(f"[SOS]   - {t['code']}: token={t['fcm_token'][:30]}...")
        
        # Send FCM push notifications to family members
        notified_count = 0
        if tokens_to_notify and init_firebase():
            from firebase_admin import messaging
            
            for member in tokens_to_notify:
                try:
                    # Prepare SOS notification
                    sos_message = f"🆘 {sender_name or code} потребує допомоги!"
                    if location and location.get('address'):
                        sos_message += f"\n📍 {location['address']}"
                    
                    # Send FCM notification
                    message = messaging.Message(
                        token=member['fcm_token'],
                        data={
                            'type': 'sos',
                            'sender_code': code,
                            'sender_name': sender_name,
                            'title': '🆘 SOS Сигнал!',
                            'body': sos_message,
                            'location_lat': str(location.get('lat', '')) if location else '',
                            'location_lng': str(location.get('lng', '')) if location else '',
                            'location_address': location.get('address', '') if location else '',
                        },
                        android=messaging.AndroidConfig(
                            priority='high',
                            ttl=3600,
                        ),
                        apns=messaging.APNSConfig(
                            headers={'apns-priority': '10'},
                            payload=messaging.APNSPayload(
                                aps=messaging.Aps(
                                    alert=messaging.ApsAlert(
                                        title='🆘 SOS Сигнал!',
                                        body=sos_message,
                                    ),
                                    sound='default',
                                    badge=1,
                                ),
                            ),
                        ),
                    )
                    
                    messaging.send(message)
                    notified_count += 1
                    print(f"[SOS] Notified {member['code']} via FCM")
                    
                except Exception as fcm_error:
                    print(f"[SOS] Failed to notify {member['code']}: {fcm_error}")
        
        print(f"[SOS] Code {code} sent SOS to {len(family_codes)} family members, {notified_count} notified via FCM")
        
        response = jsonify({
            'success': True, 
            'code': code, 
            'notified': notified_count,
            'total_family': len(family_codes)
        })
        response.headers['Access-Control-Allow-Origin'] = '*'
        return response
        
    except Exception as e:
        print(f"[ERROR] /api/family/sos failed: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/family/clear-sos', methods=['POST'])
def clear_family_sos():
    """Clear SOS status for a family member (they are OK now)."""
    try:
        data = request.get_json() or {}
        code = (data.get('code', '') or '').upper()
        
        if not code:
            return jsonify({'success': False, 'error': 'Invalid code'}), 400
        
        family_store.clear_sos(code)
        
        response = jsonify({'success': True, 'code': code})
        response.headers['Access-Control-Allow-Origin'] = '*'
        return response
        
    except Exception as e:
        print(f"[ERROR] /api/family/clear-sos failed: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/family/check-tokens', methods=['POST'])
def check_family_tokens():
    """Debug endpoint to check which family codes have FCM tokens registered."""
    try:
        data = request.get_json() or {}
        codes = data.get('codes', [])
        
        if not codes:
            return jsonify({'success': False, 'error': 'No codes provided'}), 400
        
        result = {}
        for code in codes:
            code_upper = code.upper()
            status = family_store.get_status(code_upper)
            # Check if member has FCM token
            family_data = family_store._load()
            member_data = family_data.get('members', {}).get(code_upper, {})
            has_token = bool(member_data.get('fcm_token'))
            
            result[code_upper] = {
                'has_token': has_token,
                'last_active': member_data.get('last_active'),
                'status': status,
            }
        
        response = jsonify({'success': True, 'codes': result})
        response.headers['Access-Control-Allow-Origin'] = '*'
        return response
        
    except Exception as e:
        print(f"[ERROR] /api/family/check-tokens failed: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/test_parse')
def test_parse():
    """Test endpoint to manually test message parsing without auth."""
    test_message = "Чернігівщина: 1 БпЛА на Козелець 1 БпЛА на Носівку 1 БпЛА неподалік Ічні 2 БпЛА на Куликівку 2 БпЛА між Корюківкою та Меною Сумщина: 3 БпЛА в районі Конотопу ㅤ ➡Підписатися"
    
    try:
        print("="*50)
        print("MANUAL TEST STARTED")
        print("="*50)
        tracks = process_message(test_message, 'TEST_1', '2025-09-05 17:20:00', 'test')
        print("="*50)
        print("MANUAL TEST COMPLETED")
        print("="*50)
        
        return jsonify({
            'success': True,
            'message': test_message,
            'tracks_count': len(tracks) if tracks else 0,
            'tracks': tracks,
            'test_time': datetime.now().isoformat()
        })
    except Exception as e:
        import traceback
        error_details = traceback.format_exc()
        print(f"ERROR in test_parse: {error_details}")
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': error_details
        }), 500
    """Locate a settlement or raion by name. Query param: q=<name>
    Returns: {status:'ok', name, lat, lng, source:'dict'|'geocode'|'fallback'} or {status:'not_found'}
    Lightweight normalization reusing UA_CITY_NORMALIZE and CITY_COORDS. Falls back to ensure_city_coords (may geocode if key allowed).
    """
    q = (request.args.get('q') or '').strip()
    if not q:
        return jsonify({'status':'empty'}), 400
    raw = q.lower()
    # Basic cleanup similar to parser's normalization
    raw = re.sub(r'["`ʼ’\'".,:;()]+','', raw)
    raw = re.sub(r'\s+',' ', raw)
    # Try direct dict match
    key = raw
    if key in UA_CITY_NORMALIZE:
        key = UA_CITY_NORMALIZE[key]
    # Heuristic accusative -> nominative (simple feminine endings) if still not found
    if key not in CITY_COORDS and len(key) > 4 and key.endswith(('у','ю')):
        alt = key[:-1] + 'а'
        if alt in CITY_COORDS:
            key = alt
    # Direct dictionary coordinate fetch
    if key in CITY_COORDS:
        lat,lng = CITY_COORDS[key]
        return jsonify({'status':'ok','name':key.title(),'lat':lat,'lng':lng,'source':'dict'})
    # Check full settlements index (all cities/villages loaded from external file)
    if 'SETTLEMENTS_INDEX' in globals() and key in SETTLEMENTS_INDEX:
        lat,lng = SETTLEMENTS_INDEX[key]
        return jsonify({'status':'ok','name':key.title(),'lat':lat,'lng':lng,'source':'settlement'})
    # If not exact, attempt prefix suggestions for UI autocomplete
    if 'SETTLEMENTS_INDEX' in globals() and len(key) >= 3:
        pref = key
        matches = [n for n in SETTLEMENTS_INDEX.keys() if n.startswith(pref)][:15]
        if not matches and pref.endswith(('у','ю')):
            pref2 = pref[:-1] + 'а'
            matches = [n for n in SETTLEMENTS_INDEX.keys() if n.startswith(pref2)][:15]
        if matches:
            return jsonify({'status':'suggest','query':q,'matches':matches})
    # Attempt dynamic ensure (geocode) unless negative cache prohibits
    coords = None
    try:
        coords = ensure_city_coords(key)
    except Exception:
        coords = None
    if coords:
        lat,lng = coords
        return jsonify({'status':'ok','name':key.title(),'lat':lat,'lng':lng,'source':'geocode'})
    return jsonify({'status':'not_found','query':q}), 404

@app.route('/add_channel', methods=['POST'])
def add_channel():
    """Add a channel username or numeric ID at runtime.
    Body JSON: {"id": "-1001234567890", "secret": "..."}
    Requires AUTH_SECRET match if set.
    Persists into channels_dynamic.json and updates global list.
    """
    if AUTH_SECRET and request.json.get('secret') != AUTH_SECRET:
        return jsonify({'status':'error','error':'unauthorized'}), 403
    cid = str(request.json.get('id','')).strip()
    if not cid:
        return jsonify({'status':'error','error':'empty_id'}), 400
    global CHANNELS
    # Normalize removing leading @ or https link wrappers
    cid = cid.replace('https://t.me/','').replace('t.me/','')
    # Remove joinchat pattern if present (cannot directly fetch by invite hash)
    if cid.startswith('+'):
        # Cannot use invite hash directly; require numeric ID user already joined from session
        return jsonify({'status':'error','error':'invite_link_not_supported_use_numeric_id'}), 400
    if cid not in CHANNELS:
        CHANNELS.append(cid)
        # Persist dynamic list excluding originals from env for clarity
        orig_env = os.getenv('TELEGRAM_CHANNELS', '').split(',') if os.getenv('TELEGRAM_CHANNELS') else []
        dynamic_part = [c for c in CHANNELS if c.strip() and c.strip() not in orig_env]
        save_dynamic_channels(dynamic_part)
        log.info(f'Added channel {cid}. Total now {len(CHANNELS)}')
        return jsonify({'status':'ok','added':cid,'total':len(CHANNELS)})
    return jsonify({'status':'ok','added':False,'message':'exists','total':len(CHANNELS)})

# ---------------- Manual marker management -----------------

def _normalize_admin_trajectory(raw_traj):
    """Sanitize trajectory payload coming from admin UI."""
    if not isinstance(raw_traj, dict):
        return None

    def _pt(val):
        if not isinstance(val, (list, tuple)) or len(val) != 2:
            return None
        try:
            lat = float(val[0])
            lng = float(val[1])
            return [round(lat, 6), round(lng, 6)]
        except (TypeError, ValueError):
            return None

    start = _pt(raw_traj.get('start'))
    end = _pt(raw_traj.get('end'))
    if not (start and end):
        return None

    traj = {'start': start, 'end': end}
    for key in ('source', 'target', 'kind'):
        value = raw_traj.get(key)
        if isinstance(value, str):
            value = value.strip()
            if value:
                traj[key] = value[:160]
    return traj
@app.route('/admin/add_manual_marker', methods=['POST'])
def admin_add_manual_marker():
    """Add a manual marker via admin panel.
    JSON body: {"lat":..., "lng":..., "text":"...", "place":"...", "threat_type":"shahed", "icon":"optional.png", "rotation":0}
    Requires secret if configured.
    """
    if not _require_secret(request):
        return jsonify({'status':'forbidden'}), 403
    payload = request.get_json(silent=True) or {}
    try:
        lat = safe_float(payload.get('lat'))
        lng = safe_float(payload.get('lng'))
        if lat is None or lng is None:
            raise ValueError('invalid_coordinates')
        if not (43 <= lat <= 53.8 and 21 <= lng <= 41.5):
            raise ValueError('out_of_bounds')
        text = (payload.get('text') or '').strip()
        if not text:
            raise ValueError('empty_text')
        place = (payload.get('place') or '').strip()
        threat_type = (payload.get('threat_type') or '').strip().lower() or 'manual'
        allowed_types = {'shahed','raketa','avia','pvo','vibuh','alarm','alarm_cancel','mlrs','artillery','obstril','fpv','pusk','manual'}
        if threat_type not in allowed_types:
            threat_type = 'manual'
        icon = (payload.get('icon') or '').strip()
        rotation = payload.get('rotation', 0)
        try:
            rotation = float(rotation)
        except:
            rotation = 0
        trajectory = _normalize_admin_trajectory(payload.get('trajectory'))
        course_direction = (payload.get('course_direction') or '').strip() or None
        course_target = (payload.get('course_target') or '').strip() or None
        course_source = (payload.get('course_source') or '').strip() or (place or None)
        course_type = (payload.get('course_type') or '').strip() or None

        tz = pytz.timezone('Europe/Kyiv')
        now_dt = datetime.now(tz).strftime('%Y-%m-%d %H:%M:%S')
        mid = 'manual-' + uuid.uuid4().hex[:12]
        messages = load_messages()
        # Build message dict similar to parsed messages
        msg = {
            'id': mid,
            'date': now_dt,
            'text': text,
            'place': place,
            'lat': round(lat, 6),
            'lng': round(lng, 6),
            'threat_type': threat_type,
            'marker_icon': icon or None,
            'rotation': rotation,
            'manual': True,
            'channel': 'manual',
            'source': 'manual'
        }
        if trajectory:
            msg['trajectory'] = trajectory
        if course_direction:
            msg['course_direction'] = course_direction
        if course_target:
            msg['course_target'] = course_target
        if course_source:
            msg['course_source'] = course_source
        if course_type:
            msg['course_type'] = course_type
        messages.append(msg)
        save_messages(messages)
        return jsonify({'status':'ok','id':mid})
    except Exception as e:
        return jsonify({'status':'error','error':str(e)}), 400

@app.route('/admin/update_manual_marker', methods=['POST'])
def admin_update_manual_marker():
    """Update existing manual marker coordinates/text/type."""
    if not _require_secret(request):
        return jsonify({'status': 'forbidden'}), 403

    payload = request.get_json(silent=True) or {}
    marker_id = (payload.get('id') or '').strip()
    if not marker_id:
        return jsonify({'status': 'error', 'error': 'missing_id'}), 400

    try:
        lat = safe_float(payload.get('lat'))
        lng = safe_float(payload.get('lng'))
        if lat is None or lng is None:
            raise ValueError('invalid_coordinates')
        if not (43 <= lat <= 53.8 and 21 <= lng <= 41.5):
            raise ValueError('out_of_bounds')
        place = (payload.get('place') or '').strip()
        text = (payload.get('text') or '').strip()
        if not text:
            raise ValueError('empty_text')
        threat_type = (payload.get('threat_type') or '').strip().lower() or 'manual'
        allowed_types = {'shahed','raketa','avia','pvo','vibuh','alarm','alarm_cancel','mlrs','artillery','obstril','fpv','pusk','manual'}
        if threat_type not in allowed_types:
            threat_type = 'manual'
        rotation = payload.get('rotation', 0)
        try:
            rotation = safe_float(rotation) or 0
        except Exception:
            rotation = 0

        trajectory = _normalize_admin_trajectory(payload.get('trajectory'))
        course_direction = (payload.get('course_direction') or '').strip()
        course_target = (payload.get('course_target') or '').strip()
        course_source = (payload.get('course_source') or '').strip()
        course_type = (payload.get('course_type') or '').strip()

        messages = load_messages()
        updated = False
        for msg in messages:
            if msg.get('id') != marker_id:
                continue
            msg['lat'] = round(lat, 6)
            msg['lng'] = round(lng, 6)
            msg['place'] = place
            msg['text'] = text
            msg['threat_type'] = threat_type
            msg['rotation'] = rotation
            msg['manual'] = msg.get('manual', True)

            if 'trajectory' in payload:
                if trajectory:
                    msg['trajectory'] = trajectory
                else:
                    msg.pop('trajectory', None)
            if 'course_direction' in payload:
                if course_direction:
                    msg['course_direction'] = course_direction
                else:
                    msg.pop('course_direction', None)
            if 'course_target' in payload:
                if course_target:
                    msg['course_target'] = course_target
                else:
                    msg.pop('course_target', None)
            if 'course_source' in payload:
                if course_source:
                    msg['course_source'] = course_source
                else:
                    msg.pop('course_source', None)
            if 'course_type' in payload:
                if course_type:
                    msg['course_type'] = course_type
                else:
                    msg.pop('course_type', None)
            updated = True
            break

        if not updated:
            return jsonify({'status': 'error', 'error': 'not_found'}), 404

        save_messages(messages)
        return jsonify({'status': 'ok', 'id': marker_id})
    except Exception as e:
        return jsonify({'status': 'error', 'error': str(e)}), 400

@app.route('/admin/markers')
def admin_markers():
    """API endpoint to get recent markers for admin map"""
    if not _require_secret(request):
        return jsonify({'status':'forbidden'}), 403
    
    all_msgs = load_messages()
    # Get recent markers (exclude pending geo)
    recent_markers = [m for m in reversed(all_msgs) if m.get('lat') and m.get('lng') and not m.get('pending_geo')][:120]
    
    return jsonify({
        'status': 'ok',
        'markers': recent_markers,
        'count': len(recent_markers)
    })

@app.route('/admin/raw_msgs')
def admin_raw_msgs():
    """API endpoint to get raw messages (pending geo) for admin panel"""
    if not _require_secret(request):
        return jsonify({'status':'forbidden'}), 403
    
    all_msgs = load_messages()
    raw_msgs = [m for m in reversed(all_msgs) if m.get('pending_geo')][:100]  # latest 100
    raw_count = len([m for m in all_msgs if m.get('pending_geo')])
    
    return jsonify({
        'status': 'ok',
        'raw_msgs': raw_msgs,
        'raw_count': raw_count
    })

@app.route('/admin/delete_manual_marker', methods=['POST'])
def admin_delete_manual_marker():
    if not _require_secret(request):
        return jsonify({'status':'forbidden'}), 403
    payload = request.get_json(silent=True) or {}
    mid = (payload.get('id') or '').strip()
    if not mid:
        return jsonify({'status':'error','error':'missing id'}), 400
    try:
        messages = load_messages()
        new_list = [m for m in messages if not (m.get('manual') and m.get('id') == mid)]
        if len(new_list) == len(messages):
            return jsonify({'status':'ok','deleted':False})
        save_messages(new_list)
        return jsonify({'status':'ok','deleted':True})
    except Exception as e:
        return jsonify({'status':'error','error':str(e)}), 500

@app.route('/hide_marker', methods=['POST'])
def hide_marker():
    """Store a marker key so it's excluded from subsequent /data responses."""
    try:
        payload = request.get_json(force=True) or {}
        lat = round(float(payload.get('lat')), 3)
        lng = round(float(payload.get('lng')), 3)
        text = (payload.get('text') or '').strip()
        source = (payload.get('source') or '').strip()
        marker_key = f"{lat},{lng}|{text}|{source}"
        hidden = load_hidden()
        if marker_key not in hidden:
            hidden.append(marker_key)
            save_hidden(hidden)
        return jsonify({'status':'ok','hidden_count':len(hidden)})
    except Exception as e:
        log.warning(f"hide_marker error: {e}")
        return jsonify({'status':'error','error':str(e)}), 400

@app.route('/unhide_marker', methods=['POST'])
def unhide_marker():
    """Remove previously hidden marker by key or by lat,lng plus text/source prefix match."""
    try:
        payload = request.get_json(force=True) or {}
        key = (payload.get('key') or '').strip()
        hidden = load_hidden()
        changed = False
        if key:
            if key.isdigit():
                idx = int(key)
                if 0 <= idx < len(hidden):
                    del hidden[idx]
                    changed = True
            elif key in hidden:
                hidden.remove(key)
                changed = True
        else:
            lat = payload.get('lat')
            lng = payload.get('lng')
            text = (payload.get('text') or '').strip()
            source = (payload.get('source') or '').strip()
            if lat is not None and lng is not None:
                try:
                    lat_r = round(float(lat), 3)
                    lng_r = round(float(lng), 3)
                except Exception:
                    lat_r = lng_r = None
                base_prefix = f"{lat_r},{lng_r}|" if lat_r is not None else None
                if base_prefix:
                    for h in list(hidden):
                        if not h.startswith(base_prefix):
                            continue
                        try:
                            _, htext, hsource = h.split('|', 2)
                        except ValueError:
                            continue
                        if source and hsource != source:
                            continue
                        if not text or htext.startswith(text) or text.startswith(htext):
                            hidden.remove(h)
                            changed = True
        if changed:
            save_hidden(hidden)
        else:
            log.info(f"unhide_marker: no change for key='{key}' payload={payload}")
        return jsonify({'status': 'ok', 'removed': changed, 'remaining': len(hidden)})
    except Exception as e:
        log.warning(f"unhide_marker error: {e}")
        return jsonify({'status': 'error', 'error': str(e)}), 400

# Guard against duplicate registration if this file is imported twice or a previous
# health endpoint already exists (avoids Flask AssertionError: overwriting endpoint)
if 'health' not in app.view_functions:
    @app.route('/health')
    def health():  # type: ignore
        now = time.time()
        
        # Basic stats + prune visitors
        with ACTIVE_LOCK:
            for vid, meta in list(ACTIVE_VISITORS.items()):
                ts = meta if isinstance(meta,(int,float)) else meta.get('ts',0)
                if now - ts > ACTIVE_TTL:
                    del ACTIVE_VISITORS[vid]
            visitors = len(ACTIVE_VISITORS)
        
        # Calculate Groq cooldown status
        groq_cooldown_remaining = 0
        groq_available = _groq_is_available() if GROQ_ENABLED else False
        if GROQ_ENABLED and _groq_daily_cooldown_until > 0:
            import time as time_module
            groq_cooldown_remaining = max(0, int(_groq_daily_cooldown_until - time_module.time()))
        
        return jsonify({
            'status':'ok',
            'messages':len(load_messages()), 
            'auth': AUTH_STATUS, 
            'visitors': visitors,
            'firebase_initialized': firebase_initialized,
            'devices_count': len(device_store._load()) if device_store else 0,
            'groq_enabled': GROQ_ENABLED,
            'groq_model': GROQ_MODEL if GROQ_ENABLED else None,
            'groq_available': groq_available,
            'groq_cooldown_seconds': groq_cooldown_remaining
        })

@app.route('/ads.txt')
def ads_txt():
    """Serve ads.txt for ad networks verification"""
    from flask import send_from_directory
    return send_from_directory('static', 'ads.txt', mimetype='text/plain')

@app.route('/app-ads.txt')
def app_ads_txt():
    """Serve app-ads.txt for mobile app ad networks verification (Google AdMob)"""
    return send_from_directory('.', 'app-ads.txt', mimetype='text/plain')

@app.route('/robots.txt')
def robots_txt():
    """Serve robots.txt for search engines with proper SEO headers"""
    response = send_from_directory('static', 'robots.txt', mimetype='text/plain')
    response.headers['Cache-Control'] = 'public, max-age=86400'  # 24 hours
    response.headers['X-Robots-Tag'] = 'noindex'  # Don't index robots.txt itself
    return response

@app.route('/sitemap.xml')
def sitemap_xml():
    """Serve dynamic sitemap.xml for search engines with proper headers"""
    from datetime import datetime
    today = datetime.now().strftime('%Y-%m-%d')
    
    sitemap_content = f'''<?xml version="1.0" encoding="UTF-8"?>
<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9"
        xmlns:image="http://www.google.com/schemas/sitemap-image/1.1"
        xmlns:xhtml="http://www.w3.org/1999/xhtml">
  
  <!-- ГОЛОВНА СТОРІНКА -->
  <url>
    <loc>https://neptun.in.ua/</loc>
    <lastmod>{today}</lastmod>
    <changefreq>always</changefreq>
    <priority>1.0</priority>
    <image:image>
      <image:loc>https://neptun.in.ua/static/og-image.png</image:loc>
      <image:title>Карта тривог та шахедів України онлайн - NEPTUN</image:title>
      <image:caption>Карта повітряних тривог України в реальному часі. Відстеження шахедів, дронів, ракет 24/7</image:caption>
    </image:image>
    <xhtml:link rel="alternate" hreflang="uk" href="https://neptun.in.ua/"/>
    <xhtml:link rel="alternate" hreflang="x-default" href="https://neptun.in.ua/"/>
  </url>
  
  <!-- ФУНКЦІОНАЛЬНІ СТОРІНКИ -->
  <url>
    <loc>https://neptun.in.ua/map</loc>
    <lastmod>{today}</lastmod>
    <changefreq>always</changefreq>
    <priority>0.95</priority>
  </url>
  
  <url>
    <loc>https://neptun.in.ua/blackouts</loc>
    <lastmod>{today}</lastmod>
    <changefreq>hourly</changefreq>
    <priority>0.9</priority>
  </url>
  
  <!-- РЕГІОНАЛЬНІ СТОРІНКИ -->
  <url>
    <loc>https://neptun.in.ua/region/kyiv</loc>
    <lastmod>{today}</lastmod>
    <changefreq>always</changefreq>
    <priority>0.9</priority>
  </url>
  <url>
    <loc>https://neptun.in.ua/region/kyivska</loc>
    <lastmod>{today}</lastmod>
    <changefreq>always</changefreq>
    <priority>0.88</priority>
  </url>
  <url>
    <loc>https://neptun.in.ua/region/kharkivska</loc>
    <lastmod>{today}</lastmod>
    <changefreq>always</changefreq>
    <priority>0.88</priority>
  </url>
  <url>
    <loc>https://neptun.in.ua/region/odeska</loc>
    <lastmod>{today}</lastmod>
    <changefreq>always</changefreq>
    <priority>0.88</priority>
  </url>
  <url>
    <loc>https://neptun.in.ua/region/dnipropetrovska</loc>
    <lastmod>{today}</lastmod>
    <changefreq>always</changefreq>
    <priority>0.88</priority>
  </url>
  <url>
    <loc>https://neptun.in.ua/region/lvivska</loc>
    <lastmod>{today}</lastmod>
    <changefreq>always</changefreq>
    <priority>0.87</priority>
  </url>
  <url>
    <loc>https://neptun.in.ua/region/zaporizka</loc>
    <lastmod>{today}</lastmod>
    <changefreq>always</changefreq>
    <priority>0.87</priority>
  </url>
  <url>
    <loc>https://neptun.in.ua/region/mykolaivska</loc>
    <lastmod>{today}</lastmod>
    <changefreq>always</changefreq>
    <priority>0.86</priority>
  </url>
  <url>
    <loc>https://neptun.in.ua/region/poltavska</loc>
    <lastmod>{today}</lastmod>
    <changefreq>always</changefreq>
    <priority>0.85</priority>
  </url>
  <url>
    <loc>https://neptun.in.ua/region/vinnytska</loc>
    <lastmod>{today}</lastmod>
    <changefreq>always</changefreq>
    <priority>0.85</priority>
  </url>
  <url>
    <loc>https://neptun.in.ua/region/zhytomyrska</loc>
    <lastmod>{today}</lastmod>
    <changefreq>always</changefreq>
    <priority>0.84</priority>
  </url>
  <url>
    <loc>https://neptun.in.ua/region/cherkaska</loc>
    <lastmod>{today}</lastmod>
    <changefreq>always</changefreq>
    <priority>0.84</priority>
  </url>
  <url>
    <loc>https://neptun.in.ua/region/sumska</loc>
    <lastmod>{today}</lastmod>
    <changefreq>always</changefreq>
    <priority>0.84</priority>
  </url>
  <url>
    <loc>https://neptun.in.ua/region/chernihivska</loc>
    <lastmod>{today}</lastmod>
    <changefreq>always</changefreq>
    <priority>0.84</priority>
  </url>
  <url>
    <loc>https://neptun.in.ua/region/khmelnytska</loc>
    <lastmod>{today}</lastmod>
    <changefreq>always</changefreq>
    <priority>0.83</priority>
  </url>
  <url>
    <loc>https://neptun.in.ua/region/volynska</loc>
    <lastmod>{today}</lastmod>
    <changefreq>always</changefreq>
    <priority>0.83</priority>
  </url>
  <url>
    <loc>https://neptun.in.ua/region/rivnenska</loc>
    <lastmod>{today}</lastmod>
    <changefreq>always</changefreq>
    <priority>0.83</priority>
  </url>
  <url>
    <loc>https://neptun.in.ua/region/ternopilska</loc>
    <lastmod>{today}</lastmod>
    <changefreq>always</changefreq>
    <priority>0.82</priority>
  </url>
  <url>
    <loc>https://neptun.in.ua/region/ivano-frankivska</loc>
    <lastmod>{today}</lastmod>
    <changefreq>always</changefreq>
    <priority>0.82</priority>
  </url>
  <url>
    <loc>https://neptun.in.ua/region/zakarpatska</loc>
    <lastmod>{today}</lastmod>
    <changefreq>always</changefreq>
    <priority>0.82</priority>
  </url>
  <url>
    <loc>https://neptun.in.ua/region/chernivetska</loc>
    <lastmod>{today}</lastmod>
    <changefreq>always</changefreq>
    <priority>0.81</priority>
  </url>
  <url>
    <loc>https://neptun.in.ua/region/kirovohradska</loc>
    <lastmod>{today}</lastmod>
    <changefreq>always</changefreq>
    <priority>0.81</priority>
  </url>
  <url>
    <loc>https://neptun.in.ua/region/khersonska</loc>
    <lastmod>{today}</lastmod>
    <changefreq>always</changefreq>
    <priority>0.85</priority>
  </url>
  <url>
    <loc>https://neptun.in.ua/region/donetska</loc>
    <lastmod>{today}</lastmod>
    <changefreq>always</changefreq>
    <priority>0.86</priority>
  </url>
  <url>
    <loc>https://neptun.in.ua/region/luhanska</loc>
    <lastmod>{today}</lastmod>
    <changefreq>always</changefreq>
    <priority>0.85</priority>
  </url>
  
  <!-- ІНФОРМАЦІЙНІ СТОРІНКИ -->
  <url>
    <loc>https://neptun.in.ua/about</loc>
    <lastmod>{today}</lastmod>
    <changefreq>monthly</changefreq>
    <priority>0.6</priority>
  </url>
  <url>
    <loc>https://neptun.in.ua/faq</loc>
    <lastmod>{today}</lastmod>
    <changefreq>weekly</changefreq>
    <priority>0.7</priority>
  </url>
  <url>
    <loc>https://neptun.in.ua/privacy</loc>
    <lastmod>{today}</lastmod>
    <changefreq>yearly</changefreq>
    <priority>0.3</priority>
  </url>
  <url>
    <loc>https://neptun.in.ua/terms</loc>
    <lastmod>{today}</lastmod>
    <changefreq>yearly</changefreq>
    <priority>0.3</priority>
  </url>

</urlset>'''
    
    response = Response(sitemap_content, mimetype='application/xml')
    response.headers['Cache-Control'] = 'public, max-age=3600'  # 1 hour
    response.headers['X-Content-Type-Options'] = 'nosniff'
    return response

@app.route('/presence', methods=['POST'])
def presence():
    """Register active viewers and return synchronized counts per platform."""
    client_ip = request.environ.get('HTTP_X_FORWARDED_FOR', request.remote_addr) or 'unknown'
    rate_key = f"{client_ip}_presence"
    now_time = time.time()
    recent = [ts for ts in request_counts[rate_key] if now_time - ts < PRESENCE_RATE_WINDOW]
    if len(recent) >= PRESENCE_RATE_LIMIT:
        return jsonify({'error': 'presence rate limited', 'retry_after': PRESENCE_RATE_WINDOW}), 429
    recent.append(now_time)
    request_counts[rate_key] = recent

    data = request.get_json(silent=True) or {}
    vid = str(data.get('id') or '').strip()
    if not vid:
        return jsonify({'status': 'error', 'error': 'id required'}), 400

    now = time.time()
    blocked = set(load_blocked())
    if vid in blocked:
        return jsonify({'status': 'blocked'})

    remote_ip = request.headers.get('X-Forwarded-For', request.remote_addr or '')
    ua = request.headers.get('User-Agent', '')[:300]
    platform_label = _normalize_platform(data.get('platform') or '', ua)
    nickname = data.get('nickname', '')[:20] if data.get('nickname') else ''  # Max 20 chars

    stats = _load_visit_stats()
    if vid not in stats:
        stats[vid] = now
        if int(now) % 200 == 0:
            _prune_visit_stats()
        _save_visit_stats()

    try:
        _update_recent_visits(vid)
    except Exception as e:
        log.warning(f"recent visits update failed: {e}")

    try:
        record_visit_sql(vid, now, remote_ip)
    except Exception:
        pass

    db_first = None
    try:
        with _visits_db_conn() as conn:
            cur = conn.execute("SELECT first_seen FROM visits WHERE id=?", (vid,))
            row = cur.fetchone()
            if row and row[0]:
                try:
                    db_first = float(row[0])
                except Exception:
                    db_first = None
    except Exception:
        pass

    with ACTIVE_LOCK:
        prev = ACTIVE_VISITORS.get(vid) if isinstance(ACTIVE_VISITORS.get(vid), dict) else {}
        first_seen = prev.get('first') or db_first or stats.get(vid) or now
        ACTIVE_VISITORS[vid] = {
            'ts': now,
            'first': first_seen,
            'ip': remote_ip,
            'ua': prev.get('ua') or ua,
            'platform': platform_label,
            'nickname': nickname if nickname else prev.get('nickname', '')
        }
        for key, meta in list(ACTIVE_VISITORS.items()):
            ts = meta if isinstance(meta, (int, float)) else meta.get('ts', 0)
            if now - ts > ACTIVE_TTL:
                del ACTIVE_VISITORS[key]

        platform_counts = {}
        for meta in ACTIVE_VISITORS.values():
            bucket = meta.get('platform') or 'web'
            platform_counts[bucket] = platform_counts.get(bucket, 0) + 1
        total = sum(platform_counts.values())

    apps_total = platform_counts.get('android', 0) + platform_counts.get('ios', 0)
    payload = {
        'status': 'ok',
        'visitors': total,
        'platforms': {
            'web': platform_counts.get('web', 0),
            'android': platform_counts.get('android', 0),
            'ios': platform_counts.get('ios', 0),
            'other': sum(v for k, v in platform_counts.items() if k not in VALID_PLATFORMS)
        },
        'apps': apps_total
    }
    return jsonify(payload)

@app.route('/raion_alarms')
def raion_alarms():
    # ...existing code...
    
    # Expose current active district air alarms
    out = []
    now = time.time()
    for key, info in list(RAION_ALARMS.items()):
        # Optional expiry cleanup (e.g., 3h stale auto-clear)
        if now - info.get('since', now) > 3*3600:
            RAION_ALARMS.pop(key, None)
            continue
        out.append({
            'raion': key,
            'place': info['place'],
            'lat': info['lat'],
            'lng': info['lng'],
            'since': info['since']
        })
    return jsonify({'alarms': out, 'count': len(out)})

# SSE stream endpoint
@app.route('/stream')
def stream():
    def gen():
        q = queue.Queue()
        SUBSCRIBERS.add(q)
        last_ping = time.time()
        try:
            while True:
                try:
                    item = q.get(timeout=5)
                    yield f'data: {item}\n\n'
                except Exception:
                    pass
                now_t = time.time()
                if now_t - last_ping > 25:
                    last_ping = now_t
                    yield ': ping\n\n'
        except GeneratorExit:
            pass
        finally:
            SUBSCRIBERS.discard(q)
    headers = {
        'Cache-Control': 'no-store',
        'Connection': 'keep-alive',
        'X-Accel-Buffering': 'no'
    }
    return Response(gen(), mimetype='text/event-stream', headers=headers)

def broadcast_new(tracks):
    """Send new geo tracks to all connected SSE subscribers."""
    if not tracks:
        return
    payload = json.dumps({'tracks': tracks}, ensure_ascii=False)
    dead = []
    for q in list(SUBSCRIBERS):
        try:
            q.put_nowait(payload)
        except Exception:
            dead.append(q)
    for d in dead:
        SUBSCRIBERS.discard(d)
def broadcast_control(event:dict):
    try:
        payload = json.dumps({'control': event}, ensure_ascii=False)
    except Exception:
        return
    dead = []
    for q in list(SUBSCRIBERS):
        try:
            q.put_nowait(payload)
        except Exception:
            dead.append(q)

# ---------------- Admin & blocking endpoints -----------------
def _require_secret(req):
    if not AUTH_SECRET:
        return True
    supplied = req.args.get('secret') or req.headers.get('X-Auth-Secret') or req.form.get('secret')
    return supplied and supplied == AUTH_SECRET

@app.route('/version')
def version_check():
    return {'version': '2024-12-06-oblast-raion-fix', 'timestamp': time.time()}

@app.route('/test_oblast_raion')
def test_oblast_raion():
    if not _require_secret(request):
        return Response('Forbidden', status=403)
    
    test_text = "Загроза застосування БПЛА. Перейдіть в укриття! | чернігівська область (чернігівський район), київська область (вишгородський район), сумська область (сумський, конотопський райони) - загроза ударних бпла!"
    result = process_message(test_text, 'test_99999', '2024-12-06', 'test_channel')
    
    return {
        'test_text': test_text,
        'result': result,
        'debug_logs': [log for log in DEBUG_LOGS if log.get('category') == 'oblast_raion'][-10:]
    }

@app.route('/test-pusk')
def test_pusk_icon():
    """Test route to debug pusk.png display issues"""
    with open('/Users/vladimirmalik/Desktop/render2/test_pusk_icon.html', 'r', encoding='utf-8') as f:
        return f.read()

@app.route('/admin')
def admin_panel():
    if not _require_secret(request):
        return Response('Forbidden', status=403)
    # Ensure rolling recent visits file is seeded from durable SQLite (survives redeploy)
    try:
        _seed_recent_from_sql()
    except Exception:
        pass
    now = time.time()
    # Merge ACTIVE_VISITORS volatile data with persistent DB to avoid session age resets on restart
    # Strategy: build dict from DB for active window; overlay runtime (for ip/ua freshness)
    db_active = {s['id']: s for s in _active_sessions_from_db(ACTIVE_TTL)}
    with ACTIVE_LOCK:
        visitors = []
        for vid, meta in ACTIVE_VISITORS.items():
            if isinstance(meta,(int,float)):
                mem_first = meta
                mem_last = meta
                db_sess = db_active.get(vid)
                if db_sess:
                    first_ts = db_sess.get('first') or mem_first
                    last_ts = db_sess.get('last') or mem_last
                else:
                    first_ts = mem_first
                    last_ts = mem_last
            else:
                mem_first = meta.get('first') or meta.get('ts', now)
                mem_last = meta.get('ts', mem_first)
                db_sess = db_active.get(vid)
                if db_sess:
                    # Use earlier first (older session start) and later last (most recent activity)
                    first_ts = min(mem_first, db_sess.get('first') or mem_first)
                    last_ts = max(mem_last, db_sess.get('last') or mem_last)
                else:
                    first_ts, last_ts = mem_first, mem_last
            if first_ts > last_ts:
                first_ts, last_ts = last_ts, first_ts
            sess_age = int(now - first_ts)
            idle_age = int(now - last_ts)
            ua = (meta.get('ua') if isinstance(meta, dict) else '') or ''
            ip = (meta.get('ip') if isinstance(meta, dict) else '') or ''
            nickname = (meta.get('nickname') if isinstance(meta, dict) else '') or ''
            visitors.append({
                'id': vid,
                'ip': ip,
                'age': sess_age,
                'age_fmt': _fmt_age(sess_age),
                'ua': ua,
                'ua_short': _ua_label(ua) if ua else '',
                'last_seen': _fmt_age(idle_age),
                'nickname': nickname
            })
    blocked = load_blocked()
    # Load raw (pending geo) messages
    all_msgs = load_messages()
    raw_msgs = [m for m in reversed(all_msgs) if m.get('pending_geo')][:100]  # latest 100
    # Collect last N geo markers (exclude pending geo) for hide management
    recent_markers = [m for m in reversed(all_msgs) if m.get('lat') and m.get('lng') and not m.get('pending_geo')][:120]
    # --- Visit stats aggregation (prefer durable SQLite to survive redeploy) ---
    daily_unique, week_unique = sql_unique_counts()
    if daily_unique is None:
        # fallback to rolling sets file if DB unavailable
        daily_unique, week_unique = _recent_counts()
    if daily_unique is None:  # final fallback to json stats
        stats = _load_visit_stats()
        tz = pytz.timezone('Europe/Kyiv')
        now_dt = datetime.now(tz)
        today_str = now_dt.strftime('%Y-%m-%d')
        week_cut = now_dt - timedelta(days=7)
        daily_unique = 0
        week_unique = 0
        for vid, ts in stats.items():
            try:
                tsf = float(ts)
            except Exception:
                continue
            dt = datetime.fromtimestamp(tsf, tz)
            if dt.strftime('%Y-%m-%d') == today_str:
                daily_unique += 1
            if dt >= week_cut:
                week_unique += 1
    hidden_keys = load_hidden()
    parsed_hidden = []
    for hk in hidden_keys:
        try:
            coord_part, text_part, source_part = hk.split('|',2)
            lat_str, lng_str = coord_part.split(',',1)
            parsed_hidden.append({'lat':lat_str,'lng':lng_str,'text':text_part,'source':source_part,'key':hk})
        except Exception:
            continue
    
    # Load commercial subscriptions (from persistent storage)
    subscriptions = []
    if os.path.exists(COMMERCIAL_SUBSCRIPTIONS_FILE):
        try:
            with open(COMMERCIAL_SUBSCRIPTIONS_FILE, 'r', encoding='utf-8') as f:
                subscriptions = json.load(f)
            # Sort by timestamp (newest first)
            subscriptions.sort(key=lambda x: x.get('timestamp', ''), reverse=True)
        except Exception as e:
            print(f"❌ Failed to load subscriptions: {e}")
    
    return render_template(
        'admin.html',
        visitors=visitors,
        blocked=blocked,
        raw_msgs=raw_msgs,
        raw_count=len([m for m in all_msgs if m.get('pending_geo')]),
        secret=(request.args.get('secret') or ''),
        monitor_period=MONITOR_PERIOD_MINUTES,
        markers=recent_markers,
        daily_unique=daily_unique,
        week_unique=week_unique,
        hidden_markers=parsed_hidden,
        neg_geocode=list(_load_neg_geocode_cache().items())[:150],
        debug_logs=DEBUG_LOGS,
        redirect_stats=get_redirect_stats(),
        subscriptions=subscriptions
    )

@app.route('/admin/clear_debug_logs', methods=['POST'])
def clear_debug_logs():
    if not _require_secret(request):
        return jsonify({'status': 'forbidden'}), 403
    global DEBUG_LOGS
    DEBUG_LOGS.clear()
    return jsonify({'status': 'ok', 'cleared': True})

@app.route('/admin/set_monitor_period', methods=['POST'])
def set_monitor_period():
    if not _require_secret(request):
        return jsonify({'status': 'forbidden'}), 403
    global MONITOR_PERIOD_MINUTES
    payload = request.get_json(silent=True) or request.form
    try:
        val = int(payload.get('value'))
        if not (1 <= val <= 360):
            raise ValueError('out of range')
        MONITOR_PERIOD_MINUTES = val
        save_config()
        print(f"[DEBUG] MONITOR_PERIOD_MINUTES updated to {MONITOR_PERIOD_MINUTES} minutes")
        return jsonify({'status':'ok','monitor_period':MONITOR_PERIOD_MINUTES})
    except Exception as e:
        return jsonify({'status':'error','error':str(e)}), 400

@app.route('/admin/set_ai_ttl', methods=['POST'])
def set_ai_ttl():
    """Enable or disable AI-based marker TTL system"""
    if not _require_secret(request):
        return jsonify({'status': 'forbidden'}), 403
    global AI_TTL_ENABLED
    payload = request.get_json(silent=True) or request.form
    try:
        enabled = payload.get('enabled')
        if isinstance(enabled, str):
            enabled = enabled.lower() in ('true', '1', 'yes', 'on')
        AI_TTL_ENABLED = bool(enabled)
        print(f"[DEBUG] AI_TTL_ENABLED updated to {AI_TTL_ENABLED}")
        return jsonify({
            'status': 'ok',
            'ai_ttl_enabled': AI_TTL_ENABLED,
            'description': 'AI визначає час життя міток на основі типу загрози та контексту' if AI_TTL_ENABLED else 'Фіксований час життя міток з адмін панелі'
        })
    except Exception as e:
        return jsonify({'status': 'error', 'error': str(e)}), 400

@app.route('/admin/ai_ttl_status', methods=['GET'])
def get_ai_ttl_status():
    """Get current AI TTL status and configuration"""
    return jsonify({
        'ai_ttl_enabled': AI_TTL_ENABLED,
        'fallback_minutes': MONITOR_PERIOD_MINUTES,
        'threat_base_ttl': THREAT_BASE_TTL,
        'description': 'AI визначає час життя міток на основі типу загрози та контексту' if AI_TTL_ENABLED else 'Фіксований час життя міток з адмін панелі'
    })

@app.route('/admin/test_ai_ttl', methods=['POST'])
def test_ai_ttl():
    """Test AI TTL calculation for a message"""
    if not _require_secret(request):
        return jsonify({'status': 'forbidden'}), 403
    payload = request.get_json(silent=True) or {}
    text = payload.get('text', '')
    threat_type = payload.get('threat_type')
    distance_km = payload.get('distance_km')
    eta_minutes = payload.get('eta_minutes')
    
    result = calculate_ai_marker_ttl(
        message_text=text,
        threat_type=threat_type,
        distance_km=distance_km,
        eta_minutes=eta_minutes
    )
    
    # Convert datetime to string for JSON
    if 'expires_at' in result:
        result['expires_at'] = result['expires_at'].strftime('%Y-%m-%d %H:%M:%S')
    
    return jsonify(result)

@app.route('/admin/threat_tracker', methods=['GET'])
def admin_threat_tracker():
    """Get current threat tracking status"""
    active_threats = THREAT_TRACKER.get_all_active_threats()
    
    # Serialize threats for JSON
    threats_json = []
    for t in active_threats:
        threat_copy = {}
        for k, v in t.items():
            if isinstance(v, datetime):
                threat_copy[k] = v.isoformat()
            elif k == 'history':
                # Skip history for summary
                threat_copy[k] = len(v)
            else:
                threat_copy[k] = v
        threats_json.append(threat_copy)
    
    # Summary by type
    by_type = {}
    for t in active_threats:
        tt = t.get('threat_type', 'unknown')
        if tt not in by_type:
            by_type[tt] = {'count': 0, 'total_quantity': 0, 'destroyed': 0}
        by_type[tt]['count'] += 1
        by_type[tt]['total_quantity'] += t.get('quantity', 1)
        by_type[tt]['destroyed'] += t.get('quantity_destroyed', 0)
    
    return jsonify({
        'active_threats': threats_json,
        'by_type': by_type,
        'total_active': len(active_threats),
        'total_tracked': len(THREAT_TRACKER.threats),
        'regions_with_threats': list(THREAT_TRACKER.region_to_threats.keys())
    })

@app.route('/api/threats', methods=['GET'])
def api_threats():
    """Public API for active threats - used by frontend"""
    active_threats = THREAT_TRACKER.get_all_active_threats()
    
    # Generate markers for each threat
    markers = []
    for t in active_threats:
        marker = THREAT_TRACKER.get_marker_for_threat(t['id'])
        if marker and marker.get('lat') and marker.get('lng'):
            markers.append(marker)
    
    return jsonify({
        'threats': markers,
        'summary': {
            'total': len(markers),
            'by_type': {}
        }
    })

@app.route('/api/fusion/events', methods=['GET'])
def api_fusion_events():
    """
    API для отримання об'єднаних подій з системи злиття каналів.
    
    Повертає активні події з комбінованою інформацією з різних джерел.
    """
    try:
        events = CHANNEL_FUSION.get_active_events()
        
        # Group by status
        by_status = {
            'active': [],
            'partially_destroyed': [],
            'destroyed': [],
            'passed': [],
        }
        
        for event in events:
            status = event.get('status', 'active')
            if status in by_status:
                by_status[status].append(event)
            else:
                by_status['active'].append(event)
        
        # Serialize events
        serialized = []
        for event in events:
            ser_event = {
                'id': event['id'],
                'threat_type': event['threat_type'],
                'quantity': event['quantity'],
                'quantity_destroyed': event['quantity_destroyed'],
                'regions': event['regions'],
                'direction': event['direction'],
                'status': event['status'],
                'confidence': event['confidence'],
                'coordinates': event['best_coordinates'],
                'trajectory_points': len(event['trajectory']),
                'source_count': len(set(m['channel'] for m in event['messages'])),
                'sources': list(set(m['channel'] for m in event['messages'])),
                'created_at': event['created_at'].isoformat(),
                'last_update': event['last_update'].isoformat(),
            }
            serialized.append(ser_event)
        
        return jsonify({
            'status': 'ok',
            'events': serialized,
            'summary': {
                'total': len(events),
                'active': len(by_status['active']),
                'destroyed': len(by_status['destroyed']),
                'passed': len(by_status['passed']),
            }
        })
    except Exception as e:
        return jsonify({
            'status': 'error',
            'error': str(e)
        }), 500

@app.route('/api/fusion/markers', methods=['GET'])
def api_fusion_markers():
    """
    API для отримання маркерів з системи злиття.
    
    Ці маркери можна використовувати на карті замість звичайних.
    """
    try:
        markers = get_fused_markers()
        
        return jsonify({
            'status': 'ok',
            'markers': markers,
            'count': len(markers)
        })
    except Exception as e:
        return jsonify({
            'status': 'error',
            'error': str(e)
        }), 500

@app.route('/api/fusion/trajectories', methods=['GET'])
def api_fusion_trajectories():
    """
    API для отримання траєкторій руху загроз.
    
    Повертає траєкторії побудовані з послідовних повідомлень.
    """
    try:
        trajectories = get_fused_trajectories()
        
        return jsonify({
            'status': 'ok',
            'trajectories': trajectories,
            'count': len(trajectories)
        })
    except Exception as e:
        return jsonify({
            'status': 'error',
            'error': str(e)
        }), 500

@app.route('/api/fusion/status', methods=['GET'])
def api_fusion_status():
    """
    Статус системи злиття каналів.
    """
    try:
        with CHANNEL_FUSION.lock:
            total_events = len(CHANNEL_FUSION.fused_events)
            total_messages = len(CHANNEL_FUSION.message_to_event)
            
            # Count by channel
            channel_counts = {}
            ai_analyzed_count = 0
            for event in CHANNEL_FUSION.fused_events.values():
                for msg in event['messages']:
                    ch = msg['channel']
                    channel_counts[ch] = channel_counts.get(ch, 0) + 1
                # Check if AI analyzed
                sig = event.get('signature', {})
                if sig.get('ai_analyzed'):
                    ai_analyzed_count += 1
        
        return jsonify({
            'status': 'ok',
            'fusion_enabled': True,
            'ai_enabled': GROQ_ENABLED,
            'ai_model': GROQ_MODEL if GROQ_ENABLED else None,
            'ai_analyzed_events': ai_analyzed_count,
            'total_events': total_events,
            'total_messages_processed': total_messages,
            'by_channel': channel_counts,
            'channel_priorities': CHANNEL_FUSION.CHANNEL_PRIORITY,
            'mode': 'AI-FIRST' if GROQ_ENABLED else 'REGEX-FALLBACK',
        })
    except Exception as e:
        return jsonify({
            'status': 'error',
            'error': str(e)
        }), 500

@app.route('/admin/fusion/cleanup', methods=['POST'])
def admin_fusion_cleanup():
    """
    Примусове очищення старих подій fusion.
    """
    if not _require_secret(request):
        return jsonify({'status':'forbidden'}), 403
    
    try:
        removed = CHANNEL_FUSION.cleanup_old_events(max_age_hours=1)
        return jsonify({
            'status': 'ok',
            'removed_events': removed
        })
    except Exception as e:
        return jsonify({
            'status': 'error',
            'error': str(e)
        }), 500

@app.route('/admin/neg_geocode_clear', methods=['POST'])
def admin_neg_geocode_clear():
    if not _require_secret(request):
        return jsonify({'status':'forbidden'}), 403
    global _neg_geocode_cache
    _neg_geocode_cache = {}
    _save_neg_geocode_cache()
    return jsonify({'status':'ok','cleared':True})

@app.route('/admin/neg_geocode_delete', methods=['POST'])
def admin_neg_geocode_delete():
    if not _require_secret(request):
        return jsonify({'status':'forbidden'}), 403
    payload = request.get_json(silent=True) or {}
    name = (payload.get('name') or '').strip().lower()
    if not name:
        return jsonify({'status':'error','error':'name required'}),400
    cache = _load_neg_geocode_cache()
    if name in cache:
        del cache[name]
        _save_neg_geocode_cache()
        return jsonify({'status':'ok','deleted':True})
    return jsonify({'status':'error','error':'not found'}),404

@app.route('/admin/stats', methods=['GET'])
def admin_stats():
    """Get comprehensive system statistics for admin dashboard"""
    if not _require_secret(request):
        return jsonify({'status':'forbidden'}), 403
    
    try:
        all_msgs = load_messages()
        now = time.time()
        tz = pytz.timezone('Europe/Kyiv')
        
        # Message statistics
        total_messages = len(all_msgs)
        pending_geo = len([m for m in all_msgs if m.get('pending_geo')])
        with_coordinates = len([m for m in all_msgs if m.get('lat') and m.get('lng')])
        
        # Recent activity (last 24h)
        cutoff_24h = now - 86400
        recent_msgs = [m for m in all_msgs if _msg_timestamp(m) > cutoff_24h]
        
        # Threat type breakdown
        threat_counts = {}
        for msg in all_msgs:
            if not msg.get('pending_geo') and msg.get('lat') and msg.get('lng'):
                threat_type = msg.get('threat_type', 'unknown')
                threat_counts[threat_type] = threat_counts.get(threat_type, 0) + 1
        
        # System health
        with ACTIVE_LOCK:
            active_users = len(ACTIVE_VISITORS)
        blocked_users = len(load_blocked())
        hidden_markers = len(load_hidden())
        neg_cache_size = len(_load_neg_geocode_cache())
        debug_logs_count = len(DEBUG_LOGS)
        
        return jsonify({
            'status': 'ok',
            'stats': {
                'messages': {
                    'total': total_messages,
                    'pending_geo': pending_geo,
                    'with_coordinates': with_coordinates,
                    'recent_24h': len(recent_msgs)
                },
                'threats': threat_counts,
                'system': {
                    'active_users': active_users,
                    'blocked_users': blocked_users,
                    'hidden_markers': hidden_markers,
                    'neg_cache_size': neg_cache_size,
                    'debug_logs': debug_logs_count,
                    'monitor_period': MONITOR_PERIOD_MINUTES
                },
                'timestamp': now
            }
        })
    except Exception as e:
        return jsonify({'status': 'error', 'error': str(e)}), 500

# ==================== API PROTECTION MONITORING ====================
@app.route('/admin/protection_status', methods=['GET'])
def admin_protection_status():
    """Get API protection statistics for monitoring bandwidth/abuse."""
    if not _require_secret(request):
        return jsonify({'status':'forbidden'}), 403
    
    try:
        if API_PROTECTION_ENABLED:
            stats = get_protection_stats()
            return jsonify({
                'status': 'ok',
                'protection_enabled': True,
                'max_response_size_mb': MAX_RESPONSE_SIZE_BYTES / 1024 / 1024,
                'stats': stats,
                'endpoint_limits': {
                    '/data': {'max_tracks': 200, 'max_events': 100},
                    '/api/messages': {'max_messages': 100},
                    '/api/events': {'max_process': 500, 'max_return': 100},
                    '/api/alarm-history': {'max_days': 7, 'max_results': 200},
                    '/alarms_stats': {'max_limit': 500, 'max_minutes': 360},
                }
            })
        else:
            return jsonify({
                'status': 'ok',
                'protection_enabled': False,
                'message': 'API protection module not loaded'
            })
    except Exception as e:
        return jsonify({'status': 'error', 'error': str(e)}), 500
# ===================================================================

@app.route('/admin/cleanup', methods=['POST'])
def admin_cleanup():
    """Clean up old data to maintain performance"""
    if not _require_secret(request):
        return jsonify({'status':'forbidden'}), 403
    
    payload = request.get_json(silent=True) or {}
    days_to_keep = int(payload.get('days', 7))  # Keep last 7 days by default
    
    try:    
        cutoff_time = time.time() - (days_to_keep * 86400)
        
        # Clean old messages
        all_msgs = load_messages()
        old_count = len(all_msgs)
        new_msgs = [m for m in all_msgs if _msg_timestamp(m) > cutoff_time]
        
        # Always keep at least 100 most recent messages
        if len(new_msgs) < 100 and len(all_msgs) >= 100:
            new_msgs = sorted(all_msgs, key=_msg_timestamp, reverse=True)[:100]
        
        save_messages(new_msgs)
        
        # Clean old debug logs (keep last 500)
        global DEBUG_LOGS
        if len(DEBUG_LOGS) > 500:
            DEBUG_LOGS = DEBUG_LOGS[-500:]
        
        # Clean old visitor data from SQLite
        try:
            conn = sqlite3.connect(VISIT_DB_PATH)
            c = conn.cursor()
            c.execute("DELETE FROM visits WHERE first_seen < ?", (cutoff_time,))
            deleted_visits = c.rowcount
            conn.commit()
            conn.close()
        except Exception:
            deleted_visits = 0
        
        return jsonify({
            'status': 'ok',
            'cleaned': {
                'messages': old_count - len(new_msgs),
                'debug_logs': max(0, len(DEBUG_LOGS) - 500),
                'visitor_records': deleted_visits
            },
            'remaining': {
                'messages': len(new_msgs),
                'debug_logs': len(DEBUG_LOGS)
            }
        })
    except Exception as e:
        return jsonify({'status': 'error', 'error': str(e)}), 500

@app.route('/admin/export', methods=['GET'])
def admin_export():
    """Export data for backup/analysis"""
    if not _require_secret(request):
        return jsonify({'status':'forbidden'}), 403
    
    export_type = request.args.get('type', 'messages')
    
    try:
        if export_type == 'messages':
            all_msgs = load_messages()
            # Remove sensitive data
            clean_msgs = []
            for msg in all_msgs:
                clean_msg = {k: v for k, v in msg.items() if k not in ['id']}
                clean_msgs.append(clean_msg)
            return jsonify({'status': 'ok', 'data': clean_msgs, 'count': len(clean_msgs)})
        
        elif export_type == 'stats':
            with ACTIVE_LOCK:
                active_count = len(ACTIVE_VISITORS)
            
            return jsonify({
                'status': 'ok',
                'data': {
                    'active_users': active_count,
                    'blocked_users': len(load_blocked()),
                    'hidden_markers': len(load_hidden()),
                    'neg_cache_entries': len(_load_neg_geocode_cache()),
                    'debug_logs': len(DEBUG_LOGS),
                    'monitor_period': MONITOR_PERIOD_MINUTES,
                    'export_time': time.time()
                }
            })
        
        else:
            return jsonify({'status': 'error', 'error': 'Invalid export type'}), 400
    
    except Exception as e:
        return jsonify({'status': 'error', 'error': str(e)}), 500
        _save_neg_geocode_cache()
        return jsonify({'status':'ok','removed':name})
    return jsonify({'status':'ok','removed':None})

@app.route('/block', methods=['POST'])
def block_id():
    if not _require_secret(request):
        return jsonify({'status':'forbidden'}), 403
    payload = request.get_json(silent=True) or request.form
    vid = (payload or {}).get('id')
    if not vid:
        return jsonify({'status':'error','error':'id required'}), 400
    blocked = load_blocked()
    if vid not in blocked:
        blocked.append(vid)
        save_blocked(blocked)
    # push control event so client can self-block immediately
    broadcast_control({'type':'block','id':vid})
    return jsonify({'status':'ok','blocked':blocked})

@app.route('/unblock', methods=['POST'])
def unblock_id():
    if not _require_secret(request):
        return jsonify({'status':'forbidden'}), 403
    payload = request.get_json(silent=True) or request.form
    vid = (payload or {}).get('id')
    if not vid:
        return jsonify({'status':'error','error':'id required'}), 400
    blocked = load_blocked()
    if vid in blocked:
        blocked.remove(vid)
        save_blocked(blocked)
    return jsonify({'status':'ok','blocked':blocked})

@app.route('/admin/hidden_markers')
def admin_hidden_markers():
    """Return list of all hidden markers with metadata."""
    if not _require_secret(request):
        return jsonify({'status':'forbidden'}), 403
    hidden_keys = load_hidden()
    hidden_list = []
    for key in hidden_keys:
        try:
            parts = key.split('|', 2)
            if len(parts) >= 3:
                lat_lng, text, source = parts
                lat_str, lng_str = lat_lng.split(',')
                hidden_list.append({
                    'lat': float(lat_str),
                    'lng': float(lng_str),
                    'text': text,
                    'source': source,
                    'key': key
                })
        except Exception as e:
            log.warning(f"Failed to parse hidden marker key: {key}, error: {e}")
    return jsonify({'status':'ok', 'hidden': hidden_list, 'count': len(hidden_list)})

@app.route('/admin/unhide_marker', methods=['POST'])
def admin_unhide_marker():
    """Unhide a marker (alias for /unhide_marker with auth check)."""
    if not _require_secret(request):
        return jsonify({'status':'forbidden'}), 403
    return unhide_marker()

def _fmt_age(age_seconds:int)->str:
    # Format seconds to H:MM:SS (or M:SS if <1h)
    if age_seconds < 3600:
        m, s = divmod(age_seconds, 60)
        return f"{m}:{s:02d}"
    h, rem = divmod(age_seconds, 3600)
    m, s = divmod(rem, 60)
    return f"{h}:{m:02d}:{s:02d}"

def _ua_label(ua:str)->str:
    u = ua.lower()
    # Simple detection heuristics
    if 'android' in u:
        if 'wv' in u or 'version/' in u:
            base = 'Android WebView'
        else:
            base = 'Android'
    elif 'iphone' in u or 'ipad' in u or 'ipod' in u:
        base = 'iOS'
    elif 'mac os x' in u and 'mobile' not in u:
        base = 'macOS'
    elif 'windows nt' in u:
        base = 'Windows'
    elif 'linux' in u:
        base = 'Linux'
    else:
        base = 'Other'
    # Browser
    browser = 'Browser'
    if 'chrome/' in u and 'edg/' not in u and 'opr/' not in u:
        browser = 'Chrome'
    elif 'edg/' in u:
        browser = 'Edge'
    elif 'firefox/' in u:
        browser = 'Firefox'
    elif 'safari/' in u and 'chrome/' not in u:
        browser = 'Safari'
    elif 'opr/' in u or 'opera' in u:
        browser = 'Opera'
    return f"{base} {browser}"

# NOTE: _load_opencage_cache, _save_opencage_cache, SETTLEMENTS_* defined earlier in the file

# --------------- Optional Git auto-commit settings ---------------
GIT_AUTO_COMMIT = os.getenv('GIT_AUTO_COMMIT', '0') not in ('0','false','False','')
GIT_REPO_SLUG = os.getenv('GIT_REPO_SLUG')  # e.g. 'vavaika22423232/neptun'
GIT_SYNC_TOKEN = os.getenv('GIT_SYNC_TOKEN')  # GitHub PAT (classic or fine-grained) with repo write
GIT_COMMIT_INTERVAL = int(os.getenv('GIT_COMMIT_INTERVAL', '60'))  # seconds between commits (reduced for chat)
_last_git_commit = 0
_git_pull_done = False  # Track if initial pull was done

# Delay before first Telegram connect (helps избежать пересечения старого и нового инстанса при деплое)
FETCH_START_DELAY = int(os.getenv('FETCH_START_DELAY', '0'))  # seconds

def git_pull_on_startup():
    """Pull latest data from GitHub on startup to restore chat messages."""
    global _git_pull_done
    if _git_pull_done:
        return
    if not GIT_AUTO_COMMIT or not GIT_REPO_SLUG or not GIT_SYNC_TOKEN:
        log.info("Git sync not configured, skipping pull on startup")
        return
    if not os.path.isdir('.git'):
        log.warning("Not a git repo, skipping pull")
        return
    try:
        def run(cmd):
            return subprocess.run(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
        
        run('git config user.email "bot@local"')
        run('git config user.name "Auto Sync Bot"')
        
        safe_remote = f'https://x-access-token:{GIT_SYNC_TOKEN}@github.com/{GIT_REPO_SLUG}.git'
        remotes = run('git remote -v').stdout
        if 'origin' not in remotes or GIT_REPO_SLUG not in remotes:
            run('git remote remove origin')
            run(f'git remote add origin "{safe_remote}"')
        
        # Stash any local changes, pull, then pop
        run('git stash')
        pull_result = run('git pull origin main --rebase')
        run('git stash pop')
        
        if pull_result.returncode == 0:
            log.info("Git pull on startup successful - chat messages restored")
            # Copy pulled files to persistent storage if using /data directory
            _copy_git_files_to_persistent_storage()
        else:
            log.warning(f"Git pull failed: {pull_result.stderr}")
        
        _git_pull_done = True
    except Exception as e:
        log.error(f"Git pull on startup error: {e}")


def _copy_git_files_to_persistent_storage():
    """Copy files from git repo to persistent storage directory after pull."""
    import shutil
    persistent_dir = os.getenv('PERSISTENT_DATA_DIR', '/data')
    if not os.path.isdir(persistent_dir):
        log.info(f"No persistent storage at {persistent_dir}, skipping copy")
        return
    
    # Files to copy from repo root to persistent storage
    files_to_copy = ['chat_messages.json', 'messages.json', 'devices.json']
    
    for filename in files_to_copy:
        src = filename  # In repo root
        dst = os.path.join(persistent_dir, filename)
        
        if os.path.exists(src):
            try:
                # Only copy if source is newer or destination doesn't exist
                if not os.path.exists(dst):
                    shutil.copy2(src, dst)
                    log.info(f"Copied {src} to {dst}")
                else:
                    # Compare file sizes - copy if source has more data
                    src_size = os.path.getsize(src)
                    dst_size = os.path.getsize(dst)
                    if src_size > dst_size:
                        shutil.copy2(src, dst)
                        log.info(f"Updated {dst} from git (src={src_size}b, dst={dst_size}b)")
                    else:
                        log.info(f"Keeping existing {dst} (src={src_size}b, dst={dst_size}b)")
            except Exception as e:
                log.error(f"Error copying {src} to {dst}: {e}")

def maybe_git_autocommit():
    """If enabled, commit & push updated messages.json back to GitHub.
    Requirements:
      - Set GIT_AUTO_COMMIT=1
      - Provide GIT_REPO_SLUG (owner/repo)
      - Provide GIT_SYNC_TOKEN (PAT with repo write)
    The container build must include git (Render base images do).
    Commits throttled by GIT_COMMIT_INTERVAL seconds.
    """
    global _last_git_commit
    if not GIT_AUTO_COMMIT or not GIT_REPO_SLUG or not GIT_SYNC_TOKEN:
        return
    now = time.time()
    if now - _last_git_commit < GIT_COMMIT_INTERVAL:
        return
    if not os.path.isdir('.git'):
        raise RuntimeError('Not a git repo')
    
    # Copy files from persistent storage to repo root before committing
    _copy_persistent_files_to_git_repo()
    
    # Configure user (once)
    def run(cmd):
        return subprocess.run(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
    run('git config user.email "bot@local"')
    run('git config user.name "Auto Sync Bot"')
    # Set remote URL embedding token (avoid logging token!)
    safe_remote = f'https://x-access-token:{GIT_SYNC_TOKEN}@github.com/{GIT_REPO_SLUG}.git'
    # Do not print safe_remote (contains secret)
    # Update origin only if needed
    remotes = run('git remote -v').stdout
    if 'origin' not in remotes or GIT_REPO_SLUG not in remotes:
        run('git remote remove origin')
        run(f'git remote add origin "{safe_remote}"')
    # Stage & commit if there is a change (use repo root filenames, not /data paths)
    run('git add messages.json')
    run('git add chat_messages.json')
    run('git add devices.json')
    status = run('git status --porcelain').stdout
    if 'messages.json' not in status and 'chat_messages.json' not in status and 'devices.json' not in status:
        return  # no actual diff
    commit_msg = f'Update messages (auto)'  # no secrets
    run(f'git commit -m "{commit_msg}"')
    push_res = run('git push origin HEAD:main')
    if push_res.returncode == 0:
        _last_git_commit = now
        log.info("Git autocommit successful")
    else:
        # If push fails (e.g., diverged), attempt pull+rebase then push
        run('git fetch origin')
        run('git rebase origin/main || git rebase --abort')
        push_res2 = run('git push origin HEAD:main')
        if push_res2.returncode == 0:
            _last_git_commit = now
        # else: give up silently to avoid spamming logs


def _copy_persistent_files_to_git_repo():
    """Copy files from persistent storage to repo root for git commit."""
    import shutil
    persistent_dir = os.getenv('PERSISTENT_DATA_DIR', '/data')
    if not os.path.isdir(persistent_dir):
        return  # Not using persistent storage
    
    files_to_copy = ['chat_messages.json', 'messages.json', 'devices.json']
    
    for filename in files_to_copy:
        src = os.path.join(persistent_dir, filename)
        dst = filename  # Repo root
        
        if os.path.exists(src):
            try:
                shutil.copy2(src, dst)
            except Exception as e:
                log.error(f"Error copying {src} to {dst} for git: {e}")

# NOTE: _load_settlements() defined and called earlier in the file

"""(Removed duplicate legacy process_message; canonical version defined earlier.)"""

# ----------------------- Deferred initialization hooks -----------------------
# CPU OPTIMIZATION: Use before_first_request pattern manually
_INIT_BACKGROUND_DONE = False

def _init_background():
    global _INIT_BACKGROUND_DONE, INIT_ONCE
    if _INIT_BACKGROUND_DONE:
        return
    _INIT_BACKGROUND_DONE = True
    INIT_ONCE = True
    _startup_diagnostics()
    # Start background workers
    try:
        start_fetch_thread()
    except Exception as e:
        log.error(f'Failed to start fetch thread: {e}\n{traceback.format_exc()}')
    try:
        start_session_watcher()
    except Exception as e:
        log.error(f'Failed to start session watcher: {e}\n{traceback.format_exc()}')

@app.before_request
def _maybe_init_background():
    # CPU OPTIMIZATION: Skip quickly if already initialized
    if _INIT_BACKGROUND_DONE:
        return
    _init_background()

@app.route('/startup_diag')
def startup_diag():
    """Expose current diagnostic snapshot (no secrets)."""
    try:
        info = {
            'pid': os.getpid(),
            'python': sys.version.split()[0],
            'platform': platform.platform(),
            'channels': CHANNELS,
            'authorized': AUTH_STATUS,
            'messages_file_exists': os.path.exists(MESSAGES_FILE),
            'messages_count': len(load_messages()),
            'fetch_thread_started': FETCH_THREAD_STARTED,
            'session_present': bool(session_str),
            'retention_minutes': MESSAGES_RETENTION_MINUTES,
            'retention_max_count': MESSAGES_MAX_COUNT,
            'subscribers': len(SUBSCRIBERS),
            'cache_stats': RESPONSE_CACHE.stats(),  # HIGH-LOAD: Cache statistics
        }
        return jsonify(info)
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/cache-stats')
def cache_stats():
    """Get response cache statistics for monitoring."""
    stats = RESPONSE_CACHE.stats()
    # Also clean expired entries
    cleaned = RESPONSE_CACHE.clear_expired()
    stats['expired_cleaned'] = cleaned
    return jsonify(stats)


@app.route('/healthz')
def healthz():
    """Lightweight health endpoint for uptime monitors."""
    try:
        messages = load_messages()
        file_exists = os.path.exists(MESSAGES_FILE)
        latest_date = None
        for m in messages:
            candidate = m.get('date')
            if candidate and (latest_date is None or candidate > latest_date):
                latest_date = candidate
        payload = {
            'status': 'ok',
            'messages_count': len(messages),
            'manual_count': sum(1 for m in messages if m.get('manual')),
            'messages_file_size': os.path.getsize(MESSAGES_FILE) if file_exists else 0,
            'messages_file_present': file_exists,
            'latest_message_at': latest_date,
            'fetch_thread_started': FETCH_THREAD_STARTED,
            'backfill': BACKFILL_STATUS.copy(),
            'retention': {
                'minutes': MESSAGES_RETENTION_MINUTES,
                'max_count': MESSAGES_MAX_COUNT,
            },
        }
        return jsonify(payload)
    except Exception as exc:
        return jsonify({'status': 'error', 'error': str(exc)}), 500

@app.route('/admin/test-nominatim')
def test_nominatim():
    """Test if Nominatim is reachable from this server."""
    import time as time_module
    
    # Safely get settlements count
    try:
        all_settlements_count = len(UKRAINE_ALL_SETTLEMENTS) if UKRAINE_ALL_SETTLEMENTS else 0
    except:
        all_settlements_count = 0
    try:
        oblast_settlements_count = len(UKRAINE_SETTLEMENTS_BY_OBLAST) if UKRAINE_SETTLEMENTS_BY_OBLAST else 0
    except:
        oblast_settlements_count = 0
    
    results = {
        'nominatim': {'status': 'unknown', 'time_ms': 0, 'error': None},
        'settlements_db': {
            'all_loaded': all_settlements_count,
            'oblast_aware_loaded': oblast_settlements_count,
        },
        'memory_optimized': os.environ.get('MEMORY_OPTIMIZED', 'false'),
    }
    
    # Test Nominatim
    try:
        start = time_module.time()
        nominatim_url = 'https://nominatim.openstreetmap.org/search'
        params = {'q': 'Kyiv, Ukraine', 'format': 'json', 'limit': 1}
        headers = {'User-Agent': 'neptun.in.ua/1.0'}
        response = requests.get(nominatim_url, params=params, headers=headers, timeout=5)
        elapsed = (time_module.time() - start) * 1000
        
        results['nominatim']['time_ms'] = round(elapsed, 1)
        if response.status_code == 200:
            data = response.json()
            if data and len(data) > 0:
                results['nominatim']['status'] = 'ok'
                results['nominatim']['result'] = data[0].get('display_name', '')[:50]
            else:
                results['nominatim']['status'] = 'empty_response'
        else:
            results['nominatim']['status'] = f'http_{response.status_code}'
    except requests.exceptions.Timeout:
        results['nominatim']['status'] = 'timeout'
        results['nominatim']['error'] = 'Request timed out after 5s'
    except requests.exceptions.ConnectionError as e:
        results['nominatim']['status'] = 'connection_error'
        results['nominatim']['error'] = str(e)[:200]
    except Exception as e:
        results['nominatim']['status'] = 'error'
        results['nominatim']['error'] = str(e)[:200]
    
    return jsonify(results)

# Manual trigger (idempotent) if needed before first page hit
@app.route('/startup_init', methods=['POST'])
def startup_init():
    _init_background()
    return jsonify({'status': 'ok'})

# BANDWIDTH PROTECTION: Custom static route will compete with Flask's built-in route
# Flask will prioritize our custom route due to specificity

# Graceful shutdown handler
import atexit
import signal

# Force reload endpoints for admin
@app.route('/api/force-reload-status')
def force_reload_status():
    """Check if force reload flag is active"""
    global FORCE_RELOAD_TIMESTAMP
    with FORCE_RELOAD_LOCK:
        current_time = time.time()
        # Check if force reload is still active (within duration window)
        should_reload = (FORCE_RELOAD_TIMESTAMP > 0 and 
                        (current_time - FORCE_RELOAD_TIMESTAMP) < FORCE_RELOAD_DURATION)
    return jsonify({'reload': should_reload})

@app.route('/admin/trigger-force-reload', methods=['POST'])
def trigger_force_reload():
    """Admin endpoint to trigger force reload for all users"""
    if not _require_secret(request):
        return Response('Forbidden', status=403)
    
    global FORCE_RELOAD_TIMESTAMP
    with FORCE_RELOAD_LOCK:
        FORCE_RELOAD_TIMESTAMP = time.time()
    
    log.info("🔄 ADMIN: Force reload triggered for all users (active for {} seconds)".format(FORCE_RELOAD_DURATION))
    return jsonify({'success': True, 'message': 'Force reload activated for {} seconds'.format(FORCE_RELOAD_DURATION)})

def shutdown_scheduler():
    """Shutdown scheduler gracefully"""
    try:
        if 'scheduler' in globals() and hasattr(scheduler, 'running') and scheduler.running:
            log.info("Shutting down scheduler...")
            scheduler.shutdown(wait=False)
            log.info("✅ Scheduler shutdown complete")
    except Exception as e:
            log.error(f"Error shutting down scheduler: {e}")

# Register shutdown handlers
atexit.register(shutdown_scheduler)
signal.signal(signal.SIGTERM, lambda sig, frame: shutdown_scheduler())
signal.signal(signal.SIGINT, lambda sig, frame: shutdown_scheduler())


# ========== Firebase Cloud Messaging Endpoints ==========

@app.route('/api/register-device', methods=['POST'])
def register_device():
    """Register a device for push notifications."""
    try:
        data = request.get_json()
        token = data.get('token')
        regions = data.get('regions', [])
        device_id = data.get('device_id', token)
        enabled = data.get('enabled', True)  # Support disabling notifications

        if not token and not device_id:
            return jsonify({'error': 'Missing token or device_id'}), 400

        # If notifications disabled or no regions, remove device
        if not enabled or not regions:
            device_store.remove_device(device_id)
            log.info(f"Device {device_id[:20]}... unregistered (notifications disabled)")
            return jsonify({'success': True, 'device_id': device_id, 'status': 'unregistered'})

        device_store.register_device(token, regions, device_id)
        return jsonify({'success': True, 'device_id': device_id})
    except Exception as e:
        log.error(f"Error registering device: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/api/update-regions', methods=['POST'])
def update_regions():
    """Update regions for an existing device."""
    try:
        data = request.get_json()
        device_id = data.get('device_id')
        regions = data.get('regions', [])

        if not device_id or not regions:
            return jsonify({'error': 'Missing device_id or regions'}), 400

        device_store.update_regions(device_id, regions)
        return jsonify({'success': True})
    except Exception as e:
        log.error(f"Error updating regions: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/api/registered-devices', methods=['GET'])
def get_registered_devices():
    """Get all registered devices (for debugging)."""
    try:
        devices = device_store._load()
        # Mask tokens for security (show only last 10 chars) but show length
        for device_id, data in devices.items():
            if 'token' in data:
                token = data['token']
                data['token_length'] = len(token)
                data['token'] = '...' + token[-10:] if len(token) > 10 else token
        return jsonify({
            'count': len(devices),
            'devices': devices
        })
    except Exception as e:
        log.error(f"Error getting devices: {e}")
        return jsonify({'error': str(e)}), 500


# ============ FEEDBACK / BUG REPORTS ============
# Ensure we use persistent storage for feedback
if PERSISTENT_DATA_DIR and os.path.isdir(PERSISTENT_DATA_DIR):
    FEEDBACK_FILE = os.path.join(PERSISTENT_DATA_DIR, 'feedback.json')
    log.info(f'Feedback will be saved to persistent storage: {FEEDBACK_FILE}')
else:
    FEEDBACK_FILE = 'feedback.json'
    log.warning(f'Feedback will be saved locally (not persistent): {FEEDBACK_FILE}')

def load_feedback():
    """Load feedback messages."""
    try:
        if os.path.exists(FEEDBACK_FILE):
            with open(FEEDBACK_FILE, 'r', encoding='utf-8') as f:
                data = json.load(f)
                log.info(f"Loaded {len(data)} feedback items from {FEEDBACK_FILE}")
                return data
    except Exception as e:
        log.error(f"Error loading feedback: {e}")
    return []

def save_feedback(feedback_list):
    """Save feedback messages."""
    try:
        # Ensure directory exists
        feedback_dir = os.path.dirname(FEEDBACK_FILE)
        if feedback_dir and not os.path.exists(feedback_dir):
            os.makedirs(feedback_dir, exist_ok=True)
        
        with open(FEEDBACK_FILE, 'w', encoding='utf-8') as f:
            json.dump(feedback_list, f, ensure_ascii=False, indent=2)
        log.info(f"Saved {len(feedback_list)} feedback items to {FEEDBACK_FILE}")
    except Exception as e:
        log.error(f"Error saving feedback: {e}")

@app.route('/api/feedback', methods=['POST'])
def submit_feedback():
    """Submit user feedback or bug report."""
    try:
        data = request.get_json()
        message = data.get('message', '').strip()
        feedback_type = data.get('type', 'bug')  # 'bug', 'suggestion', 'other'
        device_id = data.get('device_id', '')
        device = data.get('device', '')  # iOS, Android, etc
        app_version = data.get('app_version', '')
        regions = data.get('regions', [])  # User's selected regions
        
        if not message:
            return jsonify({'error': 'Message is required'}), 400
        
        if len(message) > 5000:
            message = message[:5000]
        
        # Create feedback entry
        kyiv_tz = pytz.timezone('Europe/Kiev')
        now = datetime.now(kyiv_tz)
        
        feedback_entry = {
            'id': str(uuid.uuid4()),
            'type': feedback_type,
            'message': message,
            'device': device,
            'device_id': device_id[:50] if device_id else '',
            'app_version': app_version,
            'regions': regions[:10] if isinstance(regions, list) else [],  # Max 10 regions
            'timestamp': now.timestamp(),
            'date': now.strftime('%Y-%m-%d %H:%M:%S'),
            'status': 'new'
        }
        
        # Load, append, save
        feedback_list = load_feedback()
        feedback_list.append(feedback_entry)
        # Keep only last 500 entries
        if len(feedback_list) > 500:
            feedback_list = feedback_list[-500:]
        save_feedback(feedback_list)
        
        log.info(f"📩 New feedback received: {feedback_type} - {message[:50]}...")
        
        return jsonify({
            'success': True,
            'message': 'Дякуємо за ваш відгук!'
        })
    except Exception as e:
        log.error(f"Error submitting feedback: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/feedback', methods=['GET'])
def get_feedback():
    """Get all feedback (for admin) with nice HTML interface."""
    try:
        # Simple auth check
        auth_key = request.args.get('key', '')
        if auth_key != os.getenv('ADMIN_KEY', 'neptun_admin_2024'):
            return jsonify({'error': 'Unauthorized'}), 401
        
        feedback_list = load_feedback()
        
        # Check if JSON format requested
        if request.args.get('format') == 'json':
            return jsonify({
                'success': True,
                'feedback': feedback_list,
                'count': len(feedback_list)
            })
        
        # Sort by date (newest first)
        feedback_list.sort(key=lambda x: x.get('timestamp', ''), reverse=True)
        
        # Generate HTML
        html = '''<!DOCTYPE html>
<html lang="uk">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>NEPTUN - Зворотній зв'язок</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, sans-serif;
            background: linear-gradient(135deg, #1a1a2e 0%, #16213e 50%, #0f3460 100%);
            min-height: 100vh;
            color: #e0e0e0;
            padding: 20px;
        }
        
        .container {
            max-width: 900px;
            margin: 0 auto;
        }
        
        header {
            text-align: center;
            padding: 30px 0;
            margin-bottom: 30px;
        }
        
        h1 {
            font-size: 2.5rem;
            background: linear-gradient(90deg, #00d4ff, #7b2ff7);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
            margin-bottom: 10px;
        }
        
        .stats {
            display: flex;
            justify-content: center;
            gap: 30px;
            margin-bottom: 30px;
        }
        
        .stat-card {
            background: rgba(255, 255, 255, 0.1);
            backdrop-filter: blur(10px);
            border-radius: 16px;
            padding: 20px 40px;
            text-align: center;
            border: 1px solid rgba(255, 255, 255, 0.1);
        }
        
        .stat-number {
            font-size: 2.5rem;
            font-weight: bold;
            color: #00d4ff;
        }
        
        .stat-label {
            font-size: 0.9rem;
            color: #888;
            margin-top: 5px;
        }
        
        .feedback-list {
            display: flex;
            flex-direction: column;
            gap: 20px;
        }
        
        .feedback-card {
            background: rgba(255, 255, 255, 0.05);
            backdrop-filter: blur(10px);
            border-radius: 16px;
            padding: 25px;
            border: 1px solid rgba(255, 255, 255, 0.1);
            transition: transform 0.2s, box-shadow 0.2s;
        }
        
        .feedback-card:hover {
            transform: translateY(-2px);
            box-shadow: 0 10px 40px rgba(0, 212, 255, 0.1);
            border-color: rgba(0, 212, 255, 0.3);
        }
        
        .feedback-header {
            display: flex;
            justify-content: space-between;
            align-items: flex-start;
            margin-bottom: 15px;
        }
        
        .feedback-meta {
            display: flex;
            flex-direction: column;
            gap: 5px;
        }
        
        .feedback-device {
            font-size: 0.85rem;
            color: #888;
            display: flex;
            align-items: center;
            gap: 8px;
        }
        
        .feedback-device .icon {
            font-size: 1.1rem;
        }
        
        .feedback-time {
            font-size: 0.8rem;
            color: #666;
            background: rgba(255, 255, 255, 0.05);
            padding: 5px 12px;
            border-radius: 20px;
        }
        
        .feedback-text {
            background: rgba(0, 0, 0, 0.2);
            border-radius: 12px;
            padding: 20px;
            font-size: 1rem;
            line-height: 1.6;
            color: #f0f0f0;
            white-space: pre-wrap;
            word-break: break-word;
        }
        
        .feedback-regions {
            margin-top: 15px;
            display: flex;
            flex-wrap: wrap;
            gap: 8px;
        }
        
        .region-tag {
            background: linear-gradient(135deg, #7b2ff7 0%, #f107a3 100%);
            padding: 5px 12px;
            border-radius: 20px;
            font-size: 0.8rem;
            font-weight: 500;
        }
        
        .empty-state {
            text-align: center;
            padding: 60px 20px;
            color: #666;
        }
        
        .empty-state .icon {
            font-size: 4rem;
            margin-bottom: 20px;
        }
        
        .refresh-btn {
            position: fixed;
            bottom: 30px;
            right: 30px;
            background: linear-gradient(135deg, #00d4ff 0%, #7b2ff7 100%);
            color: white;
            border: none;
            padding: 15px 25px;
            border-radius: 30px;
            cursor: pointer;
            font-size: 1rem;
            font-weight: 600;
            box-shadow: 0 4px 20px rgba(0, 212, 255, 0.3);
            transition: transform 0.2s, box-shadow 0.2s;
        }
        
        .refresh-btn:hover {
            transform: scale(1.05);
            box-shadow: 0 6px 30px rgba(0, 212, 255, 0.4);
        }
        
        @media (max-width: 600px) {
            h1 { font-size: 1.8rem; }
            .stats { flex-direction: column; gap: 15px; }
            .stat-card { padding: 15px 30px; }
            .feedback-header { flex-direction: column; gap: 10px; }
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>🌊 NEPTUN Feedback</h1>
            <p style="color: #888;">Адмін-панель зворотнього зв'язку</p>
            <p style="color: #555; font-size: 0.8rem; margin-top: 5px;">💾 ''' + ('Persistent: ' + FEEDBACK_FILE if '/data' in FEEDBACK_FILE else '⚠️ Local: ' + FEEDBACK_FILE) + '''</p>
        </header>
        
        <div class="stats">
            <div class="stat-card">
                <div class="stat-number">''' + str(len(feedback_list)) + '''</div>
                <div class="stat-label">Всього повідомлень</div>
            </div>
            <div class="stat-card">
                <div class="stat-number">''' + str(len([f for f in feedback_list if str(f.get('timestamp', ''))[:10] == datetime.now().strftime('%Y-%m-%d')])) + '''</div>
                <div class="stat-label">Сьогодні</div>
            </div>
        </div>
        
        <div class="feedback-list">'''
        
        if not feedback_list:
            html += '''
            <div class="empty-state">
                <div class="icon">📭</div>
                <h3>Поки немає повідомлень</h3>
                <p>Користувачі ще не надіслали зворотній зв'язок</p>
            </div>'''
        else:
            for fb in feedback_list:
                # Get device info
                device = fb.get('device', '') or fb.get('device_id', '') or 'Невідомий пристрій'
                app_version = fb.get('app_version', '')
                feedback_type = fb.get('type', 'bug')
                
                # Determine device icon
                if 'iphone' in device.lower() or 'ios' in device.lower():
                    device_icon = '📱'
                elif 'android' in device.lower():
                    device_icon = '🤖'
                else:
                    device_icon = '💻'
                
                # Type badge
                type_badge = {'bug': '🐛 Баг', 'suggestion': '💡 Ідея', 'other': '📝 Інше'}.get(feedback_type, '📝')
                
                # Format timestamp
                ts = fb.get('timestamp', '')
                try:
                    if isinstance(ts, (int, float)):
                        # Unix timestamp
                        dt = datetime.fromtimestamp(ts)
                        formatted_time = dt.strftime('%d.%m.%Y %H:%M')
                    elif isinstance(ts, str) and ts:
                        dt = datetime.fromisoformat(ts.replace('Z', '+00:00'))
                        formatted_time = dt.strftime('%d.%m.%Y %H:%M')
                    else:
                        formatted_time = fb.get('date', 'Невідомо')
                except:
                    formatted_time = fb.get('date', str(ts)[:16] if ts else 'Невідомо')
                
                # Escape HTML in text - use 'message' field!
                text = fb.get('message', '') or fb.get('text', '')
                text = text.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')
                device_display = f"{device}" + (f" (v{app_version})" if app_version else "")
                device_escaped = device_display.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')
                
                # Get regions
                regions = fb.get('regions', [])
                
                html += f'''
            <div class="feedback-card">
                <div class="feedback-header">
                    <div class="feedback-meta">
                        <div class="feedback-device">
                            <span class="icon">{device_icon}</span>
                            <span>{device_escaped}</span>
                            <span style="margin-left: 10px; background: rgba(255,255,255,0.1); padding: 3px 8px; border-radius: 10px; font-size: 0.75rem;">{type_badge}</span>
                        </div>
                    </div>
                    <div class="feedback-time">🕐 {formatted_time}</div>
                </div>
                <div class="feedback-text">{text if text else "<i style='color:#666'>Порожнє повідомлення</i>"}</div>'''
                
                if regions:
                    html += '''
                <div class="feedback-regions">'''
                    for region in regions[:5]:  # Show max 5 regions
                        region_escaped = region.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')
                        html += f'''
                    <span class="region-tag">📍 {region_escaped}</span>'''
                    if len(regions) > 5:
                        html += f'''
                    <span class="region-tag">+{len(regions) - 5} ще</span>'''
                    html += '''
                </div>'''
                
                html += '''
            </div>'''
        
        html += '''
        </div>
    </div>
    
    <button class="refresh-btn" onclick="location.reload()">🔄 Оновити</button>
</body>
</html>'''
        
        return html, 200, {'Content-Type': 'text/html; charset=utf-8'}
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/test-notification', methods=['POST'])
def test_notification():
    """Send a test notification to a device."""
    if not firebase_initialized:
        return jsonify({'error': 'Firebase not initialized'}), 500

    try:
        from firebase_admin import messaging
        
        data = request.get_json()
        token = data.get('token')
        device_id = data.get('device_id')
        title = data.get('title', '🧪 Тестове сповіщення')
        body = data.get('body', 'NEPTUN працює коректно!')
        region = data.get('region', 'Тест')

        # If device_id provided, look up the token
        if not token and device_id:
            devices = device_store._load()
            device_data = devices.get(device_id)
            if device_data:
                token = device_data.get('token')

        if not token:
            return jsonify({'error': 'Missing token or device_id'}), 400

        # For Android: DATA-ONLY message (no notification) so background handler processes TTS
        message = messaging.Message(
            # NO notification block for Android - only data!
            data={
                'type': 'alarm',
                'title': title,
                'body': body,
                'region': region,
                'alarm_state': 'active',
                'is_critical': 'true',
                'timestamp': datetime.now(pytz.UTC).isoformat(),
            },
            android=messaging.AndroidConfig(
                priority='high',
            ),
            token=token,
        )

        response = messaging.send(message)
        log.info(f"Test notification sent successfully: {response}")
        return jsonify({'success': True, 'message_id': response})
        return jsonify({'success': True, 'message_id': response})
    except messaging.UnregisteredError:
        # Token is invalid - remove device from store
        log.warning(f"Token is invalid (UnregisteredError), removing device...")
        device_store.remove_device(token)
        return jsonify({'error': 'NotRegistered', 'message': 'Token is invalid and was removed. Please re-register the device.'}), 410
    except Exception as e:
        error_msg = str(e)
        if 'NotRegistered' in error_msg or 'not registered' in error_msg.lower():
            log.warning(f"Token not registered, removing device...")
            device_store.remove_device(token)
            return jsonify({'error': 'NotRegistered', 'message': 'Token is invalid and was removed. Please re-register the device.'}), 410
        log.error(f"Error sending test notification: {e}")
        return jsonify({'error': str(e)}), 500


def send_fcm_notification(message_data: dict):
    """Send FCM notification for a new threat message."""
    if not firebase_initialized:
        log.warning("Firebase not initialized, skipping notifications")
        return

    try:
        from firebase_admin import messaging
        import re
        
        # Check if this is a real threat (not just informational message)
        threat_type = message_data.get('threat_type', '') or message_data.get('type', '') or ''
        text = message_data.get('text', '') or ''
        text_lower = text.lower()
        
        # Check if this is an "all clear" message (відбій)
        is_all_clear = any(kw in text_lower for kw in ['відбій', 'скасовано', 'завершено'])
        
        # Skip only truly informational messages (not відбій - we want to notify about all clear too)
        skip_keywords = ['немає загрози', 'безпечно', 'інформація', 'увага!', 'попередження']
        if any(kw in text_lower for kw in skip_keywords):
            log.info(f"Skipping FCM for informational message: {text[:50]}...")
            return
            
        # Skip if no threat type detected AND not an all clear message
        if not threat_type and not is_all_clear:
            log.info(f"Skipping FCM for message without threat type")
            return
        
        # Use 'place' field for location (it's the geocoded place name)
        location = message_data.get('place', '') or message_data.get('location', '') or ''
        
        # CRITICAL: Extract specific city from text if format is "City (Oblast обл.)"
        # Example: "Овруч (Житомирська обл.) Загроза застосування БПЛА" -> city = "Овруч"
        city_from_text = ''
        if text:
            # Pattern: "City (Oblast обл.)" - extract city before parentheses
            city_oblast_match = re.search(r'^[^а-яіїєґА-ЯІЇЄҐ]*([А-ЯІЇЄҐа-яіїєґ][а-яіїєґА-ЯІЇЄҐ\'\-\s]+?)\s*\([^)]*обл[^)]*\)', text)
            if city_oblast_match:
                city_from_text = city_oblast_match.group(1).strip()
                # Clean up emoji and special chars at the beginning
                city_from_text = re.sub(r'^[^\w\s]+\s*', '', city_from_text).strip()
                log.info(f"Extracted city from text: '{city_from_text}' (full text: {text[:80]})")
        
        # Use extracted city if available, otherwise fall back to place
        specific_location = city_from_text if city_from_text else location
        
        if not specific_location and not location:
            log.info(f"Skipping FCM for message without place")
            return
        
        log.info(f"=== FCM NOTIFICATION TRIGGERED ===")
        log.info(f"Place (original): {location}")
        log.info(f"City (extracted): {city_from_text}")
        log.info(f"Location for TTS: {specific_location}")
        log.info(f"Threat type: {threat_type}")
        
        # Find matching region - search in place field AND in text for oblast pattern
        # to handle "Овруч (Житомирська обл.)" format
        region = None
        place_lower = location.lower()
        text_for_region = text.lower() if text else ''
        
        # First try to extract region from text with "(Oblast обл.)" pattern
        oblast_in_text = re.search(r'\(([а-яіїєґ]+ська)\s+обл\.?\)', text_for_region)
        if oblast_in_text:
            oblast_adj = oblast_in_text.group(1)  # e.g., "житомирська"
            log.info(f"Found oblast in text: {oblast_adj}")
        
        # Region mapping - keywords to match ONLY in place name
        regions_map = {
            'Київ': ['київ', 'києв'],
            'Київська область': ['київська обл', 'київська', 'київщин', 'бориспіль', 'бровар', 'ірпін', 'буча', 'вишгород', 'фастів', 'біла церква'],
            'Дніпропетровська область': ['дніпропетровська', 'дніпропетровськ', 'дніпро', 'кривий ріг', 'кам\'янськ', 'нікополь', 'павлоград'],
            'Харківська область': ['харківська', 'харків', 'харьков', 'ізюм', 'куп\'янськ', 'чугуїв', 'лозова'],
            'Одеська область': ['одеська', 'одес', 'одещин', 'ізмаїл', 'білгород-дністровськ', 'чорноморськ'],
            'Львівська область': ['львівська', 'львів', 'львівщин', 'дрогобич', 'стрий', 'червоноград'],
            'Донецька область': ['донецька', 'донецьк', 'донеч', 'маріуполь', 'краматорськ', 'слов\'янськ', 'бахмут', 'покровськ'],
            'Запорізька область': ['запорізька', 'запоріж', 'мелітополь', 'бердянськ', 'енергодар'],
            'Вінницька область': ['вінницька', 'вінниц', 'жмеринка', 'козятин', 'хмільник'],
            'Житомирська область': ['житомирська', 'житомир', 'бердичів', 'коростень', 'новоград', 'овруч'],
            'Черкаська область': ['черкаська', 'черкас', 'умань', 'сміла', 'золотоноша'],
            'Чернігівська область': ['чернігівська', 'чернігів', 'чернігов', 'ніжин', 'прилуки', 'корюків'],
            'Чернівецька область': ['чернівецька', 'чернівці', 'чернівц', 'чернівеч', 'буковина', 'новодністровськ', 'вижниця', 'сторожинець'],
            'Полтавська область': ['полтавська', 'полтав', 'кременчук', 'миргород', 'лубни'],
            'Сумська область': ['сумська', 'сум', 'конотоп', 'шостка', 'ромни', 'охтирка'],
            'Миколаївська область': ['миколаївська', 'миколаїв', 'миколаєв', 'первомайськ', 'вознесенськ'],
            'Херсонська область': ['херсонська', 'херсон', 'нова каховка', 'каховка'],
            'Кіровоградська область': ['кіровоградська', 'кіровоград', 'кропивниц', 'олександрія', 'знам\'янка'],
            'Хмельницька область': ['хмельницька', 'хмельниц', 'кам\'янець-подільськ', 'шепетівка'],
            'Рівненська область': ['рівненська', 'рівн', 'рівне', 'дубно', 'костопіль', 'дубровиц'],
            'Волинська область': ['волинська', 'волин', 'луцьк', 'ковель', 'нововолинськ'],
            'Тернопільська область': ['тернопільська', 'тернопіль', 'чортків', 'кременець'],
            'Івано-Франківська область': ['івано-франківська', 'івано-франків', 'калуш', 'коломия', 'надвірна'],
            'Закарпатська область': ['закарпатська', 'закарпат', 'ужгород', 'мукачево', 'хуст', 'берегово'],
            'Луганська область': ['луганська', 'луганськ', 'луганщин', 'сєвєродонецьк', 'лисичанськ'],
        }
        
        # First search in text for oblast pattern (most reliable for "City (Oblast обл.)" format)
        # IMPORTANT: Search for LONGEST matching keyword first to avoid confusion
        # between similar names like "Чернівці" vs "Чернігів"
        best_match = None
        best_keyword_len = 0
        
        for region_name, keywords in regions_map.items():
            for keyword in keywords:
                if keyword in text_for_region:
                    # Prefer longer (more specific) matches
                    if len(keyword) > best_keyword_len:
                        best_match = region_name
                        best_keyword_len = len(keyword)
                        log.info(f"Found potential match: {region_name} (keyword: '{keyword}', len={len(keyword)})")
        
        if best_match:
            region = best_match
            log.info(f"Best match from text: {region} (keyword length: {best_keyword_len})")
        
        # Fallback: search in place field
        if not region:
            best_match = None
            best_keyword_len = 0
            for region_name, keywords in regions_map.items():
                for keyword in keywords:
                    if keyword in place_lower:
                        if len(keyword) > best_keyword_len:
                            best_match = region_name
                            best_keyword_len = len(keyword)
                            log.info(f"Found potential match from place: {region_name} (keyword: '{keyword}')")
            if best_match:
                region = best_match
                log.info(f"Best match from place: {region}")
        
        if not region:
            log.info(f"Could not determine region for place: {location}")
            return

        # Determine if critical
        threat_lower = threat_type.lower()
        is_critical = any(kw in threat_lower for kw in ['ракет', 'балістич', 'kab', 'cruise', 'ballistic'])
        
        # Map internal threat codes to human-readable Ukrainian text for TTS
        threat_type_map = {
            'alarm': 'Повітряна тривога',
            'alarm_cancel': 'Відбій тривоги',
            'shahed': 'Загроза БПЛА',
            'raketa': 'Загроза ракетної атаки',
            'kab': 'Загроза КАБ',
            'fpv': 'Загроза FPV-дронів',
            'avia': 'Загроза авіаційної атаки',
            'vibuh': 'Вибухи',
            'artillery': 'Загроза обстрілу',
            'rozved': 'Розвідувальні дрони',
            'pusk': 'Пуски дронів',
            'vidboi': 'Відбій',
            'rszv': 'Загроза РСЗВ',
        }
        
        # Get human-readable threat type for notifications
        readable_threat_type = threat_type_map.get(threat_type, threat_type) if threat_type else ''
        
        # Create notification - different format for all clear vs threat
        if is_all_clear:
            title = f"🟢 Відбій тривоги"
            body = f"{specific_location}"
            alarm_state = 'ended'
            readable_threat_type = 'Відбій тривоги'
        else:
            title = f"{'🚨' if is_critical else '⚠️'} {readable_threat_type}"
            body = f"{specific_location}"
            alarm_state = 'active'

        # Send to Firebase topic for this region (more efficient than individual tokens)
        # Topic name format: region_kyivska, region_kharkivska, etc.
        region_topic_map = {
            'Київ': 'region_kyiv_city',
            'Київська область': 'region_kyivska',
            'Дніпропетровська область': 'region_dnipropetrovska',
            'Харківська область': 'region_kharkivska',
            'Одеська область': 'region_odeska',
            'Львівська область': 'region_lvivska',
            'Донецька область': 'region_donetska',
            'Запорізька область': 'region_zaporizka',
            'Вінницька область': 'region_vinnytska',
            'Житомирська область': 'region_zhytomyrska',
            'Черкаська область': 'region_cherkaska',
            'Чернігівська область': 'region_chernihivska',
            'Полтавська область': 'region_poltavska',
            'Сумська область': 'region_sumska',
            'Миколаївська область': 'region_mykolaivska',
            'Херсонська область': 'region_khersonska',
            'Кіровоградська область': 'region_kirovohradska',
            'Хмельницька область': 'region_khmelnytska',
            'Рівненська область': 'region_rivnenska',
            'Волинська область': 'region_volynska',
            'Тернопільська область': 'region_ternopilska',
            'Івано-Франківська область': 'region_ivano_frankivska',
            'Закарпатська область': 'region_zakarpatska',
            'Чернівецька область': 'region_chernivetska',
            'Луганська область': 'region_luhanska',
        }
        
        topic = region_topic_map.get(region)
        if not topic:
            log.warning(f"No topic mapping for region: {region}")
            return
        
        log.info(f"Sending FCM to topic: {topic}")

        # Send via topic (reaches all subscribed devices at once)
        success_count = 0
        try:
            message = messaging.Message(
                notification=messaging.Notification(
                    title=title,
                    body=body,
                ),
                data={
                    'type': 'all_clear' if is_all_clear else ('rocket' if is_critical else 'drone'),
                    'location': specific_location,  # Specific city for TTS
                    'body': specific_location,  # Also in body for foreground handler
                    'threat_type': readable_threat_type if readable_threat_type else 'Повітряна тривога',
                    'region': region,
                    'alarm_state': alarm_state,
                    'is_critical': 'true' if is_critical else 'false',
                    'timestamp': message_data.get('date', ''),
                    'click_action': 'FLUTTER_NOTIFICATION_CLICK',
                },
                android=messaging.AndroidConfig(
                    priority='high' if not is_all_clear else 'normal',
                    ttl=timedelta(seconds=300),
                    notification=messaging.AndroidNotification(
                        channel_id='critical_alerts' if is_critical else ('normal_alerts' if not is_all_clear else 'all_clear_alerts'),
                        priority='max' if is_critical else ('high' if not is_all_clear else 'default'),
                    ),
                ),
                apns=messaging.APNSConfig(
                    headers={
                        'apns-priority': '10',
                        'apns-push-type': 'alert',
                    },
                    payload=messaging.APNSPayload(
                        aps=messaging.Aps(
                            alert=messaging.ApsAlert(title=title, body=body),
                            sound='default',
                            content_available=True,
                        ),
                    ),
                ),
                topic=topic,  # Send to topic instead of individual token
            )
            
            response = messaging.send(message)
            success_count = 1
            log.info(f"✅ Topic notification sent to {topic}: {response}")
        except Exception as e:
            log.error(f"Failed to send topic notification to {topic}: {e}")
        
        # Also send to 'all_regions' topic for users who want all alerts
        try:
            message_all = messaging.Message(
                notification=messaging.Notification(
                    title=title,
                    body=body,
                ),
                data={
                    'type': 'all_clear' if is_all_clear else ('rocket' if is_critical else 'drone'),
                    'location': specific_location,
                    'body': specific_location,
                    'threat_type': readable_threat_type if readable_threat_type else 'Повітряна тривога',
                    'region': region,
                    'alarm_state': alarm_state,
                    'is_critical': 'true' if is_critical else 'false',
                    'timestamp': message_data.get('date', ''),
                    'click_action': 'FLUTTER_NOTIFICATION_CLICK',
                },
                android=messaging.AndroidConfig(
                    priority='high' if not is_all_clear else 'normal',
                    ttl=timedelta(seconds=300),
                ),
                topic='all_regions',
            )
            
            response_all = messaging.send(message_all)
            log.info(f"✅ All-regions notification sent: {response_all}")
        except Exception as e:
            log.error(f"Failed to send all_regions notification: {e}")
        
        log.info(f"Sent notifications for region: {region} (topic: {topic})")
    except Exception as e:
        log.error(f"Error in send_fcm_notification: {e}")


# ============== ANONYMOUS CHAT API ==============
MAX_CHAT_MESSAGES = 500  # Keep last 500 messages
_chat_initialized = False

def load_chat_messages():
    """Load chat messages from file. On first call, try git pull to restore from repo."""
    global _chat_initialized
    try:
        # On first load, try to pull latest from git
        if not _chat_initialized:
            _chat_initialized = True
            try:
                git_pull_on_startup()
            except Exception as e:
                log.warning(f"Git pull on chat init failed: {e}")
        
        if os.path.exists(CHAT_MESSAGES_FILE):
            with open(CHAT_MESSAGES_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
    except Exception as e:
        log.error(f"Error loading chat messages: {e}")
    return []

def save_chat_messages(messages):
    """Save chat messages to file."""
    try:
        # Keep only last MAX_CHAT_MESSAGES
        messages = messages[-MAX_CHAT_MESSAGES:]
        with open(CHAT_MESSAGES_FILE, 'w', encoding='utf-8') as f:
            json.dump(messages, f, ensure_ascii=False, indent=2)
    except Exception as e:
        log.error(f"Error saving chat messages: {e}")

@app.route('/api/chat/messages', methods=['GET'])
def get_chat_messages():
    """Get chat messages, optionally after a specific timestamp."""
    try:
        # HIGH-LOAD OPTIMIZATION: Cache chat messages for 3 seconds
        after = request.args.get('after', '')
        limit = min(int(request.args.get('limit', 100)), 500)
        cache_key = f'chat_messages_{after}_{limit}'
        
        cached = RESPONSE_CACHE.get(cache_key)
        if cached:
            response = jsonify(cached)
            response.headers['Cache-Control'] = 'public, max-age=3'
            response.headers['X-Cache'] = 'HIT'
            return response
        
        messages = load_chat_messages()
        
        # Optional: get only messages after timestamp
        if after:
            try:
                after_ts = float(after)
                messages = [m for m in messages if m.get('timestamp', 0) > after_ts]
            except:
                pass
        
        # Return last N messages by default
        messages = messages[-limit:]
        
        result = {
            'success': True,
            'messages': messages,
            'count': len(messages)
        }
        
        # Cache for 3 seconds
        RESPONSE_CACHE.set(cache_key, result, ttl=3)
        
        response = jsonify(result)
        response.headers['Cache-Control'] = 'public, max-age=3'
        response.headers['X-Cache'] = 'MISS'
        return response
    except Exception as e:
        log.error(f"Error getting chat messages: {e}")
        return jsonify({'error': str(e)}), 500

# File to store registered nicknames with device IDs
CHAT_NICKNAMES_FILE = os.path.join(PERSISTENT_DATA_DIR, 'chat_nicknames.json') if PERSISTENT_DATA_DIR and os.path.isdir(PERSISTENT_DATA_DIR) else 'chat_nicknames.json'
CHAT_BANNED_USERS_FILE = os.path.join(PERSISTENT_DATA_DIR, 'chat_banned_users.json') if PERSISTENT_DATA_DIR and os.path.isdir(PERSISTENT_DATA_DIR) else 'chat_banned_users.json'

def load_chat_nicknames():
    """Load registered chat nicknames."""
    try:
        if os.path.exists(CHAT_NICKNAMES_FILE):
            with open(CHAT_NICKNAMES_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
    except Exception as e:
        log.error(f"Error loading chat nicknames: {e}")
    return {}

def save_chat_nicknames(nicknames):
    """Save registered chat nicknames."""
    try:
        with open(CHAT_NICKNAMES_FILE, 'w', encoding='utf-8') as f:
            json.dump(nicknames, f, ensure_ascii=False, indent=2)
    except Exception as e:
        log.error(f"Error saving chat nicknames: {e}")

def load_banned_users():
    """Load banned users list."""
    try:
        if os.path.exists(CHAT_BANNED_USERS_FILE):
            with open(CHAT_BANNED_USERS_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
    except Exception as e:
        log.error(f"Error loading banned users: {e}")
    return {}

def save_banned_users(banned):
    """Save banned users list."""
    try:
        with open(CHAT_BANNED_USERS_FILE, 'w', encoding='utf-8') as f:
            json.dump(banned, f, ensure_ascii=False, indent=2)
    except Exception as e:
        log.error(f"Error saving banned users: {e}")

def is_user_banned(device_id):
    """Check if device is banned."""
    if not device_id:
        return False
    banned = load_banned_users()
    return device_id in banned

def is_nickname_forbidden(nickname):
    """Check if nickname contains forbidden words."""
    forbidden = ['neptun', 'нептун', 'neptune', 'admin', 'адмін', 'moderator', 'модератор', 'support', 'підтримка']
    nickname_lower = nickname.lower()
    for word in forbidden:
        if word in nickname_lower:
            return True
    return False

@app.route('/api/chat/check-nickname', methods=['POST'])
def check_chat_nickname():
    """Check if nickname is available and valid."""
    try:
        data = request.get_json()
        nickname = data.get('nickname', '').strip()
        device_id = data.get('deviceId', '')
        
        if not nickname:
            return jsonify({'available': False, 'error': 'Нікнейм не може бути порожнім'}), 400
        
        if len(nickname) < 3:
            return jsonify({'available': False, 'error': 'Нікнейм має бути мінімум 3 символи'}), 400
            
        if len(nickname) > 20:
            return jsonify({'available': False, 'error': 'Нікнейм не може бути довше 20 символів'}), 400
        
        # Check forbidden words
        if is_nickname_forbidden(nickname):
            return jsonify({'available': False, 'error': 'Цей нікнейм заборонено'}), 400
        
        # Load existing nicknames
        nicknames = load_chat_nicknames()
        nickname_lower = nickname.lower()
        
        # Check if nickname is taken by someone else
        for existing_nickname, owner_device_id in nicknames.items():
            if existing_nickname.lower() == nickname_lower:
                # Allow if same device
                if owner_device_id == device_id:
                    return jsonify({'available': True, 'message': 'Це ваш поточний нік'})
                else:
                    return jsonify({'available': False, 'error': 'Цей нікнейм вже зайнятий'}), 400
        
        return jsonify({'available': True})
    except Exception as e:
        log.error(f"Error checking nickname: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/chat/register-nickname', methods=['POST'])
def register_chat_nickname():
    """Register a nickname for a device."""
    try:
        data = request.get_json()
        nickname = data.get('nickname', '').strip()
        device_id = data.get('deviceId', '')
        
        if not nickname or not device_id:
            return jsonify({'success': False, 'error': 'Missing nickname or deviceId'}), 400
        
        if len(nickname) < 3 or len(nickname) > 20:
            return jsonify({'success': False, 'error': 'Нікнейм має бути 3-20 символів'}), 400
        
        # Check forbidden words
        if is_nickname_forbidden(nickname):
            return jsonify({'success': False, 'error': 'Цей нікнейм заборонено'}), 400
        
        # Load existing nicknames
        nicknames = load_chat_nicknames()
        nickname_lower = nickname.lower()
        
        # Check if nickname is taken by someone else
        for existing_nickname, owner_device_id in nicknames.items():
            if existing_nickname.lower() == nickname_lower and owner_device_id != device_id:
                return jsonify({'success': False, 'error': 'Цей нікнейм вже зайнятий'}), 400
        
        # Remove any previous nickname for this device
        nicknames = {k: v for k, v in nicknames.items() if v != device_id}
        
        # Register new nickname
        nicknames[nickname] = device_id
        save_chat_nicknames(nicknames)
        
        log.info(f"Registered chat nickname: {nickname} for device {device_id[:20]}...")
        
        return jsonify({'success': True, 'nickname': nickname})
    except Exception as e:
        log.error(f"Error registering nickname: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/chat/send', methods=['POST'])
def send_chat_message():
    """Send a new chat message."""
    try:
        data = request.get_json()
        
        user_id = data.get('userId', '')
        device_id = data.get('deviceId', '')
        message = data.get('message', '').strip()
        reply_to = data.get('replyTo')  # Optional reply to message id
        
        if not user_id or not message:
            return jsonify({'error': 'Missing userId or message'}), 400
        
        # Check if user is banned
        if is_user_banned(device_id):
            return jsonify({'error': 'Ви заблоковані в чаті', 'banned': True}), 403
        
        # Validate nickname ownership if device_id provided
        if device_id:
            nicknames = load_chat_nicknames()
            registered_device = nicknames.get(user_id)
            if registered_device and registered_device != device_id:
                return jsonify({'error': 'Цей нікнейм належить іншому користувачу'}), 403
        
        # Check forbidden nickname
        if is_nickname_forbidden(user_id):
            return jsonify({'error': 'Заборонений нікнейм'}), 400
        
        # Sanitize message (basic)
        if len(message) > 1000:
            message = message[:1000]
        
        # AI Moderation - check message for spam, profanity, etc.
        moderation = moderate_chat_message_with_ai(message, user_id)
        if moderation and not moderation.get('is_safe', True):
            log.warning(f"AI moderation blocked message from {user_id}: {moderation.get('reason')}")
            return jsonify({
                'error': moderation.get('reason', 'Повідомлення заблоковано модерацією'),
                'category': moderation.get('category'),
                'suggestion': moderation.get('suggestion')
            }), 403
        
        # Create message object
        kyiv_tz = pytz.timezone('Europe/Kiev')
        now = datetime.now(kyiv_tz)
        
        # Check if sender is a moderator
        sender_is_moderator = is_chat_moderator(device_id)
        
        new_message = {
            'id': str(uuid.uuid4()),
            'userId': user_id,
            'deviceId': device_id,  # Store deviceId for isMe detection after nickname change
            'message': message,
            'timestamp': now.timestamp(),
            'time': now.strftime('%H:%M'),
            'date': now.strftime('%d.%m.%Y'),
            'isModerator': sender_is_moderator  # Show moderator badge to other users
        }
        
        # Add reply reference if provided
        if reply_to:
            messages = load_chat_messages()
            # Find the original message being replied to
            original_msg = next((m for m in messages if m.get('id') == reply_to), None)
            if original_msg:
                new_message['replyTo'] = {
                    'id': original_msg.get('id'),
                    'userId': original_msg.get('userId'),
                    'message': original_msg.get('message', '')[:100]  # Truncate preview
                }
        
        # Load, append, save
        messages = load_chat_messages()
        messages.append(new_message)
        save_chat_messages(messages)
        
        # Trigger git sync for persistence
        try:
            maybe_git_autocommit()
        except Exception as git_err:
            log.warning(f"Git autocommit failed for chat: {git_err}")
        
        log.info(f"Chat message from {user_id[:20]}: {message[:50]}...")
        
        return jsonify({
            'success': True,
            'message': new_message
        })
    except Exception as e:
        log.error(f"Error sending chat message: {e}")
        return jsonify({'error': str(e)}), 500

# Moderator secret for message deletion
MODERATOR_SECRET = '99446626'

# List of moderator device IDs
CHAT_MODERATORS_FILE = os.path.join(PERSISTENT_DATA_DIR, 'chat_moderators.json') if PERSISTENT_DATA_DIR and os.path.isdir(PERSISTENT_DATA_DIR) else 'chat_moderators.json'

def load_chat_moderators():
    """Load list of moderator device IDs."""
    try:
        if os.path.exists(CHAT_MODERATORS_FILE):
            with open(CHAT_MODERATORS_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
    except Exception as e:
        log.error(f"Error loading chat moderators: {e}")
    return []

def save_chat_moderators(moderators):
    """Save list of moderator device IDs."""
    try:
        with open(CHAT_MODERATORS_FILE, 'w', encoding='utf-8') as f:
            json.dump(moderators, f, ensure_ascii=False, indent=2)
    except Exception as e:
        log.error(f"Error saving chat moderators: {e}")

def is_chat_moderator(device_id):
    """Check if device is a chat moderator."""
    if not device_id:
        return False
    moderators = load_chat_moderators()
    return device_id in moderators

@app.route('/api/chat/message/<message_id>', methods=['DELETE'])
def delete_chat_message(message_id):
    """Delete a chat message (moderator only)."""
    try:
        data = request.get_json() or {}
        device_id = data.get('deviceId', '')
        is_moderator = data.get('isModerator', False)
        
        messages = load_chat_messages()
        
        # Find the message
        message_to_delete = next((m for m in messages if m.get('id') == message_id), None)
        
        if not message_to_delete:
            return jsonify({'error': 'Повідомлення не знайдено'}), 404
        
        # Check permissions - either moderator or message owner
        if is_moderator:
            # Moderators can delete any message
            pass
        elif device_id:
            # Regular users can only delete their own messages
            nicknames = load_chat_nicknames()
            message_user = message_to_delete.get('userId')
            user_device = nicknames.get(message_user)
            if user_device != device_id:
                return jsonify({'error': 'Немає прав для видалення'}), 403
        else:
            return jsonify({'error': 'Немає прав для видалення'}), 403
        
        # Remove the message
        messages = [m for m in messages if m.get('id') != message_id]
        save_chat_messages(messages)
        
        log.info(f"Chat message {message_id} deleted by {'moderator' if is_moderator else device_id[:20]}")
        
        return jsonify({
            'success': True,
            'message': 'Повідомлення видалено'
        })
    except Exception as e:
        log.error(f"Error deleting chat message: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/chat/ban-user', methods=['POST'])
def ban_chat_user():
    """Ban a user from chat (moderator only)."""
    try:
        data = request.get_json() or {}
        target_nickname = data.get('nickname', '')
        is_moderator = data.get('isModerator', False)
        reason = data.get('reason', 'Порушення правил чату')
        
        if not is_moderator:
            return jsonify({'error': 'Тільки модератори можуть блокувати'}), 403
        
        if not target_nickname:
            return jsonify({'error': 'Вкажіть нікнейм'}), 400
        
        # Find device ID for this nickname
        nicknames = load_chat_nicknames()
        target_device_id = nicknames.get(target_nickname)
        
        if not target_device_id:
            return jsonify({'error': 'Користувача не знайдено'}), 404
        
        # Add to banned list
        banned = load_banned_users()
        kyiv_tz = pytz.timezone('Europe/Kiev')
        now = datetime.now(kyiv_tz)
        
        banned[target_device_id] = {
            'nickname': target_nickname,
            'reason': reason,
            'bannedAt': now.isoformat(),
            'bannedAtTimestamp': now.timestamp()
        }
        save_banned_users(banned)
        
        log.info(f"User banned: {target_nickname} (device: {target_device_id[:20]}...) - Reason: {reason}")
        
        return jsonify({
            'success': True,
            'message': f'Користувач {target_nickname} заблокований'
        })
    except Exception as e:
        log.error(f"Error banning user: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/chat/unban-user', methods=['POST'])
def unban_chat_user():
    """Unban a user from chat (moderator only)."""
    try:
        data = request.get_json() or {}
        target_nickname = data.get('nickname', '')
        is_moderator = data.get('isModerator', False)
        
        if not is_moderator:
            return jsonify({'error': 'Тільки модератори можуть розблоковувати'}), 403
        
        if not target_nickname:
            return jsonify({'error': 'Вкажіть нікнейм'}), 400
        
        # Find device ID for this nickname
        nicknames = load_chat_nicknames()
        target_device_id = nicknames.get(target_nickname)
        
        # Remove from banned list (check both by device and nickname)
        banned = load_banned_users()
        removed = False
        
        if target_device_id and target_device_id in banned:
            del banned[target_device_id]
            removed = True
        
        # Also check by nickname in case device ID changed
        for device_id, info in list(banned.items()):
            if info.get('nickname') == target_nickname:
                del banned[device_id]
                removed = True
        
        if not removed:
            return jsonify({'error': 'Користувач не заблокований'}), 404
        
        save_banned_users(banned)
        log.info(f"User unbanned: {target_nickname}")
        
        return jsonify({
            'success': True,
            'message': f'Користувач {target_nickname} розблокований'
        })
    except Exception as e:
        log.error(f"Error unbanning user: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/chat/check-ban', methods=['POST'])
def check_user_ban():
    """Check if current user is banned."""
    try:
        data = request.get_json() or {}
        device_id = data.get('deviceId', '')
        
        if not device_id:
            return jsonify({'banned': False})
        
        banned = load_banned_users()
        ban_info = banned.get(device_id)
        
        if ban_info:
            return jsonify({
                'banned': True,
                'reason': ban_info.get('reason', 'Порушення правил'),
                'bannedAt': ban_info.get('bannedAt', '')
            })
        
        return jsonify({'banned': False})
    except Exception as e:
        log.error(f"Error checking ban: {e}")
        return jsonify({'banned': False})

@app.route('/api/chat/banned-users', methods=['GET'])
def get_banned_users():
    """Get list of banned users (moderator only)."""
    try:
        # Check moderator via query param (simple check)
        is_mod = request.args.get('isModerator', 'false').lower() == 'true'
        if not is_mod:
            return jsonify({'error': 'Доступ заборонено'}), 403
        
        banned = load_banned_users()
        users = []
        for device_id, info in banned.items():
            users.append({
                'deviceId': device_id[:20] + '...',
                'nickname': info.get('nickname', 'Unknown'),
                'reason': info.get('reason', ''),
                'bannedAt': info.get('bannedAt', '')
            })
        
        return jsonify({'users': users, 'count': len(users)})
    except Exception as e:
        log.error(f"Error getting banned users: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/chat/add-moderator', methods=['POST'])
def add_chat_moderator():
    """Add a device as chat moderator (requires admin secret)."""
    try:
        data = request.get_json() or {}
        secret = data.get('secret', '')
        device_id = data.get('deviceId', '')
        
        if secret != MODERATOR_SECRET:
            return jsonify({'error': 'Невірний секрет'}), 403
        
        if not device_id:
            return jsonify({'error': 'deviceId обовʼязковий'}), 400
        
        moderators = load_chat_moderators()
        if device_id not in moderators:
            moderators.append(device_id)
            save_chat_moderators(moderators)
            log.info(f"Added chat moderator: {device_id[:20]}...")
        
        return jsonify({'success': True, 'message': 'Модератора додано'})
    except Exception as e:
        log.error(f"Error adding moderator: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/chat/remove-moderator', methods=['POST'])
def remove_chat_moderator():
    """Remove a device from chat moderators (requires admin secret)."""
    try:
        data = request.get_json() or {}
        secret = data.get('secret', '')
        device_id = data.get('deviceId', '')
        
        if secret != MODERATOR_SECRET:
            return jsonify({'error': 'Невірний секрет'}), 403
        
        if not device_id:
            return jsonify({'error': 'deviceId обовʼязковий'}), 400
        
        moderators = load_chat_moderators()
        if device_id in moderators:
            moderators.remove(device_id)
            save_chat_moderators(moderators)
            log.info(f"Removed chat moderator: {device_id[:20]}...")
        
        return jsonify({'success': True, 'message': 'Модератора видалено'})
    except Exception as e:
        log.error(f"Error removing moderator: {e}")
        return jsonify({'error': str(e)}), 500


@app.route('/api/chat/user-profile', methods=['POST'])
def get_chat_user_profile():
    """Get user profile info - basic info for all, detailed for moderators."""
    try:
        data = request.get_json() or {}
        requester_device_id = data.get('requesterDeviceId', '')
        target_device_id = data.get('targetDeviceId', '')
        target_user_id = data.get('targetUserId', '')
        
        log.info(f"Profile request: requester={requester_device_id[:20] if requester_device_id else 'none'}..., target_user={target_user_id}")
        
        # Check if requester is moderator
        is_requester_mod = is_chat_moderator(requester_device_id)
        log.info(f"Requester is moderator: {is_requester_mod}")
        
        # Find device_id from userId if not provided
        if not target_device_id and target_user_id:
            nicknames = load_chat_nicknames()
            target_device_id = nicknames.get(target_user_id, '')
            log.info(f"Lookup nickname '{target_user_id}' -> device: {target_device_id[:20] if target_device_id else 'NOT_FOUND'}...")
        
        # Check if target is moderator
        is_target_mod = is_chat_moderator(target_device_id) if target_device_id else False
        
        # Check if target is banned
        is_banned = is_user_banned(target_device_id) if target_device_id else False
        
        # Basic response for all users
        response_data = {
            'userId': target_user_id,
            'isModerator': is_target_mod,
            'isBanned': is_banned,
        }
        
        # If requester is moderator - show more details
        if is_requester_mod and target_device_id:
            # Load device data from device_store
            devices = device_store._load()
            device_data = devices.get(target_device_id, {})
            
            # Get regions from device data
            regions = device_data.get('regions', [])
            log.info(f"Found regions for device: {regions}")
            
            response_data['deviceId'] = target_device_id[:20] + '...' if len(target_device_id) > 20 else target_device_id
            response_data['regions'] = regions
            response_data['lastSeen'] = device_data.get('last_seen', '')
        else:
            # For regular users - only basic info
            response_data['regions'] = []
            response_data['message'] = 'Детальна інформація доступна тільки модераторам'
        
        return jsonify(response_data)
    except Exception as e:
        log.error(f"Error getting user profile: {e}")
        return jsonify({'error': str(e)}), 500


# ============= PUSH NOTIFICATIONS FOR ALARMS =============

# Store previous alarm state to detect changes
_previous_alarms = {}

def check_alarm_changes():
    """Background task to check for alarm changes and send notifications."""
    global _previous_alarms
    
    if not firebase_initialized:
        return
    
    try:
        from firebase_admin import messaging
        
        # Fetch current alarms
        response = http_requests.get(
            f'{ALARM_API_BASE}/alerts',
            headers={'Authorization': ALARM_API_KEY},
            timeout=8
        )
        
        if not response.ok:
            return
        
        data = response.json()
        current_alarms = {}
        
        # Build current alarm state by region name
        for region in data:
            region_name = region.get('regionName', '')
            active_alerts = region.get('activeAlerts', [])
            if active_alerts:
                current_alarms[region_name] = active_alerts
        
        # Compare with previous state
        if _previous_alarms:
            # Check for new alarms (started)
            for region, alerts in current_alarms.items():
                if region not in _previous_alarms:
                    # New alarm started
                    _send_alarm_notification(region, alerts, 'started')
            
            # Check for ended alarms
            for region, alerts in _previous_alarms.items():
                if region not in current_alarms:
                    # Alarm ended
                    _send_alarm_notification(region, alerts, 'ended')
        
        # Update previous state
        _previous_alarms = current_alarms
        
    except Exception as e:
        log.error(f"Error checking alarm changes: {e}")

def _send_alarm_notification(region, alerts, status):
    """Send push notification for alarm change."""
    try:
        from firebase_admin import messaging
        
        # Get alert types
        alert_types = [alert.get('type', '') for alert in alerts]
        
        # Determine criticality
        critical_types = ['Повітряна тривога', 'Ракетна небезпека', 'Хімічна загроза']
        is_critical = any(t in critical_types for t in alert_types)
        
        # Build notification message
        if status == 'started':
            emoji = '🚨' if is_critical else '⚠️'
            title = f'{emoji} Повітряна тривога!'
            body = f'{region}: {", ".join(alert_types)}'
        else:
            emoji = '✅'
            title = f'{emoji} Відбій тривоги'
            body = f'{region}: тривога закінчена'
        
        # Get devices subscribed to this region
        devices = device_store.get_devices_for_region(region)
        
        if not devices:
            return
        
        # Send to all subscribed devices
        messages = []
        for device in devices:
            if device.get('token'):
                messages.append(messaging.Message(
                    notification=messaging.Notification(
                        title=title,
                        body=body,
                    ),
                    data={
                        'type': 'rocket' if is_critical else 'drone',
                        'region': region,
                        'status': status,
                    },
                    token=device['token'],
                    android=messaging.AndroidConfig(
                        priority='high' if is_critical else 'normal',
                        notification=messaging.AndroidNotification(
                            channel_id='critical_alerts' if is_critical else 'normal_alerts',
                            sound='default',
                        ),
                    ),
                    apns=messaging.APNSConfig(
                        payload=messaging.APNSPayload(
                            aps=messaging.Aps(
                                sound='default',
                                badge=1,
                            ),
                        ),
                    ),
                ))
        
        if messages:
            # Send batch
            response = messaging.send_all(messages)
            log.info(f"Sent {response.success_count} notifications for {region} ({status})")
            
    except Exception as e:
        log.error(f"Error sending alarm notification: {e}")

# Background thread for monitoring alarms
def _alarm_monitor_thread():
    """Background thread that checks for alarm changes every 30 seconds."""
    gc_counter = 0
    while True:
        try:
            check_alarm_changes()
            
            # MEMORY OPTIMIZATION: Force garbage collection every 5 minutes
            gc_counter += 1
            if gc_counter >= 10:  # 10 * 30 sec = 5 minutes
                gc.collect()
                gc_counter = 0
                
        except Exception as e:
            log.error(f"Alarm monitor thread error: {e}")
        time.sleep(30)  # Check every 30 seconds

# Start alarm monitoring thread
# DISABLED: Using monitor_alarms() instead which has better deduplication logic
# _alarm_monitor = threading.Thread(target=_alarm_monitor_thread, daemon=True)
# _alarm_monitor.start()
log.info("Old alarm monitoring thread DISABLED - using monitor_alarms() instead")


@app.route('/api/stats')
def get_alarm_stats():
    """Get alarm statistics for a region."""
    try:
        region = request.args.get('region', 'Дніпропетровська')
        
        # Load messages from file to calculate stats
        messages = []
        try:
            with open(MESSAGES_FILE, 'r', encoding='utf-8') as f:
                all_messages = json.load(f)
                # Filter by region if needed
                for msg in all_messages:
                    msg_region = msg.get('region', '') or msg.get('location', '')
                    if region.lower() in msg_region.lower():
                        messages.append(msg)
        except FileNotFoundError:
            pass
        
        # Calculate stats
        now = datetime.now(pytz.timezone('Europe/Kyiv'))
        today_start = now.replace(hour=0, minute=0, second=0, microsecond=0)
        week_start = today_start - timedelta(days=7)
        month_start = today_start - timedelta(days=30)
        
        today_count = 0
        week_count = 0
        month_count = 0
        durations = []
        
        for msg in messages:
            try:
                timestamp = msg.get('timestamp', '')
                msg_time = datetime.fromisoformat(timestamp.replace('Z', '+00:00'))
                if msg_time.tzinfo is None:
                    msg_time = pytz.timezone('Europe/Kyiv').localize(msg_time)
                
                if msg_time >= today_start:
                    today_count += 1
                if msg_time >= week_start:
                    week_count += 1
                if msg_time >= month_start:
                    month_count += 1
                    
            except (ValueError, TypeError):
                continue
        
        # Average alarm duration (rough estimate based on message pairs)
        avg_duration = 25  # Default 25 min if no data
        
        return jsonify({
            'region': region,
            'today_alarms': today_count,
            'week_alarms': week_count,
            'month_alarms': month_count,
            'avg_duration_min': avg_duration,
        })
    except Exception as e:
        log.error(f"Error getting stats: {e}")
        return jsonify({
            'today_alarms': 0,
            'week_alarms': 0,
            'month_alarms': 0,
            'avg_duration_min': 0,
        })

# =============================================================================
# DEBUG: Route Patterns Viewer
# =============================================================================
@app.route('/api/ai/route-patterns')
def api_route_patterns():
    """View AI learned route patterns"""
    try:
        patterns = _load_route_patterns()
        return jsonify({
            'status': 'ok',
            'file': ROUTE_PATTERNS_FILE,
            'patterns_count': len(patterns.get('patterns', {})),
            'historical_routes_count': len(patterns.get('historical_routes', [])),
            'ai_corrections_count': len(patterns.get('ai_corrections', [])),
            'last_updated': patterns.get('last_updated'),
            'data': patterns
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500


if __name__ == '__main__':
    # Local / container direct run (not needed if a WSGI server like gunicorn is used)
    port = int(os.getenv('PORT', '5000'))
    host = os.getenv('HOST', '0.0.0.0')
    log.info(f'Launching Flask app on {host}:{port}')
    # Eager start (still guarded) so that fetch begins even without first HTTP request locally
    try:
        _init_background()
    except Exception:
        pass
    app.run(host=host, port=port, debug=False)